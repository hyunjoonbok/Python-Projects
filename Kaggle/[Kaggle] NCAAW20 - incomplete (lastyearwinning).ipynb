{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "%matplotlib inline\n",
    "import copy\n",
    "import datetime\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "#import plotly.offline as py\n",
    "#py.init_notebook_mode(connected=True)\n",
    "#import plotly.graph_objs as go\n",
    "#import plotly.tools as tls\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "#from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, roc_auc_score, log_loss, classification_report, confusion_matrix\n",
    "import json\n",
    "import ast\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\bokhy\\\\Desktop\\\\kaggle\\\\google-cloud-ncaa-march-madness-2020-division-1-womens-tournament\\\\'\n",
    "SeasonCompactResults = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WRegularSeasonCompactResults.csv'))\n",
    "SeasonDetailedResults = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WRegularSeasonDetailedResults.csv'))\n",
    "TourneyCompactResults = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WNCAATourneyCompactResults.csv'))\n",
    "TourneyDetailedResults = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WNCAATourneyDetailedResults.csv'))\n",
    "TourneySeeds = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WNCAATourneySeeds.csv'))\n",
    "GameCities = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WGameCities.csv'))\n",
    "Cities = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\Cities.csv'))\n",
    "Teams = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WTeams.csv'))\n",
    "Conferences = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WTeamConferences.csv'))\n",
    "Seasons = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WSeasons.csv'))\n",
    "TourneySlots = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WNCAATourneySlots.csv'))\n",
    "\n",
    "test = pd.read_csv(os.path.join(path, 'WSampleSubmissionStage1_2020.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format ID\n",
    "test = test.drop(['Pred'], axis=1)\n",
    "test['Season'] = test['ID'].apply(lambda x: int(x.split('_')[0]))\n",
    "test['WTeamID'] = test['ID'].apply(lambda x: int(x.split('_')[1]))\n",
    "test['LTeamID'] = test['ID'].apply(lambda x: int(x.split('_')[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>WFGA3</th>\n",
       "      <th>WFTM</th>\n",
       "      <th>WFTA</th>\n",
       "      <th>WOR</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WAst</th>\n",
       "      <th>WTO</th>\n",
       "      <th>WStl</th>\n",
       "      <th>WBlk</th>\n",
       "      <th>WPF</th>\n",
       "      <th>LFGM</th>\n",
       "      <th>LFGA</th>\n",
       "      <th>LFGM3</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3103</td>\n",
       "      <td>63</td>\n",
       "      <td>3237</td>\n",
       "      <td>49</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3104</td>\n",
       "      <td>73</td>\n",
       "      <td>3399</td>\n",
       "      <td>68</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3110</td>\n",
       "      <td>71</td>\n",
       "      <td>3224</td>\n",
       "      <td>59</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3111</td>\n",
       "      <td>63</td>\n",
       "      <td>3267</td>\n",
       "      <td>58</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3119</td>\n",
       "      <td>74</td>\n",
       "      <td>3447</td>\n",
       "      <td>70</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>74</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>74</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
       "0    2010      11     3103      63     3237      49    H      0    23    54   \n",
       "1    2010      11     3104      73     3399      68    N      0    26    62   \n",
       "2    2010      11     3110      71     3224      59    A      0    29    62   \n",
       "3    2010      11     3111      63     3267      58    A      0    27    52   \n",
       "4    2010      11     3119      74     3447      70    H      1    30    74   \n",
       "\n",
       "   WFGM3  WFGA3  WFTM  WFTA  WOR  WDR  WAst  WTO  WStl  WBlk  WPF  LFGM  LFGA  \\\n",
       "0      5      9    12    19   10   26    14   18     7     0   15    20    54   \n",
       "1      5     12    16    28   16   31    15   20     5     2   25    25    63   \n",
       "2      6     15     7    12   14   23    18   13     6     2   17    19    58   \n",
       "3      4     11     5     9    6   40    14   27     5    10   18    18    74   \n",
       "4      7     20     7    11   14   33    18   11     5     3   18    25    74   \n",
       "\n",
       "   LFGM3  LFGA3  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF  \n",
       "0      3     13     6    10   11   27    11   23     7     6   19  \n",
       "1      4     21    14    27   14   26     7   20     4     2   27  \n",
       "2      2     14    19    23   17   23     8   15     6     0   15  \n",
       "3      6     26    16    25   22   22    15   11    14     5   14  \n",
       "4      9     17    11    21   21   32    12   14     4     2   14  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TourneyDetailedResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeasonDetailedResults_1 = SeasonDetailedResults[[\n",
    "    'Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc', 'NumOT', \n",
    "    'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', \n",
    "    'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeasonDetailedResults_2 = SeasonDetailedResults[[\n",
    "    'Season', 'DayNum', 'LTeamID', 'LScore', 'WTeamID', 'WScore', 'WLoc', 'NumOT', \n",
    "    'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF', \n",
    "    'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeasonDetailedResults_2.loc[SeasonDetailedResults_1['WLoc'] == 'H', 'WLoc'] = 'A'\n",
    "SeasonDetailedResults_2.loc[SeasonDetailedResults_1['WLoc'] == 'A', 'WLoc'] = 'H'\n",
    "SeasonDetailedResults_1.columns.values[6] = 'location'\n",
    "SeasonDetailedResults_2.columns.values[6] = 'location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeasonDetailedResults_1.columns = [x.replace('W','T1_').replace('L','T2_') for x in list(SeasonDetailedResults_1.columns)]\n",
    "SeasonDetailedResults_2.columns = [x.replace('L','T1_').replace('W','T2_') for x in list(SeasonDetailedResults_2.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>T1_TeamID</th>\n",
       "      <th>T1_Score</th>\n",
       "      <th>T2_TeamID</th>\n",
       "      <th>T2_Score</th>\n",
       "      <th>location</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>T1_FGM</th>\n",
       "      <th>T1_FGA</th>\n",
       "      <th>T1_FGM3</th>\n",
       "      <th>T1_FGA3</th>\n",
       "      <th>T1_FTM</th>\n",
       "      <th>T1_FTA</th>\n",
       "      <th>T1_OR</th>\n",
       "      <th>T1_DR</th>\n",
       "      <th>T1_Ast</th>\n",
       "      <th>T1_TO</th>\n",
       "      <th>T1_Stl</th>\n",
       "      <th>T1_Blk</th>\n",
       "      <th>T1_PF</th>\n",
       "      <th>T2_FGM</th>\n",
       "      <th>T2_FGA</th>\n",
       "      <th>T2_FGM3</th>\n",
       "      <th>T2_FGA3</th>\n",
       "      <th>T2_FTM</th>\n",
       "      <th>T2_FTA</th>\n",
       "      <th>T2_OR</th>\n",
       "      <th>T2_DR</th>\n",
       "      <th>T2_Ast</th>\n",
       "      <th>T2_TO</th>\n",
       "      <th>T2_Stl</th>\n",
       "      <th>T2_Blk</th>\n",
       "      <th>T2_PF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3103</td>\n",
       "      <td>63</td>\n",
       "      <td>3237</td>\n",
       "      <td>49</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3104</td>\n",
       "      <td>73</td>\n",
       "      <td>3399</td>\n",
       "      <td>68</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3110</td>\n",
       "      <td>71</td>\n",
       "      <td>3224</td>\n",
       "      <td>59</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3111</td>\n",
       "      <td>63</td>\n",
       "      <td>3267</td>\n",
       "      <td>58</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3119</td>\n",
       "      <td>74</td>\n",
       "      <td>3447</td>\n",
       "      <td>70</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>74</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>74</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  T1_TeamID  T1_Score  T2_TeamID  T2_Score location  NumOT  \\\n",
       "0    2010      11       3103        63       3237        49        H      0   \n",
       "1    2010      11       3104        73       3399        68        N      0   \n",
       "2    2010      11       3110        71       3224        59        A      0   \n",
       "3    2010      11       3111        63       3267        58        A      0   \n",
       "4    2010      11       3119        74       3447        70        H      1   \n",
       "\n",
       "   T1_FGM  T1_FGA  T1_FGM3  T1_FGA3  T1_FTM  T1_FTA  T1_OR  T1_DR  T1_Ast  \\\n",
       "0      23      54        5        9      12      19     10     26      14   \n",
       "1      26      62        5       12      16      28     16     31      15   \n",
       "2      29      62        6       15       7      12     14     23      18   \n",
       "3      27      52        4       11       5       9      6     40      14   \n",
       "4      30      74        7       20       7      11     14     33      18   \n",
       "\n",
       "   T1_TO  T1_Stl  T1_Blk  T1_PF  T2_FGM  T2_FGA  T2_FGM3  T2_FGA3  T2_FTM  \\\n",
       "0     18       7       0     15      20      54        3       13       6   \n",
       "1     20       5       2     25      25      63        4       21      14   \n",
       "2     13       6       2     17      19      58        2       14      19   \n",
       "3     27       5      10     18      18      74        6       26      16   \n",
       "4     11       5       3     18      25      74        9       17      11   \n",
       "\n",
       "   T2_FTA  T2_OR  T2_DR  T2_Ast  T2_TO  T2_Stl  T2_Blk  T2_PF  \n",
       "0      10     11     27      11     23       7       6     19  \n",
       "1      27     14     26       7     20       4       2     27  \n",
       "2      23     17     23       8     15       6       0     15  \n",
       "3      25     22     22      15     11      14       5     14  \n",
       "4      21     21     32      12     14       4       2     14  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SeasonDetailedResults_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeasonDetailedResults = pd.concat([SeasonDetailedResults_1, SeasonDetailedResults_2]).sort_values(by=['DayNum']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>T1_TeamID</th>\n",
       "      <th>T1_Score</th>\n",
       "      <th>T2_TeamID</th>\n",
       "      <th>T2_Score</th>\n",
       "      <th>location</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>T1_FGM</th>\n",
       "      <th>T1_FGA</th>\n",
       "      <th>T1_FGM3</th>\n",
       "      <th>T1_FGA3</th>\n",
       "      <th>T1_FTM</th>\n",
       "      <th>T1_FTA</th>\n",
       "      <th>T1_OR</th>\n",
       "      <th>T1_DR</th>\n",
       "      <th>T1_Ast</th>\n",
       "      <th>T1_TO</th>\n",
       "      <th>T1_Stl</th>\n",
       "      <th>T1_Blk</th>\n",
       "      <th>T1_PF</th>\n",
       "      <th>T2_FGM</th>\n",
       "      <th>T2_FGA</th>\n",
       "      <th>T2_FGM3</th>\n",
       "      <th>T2_FGA3</th>\n",
       "      <th>T2_FTM</th>\n",
       "      <th>T2_FTA</th>\n",
       "      <th>T2_OR</th>\n",
       "      <th>T2_DR</th>\n",
       "      <th>T2_Ast</th>\n",
       "      <th>T2_TO</th>\n",
       "      <th>T2_Stl</th>\n",
       "      <th>T2_Blk</th>\n",
       "      <th>T2_PF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>3113</td>\n",
       "      <td>81</td>\n",
       "      <td>3230</td>\n",
       "      <td>43</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>3442</td>\n",
       "      <td>64</td>\n",
       "      <td>3281</td>\n",
       "      <td>89</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>3189</td>\n",
       "      <td>69</td>\n",
       "      <td>3314</td>\n",
       "      <td>100</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>3201</td>\n",
       "      <td>73</td>\n",
       "      <td>3319</td>\n",
       "      <td>86</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>56</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>3453</td>\n",
       "      <td>55</td>\n",
       "      <td>3321</td>\n",
       "      <td>57</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  T1_TeamID  T1_Score  T2_TeamID  T2_Score location  NumOT  \\\n",
       "0    2019       1       3113        81       3230        43        H      0   \n",
       "1    2019       1       3442        64       3281        89        H      0   \n",
       "2    2019       1       3189        69       3314       100        H      0   \n",
       "3    2019       1       3201        73       3319        86        A      0   \n",
       "4    2019       1       3453        55       3321        57        H      0   \n",
       "\n",
       "   T1_FGM  T1_FGA  T1_FGM3  T1_FGA3  T1_FTM  T1_FTA  T1_OR  T1_DR  T1_Ast  \\\n",
       "0      29      65       10       28      13      23     19     39      23   \n",
       "1      17      59        4       20      26      33      6     26       3   \n",
       "2      27      58        1       12      14      22      7     26      12   \n",
       "3      28      71        5       20      12      17     16     15      12   \n",
       "4      20      50        8       14       7      11     13     28      17   \n",
       "\n",
       "   T1_TO  T1_Stl  T1_Blk  T1_PF  T2_FGM  T2_FGA  T2_FGM3  T2_FGA3  T2_FTM  \\\n",
       "0     19      11       8     20      17      66        3       17       6   \n",
       "1     10       6       1     19      33      71        9       27      14   \n",
       "2     23       7       1     20      35      67       11       24      19   \n",
       "3     14      17       1     16      32      56       15       20       7   \n",
       "4     21       9       1     18      19      53        5       19      14   \n",
       "\n",
       "   T2_FTA  T2_OR  T2_DR  T2_Ast  T2_TO  T2_Stl  T2_Blk  T2_PF  \n",
       "0      15     13     21       5     16      12       1     21  \n",
       "1      17     13     39      18     14       7       7     25  \n",
       "2      29     12     30      23     21      14       4     21  \n",
       "3       8      8     31      21     23       6       5     16  \n",
       "4      20      9     18       8     16      10       4     16  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SeasonDetailedResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>WFGA3</th>\n",
       "      <th>WFTM</th>\n",
       "      <th>WFTA</th>\n",
       "      <th>WOR</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WAst</th>\n",
       "      <th>WTO</th>\n",
       "      <th>WStl</th>\n",
       "      <th>WBlk</th>\n",
       "      <th>WPF</th>\n",
       "      <th>LFGM</th>\n",
       "      <th>LFGA</th>\n",
       "      <th>LFGM3</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>138</td>\n",
       "      <td>3124</td>\n",
       "      <td>69</td>\n",
       "      <td>3201</td>\n",
       "      <td>55</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>138</td>\n",
       "      <td>3173</td>\n",
       "      <td>67</td>\n",
       "      <td>3395</td>\n",
       "      <td>66</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>138</td>\n",
       "      <td>3181</td>\n",
       "      <td>72</td>\n",
       "      <td>3214</td>\n",
       "      <td>37</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>138</td>\n",
       "      <td>3199</td>\n",
       "      <td>75</td>\n",
       "      <td>3256</td>\n",
       "      <td>61</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>138</td>\n",
       "      <td>3207</td>\n",
       "      <td>62</td>\n",
       "      <td>3265</td>\n",
       "      <td>42</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
       "0    2010     138     3124      69     3201      55    N      0    28    57   \n",
       "1    2010     138     3173      67     3395      66    N      0    23    59   \n",
       "2    2010     138     3181      72     3214      37    H      0    26    57   \n",
       "3    2010     138     3199      75     3256      61    H      0    25    63   \n",
       "4    2010     138     3207      62     3265      42    N      0    24    68   \n",
       "\n",
       "   WFGM3  WFGA3  WFTM  WFTA  WOR  WDR  WAst  WTO  WStl  WBlk  WPF  LFGM  LFGA  \\\n",
       "0      1      5    12    19   13   24    22   12     6     2   12    21    61   \n",
       "1      9     26    12    19   13   34    13   16     3    10   14    22    73   \n",
       "2      4     13    16    22   13   34    15   11    10     7   11    15    56   \n",
       "3      3     15    22    26   20   27    13   17     8     3   21    21    62   \n",
       "4      8     25     6     8   20   29    16    8     5     5   18    13    60   \n",
       "\n",
       "   LFGM3  LFGA3  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF  \n",
       "0     10     34     3     5   17   19    12   18     4     1   18  \n",
       "1      8     27    14    15   18   26     8    8     8     6   22  \n",
       "2      4     15     3     8   10   21     4   16     6     4   20  \n",
       "3      2     20    17    22   16   21    13   16     5     4   24  \n",
       "4      5     26    11    17   16   22     9   10     3     4   12  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TourneyDetailedResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(630, 34)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TourneyDetailedResults.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneyDetailedResults_1 = TourneyDetailedResults[[\n",
    "    'Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc', 'NumOT', \n",
    "    'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', \n",
    "    'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneyDetailedResults_2 = TourneyDetailedResults[[\n",
    "    'Season', 'DayNum', 'LTeamID', 'LScore', 'WTeamID', 'WScore', 'WLoc', 'NumOT', \n",
    "    'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF', \n",
    "    'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneyDetailedResults_2.loc[TourneyDetailedResults_1['WLoc'] == 'H', 'WLoc'] = 'A'\n",
    "TourneyDetailedResults_2.loc[TourneyDetailedResults_1['WLoc'] == 'A', 'WLoc'] = 'H'\n",
    "TourneyDetailedResults_1.columns.values[6] = 'location'\n",
    "TourneyDetailedResults_2.columns.values[6] = 'location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneyDetailedResults_1.columns = [x.replace('W','T1_').replace('L','T2_') for x in list(TourneyDetailedResults_1.columns)]\n",
    "TourneyDetailedResults_2.columns = [x.replace('L','T1_').replace('W','T2_') for x in list(TourneyDetailedResults_2.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneyDetailedResults_1[\"result\"] = 1\n",
    "TourneyDetailedResults_2[\"result\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneyDetailedResults = pd.concat([TourneyDetailedResults_1, TourneyDetailedResults_2]).sort_values(by=['DayNum']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>T1_TeamID</th>\n",
       "      <th>T1_Score</th>\n",
       "      <th>T2_TeamID</th>\n",
       "      <th>T2_Score</th>\n",
       "      <th>location</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>T1_FGM</th>\n",
       "      <th>T1_FGA</th>\n",
       "      <th>T1_FGM3</th>\n",
       "      <th>T1_FGA3</th>\n",
       "      <th>T1_FTM</th>\n",
       "      <th>T1_FTA</th>\n",
       "      <th>T1_OR</th>\n",
       "      <th>T1_DR</th>\n",
       "      <th>T1_Ast</th>\n",
       "      <th>T1_TO</th>\n",
       "      <th>T1_Stl</th>\n",
       "      <th>T1_Blk</th>\n",
       "      <th>T1_PF</th>\n",
       "      <th>T2_FGM</th>\n",
       "      <th>T2_FGA</th>\n",
       "      <th>T2_FGM3</th>\n",
       "      <th>T2_FGA3</th>\n",
       "      <th>T2_FTM</th>\n",
       "      <th>T2_FTA</th>\n",
       "      <th>T2_OR</th>\n",
       "      <th>T2_DR</th>\n",
       "      <th>T2_Ast</th>\n",
       "      <th>T2_TO</th>\n",
       "      <th>T2_Stl</th>\n",
       "      <th>T2_Blk</th>\n",
       "      <th>T2_PF</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3125</td>\n",
       "      <td>52</td>\n",
       "      <td>3376</td>\n",
       "      <td>74</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3332</td>\n",
       "      <td>78</td>\n",
       "      <td>3340</td>\n",
       "      <td>40</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3281</td>\n",
       "      <td>77</td>\n",
       "      <td>3179</td>\n",
       "      <td>76</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>65</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3280</td>\n",
       "      <td>103</td>\n",
       "      <td>3380</td>\n",
       "      <td>46</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3276</td>\n",
       "      <td>84</td>\n",
       "      <td>3243</td>\n",
       "      <td>54</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  T1_TeamID  T1_Score  T2_TeamID  T2_Score location  NumOT  \\\n",
       "0    2019     137       3125        52       3376        74        N      0   \n",
       "1    2019     137       3332        78       3340        40        H      0   \n",
       "2    2019     137       3281        77       3179        76        N      1   \n",
       "3    2019     137       3280       103       3380        46        H      0   \n",
       "4    2019     137       3276        84       3243        54        N      0   \n",
       "\n",
       "   T1_FGM  T1_FGA  T1_FGM3  T1_FGA3  T1_FTM  T1_FTA  T1_OR  T1_DR  T1_Ast  \\\n",
       "0      18      52        7       25       9      11     10     12      11   \n",
       "1      29      63        8       23      12      15     20     30      17   \n",
       "2      27      58        9       25      14      16     11     26      15   \n",
       "3      36      68        3       13      28      37     17     34      13   \n",
       "4      35      63        5       13       9      14     17     33      22   \n",
       "\n",
       "   T1_TO  T1_Stl  T1_Blk  T1_PF  T2_FGM  T2_FGA  T2_FGM3  T2_FGA3  T2_FTM  \\\n",
       "0     17       3       2     13      31      56        5       15       7   \n",
       "1     12      16       2      8      12      49        8       28       8   \n",
       "2     19      10       5     16      28      65       12       26       8   \n",
       "3     13      17       3     12      15      55        5       16      11   \n",
       "4     21       9       2     17      20      55        7       22       7   \n",
       "\n",
       "   T2_FTA  T2_OR  T2_DR  T2_Ast  T2_TO  T2_Stl  T2_Blk  T2_PF  result  \n",
       "0      11     14     24      14     14       6       6     16       0  \n",
       "1      11      8     15      10     17       5       2     11       1  \n",
       "2      11     13     21      23     16       8       3     20       1  \n",
       "3      12      7     21       6     28       6       2     27       1  \n",
       "4      17      6     13      11     17      15       4     11       1  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TourneyDetailedResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260, 35)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TourneyDetailedResults.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeasonDetailedResults.loc[SeasonDetailedResults.location=='N','location'] = '0'\n",
    "SeasonDetailedResults.loc[SeasonDetailedResults.location=='H','location'] = '1'\n",
    "SeasonDetailedResults.loc[SeasonDetailedResults.location=='A','location'] = '-1'\n",
    "SeasonDetailedResults.location = SeasonDetailedResults.location.astype(int) \n",
    "SeasonDetailedResults['PointDiff'] = SeasonDetailedResults['T1_Score'] - SeasonDetailedResults['T2_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneyDetailedResults.loc[TourneyDetailedResults.location=='N','location'] = '0'\n",
    "TourneyDetailedResults.loc[TourneyDetailedResults.location=='H','location'] = '1'\n",
    "TourneyDetailedResults.loc[TourneyDetailedResults.location=='A','location'] = '-1'\n",
    "TourneyDetailedResults.location = TourneyDetailedResults.location.astype(int) \n",
    "TourneyDetailedResults['PointDiff'] = TourneyDetailedResults['T1_Score'] - TourneyDetailedResults['T2_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103164, 35)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SeasonDetailedResults.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260, 36)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TourneyDetailedResults.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Season Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxscore_cols = [\n",
    "        'T1_FGM', 'T1_FGA', 'T1_FGM3', 'T1_FGA3', 'T1_FTM', 'T1_FTA', 'T1_OR', 'T1_DR', 'T1_Ast', 'T1_TO', 'T1_Stl', 'T1_Blk', 'T1_PF', \n",
    "        'T2_FGM', 'T2_FGA', 'T2_FGM3', 'T2_FGA3', 'T2_FTM', 'T2_FTA', 'T2_OR', 'T2_DR', 'T2_Ast', 'T2_TO', 'T2_Stl', 'T2_Blk', 'T2_PF', \n",
    "        'PointDiff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeasonDetailedResults_Stat = SeasonDetailedResults.groupby(['Season', 'T1_TeamID'])[boxscore_cols].agg([np.mean]).reset_index()\n",
    "#SeasonDetailedResults_Stat = SeasonDetailedResults.groupby(['Season', 'T1_TeamID'])[boxscore_cols].agg(['median','mean','sum', 'count', 'var','std']).reset_index()\n",
    "SeasonDetailedResults_Stat.columns = [' '.join(col).strip() for col in SeasonDetailedResults_Stat.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>T1_TeamID</th>\n",
       "      <th>T1_FGM mean</th>\n",
       "      <th>T1_FGA mean</th>\n",
       "      <th>T1_FGM3 mean</th>\n",
       "      <th>T1_FGA3 mean</th>\n",
       "      <th>T1_FTM mean</th>\n",
       "      <th>T1_FTA mean</th>\n",
       "      <th>T1_OR mean</th>\n",
       "      <th>T1_DR mean</th>\n",
       "      <th>T1_Ast mean</th>\n",
       "      <th>T1_TO mean</th>\n",
       "      <th>T1_Stl mean</th>\n",
       "      <th>T1_Blk mean</th>\n",
       "      <th>T1_PF mean</th>\n",
       "      <th>T2_FGM mean</th>\n",
       "      <th>T2_FGA mean</th>\n",
       "      <th>T2_FGM3 mean</th>\n",
       "      <th>T2_FGA3 mean</th>\n",
       "      <th>T2_FTM mean</th>\n",
       "      <th>T2_FTA mean</th>\n",
       "      <th>T2_OR mean</th>\n",
       "      <th>T2_DR mean</th>\n",
       "      <th>T2_Ast mean</th>\n",
       "      <th>T2_TO mean</th>\n",
       "      <th>T2_Stl mean</th>\n",
       "      <th>T2_Blk mean</th>\n",
       "      <th>T2_PF mean</th>\n",
       "      <th>PointDiff mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>3102</td>\n",
       "      <td>19.142857</td>\n",
       "      <td>53.142857</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>16.071429</td>\n",
       "      <td>8.964286</td>\n",
       "      <td>13.214286</td>\n",
       "      <td>12.464286</td>\n",
       "      <td>19.535714</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>17.714286</td>\n",
       "      <td>6.035714</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>14.964286</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>56.392857</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>10.071429</td>\n",
       "      <td>14.892857</td>\n",
       "      <td>12.821429</td>\n",
       "      <td>23.857143</td>\n",
       "      <td>19.535714</td>\n",
       "      <td>14.392857</td>\n",
       "      <td>9.821429</td>\n",
       "      <td>5.035714</td>\n",
       "      <td>13.607143</td>\n",
       "      <td>-19.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>3103</td>\n",
       "      <td>22.233333</td>\n",
       "      <td>55.266667</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>12.466667</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>23.566667</td>\n",
       "      <td>13.433333</td>\n",
       "      <td>18.266667</td>\n",
       "      <td>8.033333</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>17.533333</td>\n",
       "      <td>20.966667</td>\n",
       "      <td>54.966667</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>15.166667</td>\n",
       "      <td>12.866667</td>\n",
       "      <td>18.833333</td>\n",
       "      <td>13.633333</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>9.233333</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>17.633333</td>\n",
       "      <td>2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>3104</td>\n",
       "      <td>24.724138</td>\n",
       "      <td>62.103448</td>\n",
       "      <td>4.344828</td>\n",
       "      <td>14.724138</td>\n",
       "      <td>10.344828</td>\n",
       "      <td>16.793103</td>\n",
       "      <td>14.482759</td>\n",
       "      <td>25.931034</td>\n",
       "      <td>13.103448</td>\n",
       "      <td>19.172414</td>\n",
       "      <td>7.379310</td>\n",
       "      <td>2.931034</td>\n",
       "      <td>20.413793</td>\n",
       "      <td>23.896552</td>\n",
       "      <td>60.137931</td>\n",
       "      <td>5.103448</td>\n",
       "      <td>16.517241</td>\n",
       "      <td>14.103448</td>\n",
       "      <td>21.965517</td>\n",
       "      <td>14.862069</td>\n",
       "      <td>26.482759</td>\n",
       "      <td>12.517241</td>\n",
       "      <td>19.241379</td>\n",
       "      <td>8.758621</td>\n",
       "      <td>3.586207</td>\n",
       "      <td>16.413793</td>\n",
       "      <td>-2.862069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>3105</td>\n",
       "      <td>20.370370</td>\n",
       "      <td>50.851852</td>\n",
       "      <td>3.037037</td>\n",
       "      <td>9.888889</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>23.370370</td>\n",
       "      <td>9.740741</td>\n",
       "      <td>25.037037</td>\n",
       "      <td>8.777778</td>\n",
       "      <td>5.148148</td>\n",
       "      <td>19.148148</td>\n",
       "      <td>22.777778</td>\n",
       "      <td>57.518519</td>\n",
       "      <td>3.740741</td>\n",
       "      <td>12.777778</td>\n",
       "      <td>15.444444</td>\n",
       "      <td>23.518519</td>\n",
       "      <td>15.185185</td>\n",
       "      <td>21.296296</td>\n",
       "      <td>13.481481</td>\n",
       "      <td>20.740741</td>\n",
       "      <td>12.222222</td>\n",
       "      <td>4.407407</td>\n",
       "      <td>20.962963</td>\n",
       "      <td>-3.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>3106</td>\n",
       "      <td>18.448276</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>2.689655</td>\n",
       "      <td>9.586207</td>\n",
       "      <td>15.551724</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>24.758621</td>\n",
       "      <td>11.482759</td>\n",
       "      <td>20.103448</td>\n",
       "      <td>8.034483</td>\n",
       "      <td>4.482759</td>\n",
       "      <td>22.068966</td>\n",
       "      <td>17.896552</td>\n",
       "      <td>50.689655</td>\n",
       "      <td>3.724138</td>\n",
       "      <td>11.827586</td>\n",
       "      <td>17.896552</td>\n",
       "      <td>26.655172</td>\n",
       "      <td>12.379310</td>\n",
       "      <td>23.413793</td>\n",
       "      <td>9.517241</td>\n",
       "      <td>18.310345</td>\n",
       "      <td>8.793103</td>\n",
       "      <td>3.965517</td>\n",
       "      <td>20.068966</td>\n",
       "      <td>-2.275862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  T1_TeamID  T1_FGM mean  T1_FGA mean  T1_FGM3 mean  T1_FGA3 mean  \\\n",
       "0    2010       3102    19.142857    53.142857      4.571429     16.071429   \n",
       "1    2010       3103    22.233333    55.266667      3.933333     12.466667   \n",
       "2    2010       3104    24.724138    62.103448      4.344828     14.724138   \n",
       "3    2010       3105    20.370370    50.851852      3.037037      9.888889   \n",
       "4    2010       3106    18.448276    53.000000      2.689655      9.586207   \n",
       "\n",
       "   T1_FTM mean  T1_FTA mean  T1_OR mean  T1_DR mean  T1_Ast mean  T1_TO mean  \\\n",
       "0     8.964286    13.214286   12.464286   19.535714    10.250000   17.714286   \n",
       "1    13.833333    19.600000   14.200000   23.566667    13.433333   18.266667   \n",
       "2    10.344828    16.793103   14.482759   25.931034    13.103448   19.172414   \n",
       "3    17.000000    24.333333   13.666667   23.370370     9.740741   25.037037   \n",
       "4    15.551724    24.000000   15.000000   24.758621    11.482759   20.103448   \n",
       "\n",
       "   T1_Stl mean  T1_Blk mean  T1_PF mean  T2_FGM mean  T2_FGA mean  \\\n",
       "0     6.035714     0.642857   14.964286    27.000000    56.392857   \n",
       "1     8.033333     2.400000   17.533333    20.966667    54.966667   \n",
       "2     7.379310     2.931034   20.413793    23.896552    60.137931   \n",
       "3     8.777778     5.148148   19.148148    22.777778    57.518519   \n",
       "4     8.034483     4.482759   22.068966    17.896552    50.689655   \n",
       "\n",
       "   T2_FGM3 mean  T2_FGA3 mean  T2_FTM mean  T2_FTA mean  T2_OR mean  \\\n",
       "0      7.714286     20.500000    10.071429    14.892857   12.821429   \n",
       "1      4.833333     15.166667    12.866667    18.833333   13.633333   \n",
       "2      5.103448     16.517241    14.103448    21.965517   14.862069   \n",
       "3      3.740741     12.777778    15.444444    23.518519   15.185185   \n",
       "4      3.724138     11.827586    17.896552    26.655172   12.379310   \n",
       "\n",
       "   T2_DR mean  T2_Ast mean  T2_TO mean  T2_Stl mean  T2_Blk mean  T2_PF mean  \\\n",
       "0   23.857143    19.535714   14.392857     9.821429     5.035714   13.607143   \n",
       "1   21.600000    11.700000   18.700000     9.233333     3.800000   17.633333   \n",
       "2   26.482759    12.517241   19.241379     8.758621     3.586207   16.413793   \n",
       "3   21.296296    13.481481   20.740741    12.222222     4.407407   20.962963   \n",
       "4   23.413793     9.517241   18.310345     8.793103     3.965517   20.068966   \n",
       "\n",
       "   PointDiff mean  \n",
       "0      -19.964286  \n",
       "1        2.600000  \n",
       "2       -2.862069  \n",
       "3       -3.962963  \n",
       "4       -2.275862  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SeasonDetailedResults_Stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeasonDetailedResults_Stat_T1 = SeasonDetailedResults_Stat.copy()\n",
    "SeasonDetailedResults_Stat_T2 = SeasonDetailedResults_Stat.copy()\n",
    "\n",
    "SeasonDetailedResults_Stat_T1.columns = [\"T1_\" + x.replace(\"T1_\",\"\").replace(\"T2_\",\"opponent_\") for x in list(SeasonDetailedResults_Stat_T1.columns)]\n",
    "SeasonDetailedResults_Stat_T2.columns = [\"T2_\" + x.replace(\"T1_\",\"\").replace(\"T2_\",\"opponent_\") for x in list(SeasonDetailedResults_Stat_T2.columns)]\n",
    "\n",
    "SeasonDetailedResults_Stat_T1.columns.values[0] = \"Season\"\n",
    "SeasonDetailedResults_Stat_T2.columns.values[0] = \"Season\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tournament Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneyDetailedResults = TourneyDetailedResults[['Season', 'DayNum', 'T1_TeamID', 'T1_Score', 'T2_TeamID' ,'T2_Score','result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneyDetailedResults = pd.merge(TourneyDetailedResults, SeasonDetailedResults_Stat_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n",
    "TourneyDetailedResults = pd.merge(TourneyDetailedResults, SeasonDetailedResults_Stat_T2, on = ['Season', 'T2_TeamID'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>T1_TeamID</th>\n",
       "      <th>T1_Score</th>\n",
       "      <th>T2_TeamID</th>\n",
       "      <th>T2_Score</th>\n",
       "      <th>result</th>\n",
       "      <th>T1_FGM mean</th>\n",
       "      <th>T1_FGA mean</th>\n",
       "      <th>T1_FGM3 mean</th>\n",
       "      <th>T1_FGA3 mean</th>\n",
       "      <th>T1_FTM mean</th>\n",
       "      <th>T1_FTA mean</th>\n",
       "      <th>T1_OR mean</th>\n",
       "      <th>T1_DR mean</th>\n",
       "      <th>T1_Ast mean</th>\n",
       "      <th>T1_TO mean</th>\n",
       "      <th>T1_Stl mean</th>\n",
       "      <th>T1_Blk mean</th>\n",
       "      <th>T1_PF mean</th>\n",
       "      <th>T1_opponent_FGM mean</th>\n",
       "      <th>T1_opponent_FGA mean</th>\n",
       "      <th>T1_opponent_FGM3 mean</th>\n",
       "      <th>T1_opponent_FGA3 mean</th>\n",
       "      <th>T1_opponent_FTM mean</th>\n",
       "      <th>T1_opponent_FTA mean</th>\n",
       "      <th>T1_opponent_OR mean</th>\n",
       "      <th>T1_opponent_DR mean</th>\n",
       "      <th>T1_opponent_Ast mean</th>\n",
       "      <th>T1_opponent_TO mean</th>\n",
       "      <th>T1_opponent_Stl mean</th>\n",
       "      <th>T1_opponent_Blk mean</th>\n",
       "      <th>T1_opponent_PF mean</th>\n",
       "      <th>T1_PointDiff mean</th>\n",
       "      <th>T2_FGM mean</th>\n",
       "      <th>T2_FGA mean</th>\n",
       "      <th>T2_FGM3 mean</th>\n",
       "      <th>T2_FGA3 mean</th>\n",
       "      <th>T2_FTM mean</th>\n",
       "      <th>T2_FTA mean</th>\n",
       "      <th>T2_OR mean</th>\n",
       "      <th>T2_DR mean</th>\n",
       "      <th>T2_Ast mean</th>\n",
       "      <th>T2_TO mean</th>\n",
       "      <th>T2_Stl mean</th>\n",
       "      <th>T2_Blk mean</th>\n",
       "      <th>T2_PF mean</th>\n",
       "      <th>T2_opponent_FGM mean</th>\n",
       "      <th>T2_opponent_FGA mean</th>\n",
       "      <th>T2_opponent_FGM3 mean</th>\n",
       "      <th>T2_opponent_FGA3 mean</th>\n",
       "      <th>T2_opponent_FTM mean</th>\n",
       "      <th>T2_opponent_FTA mean</th>\n",
       "      <th>T2_opponent_OR mean</th>\n",
       "      <th>T2_opponent_DR mean</th>\n",
       "      <th>T2_opponent_Ast mean</th>\n",
       "      <th>T2_opponent_TO mean</th>\n",
       "      <th>T2_opponent_Stl mean</th>\n",
       "      <th>T2_opponent_Blk mean</th>\n",
       "      <th>T2_opponent_PF mean</th>\n",
       "      <th>T2_PointDiff mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3125</td>\n",
       "      <td>52</td>\n",
       "      <td>3376</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>26.968750</td>\n",
       "      <td>59.687500</td>\n",
       "      <td>10.43750</td>\n",
       "      <td>29.093750</td>\n",
       "      <td>11.312500</td>\n",
       "      <td>16.468750</td>\n",
       "      <td>11.812500</td>\n",
       "      <td>29.156250</td>\n",
       "      <td>16.312500</td>\n",
       "      <td>12.562500</td>\n",
       "      <td>5.562500</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>14.656250</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>60.437500</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>9.343750</td>\n",
       "      <td>13.46875</td>\n",
       "      <td>10.96875</td>\n",
       "      <td>23.312500</td>\n",
       "      <td>11.593750</td>\n",
       "      <td>12.031250</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>17.531250</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>27.433333</td>\n",
       "      <td>63.233333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>18.233333</td>\n",
       "      <td>14.866667</td>\n",
       "      <td>20.533333</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>25.166667</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>16.766667</td>\n",
       "      <td>24.466667</td>\n",
       "      <td>62.133333</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>15.533333</td>\n",
       "      <td>12.766667</td>\n",
       "      <td>17.233333</td>\n",
       "      <td>13.466667</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>11.033333</td>\n",
       "      <td>15.866667</td>\n",
       "      <td>6.766667</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>9.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3332</td>\n",
       "      <td>78</td>\n",
       "      <td>3340</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>31.937500</td>\n",
       "      <td>63.625000</td>\n",
       "      <td>9.75000</td>\n",
       "      <td>23.343750</td>\n",
       "      <td>11.531250</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>10.937500</td>\n",
       "      <td>26.343750</td>\n",
       "      <td>19.031250</td>\n",
       "      <td>10.125000</td>\n",
       "      <td>6.906250</td>\n",
       "      <td>2.593750</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>24.218750</td>\n",
       "      <td>60.281250</td>\n",
       "      <td>6.656250</td>\n",
       "      <td>21.562500</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>11.68750</td>\n",
       "      <td>10.03125</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>13.687500</td>\n",
       "      <td>13.218750</td>\n",
       "      <td>4.687500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>14.875000</td>\n",
       "      <td>21.406250</td>\n",
       "      <td>25.967742</td>\n",
       "      <td>60.258065</td>\n",
       "      <td>5.838710</td>\n",
       "      <td>16.806452</td>\n",
       "      <td>12.967742</td>\n",
       "      <td>16.225806</td>\n",
       "      <td>11.064516</td>\n",
       "      <td>28.258065</td>\n",
       "      <td>17.225806</td>\n",
       "      <td>14.741935</td>\n",
       "      <td>9.580645</td>\n",
       "      <td>5.258065</td>\n",
       "      <td>14.935484</td>\n",
       "      <td>22.032258</td>\n",
       "      <td>61.870968</td>\n",
       "      <td>6.548387</td>\n",
       "      <td>21.612903</td>\n",
       "      <td>9.516129</td>\n",
       "      <td>14.290323</td>\n",
       "      <td>13.354839</td>\n",
       "      <td>24.258065</td>\n",
       "      <td>14.548387</td>\n",
       "      <td>15.903226</td>\n",
       "      <td>7.548387</td>\n",
       "      <td>1.806452</td>\n",
       "      <td>16.225806</td>\n",
       "      <td>10.612903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3281</td>\n",
       "      <td>77</td>\n",
       "      <td>3179</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>22.757576</td>\n",
       "      <td>50.757576</td>\n",
       "      <td>8.30303</td>\n",
       "      <td>22.878788</td>\n",
       "      <td>12.151515</td>\n",
       "      <td>16.424242</td>\n",
       "      <td>9.242424</td>\n",
       "      <td>26.393939</td>\n",
       "      <td>13.969697</td>\n",
       "      <td>16.181818</td>\n",
       "      <td>5.939394</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>17.181818</td>\n",
       "      <td>21.030303</td>\n",
       "      <td>57.787879</td>\n",
       "      <td>4.848485</td>\n",
       "      <td>17.030303</td>\n",
       "      <td>11.030303</td>\n",
       "      <td>15.69697</td>\n",
       "      <td>12.30303</td>\n",
       "      <td>20.242424</td>\n",
       "      <td>8.393939</td>\n",
       "      <td>12.212121</td>\n",
       "      <td>6.757576</td>\n",
       "      <td>1.939394</td>\n",
       "      <td>18.909091</td>\n",
       "      <td>8.030303</td>\n",
       "      <td>28.406250</td>\n",
       "      <td>59.937500</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>24.437500</td>\n",
       "      <td>14.781250</td>\n",
       "      <td>19.343750</td>\n",
       "      <td>11.093750</td>\n",
       "      <td>28.562500</td>\n",
       "      <td>21.093750</td>\n",
       "      <td>17.781250</td>\n",
       "      <td>9.031250</td>\n",
       "      <td>2.562500</td>\n",
       "      <td>17.156250</td>\n",
       "      <td>24.312500</td>\n",
       "      <td>63.156250</td>\n",
       "      <td>7.187500</td>\n",
       "      <td>25.125000</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>11.468750</td>\n",
       "      <td>22.281250</td>\n",
       "      <td>13.593750</td>\n",
       "      <td>16.281250</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>19.562500</td>\n",
       "      <td>13.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3280</td>\n",
       "      <td>103</td>\n",
       "      <td>3380</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>32.531250</td>\n",
       "      <td>66.156250</td>\n",
       "      <td>5.25000</td>\n",
       "      <td>13.781250</td>\n",
       "      <td>15.781250</td>\n",
       "      <td>21.531250</td>\n",
       "      <td>17.343750</td>\n",
       "      <td>25.468750</td>\n",
       "      <td>16.562500</td>\n",
       "      <td>12.625000</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>5.437500</td>\n",
       "      <td>16.937500</td>\n",
       "      <td>21.093750</td>\n",
       "      <td>55.625000</td>\n",
       "      <td>5.187500</td>\n",
       "      <td>15.562500</td>\n",
       "      <td>10.375000</td>\n",
       "      <td>14.93750</td>\n",
       "      <td>11.03125</td>\n",
       "      <td>18.843750</td>\n",
       "      <td>9.281250</td>\n",
       "      <td>19.656250</td>\n",
       "      <td>5.937500</td>\n",
       "      <td>3.937500</td>\n",
       "      <td>19.968750</td>\n",
       "      <td>28.343750</td>\n",
       "      <td>21.214286</td>\n",
       "      <td>55.750000</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>16.178571</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>18.964286</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>22.857143</td>\n",
       "      <td>11.464286</td>\n",
       "      <td>18.392857</td>\n",
       "      <td>8.642857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.392857</td>\n",
       "      <td>21.071429</td>\n",
       "      <td>50.607143</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>14.392857</td>\n",
       "      <td>15.464286</td>\n",
       "      <td>25.142857</td>\n",
       "      <td>11.535714</td>\n",
       "      <td>24.714286</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>19.321429</td>\n",
       "      <td>8.214286</td>\n",
       "      <td>3.107143</td>\n",
       "      <td>19.285714</td>\n",
       "      <td>-2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3276</td>\n",
       "      <td>84</td>\n",
       "      <td>3243</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>27.093750</td>\n",
       "      <td>60.437500</td>\n",
       "      <td>4.56250</td>\n",
       "      <td>13.937500</td>\n",
       "      <td>13.218750</td>\n",
       "      <td>18.875000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>25.656250</td>\n",
       "      <td>15.187500</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>7.312500</td>\n",
       "      <td>3.531250</td>\n",
       "      <td>17.156250</td>\n",
       "      <td>23.156250</td>\n",
       "      <td>57.562500</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>18.875000</td>\n",
       "      <td>11.468750</td>\n",
       "      <td>16.84375</td>\n",
       "      <td>10.53125</td>\n",
       "      <td>21.937500</td>\n",
       "      <td>12.687500</td>\n",
       "      <td>16.625000</td>\n",
       "      <td>7.968750</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>8.312500</td>\n",
       "      <td>23.062500</td>\n",
       "      <td>56.718750</td>\n",
       "      <td>5.656250</td>\n",
       "      <td>18.781250</td>\n",
       "      <td>13.031250</td>\n",
       "      <td>18.062500</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>24.437500</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.468750</td>\n",
       "      <td>14.562500</td>\n",
       "      <td>23.031250</td>\n",
       "      <td>60.093750</td>\n",
       "      <td>6.343750</td>\n",
       "      <td>20.156250</td>\n",
       "      <td>11.406250</td>\n",
       "      <td>15.187500</td>\n",
       "      <td>13.375000</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>13.906250</td>\n",
       "      <td>15.937500</td>\n",
       "      <td>8.218750</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  T1_TeamID  T1_Score  T2_TeamID  T2_Score  result  \\\n",
       "0    2019     137       3125        52       3376        74       0   \n",
       "1    2019     137       3332        78       3340        40       1   \n",
       "2    2019     137       3281        77       3179        76       1   \n",
       "3    2019     137       3280       103       3380        46       1   \n",
       "4    2019     137       3276        84       3243        54       1   \n",
       "\n",
       "   T1_FGM mean  T1_FGA mean  T1_FGM3 mean  T1_FGA3 mean  T1_FTM mean  \\\n",
       "0    26.968750    59.687500      10.43750     29.093750    11.312500   \n",
       "1    31.937500    63.625000       9.75000     23.343750    11.531250   \n",
       "2    22.757576    50.757576       8.30303     22.878788    12.151515   \n",
       "3    32.531250    66.156250       5.25000     13.781250    15.781250   \n",
       "4    27.093750    60.437500       4.56250     13.937500    13.218750   \n",
       "\n",
       "   T1_FTA mean  T1_OR mean  T1_DR mean  T1_Ast mean  T1_TO mean  T1_Stl mean  \\\n",
       "0    16.468750   11.812500   29.156250    16.312500   12.562500     5.562500   \n",
       "1    15.062500   10.937500   26.343750    19.031250   10.125000     6.906250   \n",
       "2    16.424242    9.242424   26.393939    13.969697   16.181818     5.939394   \n",
       "3    21.531250   17.343750   25.468750    16.562500   12.625000     8.656250   \n",
       "4    18.875000   13.750000   25.656250    15.187500   16.250000     7.312500   \n",
       "\n",
       "   T1_Blk mean  T1_PF mean  T1_opponent_FGM mean  T1_opponent_FGA mean  \\\n",
       "0     2.125000   14.656250             22.000000             60.437500   \n",
       "1     2.593750   13.000000             24.218750             60.281250   \n",
       "2     3.181818   17.181818             21.030303             57.787879   \n",
       "3     5.437500   16.937500             21.093750             55.625000   \n",
       "4     3.531250   17.156250             23.156250             57.562500   \n",
       "\n",
       "   T1_opponent_FGM3 mean  T1_opponent_FGA3 mean  T1_opponent_FTM mean  \\\n",
       "0               6.250000              20.750000              9.343750   \n",
       "1               6.656250              21.562500              8.656250   \n",
       "2               4.848485              17.030303             11.030303   \n",
       "3               5.187500              15.562500             10.375000   \n",
       "4               5.875000              18.875000             11.468750   \n",
       "\n",
       "   T1_opponent_FTA mean  T1_opponent_OR mean  T1_opponent_DR mean  \\\n",
       "0              13.46875             10.96875            23.312500   \n",
       "1              11.68750             10.03125            20.750000   \n",
       "2              15.69697             12.30303            20.242424   \n",
       "3              14.93750             11.03125            18.843750   \n",
       "4              16.84375             10.53125            21.937500   \n",
       "\n",
       "   T1_opponent_Ast mean  T1_opponent_TO mean  T1_opponent_Stl mean  \\\n",
       "0             11.593750            12.031250              5.625000   \n",
       "1             13.687500            13.218750              4.687500   \n",
       "2              8.393939            12.212121              6.757576   \n",
       "3              9.281250            19.656250              5.937500   \n",
       "4             12.687500            16.625000              7.968750   \n",
       "\n",
       "   T1_opponent_Blk mean  T1_opponent_PF mean  T1_PointDiff mean  T2_FGM mean  \\\n",
       "0              2.875000            17.531250          16.093750    27.433333   \n",
       "1              2.500000            14.875000          21.406250    25.967742   \n",
       "2              1.939394            18.909091           8.030303    28.406250   \n",
       "3              3.937500            19.968750          28.343750    21.214286   \n",
       "4              3.437500            17.750000           8.312500    23.062500   \n",
       "\n",
       "   T2_FGA mean  T2_FGM3 mean  T2_FGA3 mean  T2_FTM mean  T2_FTA mean  \\\n",
       "0    63.233333      6.000000     18.233333    14.866667    20.533333   \n",
       "1    60.258065      5.838710     16.806452    12.967742    16.225806   \n",
       "2    59.937500      8.750000     24.437500    14.781250    19.343750   \n",
       "3    55.750000      4.428571     16.178571    11.750000    18.964286   \n",
       "4    56.718750      5.656250     18.781250    13.031250    18.062500   \n",
       "\n",
       "   T2_OR mean  T2_DR mean  T2_Ast mean  T2_TO mean  T2_Stl mean  T2_Blk mean  \\\n",
       "0   13.833333   25.166667    13.100000   13.600000     8.333333     6.300000   \n",
       "1   11.064516   28.258065    17.225806   14.741935     9.580645     5.258065   \n",
       "2   11.093750   28.562500    21.093750   17.781250     9.031250     2.562500   \n",
       "3   12.750000   22.857143    11.464286   18.392857     8.642857     2.000000   \n",
       "4   10.500000   24.437500    13.000000   15.062500     8.000000     4.468750   \n",
       "\n",
       "   T2_PF mean  T2_opponent_FGM mean  T2_opponent_FGA mean  \\\n",
       "0   16.766667             24.466667             62.133333   \n",
       "1   14.935484             22.032258             61.870968   \n",
       "2   17.156250             24.312500             63.156250   \n",
       "3   22.392857             21.071429             50.607143   \n",
       "4   14.562500             23.031250             60.093750   \n",
       "\n",
       "   T2_opponent_FGM3 mean  T2_opponent_FGA3 mean  T2_opponent_FTM mean  \\\n",
       "0               4.800000              15.533333             12.766667   \n",
       "1               6.548387              21.612903              9.516129   \n",
       "2               7.187500              25.125000             11.250000   \n",
       "3               3.857143              14.392857             15.464286   \n",
       "4               6.343750              20.156250             11.406250   \n",
       "\n",
       "   T2_opponent_FTA mean  T2_opponent_OR mean  T2_opponent_DR mean  \\\n",
       "0             17.233333            13.466667            23.300000   \n",
       "1             14.290323            13.354839            24.258065   \n",
       "2             15.750000            11.468750            22.281250   \n",
       "3             25.142857            11.535714            24.714286   \n",
       "4             15.187500            13.375000            24.750000   \n",
       "\n",
       "   T2_opponent_Ast mean  T2_opponent_TO mean  T2_opponent_Stl mean  \\\n",
       "0             11.033333            15.866667              6.766667   \n",
       "1             14.548387            15.903226              7.548387   \n",
       "2             13.593750            16.281250              8.656250   \n",
       "3             11.500000            19.321429              8.214286   \n",
       "4             13.906250            15.937500              8.218750   \n",
       "\n",
       "   T2_opponent_Blk mean  T2_opponent_PF mean  T2_PointDiff mean  \n",
       "0              3.133333            18.900000           9.233333  \n",
       "1              1.806452            16.225806          10.612903  \n",
       "2              2.875000            19.562500          13.281250  \n",
       "3              3.107143            19.285714          -2.857143  \n",
       "4              2.812500            16.500000           1.000000  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TourneyDetailedResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "last14days_stats_T1 = SeasonDetailedResults.loc[SeasonDetailedResults.DayNum>118].reset_index(drop=True)\n",
    "last14days_stats_T1['last14days'] = np.where(last14days_stats_T1['T1_Score'] > last14days_stats_T1['T2_Score'], 1, 0)\n",
    "last14days_stats_T1 = last14days_stats_T1.groupby(['Season','T1_TeamID'])['last14days'].mean().reset_index(name='T1_win_ratio_14d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "last14days_stats_T2 = SeasonDetailedResults.loc[SeasonDetailedResults.DayNum>118].reset_index(drop=True)\n",
    "last14days_stats_T2['last14days'] = np.where(last14days_stats_T2['T1_Score'] > last14days_stats_T2['T2_Score'], 1, 0)\n",
    "last14days_stats_T2 = last14days_stats_T2.groupby(['Season','T2_TeamID'])['last14days'].mean().reset_index(name='T2_win_ratio_14d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneyDetailedResults = pd.merge(TourneyDetailedResults, last14days_stats_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n",
    "TourneyDetailedResults = pd.merge(TourneyDetailedResults, last14days_stats_T2, on = ['Season', 'T2_TeamID'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>T1_TeamID</th>\n",
       "      <th>T1_Score</th>\n",
       "      <th>T2_TeamID</th>\n",
       "      <th>T2_Score</th>\n",
       "      <th>result</th>\n",
       "      <th>T1_FGM mean</th>\n",
       "      <th>T1_FGA mean</th>\n",
       "      <th>T1_FGM3 mean</th>\n",
       "      <th>T1_FGA3 mean</th>\n",
       "      <th>T1_FTM mean</th>\n",
       "      <th>T1_FTA mean</th>\n",
       "      <th>T1_OR mean</th>\n",
       "      <th>T1_DR mean</th>\n",
       "      <th>T1_Ast mean</th>\n",
       "      <th>T1_TO mean</th>\n",
       "      <th>T1_Stl mean</th>\n",
       "      <th>T1_Blk mean</th>\n",
       "      <th>T1_PF mean</th>\n",
       "      <th>T1_opponent_FGM mean</th>\n",
       "      <th>T1_opponent_FGA mean</th>\n",
       "      <th>T1_opponent_FGM3 mean</th>\n",
       "      <th>T1_opponent_FGA3 mean</th>\n",
       "      <th>T1_opponent_FTM mean</th>\n",
       "      <th>T1_opponent_FTA mean</th>\n",
       "      <th>T1_opponent_OR mean</th>\n",
       "      <th>T1_opponent_DR mean</th>\n",
       "      <th>T1_opponent_Ast mean</th>\n",
       "      <th>T1_opponent_TO mean</th>\n",
       "      <th>T1_opponent_Stl mean</th>\n",
       "      <th>T1_opponent_Blk mean</th>\n",
       "      <th>T1_opponent_PF mean</th>\n",
       "      <th>T1_PointDiff mean</th>\n",
       "      <th>T2_FGM mean</th>\n",
       "      <th>T2_FGA mean</th>\n",
       "      <th>T2_FGM3 mean</th>\n",
       "      <th>T2_FGA3 mean</th>\n",
       "      <th>T2_FTM mean</th>\n",
       "      <th>T2_FTA mean</th>\n",
       "      <th>T2_OR mean</th>\n",
       "      <th>T2_DR mean</th>\n",
       "      <th>T2_Ast mean</th>\n",
       "      <th>T2_TO mean</th>\n",
       "      <th>T2_Stl mean</th>\n",
       "      <th>T2_Blk mean</th>\n",
       "      <th>T2_PF mean</th>\n",
       "      <th>T2_opponent_FGM mean</th>\n",
       "      <th>T2_opponent_FGA mean</th>\n",
       "      <th>T2_opponent_FGM3 mean</th>\n",
       "      <th>T2_opponent_FGA3 mean</th>\n",
       "      <th>T2_opponent_FTM mean</th>\n",
       "      <th>T2_opponent_FTA mean</th>\n",
       "      <th>T2_opponent_OR mean</th>\n",
       "      <th>T2_opponent_DR mean</th>\n",
       "      <th>T2_opponent_Ast mean</th>\n",
       "      <th>T2_opponent_TO mean</th>\n",
       "      <th>T2_opponent_Stl mean</th>\n",
       "      <th>T2_opponent_Blk mean</th>\n",
       "      <th>T2_opponent_PF mean</th>\n",
       "      <th>T2_PointDiff mean</th>\n",
       "      <th>T1_win_ratio_14d</th>\n",
       "      <th>T2_win_ratio_14d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3125</td>\n",
       "      <td>52</td>\n",
       "      <td>3376</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>26.968750</td>\n",
       "      <td>59.687500</td>\n",
       "      <td>10.43750</td>\n",
       "      <td>29.093750</td>\n",
       "      <td>11.312500</td>\n",
       "      <td>16.468750</td>\n",
       "      <td>11.812500</td>\n",
       "      <td>29.156250</td>\n",
       "      <td>16.312500</td>\n",
       "      <td>12.562500</td>\n",
       "      <td>5.562500</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>14.656250</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>60.437500</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>9.343750</td>\n",
       "      <td>13.46875</td>\n",
       "      <td>10.96875</td>\n",
       "      <td>23.312500</td>\n",
       "      <td>11.593750</td>\n",
       "      <td>12.031250</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>17.531250</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>27.433333</td>\n",
       "      <td>63.233333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>18.233333</td>\n",
       "      <td>14.866667</td>\n",
       "      <td>20.533333</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>25.166667</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>16.766667</td>\n",
       "      <td>24.466667</td>\n",
       "      <td>62.133333</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>15.533333</td>\n",
       "      <td>12.766667</td>\n",
       "      <td>17.233333</td>\n",
       "      <td>13.466667</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>11.033333</td>\n",
       "      <td>15.866667</td>\n",
       "      <td>6.766667</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>9.233333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3332</td>\n",
       "      <td>78</td>\n",
       "      <td>3340</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>31.937500</td>\n",
       "      <td>63.625000</td>\n",
       "      <td>9.75000</td>\n",
       "      <td>23.343750</td>\n",
       "      <td>11.531250</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>10.937500</td>\n",
       "      <td>26.343750</td>\n",
       "      <td>19.031250</td>\n",
       "      <td>10.125000</td>\n",
       "      <td>6.906250</td>\n",
       "      <td>2.593750</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>24.218750</td>\n",
       "      <td>60.281250</td>\n",
       "      <td>6.656250</td>\n",
       "      <td>21.562500</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>11.68750</td>\n",
       "      <td>10.03125</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>13.687500</td>\n",
       "      <td>13.218750</td>\n",
       "      <td>4.687500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>14.875000</td>\n",
       "      <td>21.406250</td>\n",
       "      <td>25.967742</td>\n",
       "      <td>60.258065</td>\n",
       "      <td>5.838710</td>\n",
       "      <td>16.806452</td>\n",
       "      <td>12.967742</td>\n",
       "      <td>16.225806</td>\n",
       "      <td>11.064516</td>\n",
       "      <td>28.258065</td>\n",
       "      <td>17.225806</td>\n",
       "      <td>14.741935</td>\n",
       "      <td>9.580645</td>\n",
       "      <td>5.258065</td>\n",
       "      <td>14.935484</td>\n",
       "      <td>22.032258</td>\n",
       "      <td>61.870968</td>\n",
       "      <td>6.548387</td>\n",
       "      <td>21.612903</td>\n",
       "      <td>9.516129</td>\n",
       "      <td>14.290323</td>\n",
       "      <td>13.354839</td>\n",
       "      <td>24.258065</td>\n",
       "      <td>14.548387</td>\n",
       "      <td>15.903226</td>\n",
       "      <td>7.548387</td>\n",
       "      <td>1.806452</td>\n",
       "      <td>16.225806</td>\n",
       "      <td>10.612903</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3281</td>\n",
       "      <td>77</td>\n",
       "      <td>3179</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>22.757576</td>\n",
       "      <td>50.757576</td>\n",
       "      <td>8.30303</td>\n",
       "      <td>22.878788</td>\n",
       "      <td>12.151515</td>\n",
       "      <td>16.424242</td>\n",
       "      <td>9.242424</td>\n",
       "      <td>26.393939</td>\n",
       "      <td>13.969697</td>\n",
       "      <td>16.181818</td>\n",
       "      <td>5.939394</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>17.181818</td>\n",
       "      <td>21.030303</td>\n",
       "      <td>57.787879</td>\n",
       "      <td>4.848485</td>\n",
       "      <td>17.030303</td>\n",
       "      <td>11.030303</td>\n",
       "      <td>15.69697</td>\n",
       "      <td>12.30303</td>\n",
       "      <td>20.242424</td>\n",
       "      <td>8.393939</td>\n",
       "      <td>12.212121</td>\n",
       "      <td>6.757576</td>\n",
       "      <td>1.939394</td>\n",
       "      <td>18.909091</td>\n",
       "      <td>8.030303</td>\n",
       "      <td>28.406250</td>\n",
       "      <td>59.937500</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>24.437500</td>\n",
       "      <td>14.781250</td>\n",
       "      <td>19.343750</td>\n",
       "      <td>11.093750</td>\n",
       "      <td>28.562500</td>\n",
       "      <td>21.093750</td>\n",
       "      <td>17.781250</td>\n",
       "      <td>9.031250</td>\n",
       "      <td>2.562500</td>\n",
       "      <td>17.156250</td>\n",
       "      <td>24.312500</td>\n",
       "      <td>63.156250</td>\n",
       "      <td>7.187500</td>\n",
       "      <td>25.125000</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>11.468750</td>\n",
       "      <td>22.281250</td>\n",
       "      <td>13.593750</td>\n",
       "      <td>16.281250</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>19.562500</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3280</td>\n",
       "      <td>103</td>\n",
       "      <td>3380</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>32.531250</td>\n",
       "      <td>66.156250</td>\n",
       "      <td>5.25000</td>\n",
       "      <td>13.781250</td>\n",
       "      <td>15.781250</td>\n",
       "      <td>21.531250</td>\n",
       "      <td>17.343750</td>\n",
       "      <td>25.468750</td>\n",
       "      <td>16.562500</td>\n",
       "      <td>12.625000</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>5.437500</td>\n",
       "      <td>16.937500</td>\n",
       "      <td>21.093750</td>\n",
       "      <td>55.625000</td>\n",
       "      <td>5.187500</td>\n",
       "      <td>15.562500</td>\n",
       "      <td>10.375000</td>\n",
       "      <td>14.93750</td>\n",
       "      <td>11.03125</td>\n",
       "      <td>18.843750</td>\n",
       "      <td>9.281250</td>\n",
       "      <td>19.656250</td>\n",
       "      <td>5.937500</td>\n",
       "      <td>3.937500</td>\n",
       "      <td>19.968750</td>\n",
       "      <td>28.343750</td>\n",
       "      <td>21.214286</td>\n",
       "      <td>55.750000</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>16.178571</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>18.964286</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>22.857143</td>\n",
       "      <td>11.464286</td>\n",
       "      <td>18.392857</td>\n",
       "      <td>8.642857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.392857</td>\n",
       "      <td>21.071429</td>\n",
       "      <td>50.607143</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>14.392857</td>\n",
       "      <td>15.464286</td>\n",
       "      <td>25.142857</td>\n",
       "      <td>11.535714</td>\n",
       "      <td>24.714286</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>19.321429</td>\n",
       "      <td>8.214286</td>\n",
       "      <td>3.107143</td>\n",
       "      <td>19.285714</td>\n",
       "      <td>-2.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3276</td>\n",
       "      <td>84</td>\n",
       "      <td>3243</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>27.093750</td>\n",
       "      <td>60.437500</td>\n",
       "      <td>4.56250</td>\n",
       "      <td>13.937500</td>\n",
       "      <td>13.218750</td>\n",
       "      <td>18.875000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>25.656250</td>\n",
       "      <td>15.187500</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>7.312500</td>\n",
       "      <td>3.531250</td>\n",
       "      <td>17.156250</td>\n",
       "      <td>23.156250</td>\n",
       "      <td>57.562500</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>18.875000</td>\n",
       "      <td>11.468750</td>\n",
       "      <td>16.84375</td>\n",
       "      <td>10.53125</td>\n",
       "      <td>21.937500</td>\n",
       "      <td>12.687500</td>\n",
       "      <td>16.625000</td>\n",
       "      <td>7.968750</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>8.312500</td>\n",
       "      <td>23.062500</td>\n",
       "      <td>56.718750</td>\n",
       "      <td>5.656250</td>\n",
       "      <td>18.781250</td>\n",
       "      <td>13.031250</td>\n",
       "      <td>18.062500</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>24.437500</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.468750</td>\n",
       "      <td>14.562500</td>\n",
       "      <td>23.031250</td>\n",
       "      <td>60.093750</td>\n",
       "      <td>6.343750</td>\n",
       "      <td>20.156250</td>\n",
       "      <td>11.406250</td>\n",
       "      <td>15.187500</td>\n",
       "      <td>13.375000</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>13.906250</td>\n",
       "      <td>15.937500</td>\n",
       "      <td>8.218750</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  T1_TeamID  T1_Score  T2_TeamID  T2_Score  result  \\\n",
       "0    2019     137       3125        52       3376        74       0   \n",
       "1    2019     137       3332        78       3340        40       1   \n",
       "2    2019     137       3281        77       3179        76       1   \n",
       "3    2019     137       3280       103       3380        46       1   \n",
       "4    2019     137       3276        84       3243        54       1   \n",
       "\n",
       "   T1_FGM mean  T1_FGA mean  T1_FGM3 mean  T1_FGA3 mean  T1_FTM mean  \\\n",
       "0    26.968750    59.687500      10.43750     29.093750    11.312500   \n",
       "1    31.937500    63.625000       9.75000     23.343750    11.531250   \n",
       "2    22.757576    50.757576       8.30303     22.878788    12.151515   \n",
       "3    32.531250    66.156250       5.25000     13.781250    15.781250   \n",
       "4    27.093750    60.437500       4.56250     13.937500    13.218750   \n",
       "\n",
       "   T1_FTA mean  T1_OR mean  T1_DR mean  T1_Ast mean  T1_TO mean  T1_Stl mean  \\\n",
       "0    16.468750   11.812500   29.156250    16.312500   12.562500     5.562500   \n",
       "1    15.062500   10.937500   26.343750    19.031250   10.125000     6.906250   \n",
       "2    16.424242    9.242424   26.393939    13.969697   16.181818     5.939394   \n",
       "3    21.531250   17.343750   25.468750    16.562500   12.625000     8.656250   \n",
       "4    18.875000   13.750000   25.656250    15.187500   16.250000     7.312500   \n",
       "\n",
       "   T1_Blk mean  T1_PF mean  T1_opponent_FGM mean  T1_opponent_FGA mean  \\\n",
       "0     2.125000   14.656250             22.000000             60.437500   \n",
       "1     2.593750   13.000000             24.218750             60.281250   \n",
       "2     3.181818   17.181818             21.030303             57.787879   \n",
       "3     5.437500   16.937500             21.093750             55.625000   \n",
       "4     3.531250   17.156250             23.156250             57.562500   \n",
       "\n",
       "   T1_opponent_FGM3 mean  T1_opponent_FGA3 mean  T1_opponent_FTM mean  \\\n",
       "0               6.250000              20.750000              9.343750   \n",
       "1               6.656250              21.562500              8.656250   \n",
       "2               4.848485              17.030303             11.030303   \n",
       "3               5.187500              15.562500             10.375000   \n",
       "4               5.875000              18.875000             11.468750   \n",
       "\n",
       "   T1_opponent_FTA mean  T1_opponent_OR mean  T1_opponent_DR mean  \\\n",
       "0              13.46875             10.96875            23.312500   \n",
       "1              11.68750             10.03125            20.750000   \n",
       "2              15.69697             12.30303            20.242424   \n",
       "3              14.93750             11.03125            18.843750   \n",
       "4              16.84375             10.53125            21.937500   \n",
       "\n",
       "   T1_opponent_Ast mean  T1_opponent_TO mean  T1_opponent_Stl mean  \\\n",
       "0             11.593750            12.031250              5.625000   \n",
       "1             13.687500            13.218750              4.687500   \n",
       "2              8.393939            12.212121              6.757576   \n",
       "3              9.281250            19.656250              5.937500   \n",
       "4             12.687500            16.625000              7.968750   \n",
       "\n",
       "   T1_opponent_Blk mean  T1_opponent_PF mean  T1_PointDiff mean  T2_FGM mean  \\\n",
       "0              2.875000            17.531250          16.093750    27.433333   \n",
       "1              2.500000            14.875000          21.406250    25.967742   \n",
       "2              1.939394            18.909091           8.030303    28.406250   \n",
       "3              3.937500            19.968750          28.343750    21.214286   \n",
       "4              3.437500            17.750000           8.312500    23.062500   \n",
       "\n",
       "   T2_FGA mean  T2_FGM3 mean  T2_FGA3 mean  T2_FTM mean  T2_FTA mean  \\\n",
       "0    63.233333      6.000000     18.233333    14.866667    20.533333   \n",
       "1    60.258065      5.838710     16.806452    12.967742    16.225806   \n",
       "2    59.937500      8.750000     24.437500    14.781250    19.343750   \n",
       "3    55.750000      4.428571     16.178571    11.750000    18.964286   \n",
       "4    56.718750      5.656250     18.781250    13.031250    18.062500   \n",
       "\n",
       "   T2_OR mean  T2_DR mean  T2_Ast mean  T2_TO mean  T2_Stl mean  T2_Blk mean  \\\n",
       "0   13.833333   25.166667    13.100000   13.600000     8.333333     6.300000   \n",
       "1   11.064516   28.258065    17.225806   14.741935     9.580645     5.258065   \n",
       "2   11.093750   28.562500    21.093750   17.781250     9.031250     2.562500   \n",
       "3   12.750000   22.857143    11.464286   18.392857     8.642857     2.000000   \n",
       "4   10.500000   24.437500    13.000000   15.062500     8.000000     4.468750   \n",
       "\n",
       "   T2_PF mean  T2_opponent_FGM mean  T2_opponent_FGA mean  \\\n",
       "0   16.766667             24.466667             62.133333   \n",
       "1   14.935484             22.032258             61.870968   \n",
       "2   17.156250             24.312500             63.156250   \n",
       "3   22.392857             21.071429             50.607143   \n",
       "4   14.562500             23.031250             60.093750   \n",
       "\n",
       "   T2_opponent_FGM3 mean  T2_opponent_FGA3 mean  T2_opponent_FTM mean  \\\n",
       "0               4.800000              15.533333             12.766667   \n",
       "1               6.548387              21.612903              9.516129   \n",
       "2               7.187500              25.125000             11.250000   \n",
       "3               3.857143              14.392857             15.464286   \n",
       "4               6.343750              20.156250             11.406250   \n",
       "\n",
       "   T2_opponent_FTA mean  T2_opponent_OR mean  T2_opponent_DR mean  \\\n",
       "0             17.233333            13.466667            23.300000   \n",
       "1             14.290323            13.354839            24.258065   \n",
       "2             15.750000            11.468750            22.281250   \n",
       "3             25.142857            11.535714            24.714286   \n",
       "4             15.187500            13.375000            24.750000   \n",
       "\n",
       "   T2_opponent_Ast mean  T2_opponent_TO mean  T2_opponent_Stl mean  \\\n",
       "0             11.033333            15.866667              6.766667   \n",
       "1             14.548387            15.903226              7.548387   \n",
       "2             13.593750            16.281250              8.656250   \n",
       "3             11.500000            19.321429              8.214286   \n",
       "4             13.906250            15.937500              8.218750   \n",
       "\n",
       "   T2_opponent_Blk mean  T2_opponent_PF mean  T2_PointDiff mean  \\\n",
       "0              3.133333            18.900000           9.233333   \n",
       "1              1.806452            16.225806          10.612903   \n",
       "2              2.875000            19.562500          13.281250   \n",
       "3              3.107143            19.285714          -2.857143   \n",
       "4              2.812500            16.500000           1.000000   \n",
       "\n",
       "   T1_win_ratio_14d  T2_win_ratio_14d  \n",
       "0          1.000000          1.000000  \n",
       "1          0.666667          0.200000  \n",
       "2          0.666667          0.200000  \n",
       "3          1.000000          0.200000  \n",
       "4          0.500000          0.333333  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TourneyDetailedResults.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Quality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_season_effects = SeasonDetailedResults[['Season','T1_TeamID','T2_TeamID','PointDiff']].copy()\n",
    "regular_season_effects['T1_TeamID'] = regular_season_effects['T1_TeamID'].astype(str)\n",
    "regular_season_effects['T2_TeamID'] = regular_season_effects['T2_TeamID'].astype(str)\n",
    "regular_season_effects['win'] = np.where(regular_season_effects['PointDiff']>0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>T1_TeamID</th>\n",
       "      <th>T2_TeamID</th>\n",
       "      <th>PointDiff</th>\n",
       "      <th>win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>3113</td>\n",
       "      <td>3230</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>3442</td>\n",
       "      <td>3281</td>\n",
       "      <td>-25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>3189</td>\n",
       "      <td>3314</td>\n",
       "      <td>-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>3201</td>\n",
       "      <td>3319</td>\n",
       "      <td>-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>3453</td>\n",
       "      <td>3321</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season T1_TeamID T2_TeamID  PointDiff  win\n",
       "0    2019      3113      3230         38    1\n",
       "1    2019      3442      3281        -25    0\n",
       "2    2019      3189      3314        -31    0\n",
       "3    2019      3201      3319        -13    0\n",
       "4    2019      3453      3321         -2    0"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_season_effects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Seed</th>\n",
       "      <th>TeamID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>W01</td>\n",
       "      <td>3330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>W02</td>\n",
       "      <td>3163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>W03</td>\n",
       "      <td>3112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>W04</td>\n",
       "      <td>3301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>W05</td>\n",
       "      <td>3272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season Seed  TeamID\n",
       "0    1998  W01    3330\n",
       "1    1998  W02    3163\n",
       "2    1998  W03    3112\n",
       "3    1998  W04    3301\n",
       "4    1998  W05    3272"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TourneySeeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "march_madness = pd.merge(TourneySeeds[['Season','TeamID']],TourneySeeds[['Season','TeamID']],on='Season')\n",
    "march_madness.columns = ['Season', 'T1_TeamID', 'T2_TeamID']\n",
    "march_madness.T1_TeamID = march_madness.T1_TeamID.astype(str)\n",
    "march_madness.T2_TeamID = march_madness.T2_TeamID.astype(str)\n",
    "regular_season_effects = pd.merge(regular_season_effects, march_madness, on = ['Season','T1_TeamID','T2_TeamID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>T1_TeamID</th>\n",
       "      <th>T2_TeamID</th>\n",
       "      <th>PointDiff</th>\n",
       "      <th>win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>3355</td>\n",
       "      <td>3266</td>\n",
       "      <td>-39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>3266</td>\n",
       "      <td>3355</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>3413</td>\n",
       "      <td>3390</td>\n",
       "      <td>-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>3125</td>\n",
       "      <td>3301</td>\n",
       "      <td>-15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>3349</td>\n",
       "      <td>3401</td>\n",
       "      <td>-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season T1_TeamID T2_TeamID  PointDiff  win\n",
       "0    2019      3355      3266        -39    0\n",
       "1    2019      3266      3355         39    1\n",
       "2    2019      3413      3390        -28    0\n",
       "3    2019      3125      3301        -15    0\n",
       "4    2019      3349      3401        -11    0"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_season_effects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_quality(season):\n",
    "    formula = 'win~-1+T1_TeamID+T2_TeamID'\n",
    "    glm = sm.GLM.from_formula(formula=formula, \n",
    "                              data=regular_season_effects.loc[regular_season_effects.Season==season,:], \n",
    "                              family=sm.families.Binomial()).fit()\n",
    "    \n",
    "    quality = pd.DataFrame(glm.params).reset_index()\n",
    "    quality.columns = ['TeamID','quality']\n",
    "    quality['Season'] = season\n",
    "    quality['quality'] = np.exp(quality['quality'])\n",
    "    quality = quality.loc[quality.TeamID.str.contains('T1_')].reset_index(drop=True)\n",
    "    quality['TeamID'] = quality['TeamID'].apply(lambda x: x[10:14]).astype(int)\n",
    "    return quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.team_quality(season)>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_quality = pd.concat([team_quality(2010),\n",
    "                         team_quality(2011),\n",
    "                         team_quality(2012),\n",
    "                         team_quality(2013),\n",
    "                         team_quality(2014),\n",
    "                         team_quality(2015),\n",
    "                         team_quality(2016),\n",
    "                         team_quality(2017),\n",
    "                         team_quality(2018)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamID</th>\n",
       "      <th>quality</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3114</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3122</td>\n",
       "      <td>2.700316e-49</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3124</td>\n",
       "      <td>9.290078e+00</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3132</td>\n",
       "      <td>2.818303e+00</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3151</td>\n",
       "      <td>7.398088e-33</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TeamID       quality  Season\n",
       "0    3114  1.000000e+00    2010\n",
       "1    3122  2.700316e-49    2010\n",
       "2    3124  9.290078e+00    2010\n",
       "3    3132  2.818303e+00    2010\n",
       "4    3151  7.398088e-33    2010"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_quality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_quality_T1 = glm_quality.copy()\n",
    "glm_quality_T2 = glm_quality.copy()\n",
    "glm_quality_T1.columns = ['T1_TeamID','T1_quality','Season']\n",
    "glm_quality_T2.columns = ['T2_TeamID','T2_quality','Season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneyDetailedResults = pd.merge(TourneyDetailedResults, glm_quality_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n",
    "TourneyDetailedResults = pd.merge(TourneyDetailedResults, glm_quality_T2, on = ['Season', 'T2_TeamID'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>T1_TeamID</th>\n",
       "      <th>T1_Score</th>\n",
       "      <th>T2_TeamID</th>\n",
       "      <th>T2_Score</th>\n",
       "      <th>result</th>\n",
       "      <th>T1_FGM mean</th>\n",
       "      <th>T1_FGA mean</th>\n",
       "      <th>T1_FGM3 mean</th>\n",
       "      <th>T1_FGA3 mean</th>\n",
       "      <th>T1_FTM mean</th>\n",
       "      <th>T1_FTA mean</th>\n",
       "      <th>T1_OR mean</th>\n",
       "      <th>T1_DR mean</th>\n",
       "      <th>T1_Ast mean</th>\n",
       "      <th>T1_TO mean</th>\n",
       "      <th>T1_Stl mean</th>\n",
       "      <th>T1_Blk mean</th>\n",
       "      <th>T1_PF mean</th>\n",
       "      <th>T1_opponent_FGM mean</th>\n",
       "      <th>T1_opponent_FGA mean</th>\n",
       "      <th>T1_opponent_FGM3 mean</th>\n",
       "      <th>T1_opponent_FGA3 mean</th>\n",
       "      <th>T1_opponent_FTM mean</th>\n",
       "      <th>T1_opponent_FTA mean</th>\n",
       "      <th>T1_opponent_OR mean</th>\n",
       "      <th>T1_opponent_DR mean</th>\n",
       "      <th>T1_opponent_Ast mean</th>\n",
       "      <th>T1_opponent_TO mean</th>\n",
       "      <th>T1_opponent_Stl mean</th>\n",
       "      <th>T1_opponent_Blk mean</th>\n",
       "      <th>T1_opponent_PF mean</th>\n",
       "      <th>T1_PointDiff mean</th>\n",
       "      <th>T2_FGM mean</th>\n",
       "      <th>T2_FGA mean</th>\n",
       "      <th>T2_FGM3 mean</th>\n",
       "      <th>T2_FGA3 mean</th>\n",
       "      <th>T2_FTM mean</th>\n",
       "      <th>T2_FTA mean</th>\n",
       "      <th>T2_OR mean</th>\n",
       "      <th>T2_DR mean</th>\n",
       "      <th>T2_Ast mean</th>\n",
       "      <th>T2_TO mean</th>\n",
       "      <th>T2_Stl mean</th>\n",
       "      <th>T2_Blk mean</th>\n",
       "      <th>T2_PF mean</th>\n",
       "      <th>T2_opponent_FGM mean</th>\n",
       "      <th>T2_opponent_FGA mean</th>\n",
       "      <th>T2_opponent_FGM3 mean</th>\n",
       "      <th>T2_opponent_FGA3 mean</th>\n",
       "      <th>T2_opponent_FTM mean</th>\n",
       "      <th>T2_opponent_FTA mean</th>\n",
       "      <th>T2_opponent_OR mean</th>\n",
       "      <th>T2_opponent_DR mean</th>\n",
       "      <th>T2_opponent_Ast mean</th>\n",
       "      <th>T2_opponent_TO mean</th>\n",
       "      <th>T2_opponent_Stl mean</th>\n",
       "      <th>T2_opponent_Blk mean</th>\n",
       "      <th>T2_opponent_PF mean</th>\n",
       "      <th>T2_PointDiff mean</th>\n",
       "      <th>T1_win_ratio_14d</th>\n",
       "      <th>T2_win_ratio_14d</th>\n",
       "      <th>T1_quality</th>\n",
       "      <th>T2_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3125</td>\n",
       "      <td>52</td>\n",
       "      <td>3376</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>26.968750</td>\n",
       "      <td>59.687500</td>\n",
       "      <td>10.43750</td>\n",
       "      <td>29.093750</td>\n",
       "      <td>11.312500</td>\n",
       "      <td>16.468750</td>\n",
       "      <td>11.812500</td>\n",
       "      <td>29.156250</td>\n",
       "      <td>16.312500</td>\n",
       "      <td>12.562500</td>\n",
       "      <td>5.562500</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>14.656250</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>60.437500</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>9.343750</td>\n",
       "      <td>13.46875</td>\n",
       "      <td>10.96875</td>\n",
       "      <td>23.312500</td>\n",
       "      <td>11.593750</td>\n",
       "      <td>12.031250</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>17.531250</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>27.433333</td>\n",
       "      <td>63.233333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>18.233333</td>\n",
       "      <td>14.866667</td>\n",
       "      <td>20.533333</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>25.166667</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>16.766667</td>\n",
       "      <td>24.466667</td>\n",
       "      <td>62.133333</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>15.533333</td>\n",
       "      <td>12.766667</td>\n",
       "      <td>17.233333</td>\n",
       "      <td>13.466667</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>11.033333</td>\n",
       "      <td>15.866667</td>\n",
       "      <td>6.766667</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>9.233333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3332</td>\n",
       "      <td>78</td>\n",
       "      <td>3340</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>31.937500</td>\n",
       "      <td>63.625000</td>\n",
       "      <td>9.75000</td>\n",
       "      <td>23.343750</td>\n",
       "      <td>11.531250</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>10.937500</td>\n",
       "      <td>26.343750</td>\n",
       "      <td>19.031250</td>\n",
       "      <td>10.125000</td>\n",
       "      <td>6.906250</td>\n",
       "      <td>2.593750</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>24.218750</td>\n",
       "      <td>60.281250</td>\n",
       "      <td>6.656250</td>\n",
       "      <td>21.562500</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>11.68750</td>\n",
       "      <td>10.03125</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>13.687500</td>\n",
       "      <td>13.218750</td>\n",
       "      <td>4.687500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>14.875000</td>\n",
       "      <td>21.406250</td>\n",
       "      <td>25.967742</td>\n",
       "      <td>60.258065</td>\n",
       "      <td>5.838710</td>\n",
       "      <td>16.806452</td>\n",
       "      <td>12.967742</td>\n",
       "      <td>16.225806</td>\n",
       "      <td>11.064516</td>\n",
       "      <td>28.258065</td>\n",
       "      <td>17.225806</td>\n",
       "      <td>14.741935</td>\n",
       "      <td>9.580645</td>\n",
       "      <td>5.258065</td>\n",
       "      <td>14.935484</td>\n",
       "      <td>22.032258</td>\n",
       "      <td>61.870968</td>\n",
       "      <td>6.548387</td>\n",
       "      <td>21.612903</td>\n",
       "      <td>9.516129</td>\n",
       "      <td>14.290323</td>\n",
       "      <td>13.354839</td>\n",
       "      <td>24.258065</td>\n",
       "      <td>14.548387</td>\n",
       "      <td>15.903226</td>\n",
       "      <td>7.548387</td>\n",
       "      <td>1.806452</td>\n",
       "      <td>16.225806</td>\n",
       "      <td>10.612903</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3281</td>\n",
       "      <td>77</td>\n",
       "      <td>3179</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>22.757576</td>\n",
       "      <td>50.757576</td>\n",
       "      <td>8.30303</td>\n",
       "      <td>22.878788</td>\n",
       "      <td>12.151515</td>\n",
       "      <td>16.424242</td>\n",
       "      <td>9.242424</td>\n",
       "      <td>26.393939</td>\n",
       "      <td>13.969697</td>\n",
       "      <td>16.181818</td>\n",
       "      <td>5.939394</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>17.181818</td>\n",
       "      <td>21.030303</td>\n",
       "      <td>57.787879</td>\n",
       "      <td>4.848485</td>\n",
       "      <td>17.030303</td>\n",
       "      <td>11.030303</td>\n",
       "      <td>15.69697</td>\n",
       "      <td>12.30303</td>\n",
       "      <td>20.242424</td>\n",
       "      <td>8.393939</td>\n",
       "      <td>12.212121</td>\n",
       "      <td>6.757576</td>\n",
       "      <td>1.939394</td>\n",
       "      <td>18.909091</td>\n",
       "      <td>8.030303</td>\n",
       "      <td>28.406250</td>\n",
       "      <td>59.937500</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>24.437500</td>\n",
       "      <td>14.781250</td>\n",
       "      <td>19.343750</td>\n",
       "      <td>11.093750</td>\n",
       "      <td>28.562500</td>\n",
       "      <td>21.093750</td>\n",
       "      <td>17.781250</td>\n",
       "      <td>9.031250</td>\n",
       "      <td>2.562500</td>\n",
       "      <td>17.156250</td>\n",
       "      <td>24.312500</td>\n",
       "      <td>63.156250</td>\n",
       "      <td>7.187500</td>\n",
       "      <td>25.125000</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>11.468750</td>\n",
       "      <td>22.281250</td>\n",
       "      <td>13.593750</td>\n",
       "      <td>16.281250</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>19.562500</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3280</td>\n",
       "      <td>103</td>\n",
       "      <td>3380</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>32.531250</td>\n",
       "      <td>66.156250</td>\n",
       "      <td>5.25000</td>\n",
       "      <td>13.781250</td>\n",
       "      <td>15.781250</td>\n",
       "      <td>21.531250</td>\n",
       "      <td>17.343750</td>\n",
       "      <td>25.468750</td>\n",
       "      <td>16.562500</td>\n",
       "      <td>12.625000</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>5.437500</td>\n",
       "      <td>16.937500</td>\n",
       "      <td>21.093750</td>\n",
       "      <td>55.625000</td>\n",
       "      <td>5.187500</td>\n",
       "      <td>15.562500</td>\n",
       "      <td>10.375000</td>\n",
       "      <td>14.93750</td>\n",
       "      <td>11.03125</td>\n",
       "      <td>18.843750</td>\n",
       "      <td>9.281250</td>\n",
       "      <td>19.656250</td>\n",
       "      <td>5.937500</td>\n",
       "      <td>3.937500</td>\n",
       "      <td>19.968750</td>\n",
       "      <td>28.343750</td>\n",
       "      <td>21.214286</td>\n",
       "      <td>55.750000</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>16.178571</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>18.964286</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>22.857143</td>\n",
       "      <td>11.464286</td>\n",
       "      <td>18.392857</td>\n",
       "      <td>8.642857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.392857</td>\n",
       "      <td>21.071429</td>\n",
       "      <td>50.607143</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>14.392857</td>\n",
       "      <td>15.464286</td>\n",
       "      <td>25.142857</td>\n",
       "      <td>11.535714</td>\n",
       "      <td>24.714286</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>19.321429</td>\n",
       "      <td>8.214286</td>\n",
       "      <td>3.107143</td>\n",
       "      <td>19.285714</td>\n",
       "      <td>-2.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3276</td>\n",
       "      <td>84</td>\n",
       "      <td>3243</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>27.093750</td>\n",
       "      <td>60.437500</td>\n",
       "      <td>4.56250</td>\n",
       "      <td>13.937500</td>\n",
       "      <td>13.218750</td>\n",
       "      <td>18.875000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>25.656250</td>\n",
       "      <td>15.187500</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>7.312500</td>\n",
       "      <td>3.531250</td>\n",
       "      <td>17.156250</td>\n",
       "      <td>23.156250</td>\n",
       "      <td>57.562500</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>18.875000</td>\n",
       "      <td>11.468750</td>\n",
       "      <td>16.84375</td>\n",
       "      <td>10.53125</td>\n",
       "      <td>21.937500</td>\n",
       "      <td>12.687500</td>\n",
       "      <td>16.625000</td>\n",
       "      <td>7.968750</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>8.312500</td>\n",
       "      <td>23.062500</td>\n",
       "      <td>56.718750</td>\n",
       "      <td>5.656250</td>\n",
       "      <td>18.781250</td>\n",
       "      <td>13.031250</td>\n",
       "      <td>18.062500</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>24.437500</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.468750</td>\n",
       "      <td>14.562500</td>\n",
       "      <td>23.031250</td>\n",
       "      <td>60.093750</td>\n",
       "      <td>6.343750</td>\n",
       "      <td>20.156250</td>\n",
       "      <td>11.406250</td>\n",
       "      <td>15.187500</td>\n",
       "      <td>13.375000</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>13.906250</td>\n",
       "      <td>15.937500</td>\n",
       "      <td>8.218750</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  T1_TeamID  T1_Score  T2_TeamID  T2_Score  result  \\\n",
       "0    2019     137       3125        52       3376        74       0   \n",
       "1    2019     137       3332        78       3340        40       1   \n",
       "2    2019     137       3281        77       3179        76       1   \n",
       "3    2019     137       3280       103       3380        46       1   \n",
       "4    2019     137       3276        84       3243        54       1   \n",
       "\n",
       "   T1_FGM mean  T1_FGA mean  T1_FGM3 mean  T1_FGA3 mean  T1_FTM mean  \\\n",
       "0    26.968750    59.687500      10.43750     29.093750    11.312500   \n",
       "1    31.937500    63.625000       9.75000     23.343750    11.531250   \n",
       "2    22.757576    50.757576       8.30303     22.878788    12.151515   \n",
       "3    32.531250    66.156250       5.25000     13.781250    15.781250   \n",
       "4    27.093750    60.437500       4.56250     13.937500    13.218750   \n",
       "\n",
       "   T1_FTA mean  T1_OR mean  T1_DR mean  T1_Ast mean  T1_TO mean  T1_Stl mean  \\\n",
       "0    16.468750   11.812500   29.156250    16.312500   12.562500     5.562500   \n",
       "1    15.062500   10.937500   26.343750    19.031250   10.125000     6.906250   \n",
       "2    16.424242    9.242424   26.393939    13.969697   16.181818     5.939394   \n",
       "3    21.531250   17.343750   25.468750    16.562500   12.625000     8.656250   \n",
       "4    18.875000   13.750000   25.656250    15.187500   16.250000     7.312500   \n",
       "\n",
       "   T1_Blk mean  T1_PF mean  T1_opponent_FGM mean  T1_opponent_FGA mean  \\\n",
       "0     2.125000   14.656250             22.000000             60.437500   \n",
       "1     2.593750   13.000000             24.218750             60.281250   \n",
       "2     3.181818   17.181818             21.030303             57.787879   \n",
       "3     5.437500   16.937500             21.093750             55.625000   \n",
       "4     3.531250   17.156250             23.156250             57.562500   \n",
       "\n",
       "   T1_opponent_FGM3 mean  T1_opponent_FGA3 mean  T1_opponent_FTM mean  \\\n",
       "0               6.250000              20.750000              9.343750   \n",
       "1               6.656250              21.562500              8.656250   \n",
       "2               4.848485              17.030303             11.030303   \n",
       "3               5.187500              15.562500             10.375000   \n",
       "4               5.875000              18.875000             11.468750   \n",
       "\n",
       "   T1_opponent_FTA mean  T1_opponent_OR mean  T1_opponent_DR mean  \\\n",
       "0              13.46875             10.96875            23.312500   \n",
       "1              11.68750             10.03125            20.750000   \n",
       "2              15.69697             12.30303            20.242424   \n",
       "3              14.93750             11.03125            18.843750   \n",
       "4              16.84375             10.53125            21.937500   \n",
       "\n",
       "   T1_opponent_Ast mean  T1_opponent_TO mean  T1_opponent_Stl mean  \\\n",
       "0             11.593750            12.031250              5.625000   \n",
       "1             13.687500            13.218750              4.687500   \n",
       "2              8.393939            12.212121              6.757576   \n",
       "3              9.281250            19.656250              5.937500   \n",
       "4             12.687500            16.625000              7.968750   \n",
       "\n",
       "   T1_opponent_Blk mean  T1_opponent_PF mean  T1_PointDiff mean  T2_FGM mean  \\\n",
       "0              2.875000            17.531250          16.093750    27.433333   \n",
       "1              2.500000            14.875000          21.406250    25.967742   \n",
       "2              1.939394            18.909091           8.030303    28.406250   \n",
       "3              3.937500            19.968750          28.343750    21.214286   \n",
       "4              3.437500            17.750000           8.312500    23.062500   \n",
       "\n",
       "   T2_FGA mean  T2_FGM3 mean  T2_FGA3 mean  T2_FTM mean  T2_FTA mean  \\\n",
       "0    63.233333      6.000000     18.233333    14.866667    20.533333   \n",
       "1    60.258065      5.838710     16.806452    12.967742    16.225806   \n",
       "2    59.937500      8.750000     24.437500    14.781250    19.343750   \n",
       "3    55.750000      4.428571     16.178571    11.750000    18.964286   \n",
       "4    56.718750      5.656250     18.781250    13.031250    18.062500   \n",
       "\n",
       "   T2_OR mean  T2_DR mean  T2_Ast mean  T2_TO mean  T2_Stl mean  T2_Blk mean  \\\n",
       "0   13.833333   25.166667    13.100000   13.600000     8.333333     6.300000   \n",
       "1   11.064516   28.258065    17.225806   14.741935     9.580645     5.258065   \n",
       "2   11.093750   28.562500    21.093750   17.781250     9.031250     2.562500   \n",
       "3   12.750000   22.857143    11.464286   18.392857     8.642857     2.000000   \n",
       "4   10.500000   24.437500    13.000000   15.062500     8.000000     4.468750   \n",
       "\n",
       "   T2_PF mean  T2_opponent_FGM mean  T2_opponent_FGA mean  \\\n",
       "0   16.766667             24.466667             62.133333   \n",
       "1   14.935484             22.032258             61.870968   \n",
       "2   17.156250             24.312500             63.156250   \n",
       "3   22.392857             21.071429             50.607143   \n",
       "4   14.562500             23.031250             60.093750   \n",
       "\n",
       "   T2_opponent_FGM3 mean  T2_opponent_FGA3 mean  T2_opponent_FTM mean  \\\n",
       "0               4.800000              15.533333             12.766667   \n",
       "1               6.548387              21.612903              9.516129   \n",
       "2               7.187500              25.125000             11.250000   \n",
       "3               3.857143              14.392857             15.464286   \n",
       "4               6.343750              20.156250             11.406250   \n",
       "\n",
       "   T2_opponent_FTA mean  T2_opponent_OR mean  T2_opponent_DR mean  \\\n",
       "0             17.233333            13.466667            23.300000   \n",
       "1             14.290323            13.354839            24.258065   \n",
       "2             15.750000            11.468750            22.281250   \n",
       "3             25.142857            11.535714            24.714286   \n",
       "4             15.187500            13.375000            24.750000   \n",
       "\n",
       "   T2_opponent_Ast mean  T2_opponent_TO mean  T2_opponent_Stl mean  \\\n",
       "0             11.033333            15.866667              6.766667   \n",
       "1             14.548387            15.903226              7.548387   \n",
       "2             13.593750            16.281250              8.656250   \n",
       "3             11.500000            19.321429              8.214286   \n",
       "4             13.906250            15.937500              8.218750   \n",
       "\n",
       "   T2_opponent_Blk mean  T2_opponent_PF mean  T2_PointDiff mean  \\\n",
       "0              3.133333            18.900000           9.233333   \n",
       "1              1.806452            16.225806          10.612903   \n",
       "2              2.875000            19.562500          13.281250   \n",
       "3              3.107143            19.285714          -2.857143   \n",
       "4              2.812500            16.500000           1.000000   \n",
       "\n",
       "   T1_win_ratio_14d  T2_win_ratio_14d  T1_quality  T2_quality  \n",
       "0          1.000000          1.000000         NaN         NaN  \n",
       "1          0.666667          0.200000         NaN         NaN  \n",
       "2          0.666667          0.200000         NaN         NaN  \n",
       "3          1.000000          0.200000         NaN         NaN  \n",
       "4          0.500000          0.333333         NaN         NaN  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TourneyDetailedResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Seed</th>\n",
       "      <th>TeamID</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>W01</td>\n",
       "      <td>3330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>W02</td>\n",
       "      <td>3163</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>W03</td>\n",
       "      <td>3112</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>W04</td>\n",
       "      <td>3301</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>W05</td>\n",
       "      <td>3272</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season Seed  TeamID  seed\n",
       "0    1998  W01    3330     1\n",
       "1    1998  W02    3163     2\n",
       "2    1998  W03    3112     3\n",
       "3    1998  W04    3301     4\n",
       "4    1998  W05    3272     5"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TourneySeeds['seed'] = TourneySeeds['Seed'].apply(lambda x: int(x[1:3]))\n",
    "TourneySeeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneySeeds_T1 = TourneySeeds[['Season','TeamID','seed']].copy()\n",
    "TourneySeeds_T2 = TourneySeeds[['Season','TeamID','seed']].copy()\n",
    "TourneySeeds_T1.columns = ['Season','T1_TeamID','T1_seed']\n",
    "TourneySeeds_T2.columns = ['Season','T2_TeamID','T2_seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>T1_TeamID</th>\n",
       "      <th>T1_seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>3330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>3163</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>3112</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>3301</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>3272</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  T1_TeamID  T1_seed\n",
       "0    1998       3330        1\n",
       "1    1998       3163        2\n",
       "2    1998       3112        3\n",
       "3    1998       3301        4\n",
       "4    1998       3272        5"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TourneySeeds_T1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneyDetailedResults = pd.merge(TourneyDetailedResults, TourneySeeds_T1, on = ['Season', 'T1_TeamID'], how = 'left')\n",
    "TourneyDetailedResults = pd.merge(TourneyDetailedResults, TourneySeeds_T2, on = ['Season', 'T2_TeamID'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneyDetailedResults[\"Seed_diff\"] = TourneyDetailedResults[\"T1_seed\"] - TourneyDetailedResults[\"T2_seed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>T1_TeamID</th>\n",
       "      <th>T1_Score</th>\n",
       "      <th>T2_TeamID</th>\n",
       "      <th>T2_Score</th>\n",
       "      <th>result</th>\n",
       "      <th>T1_FGM mean</th>\n",
       "      <th>T1_FGA mean</th>\n",
       "      <th>T1_FGM3 mean</th>\n",
       "      <th>T1_FGA3 mean</th>\n",
       "      <th>T1_FTM mean</th>\n",
       "      <th>T1_FTA mean</th>\n",
       "      <th>T1_OR mean</th>\n",
       "      <th>T1_DR mean</th>\n",
       "      <th>T1_Ast mean</th>\n",
       "      <th>T1_TO mean</th>\n",
       "      <th>T1_Stl mean</th>\n",
       "      <th>T1_Blk mean</th>\n",
       "      <th>T1_PF mean</th>\n",
       "      <th>T1_opponent_FGM mean</th>\n",
       "      <th>T1_opponent_FGA mean</th>\n",
       "      <th>T1_opponent_FGM3 mean</th>\n",
       "      <th>T1_opponent_FGA3 mean</th>\n",
       "      <th>T1_opponent_FTM mean</th>\n",
       "      <th>T1_opponent_FTA mean</th>\n",
       "      <th>T1_opponent_OR mean</th>\n",
       "      <th>T1_opponent_DR mean</th>\n",
       "      <th>T1_opponent_Ast mean</th>\n",
       "      <th>T1_opponent_TO mean</th>\n",
       "      <th>T1_opponent_Stl mean</th>\n",
       "      <th>T1_opponent_Blk mean</th>\n",
       "      <th>T1_opponent_PF mean</th>\n",
       "      <th>T1_PointDiff mean</th>\n",
       "      <th>T2_FGM mean</th>\n",
       "      <th>T2_FGA mean</th>\n",
       "      <th>T2_FGM3 mean</th>\n",
       "      <th>T2_FGA3 mean</th>\n",
       "      <th>T2_FTM mean</th>\n",
       "      <th>T2_FTA mean</th>\n",
       "      <th>T2_OR mean</th>\n",
       "      <th>T2_DR mean</th>\n",
       "      <th>T2_Ast mean</th>\n",
       "      <th>T2_TO mean</th>\n",
       "      <th>T2_Stl mean</th>\n",
       "      <th>T2_Blk mean</th>\n",
       "      <th>T2_PF mean</th>\n",
       "      <th>T2_opponent_FGM mean</th>\n",
       "      <th>T2_opponent_FGA mean</th>\n",
       "      <th>T2_opponent_FGM3 mean</th>\n",
       "      <th>T2_opponent_FGA3 mean</th>\n",
       "      <th>T2_opponent_FTM mean</th>\n",
       "      <th>T2_opponent_FTA mean</th>\n",
       "      <th>T2_opponent_OR mean</th>\n",
       "      <th>T2_opponent_DR mean</th>\n",
       "      <th>T2_opponent_Ast mean</th>\n",
       "      <th>T2_opponent_TO mean</th>\n",
       "      <th>T2_opponent_Stl mean</th>\n",
       "      <th>T2_opponent_Blk mean</th>\n",
       "      <th>T2_opponent_PF mean</th>\n",
       "      <th>T2_PointDiff mean</th>\n",
       "      <th>T1_win_ratio_14d</th>\n",
       "      <th>T2_win_ratio_14d</th>\n",
       "      <th>T1_quality</th>\n",
       "      <th>T2_quality</th>\n",
       "      <th>T1_seed</th>\n",
       "      <th>T2_seed</th>\n",
       "      <th>Seed_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3125</td>\n",
       "      <td>52</td>\n",
       "      <td>3376</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>26.968750</td>\n",
       "      <td>59.687500</td>\n",
       "      <td>10.43750</td>\n",
       "      <td>29.093750</td>\n",
       "      <td>11.312500</td>\n",
       "      <td>16.468750</td>\n",
       "      <td>11.812500</td>\n",
       "      <td>29.156250</td>\n",
       "      <td>16.312500</td>\n",
       "      <td>12.562500</td>\n",
       "      <td>5.562500</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>14.656250</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>60.437500</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>9.343750</td>\n",
       "      <td>13.46875</td>\n",
       "      <td>10.96875</td>\n",
       "      <td>23.312500</td>\n",
       "      <td>11.593750</td>\n",
       "      <td>12.031250</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>17.531250</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>27.433333</td>\n",
       "      <td>63.233333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>18.233333</td>\n",
       "      <td>14.866667</td>\n",
       "      <td>20.533333</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>25.166667</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>16.766667</td>\n",
       "      <td>24.466667</td>\n",
       "      <td>62.133333</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>15.533333</td>\n",
       "      <td>12.766667</td>\n",
       "      <td>17.233333</td>\n",
       "      <td>13.466667</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>11.033333</td>\n",
       "      <td>15.866667</td>\n",
       "      <td>6.766667</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>9.233333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3332</td>\n",
       "      <td>78</td>\n",
       "      <td>3340</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>31.937500</td>\n",
       "      <td>63.625000</td>\n",
       "      <td>9.75000</td>\n",
       "      <td>23.343750</td>\n",
       "      <td>11.531250</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>10.937500</td>\n",
       "      <td>26.343750</td>\n",
       "      <td>19.031250</td>\n",
       "      <td>10.125000</td>\n",
       "      <td>6.906250</td>\n",
       "      <td>2.593750</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>24.218750</td>\n",
       "      <td>60.281250</td>\n",
       "      <td>6.656250</td>\n",
       "      <td>21.562500</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>11.68750</td>\n",
       "      <td>10.03125</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>13.687500</td>\n",
       "      <td>13.218750</td>\n",
       "      <td>4.687500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>14.875000</td>\n",
       "      <td>21.406250</td>\n",
       "      <td>25.967742</td>\n",
       "      <td>60.258065</td>\n",
       "      <td>5.838710</td>\n",
       "      <td>16.806452</td>\n",
       "      <td>12.967742</td>\n",
       "      <td>16.225806</td>\n",
       "      <td>11.064516</td>\n",
       "      <td>28.258065</td>\n",
       "      <td>17.225806</td>\n",
       "      <td>14.741935</td>\n",
       "      <td>9.580645</td>\n",
       "      <td>5.258065</td>\n",
       "      <td>14.935484</td>\n",
       "      <td>22.032258</td>\n",
       "      <td>61.870968</td>\n",
       "      <td>6.548387</td>\n",
       "      <td>21.612903</td>\n",
       "      <td>9.516129</td>\n",
       "      <td>14.290323</td>\n",
       "      <td>13.354839</td>\n",
       "      <td>24.258065</td>\n",
       "      <td>14.548387</td>\n",
       "      <td>15.903226</td>\n",
       "      <td>7.548387</td>\n",
       "      <td>1.806452</td>\n",
       "      <td>16.225806</td>\n",
       "      <td>10.612903</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3281</td>\n",
       "      <td>77</td>\n",
       "      <td>3179</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>22.757576</td>\n",
       "      <td>50.757576</td>\n",
       "      <td>8.30303</td>\n",
       "      <td>22.878788</td>\n",
       "      <td>12.151515</td>\n",
       "      <td>16.424242</td>\n",
       "      <td>9.242424</td>\n",
       "      <td>26.393939</td>\n",
       "      <td>13.969697</td>\n",
       "      <td>16.181818</td>\n",
       "      <td>5.939394</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>17.181818</td>\n",
       "      <td>21.030303</td>\n",
       "      <td>57.787879</td>\n",
       "      <td>4.848485</td>\n",
       "      <td>17.030303</td>\n",
       "      <td>11.030303</td>\n",
       "      <td>15.69697</td>\n",
       "      <td>12.30303</td>\n",
       "      <td>20.242424</td>\n",
       "      <td>8.393939</td>\n",
       "      <td>12.212121</td>\n",
       "      <td>6.757576</td>\n",
       "      <td>1.939394</td>\n",
       "      <td>18.909091</td>\n",
       "      <td>8.030303</td>\n",
       "      <td>28.406250</td>\n",
       "      <td>59.937500</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>24.437500</td>\n",
       "      <td>14.781250</td>\n",
       "      <td>19.343750</td>\n",
       "      <td>11.093750</td>\n",
       "      <td>28.562500</td>\n",
       "      <td>21.093750</td>\n",
       "      <td>17.781250</td>\n",
       "      <td>9.031250</td>\n",
       "      <td>2.562500</td>\n",
       "      <td>17.156250</td>\n",
       "      <td>24.312500</td>\n",
       "      <td>63.156250</td>\n",
       "      <td>7.187500</td>\n",
       "      <td>25.125000</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>11.468750</td>\n",
       "      <td>22.281250</td>\n",
       "      <td>13.593750</td>\n",
       "      <td>16.281250</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>19.562500</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3280</td>\n",
       "      <td>103</td>\n",
       "      <td>3380</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>32.531250</td>\n",
       "      <td>66.156250</td>\n",
       "      <td>5.25000</td>\n",
       "      <td>13.781250</td>\n",
       "      <td>15.781250</td>\n",
       "      <td>21.531250</td>\n",
       "      <td>17.343750</td>\n",
       "      <td>25.468750</td>\n",
       "      <td>16.562500</td>\n",
       "      <td>12.625000</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>5.437500</td>\n",
       "      <td>16.937500</td>\n",
       "      <td>21.093750</td>\n",
       "      <td>55.625000</td>\n",
       "      <td>5.187500</td>\n",
       "      <td>15.562500</td>\n",
       "      <td>10.375000</td>\n",
       "      <td>14.93750</td>\n",
       "      <td>11.03125</td>\n",
       "      <td>18.843750</td>\n",
       "      <td>9.281250</td>\n",
       "      <td>19.656250</td>\n",
       "      <td>5.937500</td>\n",
       "      <td>3.937500</td>\n",
       "      <td>19.968750</td>\n",
       "      <td>28.343750</td>\n",
       "      <td>21.214286</td>\n",
       "      <td>55.750000</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>16.178571</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>18.964286</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>22.857143</td>\n",
       "      <td>11.464286</td>\n",
       "      <td>18.392857</td>\n",
       "      <td>8.642857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.392857</td>\n",
       "      <td>21.071429</td>\n",
       "      <td>50.607143</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>14.392857</td>\n",
       "      <td>15.464286</td>\n",
       "      <td>25.142857</td>\n",
       "      <td>11.535714</td>\n",
       "      <td>24.714286</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>19.321429</td>\n",
       "      <td>8.214286</td>\n",
       "      <td>3.107143</td>\n",
       "      <td>19.285714</td>\n",
       "      <td>-2.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3276</td>\n",
       "      <td>84</td>\n",
       "      <td>3243</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>27.093750</td>\n",
       "      <td>60.437500</td>\n",
       "      <td>4.56250</td>\n",
       "      <td>13.937500</td>\n",
       "      <td>13.218750</td>\n",
       "      <td>18.875000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>25.656250</td>\n",
       "      <td>15.187500</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>7.312500</td>\n",
       "      <td>3.531250</td>\n",
       "      <td>17.156250</td>\n",
       "      <td>23.156250</td>\n",
       "      <td>57.562500</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>18.875000</td>\n",
       "      <td>11.468750</td>\n",
       "      <td>16.84375</td>\n",
       "      <td>10.53125</td>\n",
       "      <td>21.937500</td>\n",
       "      <td>12.687500</td>\n",
       "      <td>16.625000</td>\n",
       "      <td>7.968750</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>8.312500</td>\n",
       "      <td>23.062500</td>\n",
       "      <td>56.718750</td>\n",
       "      <td>5.656250</td>\n",
       "      <td>18.781250</td>\n",
       "      <td>13.031250</td>\n",
       "      <td>18.062500</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>24.437500</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.468750</td>\n",
       "      <td>14.562500</td>\n",
       "      <td>23.031250</td>\n",
       "      <td>60.093750</td>\n",
       "      <td>6.343750</td>\n",
       "      <td>20.156250</td>\n",
       "      <td>11.406250</td>\n",
       "      <td>15.187500</td>\n",
       "      <td>13.375000</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>13.906250</td>\n",
       "      <td>15.937500</td>\n",
       "      <td>8.218750</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  T1_TeamID  T1_Score  T2_TeamID  T2_Score  result  \\\n",
       "0    2019     137       3125        52       3376        74       0   \n",
       "1    2019     137       3332        78       3340        40       1   \n",
       "2    2019     137       3281        77       3179        76       1   \n",
       "3    2019     137       3280       103       3380        46       1   \n",
       "4    2019     137       3276        84       3243        54       1   \n",
       "\n",
       "   T1_FGM mean  T1_FGA mean  T1_FGM3 mean  T1_FGA3 mean  T1_FTM mean  \\\n",
       "0    26.968750    59.687500      10.43750     29.093750    11.312500   \n",
       "1    31.937500    63.625000       9.75000     23.343750    11.531250   \n",
       "2    22.757576    50.757576       8.30303     22.878788    12.151515   \n",
       "3    32.531250    66.156250       5.25000     13.781250    15.781250   \n",
       "4    27.093750    60.437500       4.56250     13.937500    13.218750   \n",
       "\n",
       "   T1_FTA mean  T1_OR mean  T1_DR mean  T1_Ast mean  T1_TO mean  T1_Stl mean  \\\n",
       "0    16.468750   11.812500   29.156250    16.312500   12.562500     5.562500   \n",
       "1    15.062500   10.937500   26.343750    19.031250   10.125000     6.906250   \n",
       "2    16.424242    9.242424   26.393939    13.969697   16.181818     5.939394   \n",
       "3    21.531250   17.343750   25.468750    16.562500   12.625000     8.656250   \n",
       "4    18.875000   13.750000   25.656250    15.187500   16.250000     7.312500   \n",
       "\n",
       "   T1_Blk mean  T1_PF mean  T1_opponent_FGM mean  T1_opponent_FGA mean  \\\n",
       "0     2.125000   14.656250             22.000000             60.437500   \n",
       "1     2.593750   13.000000             24.218750             60.281250   \n",
       "2     3.181818   17.181818             21.030303             57.787879   \n",
       "3     5.437500   16.937500             21.093750             55.625000   \n",
       "4     3.531250   17.156250             23.156250             57.562500   \n",
       "\n",
       "   T1_opponent_FGM3 mean  T1_opponent_FGA3 mean  T1_opponent_FTM mean  \\\n",
       "0               6.250000              20.750000              9.343750   \n",
       "1               6.656250              21.562500              8.656250   \n",
       "2               4.848485              17.030303             11.030303   \n",
       "3               5.187500              15.562500             10.375000   \n",
       "4               5.875000              18.875000             11.468750   \n",
       "\n",
       "   T1_opponent_FTA mean  T1_opponent_OR mean  T1_opponent_DR mean  \\\n",
       "0              13.46875             10.96875            23.312500   \n",
       "1              11.68750             10.03125            20.750000   \n",
       "2              15.69697             12.30303            20.242424   \n",
       "3              14.93750             11.03125            18.843750   \n",
       "4              16.84375             10.53125            21.937500   \n",
       "\n",
       "   T1_opponent_Ast mean  T1_opponent_TO mean  T1_opponent_Stl mean  \\\n",
       "0             11.593750            12.031250              5.625000   \n",
       "1             13.687500            13.218750              4.687500   \n",
       "2              8.393939            12.212121              6.757576   \n",
       "3              9.281250            19.656250              5.937500   \n",
       "4             12.687500            16.625000              7.968750   \n",
       "\n",
       "   T1_opponent_Blk mean  T1_opponent_PF mean  T1_PointDiff mean  T2_FGM mean  \\\n",
       "0              2.875000            17.531250          16.093750    27.433333   \n",
       "1              2.500000            14.875000          21.406250    25.967742   \n",
       "2              1.939394            18.909091           8.030303    28.406250   \n",
       "3              3.937500            19.968750          28.343750    21.214286   \n",
       "4              3.437500            17.750000           8.312500    23.062500   \n",
       "\n",
       "   T2_FGA mean  T2_FGM3 mean  T2_FGA3 mean  T2_FTM mean  T2_FTA mean  \\\n",
       "0    63.233333      6.000000     18.233333    14.866667    20.533333   \n",
       "1    60.258065      5.838710     16.806452    12.967742    16.225806   \n",
       "2    59.937500      8.750000     24.437500    14.781250    19.343750   \n",
       "3    55.750000      4.428571     16.178571    11.750000    18.964286   \n",
       "4    56.718750      5.656250     18.781250    13.031250    18.062500   \n",
       "\n",
       "   T2_OR mean  T2_DR mean  T2_Ast mean  T2_TO mean  T2_Stl mean  T2_Blk mean  \\\n",
       "0   13.833333   25.166667    13.100000   13.600000     8.333333     6.300000   \n",
       "1   11.064516   28.258065    17.225806   14.741935     9.580645     5.258065   \n",
       "2   11.093750   28.562500    21.093750   17.781250     9.031250     2.562500   \n",
       "3   12.750000   22.857143    11.464286   18.392857     8.642857     2.000000   \n",
       "4   10.500000   24.437500    13.000000   15.062500     8.000000     4.468750   \n",
       "\n",
       "   T2_PF mean  T2_opponent_FGM mean  T2_opponent_FGA mean  \\\n",
       "0   16.766667             24.466667             62.133333   \n",
       "1   14.935484             22.032258             61.870968   \n",
       "2   17.156250             24.312500             63.156250   \n",
       "3   22.392857             21.071429             50.607143   \n",
       "4   14.562500             23.031250             60.093750   \n",
       "\n",
       "   T2_opponent_FGM3 mean  T2_opponent_FGA3 mean  T2_opponent_FTM mean  \\\n",
       "0               4.800000              15.533333             12.766667   \n",
       "1               6.548387              21.612903              9.516129   \n",
       "2               7.187500              25.125000             11.250000   \n",
       "3               3.857143              14.392857             15.464286   \n",
       "4               6.343750              20.156250             11.406250   \n",
       "\n",
       "   T2_opponent_FTA mean  T2_opponent_OR mean  T2_opponent_DR mean  \\\n",
       "0             17.233333            13.466667            23.300000   \n",
       "1             14.290323            13.354839            24.258065   \n",
       "2             15.750000            11.468750            22.281250   \n",
       "3             25.142857            11.535714            24.714286   \n",
       "4             15.187500            13.375000            24.750000   \n",
       "\n",
       "   T2_opponent_Ast mean  T2_opponent_TO mean  T2_opponent_Stl mean  \\\n",
       "0             11.033333            15.866667              6.766667   \n",
       "1             14.548387            15.903226              7.548387   \n",
       "2             13.593750            16.281250              8.656250   \n",
       "3             11.500000            19.321429              8.214286   \n",
       "4             13.906250            15.937500              8.218750   \n",
       "\n",
       "   T2_opponent_Blk mean  T2_opponent_PF mean  T2_PointDiff mean  \\\n",
       "0              3.133333            18.900000           9.233333   \n",
       "1              1.806452            16.225806          10.612903   \n",
       "2              2.875000            19.562500          13.281250   \n",
       "3              3.107143            19.285714          -2.857143   \n",
       "4              2.812500            16.500000           1.000000   \n",
       "\n",
       "   T1_win_ratio_14d  T2_win_ratio_14d  T1_quality  T2_quality  T1_seed  \\\n",
       "0          1.000000          1.000000         NaN         NaN       13   \n",
       "1          0.666667          0.200000         NaN         NaN        2   \n",
       "2          0.666667          0.200000         NaN         NaN        7   \n",
       "3          1.000000          0.200000         NaN         NaN        1   \n",
       "4          0.500000          0.333333         NaN         NaN        8   \n",
       "\n",
       "   T2_seed  Seed_diff  \n",
       "0        4          9  \n",
       "1       15        -13  \n",
       "2       10         -3  \n",
       "3       16        -15  \n",
       "4        9         -1  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TourneyDetailedResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(SeasonDetailedResults_Stat_T1.columns[2:999]) + \\\n",
    "    list(SeasonDetailedResults_Stat_T2.columns[2:999]) + \\\n",
    "    list(TourneySeeds_T1.columns[2:999]) + \\\n",
    "    list(TourneySeeds_T2.columns[2:999]) + \\\n",
    "    list(last14days_stats_T1.columns[2:999]) + \\\n",
    "    list(last14days_stats_T2.columns[2:999]) + \\\n",
    "    [\"Seed_diff\"] + [\"T1_quality\",\"T2_quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T1_FGM mean',\n",
       " 'T1_FGA mean',\n",
       " 'T1_FGM3 mean',\n",
       " 'T1_FGA3 mean',\n",
       " 'T1_FTM mean',\n",
       " 'T1_FTA mean',\n",
       " 'T1_OR mean',\n",
       " 'T1_DR mean',\n",
       " 'T1_Ast mean',\n",
       " 'T1_TO mean',\n",
       " 'T1_Stl mean',\n",
       " 'T1_Blk mean',\n",
       " 'T1_PF mean',\n",
       " 'T1_opponent_FGM mean',\n",
       " 'T1_opponent_FGA mean',\n",
       " 'T1_opponent_FGM3 mean',\n",
       " 'T1_opponent_FGA3 mean',\n",
       " 'T1_opponent_FTM mean',\n",
       " 'T1_opponent_FTA mean',\n",
       " 'T1_opponent_OR mean',\n",
       " 'T1_opponent_DR mean',\n",
       " 'T1_opponent_Ast mean',\n",
       " 'T1_opponent_TO mean',\n",
       " 'T1_opponent_Stl mean',\n",
       " 'T1_opponent_Blk mean',\n",
       " 'T1_opponent_PF mean',\n",
       " 'T1_PointDiff mean',\n",
       " 'T2_FGM mean',\n",
       " 'T2_FGA mean',\n",
       " 'T2_FGM3 mean',\n",
       " 'T2_FGA3 mean',\n",
       " 'T2_FTM mean',\n",
       " 'T2_FTA mean',\n",
       " 'T2_OR mean',\n",
       " 'T2_DR mean',\n",
       " 'T2_Ast mean',\n",
       " 'T2_TO mean',\n",
       " 'T2_Stl mean',\n",
       " 'T2_Blk mean',\n",
       " 'T2_PF mean',\n",
       " 'T2_opponent_FGM mean',\n",
       " 'T2_opponent_FGA mean',\n",
       " 'T2_opponent_FGM3 mean',\n",
       " 'T2_opponent_FGA3 mean',\n",
       " 'T2_opponent_FTM mean',\n",
       " 'T2_opponent_FTA mean',\n",
       " 'T2_opponent_OR mean',\n",
       " 'T2_opponent_DR mean',\n",
       " 'T2_opponent_Ast mean',\n",
       " 'T2_opponent_TO mean',\n",
       " 'T2_opponent_Stl mean',\n",
       " 'T2_opponent_Blk mean',\n",
       " 'T2_opponent_PF mean',\n",
       " 'T2_PointDiff mean',\n",
       " 'T1_seed',\n",
       " 'T2_seed',\n",
       " 'T1_win_ratio_14d',\n",
       " 'T2_win_ratio_14d',\n",
       " 'Seed_diff',\n",
       " 'T1_quality',\n",
       " 'T2_quality']"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do same for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.rename(columns={\"WTeamID\": \"T1_TeamID\", \"LTeamID\": \"T2_TeamID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>T1_TeamID</th>\n",
       "      <th>T2_TeamID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Season  T1_TeamID  T2_TeamID\n",
       "0  2015_3106_3107    2015       3106       3107\n",
       "1  2015_3106_3110    2015       3106       3110\n",
       "2  2015_3106_3113    2015       3106       3113\n",
       "3  2015_3106_3114    2015       3106       3114\n",
       "4  2015_3106_3116    2015       3106       3116"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>T1_TeamID</th>\n",
       "      <th>T2_TeamID</th>\n",
       "      <th>T1_FGM mean</th>\n",
       "      <th>T1_FGA mean</th>\n",
       "      <th>T1_FGM3 mean</th>\n",
       "      <th>T1_FGA3 mean</th>\n",
       "      <th>T1_FTM mean</th>\n",
       "      <th>T1_FTA mean</th>\n",
       "      <th>T1_OR mean</th>\n",
       "      <th>T1_DR mean</th>\n",
       "      <th>T1_Ast mean</th>\n",
       "      <th>T1_TO mean</th>\n",
       "      <th>T1_Stl mean</th>\n",
       "      <th>T1_Blk mean</th>\n",
       "      <th>T1_PF mean</th>\n",
       "      <th>T1_opponent_FGM mean</th>\n",
       "      <th>T1_opponent_FGA mean</th>\n",
       "      <th>T1_opponent_FGM3 mean</th>\n",
       "      <th>T1_opponent_FGA3 mean</th>\n",
       "      <th>T1_opponent_FTM mean</th>\n",
       "      <th>T1_opponent_FTA mean</th>\n",
       "      <th>T1_opponent_OR mean</th>\n",
       "      <th>T1_opponent_DR mean</th>\n",
       "      <th>T1_opponent_Ast mean</th>\n",
       "      <th>T1_opponent_TO mean</th>\n",
       "      <th>T1_opponent_Stl mean</th>\n",
       "      <th>T1_opponent_Blk mean</th>\n",
       "      <th>T1_opponent_PF mean</th>\n",
       "      <th>T1_PointDiff mean</th>\n",
       "      <th>T2_FGM mean</th>\n",
       "      <th>T2_FGA mean</th>\n",
       "      <th>T2_FGM3 mean</th>\n",
       "      <th>T2_FGA3 mean</th>\n",
       "      <th>T2_FTM mean</th>\n",
       "      <th>T2_FTA mean</th>\n",
       "      <th>T2_OR mean</th>\n",
       "      <th>T2_DR mean</th>\n",
       "      <th>T2_Ast mean</th>\n",
       "      <th>T2_TO mean</th>\n",
       "      <th>T2_Stl mean</th>\n",
       "      <th>T2_Blk mean</th>\n",
       "      <th>T2_PF mean</th>\n",
       "      <th>T2_opponent_FGM mean</th>\n",
       "      <th>T2_opponent_FGA mean</th>\n",
       "      <th>T2_opponent_FGM3 mean</th>\n",
       "      <th>T2_opponent_FGA3 mean</th>\n",
       "      <th>T2_opponent_FTM mean</th>\n",
       "      <th>T2_opponent_FTA mean</th>\n",
       "      <th>T2_opponent_OR mean</th>\n",
       "      <th>T2_opponent_DR mean</th>\n",
       "      <th>T2_opponent_Ast mean</th>\n",
       "      <th>T2_opponent_TO mean</th>\n",
       "      <th>T2_opponent_Stl mean</th>\n",
       "      <th>T2_opponent_Blk mean</th>\n",
       "      <th>T2_opponent_PF mean</th>\n",
       "      <th>T2_PointDiff mean</th>\n",
       "      <th>T1_seed</th>\n",
       "      <th>T2_seed</th>\n",
       "      <th>T1_win_ratio_14d</th>\n",
       "      <th>T2_win_ratio_14d</th>\n",
       "      <th>Seed_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3107</td>\n",
       "      <td>20.464286</td>\n",
       "      <td>56.821429</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>15.678571</td>\n",
       "      <td>14.642857</td>\n",
       "      <td>23.321429</td>\n",
       "      <td>14.392857</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>11.821429</td>\n",
       "      <td>19.428571</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>4.75</td>\n",
       "      <td>22.25</td>\n",
       "      <td>21.321429</td>\n",
       "      <td>59.25</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>13.928571</td>\n",
       "      <td>15.071429</td>\n",
       "      <td>24.857143</td>\n",
       "      <td>14.714286</td>\n",
       "      <td>26.428571</td>\n",
       "      <td>10.142857</td>\n",
       "      <td>16.678571</td>\n",
       "      <td>9.25</td>\n",
       "      <td>2.464286</td>\n",
       "      <td>20.392857</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>25.935484</td>\n",
       "      <td>54.322581</td>\n",
       "      <td>2.064516</td>\n",
       "      <td>7.096774</td>\n",
       "      <td>15.064516</td>\n",
       "      <td>21.516129</td>\n",
       "      <td>13.129032</td>\n",
       "      <td>23.161290</td>\n",
       "      <td>15.193548</td>\n",
       "      <td>16.935484</td>\n",
       "      <td>10.741935</td>\n",
       "      <td>1.677419</td>\n",
       "      <td>18.290323</td>\n",
       "      <td>19.451613</td>\n",
       "      <td>49.612903</td>\n",
       "      <td>5.838710</td>\n",
       "      <td>17.483871</td>\n",
       "      <td>10.709677</td>\n",
       "      <td>16.258065</td>\n",
       "      <td>10.064516</td>\n",
       "      <td>19.161290</td>\n",
       "      <td>12.645161</td>\n",
       "      <td>20.096774</td>\n",
       "      <td>7.354839</td>\n",
       "      <td>3.870968</td>\n",
       "      <td>20.032258</td>\n",
       "      <td>13.548387</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3110</td>\n",
       "      <td>20.464286</td>\n",
       "      <td>56.821429</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>15.678571</td>\n",
       "      <td>14.642857</td>\n",
       "      <td>23.321429</td>\n",
       "      <td>14.392857</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>11.821429</td>\n",
       "      <td>19.428571</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>4.75</td>\n",
       "      <td>22.25</td>\n",
       "      <td>21.321429</td>\n",
       "      <td>59.25</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>13.928571</td>\n",
       "      <td>15.071429</td>\n",
       "      <td>24.857143</td>\n",
       "      <td>14.714286</td>\n",
       "      <td>26.428571</td>\n",
       "      <td>10.142857</td>\n",
       "      <td>16.678571</td>\n",
       "      <td>9.25</td>\n",
       "      <td>2.464286</td>\n",
       "      <td>20.392857</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>23.687500</td>\n",
       "      <td>53.531250</td>\n",
       "      <td>4.468750</td>\n",
       "      <td>13.781250</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>15.875000</td>\n",
       "      <td>8.593750</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>15.406250</td>\n",
       "      <td>12.906250</td>\n",
       "      <td>6.843750</td>\n",
       "      <td>2.843750</td>\n",
       "      <td>15.781250</td>\n",
       "      <td>20.531250</td>\n",
       "      <td>55.031250</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>15.312500</td>\n",
       "      <td>11.406250</td>\n",
       "      <td>16.218750</td>\n",
       "      <td>12.125000</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>11.312500</td>\n",
       "      <td>14.843750</td>\n",
       "      <td>5.468750</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>16.312500</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3113</td>\n",
       "      <td>20.464286</td>\n",
       "      <td>56.821429</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>15.678571</td>\n",
       "      <td>14.642857</td>\n",
       "      <td>23.321429</td>\n",
       "      <td>14.392857</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>11.821429</td>\n",
       "      <td>19.428571</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>4.75</td>\n",
       "      <td>22.25</td>\n",
       "      <td>21.321429</td>\n",
       "      <td>59.25</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>13.928571</td>\n",
       "      <td>15.071429</td>\n",
       "      <td>24.857143</td>\n",
       "      <td>14.714286</td>\n",
       "      <td>26.428571</td>\n",
       "      <td>10.142857</td>\n",
       "      <td>16.678571</td>\n",
       "      <td>9.25</td>\n",
       "      <td>2.464286</td>\n",
       "      <td>20.392857</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>57.125000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>13.187500</td>\n",
       "      <td>18.593750</td>\n",
       "      <td>13.343750</td>\n",
       "      <td>23.281250</td>\n",
       "      <td>14.656250</td>\n",
       "      <td>13.906250</td>\n",
       "      <td>8.093750</td>\n",
       "      <td>2.187500</td>\n",
       "      <td>15.281250</td>\n",
       "      <td>21.625000</td>\n",
       "      <td>51.875000</td>\n",
       "      <td>2.843750</td>\n",
       "      <td>11.187500</td>\n",
       "      <td>9.531250</td>\n",
       "      <td>13.656250</td>\n",
       "      <td>9.343750</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>9.218750</td>\n",
       "      <td>16.875000</td>\n",
       "      <td>6.468750</td>\n",
       "      <td>3.906250</td>\n",
       "      <td>17.656250</td>\n",
       "      <td>12.312500</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3114</td>\n",
       "      <td>20.464286</td>\n",
       "      <td>56.821429</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>15.678571</td>\n",
       "      <td>14.642857</td>\n",
       "      <td>23.321429</td>\n",
       "      <td>14.392857</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>11.821429</td>\n",
       "      <td>19.428571</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>4.75</td>\n",
       "      <td>22.25</td>\n",
       "      <td>21.321429</td>\n",
       "      <td>59.25</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>13.928571</td>\n",
       "      <td>15.071429</td>\n",
       "      <td>24.857143</td>\n",
       "      <td>14.714286</td>\n",
       "      <td>26.428571</td>\n",
       "      <td>10.142857</td>\n",
       "      <td>16.678571</td>\n",
       "      <td>9.25</td>\n",
       "      <td>2.464286</td>\n",
       "      <td>20.392857</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>24.218750</td>\n",
       "      <td>54.281250</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.718750</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>11.968750</td>\n",
       "      <td>22.875000</td>\n",
       "      <td>13.968750</td>\n",
       "      <td>14.156250</td>\n",
       "      <td>8.562500</td>\n",
       "      <td>2.687500</td>\n",
       "      <td>18.125000</td>\n",
       "      <td>18.593750</td>\n",
       "      <td>50.312500</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>11.281250</td>\n",
       "      <td>10.718750</td>\n",
       "      <td>16.187500</td>\n",
       "      <td>11.718750</td>\n",
       "      <td>21.593750</td>\n",
       "      <td>8.218750</td>\n",
       "      <td>19.718750</td>\n",
       "      <td>5.031250</td>\n",
       "      <td>2.218750</td>\n",
       "      <td>18.531250</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3116</td>\n",
       "      <td>20.464286</td>\n",
       "      <td>56.821429</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>15.678571</td>\n",
       "      <td>14.642857</td>\n",
       "      <td>23.321429</td>\n",
       "      <td>14.392857</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>11.821429</td>\n",
       "      <td>19.428571</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>4.75</td>\n",
       "      <td>22.25</td>\n",
       "      <td>21.321429</td>\n",
       "      <td>59.25</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>13.928571</td>\n",
       "      <td>15.071429</td>\n",
       "      <td>24.857143</td>\n",
       "      <td>14.714286</td>\n",
       "      <td>26.428571</td>\n",
       "      <td>10.142857</td>\n",
       "      <td>16.678571</td>\n",
       "      <td>9.25</td>\n",
       "      <td>2.464286</td>\n",
       "      <td>20.392857</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>20.766667</td>\n",
       "      <td>55.766667</td>\n",
       "      <td>4.966667</td>\n",
       "      <td>16.366667</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>21.033333</td>\n",
       "      <td>13.366667</td>\n",
       "      <td>26.933333</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>17.233333</td>\n",
       "      <td>20.066667</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>4.033333</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>11.233333</td>\n",
       "      <td>17.133333</td>\n",
       "      <td>11.266667</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>9.833333</td>\n",
       "      <td>13.466667</td>\n",
       "      <td>6.466667</td>\n",
       "      <td>4.766667</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Season  T1_TeamID  T2_TeamID  T1_FGM mean  T1_FGA mean  \\\n",
       "0  2015_3106_3107    2015       3106       3107    20.464286    56.821429   \n",
       "1  2015_3106_3110    2015       3106       3110    20.464286    56.821429   \n",
       "2  2015_3106_3113    2015       3106       3113    20.464286    56.821429   \n",
       "3  2015_3106_3114    2015       3106       3114    20.464286    56.821429   \n",
       "4  2015_3106_3116    2015       3106       3116    20.464286    56.821429   \n",
       "\n",
       "   T1_FGM3 mean  T1_FGA3 mean  T1_FTM mean  T1_FTA mean  T1_OR mean  \\\n",
       "0      4.857143     15.678571    14.642857    23.321429   14.392857   \n",
       "1      4.857143     15.678571    14.642857    23.321429   14.392857   \n",
       "2      4.857143     15.678571    14.642857    23.321429   14.392857   \n",
       "3      4.857143     15.678571    14.642857    23.321429   14.392857   \n",
       "4      4.857143     15.678571    14.642857    23.321429   14.392857   \n",
       "\n",
       "   T1_DR mean  T1_Ast mean  T1_TO mean  T1_Stl mean  T1_Blk mean  T1_PF mean  \\\n",
       "0   28.571429    11.821429   19.428571     6.857143         4.75       22.25   \n",
       "1   28.571429    11.821429   19.428571     6.857143         4.75       22.25   \n",
       "2   28.571429    11.821429   19.428571     6.857143         4.75       22.25   \n",
       "3   28.571429    11.821429   19.428571     6.857143         4.75       22.25   \n",
       "4   28.571429    11.821429   19.428571     6.857143         4.75       22.25   \n",
       "\n",
       "   T1_opponent_FGM mean  T1_opponent_FGA mean  T1_opponent_FGM3 mean  \\\n",
       "0             21.321429                 59.25               3.428571   \n",
       "1             21.321429                 59.25               3.428571   \n",
       "2             21.321429                 59.25               3.428571   \n",
       "3             21.321429                 59.25               3.428571   \n",
       "4             21.321429                 59.25               3.428571   \n",
       "\n",
       "   T1_opponent_FGA3 mean  T1_opponent_FTM mean  T1_opponent_FTA mean  \\\n",
       "0              13.928571             15.071429             24.857143   \n",
       "1              13.928571             15.071429             24.857143   \n",
       "2              13.928571             15.071429             24.857143   \n",
       "3              13.928571             15.071429             24.857143   \n",
       "4              13.928571             15.071429             24.857143   \n",
       "\n",
       "   T1_opponent_OR mean  T1_opponent_DR mean  T1_opponent_Ast mean  \\\n",
       "0            14.714286            26.428571             10.142857   \n",
       "1            14.714286            26.428571             10.142857   \n",
       "2            14.714286            26.428571             10.142857   \n",
       "3            14.714286            26.428571             10.142857   \n",
       "4            14.714286            26.428571             10.142857   \n",
       "\n",
       "   T1_opponent_TO mean  T1_opponent_Stl mean  T1_opponent_Blk mean  \\\n",
       "0            16.678571                  9.25              2.464286   \n",
       "1            16.678571                  9.25              2.464286   \n",
       "2            16.678571                  9.25              2.464286   \n",
       "3            16.678571                  9.25              2.464286   \n",
       "4            16.678571                  9.25              2.464286   \n",
       "\n",
       "   T1_opponent_PF mean  T1_PointDiff mean  T2_FGM mean  T2_FGA mean  \\\n",
       "0            20.392857          -0.714286    25.935484    54.322581   \n",
       "1            20.392857          -0.714286    23.687500    53.531250   \n",
       "2            20.392857          -0.714286    25.000000    57.125000   \n",
       "3            20.392857          -0.714286    24.218750    54.281250   \n",
       "4            20.392857          -0.714286    20.766667    55.766667   \n",
       "\n",
       "   T2_FGM3 mean  T2_FGA3 mean  T2_FTM mean  T2_FTA mean  T2_OR mean  \\\n",
       "0      2.064516      7.096774    15.064516    21.516129   13.129032   \n",
       "1      4.468750     13.781250    11.500000    15.875000    8.593750   \n",
       "2      4.750000     13.281250    13.187500    18.593750   13.343750   \n",
       "3      4.125000     11.000000    12.718750    19.000000   11.968750   \n",
       "4      4.966667     16.366667    13.800000    21.033333   13.366667   \n",
       "\n",
       "   T2_DR mean  T2_Ast mean  T2_TO mean  T2_Stl mean  T2_Blk mean  T2_PF mean  \\\n",
       "0   23.161290    15.193548   16.935484    10.741935     1.677419   18.290323   \n",
       "1   24.500000    15.406250   12.906250     6.843750     2.843750   15.781250   \n",
       "2   23.281250    14.656250   13.906250     8.093750     2.187500   15.281250   \n",
       "3   22.875000    13.968750   14.156250     8.562500     2.687500   18.125000   \n",
       "4   26.933333    11.800000   13.400000     6.400000     3.566667   17.233333   \n",
       "\n",
       "   T2_opponent_FGM mean  T2_opponent_FGA mean  T2_opponent_FGM3 mean  \\\n",
       "0             19.451613             49.612903               5.838710   \n",
       "1             20.531250             55.031250               4.750000   \n",
       "2             21.625000             51.875000               2.843750   \n",
       "3             18.593750             50.312500               3.125000   \n",
       "4             20.066667             55.500000               4.033333   \n",
       "\n",
       "   T2_opponent_FGA3 mean  T2_opponent_FTM mean  T2_opponent_FTA mean  \\\n",
       "0              17.483871             10.709677             16.258065   \n",
       "1              15.312500             11.406250             16.218750   \n",
       "2              11.187500              9.531250             13.656250   \n",
       "3              11.281250             10.718750             16.187500   \n",
       "4              14.100000             11.233333             17.133333   \n",
       "\n",
       "   T2_opponent_OR mean  T2_opponent_DR mean  T2_opponent_Ast mean  \\\n",
       "0            10.064516            19.161290             12.645161   \n",
       "1            12.125000            23.250000             11.312500   \n",
       "2             9.343750            22.000000              9.218750   \n",
       "3            11.718750            21.593750              8.218750   \n",
       "4            11.266667            24.333333              9.833333   \n",
       "\n",
       "   T2_opponent_TO mean  T2_opponent_Stl mean  T2_opponent_Blk mean  \\\n",
       "0            20.096774              7.354839              3.870968   \n",
       "1            14.843750              5.468750              2.625000   \n",
       "2            16.875000              6.468750              3.906250   \n",
       "3            19.718750              5.031250              2.218750   \n",
       "4            13.466667              6.466667              4.766667   \n",
       "\n",
       "   T2_opponent_PF mean  T2_PointDiff mean  T1_seed  T2_seed  T1_win_ratio_14d  \\\n",
       "0            20.032258          13.548387       15       13          0.833333   \n",
       "1            16.312500           6.125000       15       14          0.833333   \n",
       "2            17.656250          12.312500       15        3          0.833333   \n",
       "3            18.531250          14.250000       15       11          0.833333   \n",
       "4            18.900000           4.900000       15       10          0.833333   \n",
       "\n",
       "   T2_win_ratio_14d  Seed_diff  \n",
       "0               0.0          2  \n",
       "1               0.0          1  \n",
       "2               0.5         12  \n",
       "3               0.0          4  \n",
       "4               0.5          5  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.merge(test, SeasonDetailedResults_Stat_T1, on = ['Season', 'T1_TeamID'],how = 'left')\n",
    "test = pd.merge(test, SeasonDetailedResults_Stat_T2, on = ['Season', 'T2_TeamID'],how = 'left')\n",
    "test = pd.merge(test, glm_quality_T1, on = ['Season', 'T1_TeamID'],how = 'left')\n",
    "test = pd.merge(test, glm_quality_T2, on = ['Season', 'T2_TeamID'],how = 'left')\n",
    "test = pd.merge(test, TourneySeeds_T1, on = ['Season', 'T1_TeamID'],how = 'left')\n",
    "test = pd.merge(test, TourneySeeds_T2, on = ['Season', 'T2_TeamID'],how = 'left')\n",
    "test = pd.merge(test, last14days_stats_T1, on = ['Season', 'T1_TeamID'],how = 'left')\n",
    "test = pd.merge(test, last14days_stats_T2, on = ['Season', 'T2_TeamID'],how = 'left')\n",
    "test[\"Seed_diff\"] = test[\"T1_seed\"] - test[\"T2_seed\"]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with WSeasons\n",
    "columns2 = Seasons.columns.difference(TourneyDetailedResults.columns).tolist() + [\"Season\"]\n",
    "TourneyDetailedResults = TourneyDetailedResults.merge(Seasons[columns2], how=\"left\", on=\"Season\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneyDetailedResults = TourneyDetailedResults.drop(['RegionW','RegionX','RegionY','RegionZ'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneyDetailedResults = TourneyDetailedResults.sort_values(by=['DayZero', 'DayNum']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>T1_TeamID</th>\n",
       "      <th>T1_Score</th>\n",
       "      <th>T2_TeamID</th>\n",
       "      <th>T2_Score</th>\n",
       "      <th>result</th>\n",
       "      <th>T1_FGM mean</th>\n",
       "      <th>T1_FGA mean</th>\n",
       "      <th>T1_FGM3 mean</th>\n",
       "      <th>T1_FGA3 mean</th>\n",
       "      <th>T1_FTM mean</th>\n",
       "      <th>T1_FTA mean</th>\n",
       "      <th>T1_OR mean</th>\n",
       "      <th>T1_DR mean</th>\n",
       "      <th>T1_Ast mean</th>\n",
       "      <th>T1_TO mean</th>\n",
       "      <th>T1_Stl mean</th>\n",
       "      <th>T1_Blk mean</th>\n",
       "      <th>T1_PF mean</th>\n",
       "      <th>T1_opponent_FGM mean</th>\n",
       "      <th>T1_opponent_FGA mean</th>\n",
       "      <th>T1_opponent_FGM3 mean</th>\n",
       "      <th>T1_opponent_FGA3 mean</th>\n",
       "      <th>T1_opponent_FTM mean</th>\n",
       "      <th>T1_opponent_FTA mean</th>\n",
       "      <th>T1_opponent_OR mean</th>\n",
       "      <th>T1_opponent_DR mean</th>\n",
       "      <th>T1_opponent_Ast mean</th>\n",
       "      <th>T1_opponent_TO mean</th>\n",
       "      <th>T1_opponent_Stl mean</th>\n",
       "      <th>T1_opponent_Blk mean</th>\n",
       "      <th>T1_opponent_PF mean</th>\n",
       "      <th>T1_PointDiff mean</th>\n",
       "      <th>T2_FGM mean</th>\n",
       "      <th>T2_FGA mean</th>\n",
       "      <th>T2_FGM3 mean</th>\n",
       "      <th>T2_FGA3 mean</th>\n",
       "      <th>T2_FTM mean</th>\n",
       "      <th>T2_FTA mean</th>\n",
       "      <th>T2_OR mean</th>\n",
       "      <th>T2_DR mean</th>\n",
       "      <th>T2_Ast mean</th>\n",
       "      <th>T2_TO mean</th>\n",
       "      <th>T2_Stl mean</th>\n",
       "      <th>T2_Blk mean</th>\n",
       "      <th>T2_PF mean</th>\n",
       "      <th>T2_opponent_FGM mean</th>\n",
       "      <th>T2_opponent_FGA mean</th>\n",
       "      <th>T2_opponent_FGM3 mean</th>\n",
       "      <th>T2_opponent_FGA3 mean</th>\n",
       "      <th>T2_opponent_FTM mean</th>\n",
       "      <th>T2_opponent_FTA mean</th>\n",
       "      <th>T2_opponent_OR mean</th>\n",
       "      <th>T2_opponent_DR mean</th>\n",
       "      <th>T2_opponent_Ast mean</th>\n",
       "      <th>T2_opponent_TO mean</th>\n",
       "      <th>T2_opponent_Stl mean</th>\n",
       "      <th>T2_opponent_Blk mean</th>\n",
       "      <th>T2_opponent_PF mean</th>\n",
       "      <th>T2_PointDiff mean</th>\n",
       "      <th>T1_win_ratio_14d</th>\n",
       "      <th>T2_win_ratio_14d</th>\n",
       "      <th>T1_quality</th>\n",
       "      <th>T2_quality</th>\n",
       "      <th>T1_seed</th>\n",
       "      <th>T2_seed</th>\n",
       "      <th>Seed_diff</th>\n",
       "      <th>DayZero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>137</td>\n",
       "      <td>3438</td>\n",
       "      <td>68</td>\n",
       "      <td>3143</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>22.967742</td>\n",
       "      <td>56.516129</td>\n",
       "      <td>5.967742</td>\n",
       "      <td>17.354839</td>\n",
       "      <td>10.225806</td>\n",
       "      <td>14.225806</td>\n",
       "      <td>11.548387</td>\n",
       "      <td>25.258065</td>\n",
       "      <td>12.806452</td>\n",
       "      <td>16.161290</td>\n",
       "      <td>6.677419</td>\n",
       "      <td>4.064516</td>\n",
       "      <td>16.161290</td>\n",
       "      <td>22.258065</td>\n",
       "      <td>57.935484</td>\n",
       "      <td>6.225806</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.290323</td>\n",
       "      <td>14.838710</td>\n",
       "      <td>12.258065</td>\n",
       "      <td>23.419355</td>\n",
       "      <td>11.580645</td>\n",
       "      <td>14.967742</td>\n",
       "      <td>8.258065</td>\n",
       "      <td>2.838710</td>\n",
       "      <td>15.903226</td>\n",
       "      <td>1.096774</td>\n",
       "      <td>26.612903</td>\n",
       "      <td>58.580645</td>\n",
       "      <td>5.161290</td>\n",
       "      <td>15.354839</td>\n",
       "      <td>10.870968</td>\n",
       "      <td>15.774194</td>\n",
       "      <td>12.451613</td>\n",
       "      <td>25.838710</td>\n",
       "      <td>15.741935</td>\n",
       "      <td>14.903226</td>\n",
       "      <td>5.838710</td>\n",
       "      <td>3.225806</td>\n",
       "      <td>15.290323</td>\n",
       "      <td>24.483871</td>\n",
       "      <td>61.677419</td>\n",
       "      <td>6.645161</td>\n",
       "      <td>20.741935</td>\n",
       "      <td>10.258065</td>\n",
       "      <td>14.161290</td>\n",
       "      <td>11.967742</td>\n",
       "      <td>20.903226</td>\n",
       "      <td>15.096774</td>\n",
       "      <td>12.322581</td>\n",
       "      <td>6.516129</td>\n",
       "      <td>3.096774</td>\n",
       "      <td>14.870968</td>\n",
       "      <td>3.387097</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.778895e+15</td>\n",
       "      <td>2.255687e+15</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>10/30/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>137</td>\n",
       "      <td>3437</td>\n",
       "      <td>81</td>\n",
       "      <td>3355</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>57.033333</td>\n",
       "      <td>8.733333</td>\n",
       "      <td>26.566667</td>\n",
       "      <td>8.966667</td>\n",
       "      <td>12.133333</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>26.533333</td>\n",
       "      <td>14.066667</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>22.833333</td>\n",
       "      <td>59.800000</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>16.733333</td>\n",
       "      <td>9.033333</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>25.066667</td>\n",
       "      <td>10.733333</td>\n",
       "      <td>9.833333</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>14.466667</td>\n",
       "      <td>7.566667</td>\n",
       "      <td>28.064516</td>\n",
       "      <td>61.774194</td>\n",
       "      <td>8.741935</td>\n",
       "      <td>23.806452</td>\n",
       "      <td>13.548387</td>\n",
       "      <td>17.193548</td>\n",
       "      <td>12.322581</td>\n",
       "      <td>28.387097</td>\n",
       "      <td>16.838710</td>\n",
       "      <td>13.129032</td>\n",
       "      <td>7.290323</td>\n",
       "      <td>3.838710</td>\n",
       "      <td>15.129032</td>\n",
       "      <td>22.193548</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.677419</td>\n",
       "      <td>21.516129</td>\n",
       "      <td>10.516129</td>\n",
       "      <td>14.967742</td>\n",
       "      <td>10.129032</td>\n",
       "      <td>22.806452</td>\n",
       "      <td>11.709677</td>\n",
       "      <td>14.483871</td>\n",
       "      <td>7.258065</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>17.677419</td>\n",
       "      <td>16.838710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.725910e+16</td>\n",
       "      <td>1.016626e+16</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>10/30/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>137</td>\n",
       "      <td>3401</td>\n",
       "      <td>89</td>\n",
       "      <td>3179</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>28.090909</td>\n",
       "      <td>61.969697</td>\n",
       "      <td>4.454545</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>16.424242</td>\n",
       "      <td>21.090909</td>\n",
       "      <td>14.575758</td>\n",
       "      <td>27.333333</td>\n",
       "      <td>13.727273</td>\n",
       "      <td>13.484848</td>\n",
       "      <td>6.757576</td>\n",
       "      <td>3.515152</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>25.484848</td>\n",
       "      <td>63.121212</td>\n",
       "      <td>6.484848</td>\n",
       "      <td>20.030303</td>\n",
       "      <td>9.848485</td>\n",
       "      <td>14.030303</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>21.030303</td>\n",
       "      <td>14.818182</td>\n",
       "      <td>13.060606</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>3.393939</td>\n",
       "      <td>17.969697</td>\n",
       "      <td>9.757576</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>60.937500</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>25.562500</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>11.843750</td>\n",
       "      <td>27.437500</td>\n",
       "      <td>22.375000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>8.843750</td>\n",
       "      <td>3.406250</td>\n",
       "      <td>14.843750</td>\n",
       "      <td>25.437500</td>\n",
       "      <td>64.562500</td>\n",
       "      <td>8.031250</td>\n",
       "      <td>25.343750</td>\n",
       "      <td>9.156250</td>\n",
       "      <td>13.218750</td>\n",
       "      <td>13.218750</td>\n",
       "      <td>21.187500</td>\n",
       "      <td>15.125000</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>7.906250</td>\n",
       "      <td>3.343750</td>\n",
       "      <td>17.093750</td>\n",
       "      <td>13.937500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.108584e+16</td>\n",
       "      <td>8.355541e-02</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>-9</td>\n",
       "      <td>10/30/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>137</td>\n",
       "      <td>3397</td>\n",
       "      <td>100</td>\n",
       "      <td>3251</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>28.193548</td>\n",
       "      <td>62.870968</td>\n",
       "      <td>4.806452</td>\n",
       "      <td>15.483871</td>\n",
       "      <td>16.290323</td>\n",
       "      <td>23.032258</td>\n",
       "      <td>14.612903</td>\n",
       "      <td>29.419355</td>\n",
       "      <td>15.774194</td>\n",
       "      <td>16.645161</td>\n",
       "      <td>8.645161</td>\n",
       "      <td>4.225806</td>\n",
       "      <td>15.096774</td>\n",
       "      <td>24.741935</td>\n",
       "      <td>65.161290</td>\n",
       "      <td>5.129032</td>\n",
       "      <td>18.032258</td>\n",
       "      <td>9.806452</td>\n",
       "      <td>14.096774</td>\n",
       "      <td>12.354839</td>\n",
       "      <td>23.064516</td>\n",
       "      <td>11.612903</td>\n",
       "      <td>16.193548</td>\n",
       "      <td>8.387097</td>\n",
       "      <td>2.645161</td>\n",
       "      <td>19.032258</td>\n",
       "      <td>13.064516</td>\n",
       "      <td>23.870968</td>\n",
       "      <td>54.870968</td>\n",
       "      <td>4.612903</td>\n",
       "      <td>14.806452</td>\n",
       "      <td>11.096774</td>\n",
       "      <td>16.161290</td>\n",
       "      <td>14.032258</td>\n",
       "      <td>23.322581</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.935484</td>\n",
       "      <td>7.935484</td>\n",
       "      <td>3.322581</td>\n",
       "      <td>17.967742</td>\n",
       "      <td>18.677419</td>\n",
       "      <td>49.322581</td>\n",
       "      <td>4.645161</td>\n",
       "      <td>16.225806</td>\n",
       "      <td>12.516129</td>\n",
       "      <td>18.290323</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>19.193548</td>\n",
       "      <td>10.903226</td>\n",
       "      <td>16.258065</td>\n",
       "      <td>7.225806</td>\n",
       "      <td>3.193548</td>\n",
       "      <td>17.580645</td>\n",
       "      <td>8.935484</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.013256e+17</td>\n",
       "      <td>1.454042e-17</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>-11</td>\n",
       "      <td>10/30/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>137</td>\n",
       "      <td>3376</td>\n",
       "      <td>63</td>\n",
       "      <td>3299</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>28.125000</td>\n",
       "      <td>59.281250</td>\n",
       "      <td>4.562500</td>\n",
       "      <td>13.218750</td>\n",
       "      <td>15.281250</td>\n",
       "      <td>21.812500</td>\n",
       "      <td>12.687500</td>\n",
       "      <td>27.906250</td>\n",
       "      <td>15.031250</td>\n",
       "      <td>13.781250</td>\n",
       "      <td>7.281250</td>\n",
       "      <td>6.406250</td>\n",
       "      <td>15.468750</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>4.812500</td>\n",
       "      <td>15.125000</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>20.531250</td>\n",
       "      <td>11.375000</td>\n",
       "      <td>13.812500</td>\n",
       "      <td>5.906250</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>19.218750</td>\n",
       "      <td>15.531250</td>\n",
       "      <td>23.896552</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>4.413793</td>\n",
       "      <td>17.068966</td>\n",
       "      <td>13.068966</td>\n",
       "      <td>21.586207</td>\n",
       "      <td>16.241379</td>\n",
       "      <td>27.827586</td>\n",
       "      <td>13.689655</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.620690</td>\n",
       "      <td>3.793103</td>\n",
       "      <td>20.551724</td>\n",
       "      <td>20.517241</td>\n",
       "      <td>57.724138</td>\n",
       "      <td>5.344828</td>\n",
       "      <td>18.931034</td>\n",
       "      <td>12.965517</td>\n",
       "      <td>19.724138</td>\n",
       "      <td>12.931034</td>\n",
       "      <td>27.827586</td>\n",
       "      <td>12.172414</td>\n",
       "      <td>21.896552</td>\n",
       "      <td>8.379310</td>\n",
       "      <td>3.931034</td>\n",
       "      <td>21.655172</td>\n",
       "      <td>5.931034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.601154e+17</td>\n",
       "      <td>6.678446e-18</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>-13</td>\n",
       "      <td>10/30/2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  T1_TeamID  T1_Score  T2_TeamID  T2_Score  result  \\\n",
       "0    2018     137       3438        68       3143        62       1   \n",
       "1    2018     137       3437        81       3355        74       1   \n",
       "2    2018     137       3401        89       3179        76       1   \n",
       "3    2018     137       3397       100       3251        60       1   \n",
       "4    2018     137       3376        63       3299        52       1   \n",
       "\n",
       "   T1_FGM mean  T1_FGA mean  T1_FGM3 mean  T1_FGA3 mean  T1_FTM mean  \\\n",
       "0    22.967742    56.516129      5.967742     17.354839    10.225806   \n",
       "1    24.600000    57.033333      8.733333     26.566667     8.966667   \n",
       "2    28.090909    61.969697      4.454545     12.666667    16.424242   \n",
       "3    28.193548    62.870968      4.806452     15.483871    16.290323   \n",
       "4    28.125000    59.281250      4.562500     13.218750    15.281250   \n",
       "\n",
       "   T1_FTA mean  T1_OR mean  T1_DR mean  T1_Ast mean  T1_TO mean  T1_Stl mean  \\\n",
       "0    14.225806   11.548387   25.258065    12.806452   16.161290     6.677419   \n",
       "1    12.133333    8.300000   26.533333    14.066667    9.700000     4.200000   \n",
       "2    21.090909   14.575758   27.333333    13.727273   13.484848     6.757576   \n",
       "3    23.032258   14.612903   29.419355    15.774194   16.645161     8.645161   \n",
       "4    21.812500   12.687500   27.906250    15.031250   13.781250     7.281250   \n",
       "\n",
       "   T1_Blk mean  T1_PF mean  T1_opponent_FGM mean  T1_opponent_FGA mean  \\\n",
       "0     4.064516   16.161290             22.258065             57.935484   \n",
       "1     3.833333   13.300000             22.833333             59.800000   \n",
       "2     3.515152   16.000000             25.484848             63.121212   \n",
       "3     4.225806   15.096774             24.741935             65.161290   \n",
       "4     6.406250   15.468750             22.500000             62.000000   \n",
       "\n",
       "   T1_opponent_FGM3 mean  T1_opponent_FGA3 mean  T1_opponent_FTM mean  \\\n",
       "0               6.225806              20.000000             10.290323   \n",
       "1               4.633333              16.733333              9.033333   \n",
       "2               6.484848              20.030303              9.848485   \n",
       "3               5.129032              18.032258              9.806452   \n",
       "4               4.812500              15.125000             10.750000   \n",
       "\n",
       "   T1_opponent_FTA mean  T1_opponent_OR mean  T1_opponent_DR mean  \\\n",
       "0             14.838710            12.258065            23.419355   \n",
       "1             12.600000            11.666667            25.066667   \n",
       "2             14.030303            11.666667            21.030303   \n",
       "3             14.096774            12.354839            23.064516   \n",
       "4             15.625000            13.000000            20.531250   \n",
       "\n",
       "   T1_opponent_Ast mean  T1_opponent_TO mean  T1_opponent_Stl mean  \\\n",
       "0             11.580645            14.967742              8.258065   \n",
       "1             10.733333             9.833333              4.166667   \n",
       "2             14.818182            13.060606              5.666667   \n",
       "3             11.612903            16.193548              8.387097   \n",
       "4             11.375000            13.812500              5.906250   \n",
       "\n",
       "   T1_opponent_Blk mean  T1_opponent_PF mean  T1_PointDiff mean  T2_FGM mean  \\\n",
       "0              2.838710            15.903226           1.096774    26.612903   \n",
       "1              1.600000            14.466667           7.566667    28.064516   \n",
       "2              3.393939            17.969697           9.757576    29.500000   \n",
       "3              2.645161            19.032258          13.064516    23.870968   \n",
       "4              3.125000            19.218750          15.531250    23.896552   \n",
       "\n",
       "   T2_FGA mean  T2_FGM3 mean  T2_FGA3 mean  T2_FTM mean  T2_FTA mean  \\\n",
       "0    58.580645      5.161290     15.354839    10.870968    15.774194   \n",
       "1    61.774194      8.741935     23.806452    13.548387    17.193548   \n",
       "2    60.937500      9.500000     25.562500    13.500000    17.500000   \n",
       "3    54.870968      4.612903     14.806452    11.096774    16.161290   \n",
       "4    64.000000      4.413793     17.068966    13.068966    21.586207   \n",
       "\n",
       "   T2_OR mean  T2_DR mean  T2_Ast mean  T2_TO mean  T2_Stl mean  T2_Blk mean  \\\n",
       "0   12.451613   25.838710    15.741935   14.903226     5.838710     3.225806   \n",
       "1   12.322581   28.387097    16.838710   13.129032     7.290323     3.838710   \n",
       "2   11.843750   27.437500    22.375000   15.500000     8.843750     3.406250   \n",
       "3   14.032258   23.322581    13.000000   15.935484     7.935484     3.322581   \n",
       "4   16.241379   27.827586    13.689655   18.000000     8.620690     3.793103   \n",
       "\n",
       "   T2_PF mean  T2_opponent_FGM mean  T2_opponent_FGA mean  \\\n",
       "0   15.290323             24.483871             61.677419   \n",
       "1   15.129032             22.193548             59.000000   \n",
       "2   14.843750             25.437500             64.562500   \n",
       "3   17.967742             18.677419             49.322581   \n",
       "4   20.551724             20.517241             57.724138   \n",
       "\n",
       "   T2_opponent_FGM3 mean  T2_opponent_FGA3 mean  T2_opponent_FTM mean  \\\n",
       "0               6.645161              20.741935             10.258065   \n",
       "1               6.677419              21.516129             10.516129   \n",
       "2               8.031250              25.343750              9.156250   \n",
       "3               4.645161              16.225806             12.516129   \n",
       "4               5.344828              18.931034             12.965517   \n",
       "\n",
       "   T2_opponent_FTA mean  T2_opponent_OR mean  T2_opponent_DR mean  \\\n",
       "0             14.161290            11.967742            20.903226   \n",
       "1             14.967742            10.129032            22.806452   \n",
       "2             13.218750            13.218750            21.187500   \n",
       "3             18.290323            10.000000            19.193548   \n",
       "4             19.724138            12.931034            27.827586   \n",
       "\n",
       "   T2_opponent_Ast mean  T2_opponent_TO mean  T2_opponent_Stl mean  \\\n",
       "0             15.096774            12.322581              6.516129   \n",
       "1             11.709677            14.483871              7.258065   \n",
       "2             15.125000            15.250000              7.906250   \n",
       "3             10.903226            16.258065              7.225806   \n",
       "4             12.172414            21.896552              8.379310   \n",
       "\n",
       "   T2_opponent_Blk mean  T2_opponent_PF mean  T2_PointDiff mean  \\\n",
       "0              3.096774            14.870968           3.387097   \n",
       "1              3.000000            17.677419          16.838710   \n",
       "2              3.343750            17.093750          13.937500   \n",
       "3              3.193548            17.580645           8.935484   \n",
       "4              3.931034            21.655172           5.931034   \n",
       "\n",
       "   T1_win_ratio_14d  T2_win_ratio_14d    T1_quality    T2_quality  T1_seed  \\\n",
       "0          0.500000               0.5  4.778895e+15  2.255687e+15       10   \n",
       "1          0.000000               0.0  1.725910e+16  1.016626e+16        9   \n",
       "2          0.666667               0.0  4.108584e+16  8.355541e-02        4   \n",
       "3          0.500000               0.0  1.013256e+17  1.454042e-17        3   \n",
       "4          1.000000               0.0  1.601154e+17  6.678446e-18        2   \n",
       "\n",
       "   T2_seed  Seed_diff     DayZero  \n",
       "0        7          3  10/30/2017  \n",
       "1        8          1  10/30/2017  \n",
       "2       13         -9  10/30/2017  \n",
       "3       14        -11  10/30/2017  \n",
       "4       15        -13  10/30/2017  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TourneyDetailedResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_row(r):\n",
    "    if r['T1_TeamID'] < r['T2_TeamID']:\n",
    "        res = str(r['Season'])+\"_\"+str(r['T1_TeamID'])+\"_\"+str(r['T2_TeamID'])\n",
    "    else:\n",
    "        res = str(r['Season'])+\"_\"+str(r['T2_TeamID'])+\"_\"+str(r['T1_TeamID'])\n",
    "    return res\n",
    "\n",
    "# Delete leaked from train\n",
    "def delete_leaked_from_df_train(df_train, df_test):\n",
    "    df_train['Concats'] = df_train.apply(concat_row, axis=1)\n",
    "    df_train_duplicates = df_train[df_train['Concats'].isin(df_test['ID'].unique())]\n",
    "    df_train_idx = df_train_duplicates.index.values\n",
    "    df_train = df_train.drop(df_train_idx)\n",
    "    df_train = df_train.drop('Concats', axis=1)\n",
    "    \n",
    "    return df_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TourneyDetailedResults = delete_leaked_from_df_train(TourneyDetailedResults, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "\n",
    "    def __init__(self, train_df, test_df, target, features, categoricals=[], \n",
    "                n_splits=3, cv_method=\"KFold\", group=None, task=\"regression\", \n",
    "                parameter_tuning=False, seed=42, scaler=None, verbose=True):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.target = target\n",
    "        self.features = features\n",
    "        self.n_splits = n_splits\n",
    "        self.categoricals = categoricals\n",
    "        self.cv_method = cv_method\n",
    "        self.group = group\n",
    "        self.task = task\n",
    "        self.parameter_tuning = parameter_tuning\n",
    "        self.seed = seed\n",
    "        self.scaler = scaler\n",
    "        self.cv = self.get_cv()\n",
    "        self.verbose = verbose\n",
    "        self.params = self.get_params()\n",
    "        self.y_pred, self.score, self.model, self.oof, self.y_val, self.fi_df = self.fit()\n",
    "\n",
    "    def train_model(self, train_set, val_set):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_params(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def convert_x(self, x):\n",
    "        return x\n",
    "\n",
    "    def calc_metric(self, y_true, y_pred): # this may need to be changed based on the metric of interest\n",
    "        if self.task == \"multiclass\":\n",
    "            return log_loss(y_true, y_pred)\n",
    "        elif self.task == \"binary\":\n",
    "            return log_loss(y_true, y_pred)\n",
    "#             return roc_auc_score(y_true, y_pred)\n",
    "        elif self.task == \"regression\":\n",
    "            return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    def get_cv(self):\n",
    "        if self.cv_method == \"KFold\":\n",
    "            cv = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.seed)\n",
    "            return cv.split(self.train_df)\n",
    "        elif self.cv_method == \"StratifiedKFold\":\n",
    "            cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.seed)\n",
    "            return cv.split(self.train_df, self.train_df[self.target])\n",
    "        elif self.cv_method == \"TimeSeriesSplit\":\n",
    "            cv = TimeSeriesSplit(max_train_size=None, n_splits=self.n_splits)\n",
    "            return cv.split(self.train_df)\n",
    "\n",
    "    def fit(self):\n",
    "        # initialize\n",
    "        oof_pred = np.zeros((self.train_df.shape[0], ))\n",
    "        y_vals = np.zeros((self.train_df.shape[0], ))\n",
    "        y_pred = np.zeros((self.test_df.shape[0], ))\n",
    "        if self.group is not None:\n",
    "            if self.group in self.features:\n",
    "                self.features.remove(self.group)\n",
    "            if self.group in self.categoricals:\n",
    "                self.categoricals.remove(self.group)\n",
    "        fi = np.zeros((self.n_splits, len(self.features)))\n",
    "\n",
    "        # scaling, if necessary\n",
    "        if self.scaler is not None:\n",
    "            # fill NaN\n",
    "            numerical_features = [f for f in self.features if f not in self.categoricals]\n",
    "            self.train_df[numerical_features] = self.train_df[numerical_features].fillna(self.train_df[numerical_features].median())\n",
    "            self.test_df[numerical_features] = self.test_df[numerical_features].fillna(self.test_df[numerical_features].median())\n",
    "            self.train_df[self.categoricals] = self.train_df[self.categoricals].fillna(self.train_df[self.categoricals].mode().iloc[0])\n",
    "            self.test_df[self.categoricals] = self.test_df[self.categoricals].fillna(self.test_df[self.categoricals].mode().iloc[0])\n",
    "\n",
    "            # scaling\n",
    "            if self.scaler == \"MinMax\":\n",
    "                scaler = MinMaxScaler()\n",
    "            elif self.scaler == \"Standard\":\n",
    "                scaler = StandardScaler()\n",
    "            df = pd.concat([self.train_df[numerical_features], self.test_df[numerical_features]], ignore_index=True)\n",
    "            scaler.fit(df[numerical_features])\n",
    "            x_test = self.test_df.copy()\n",
    "            x_test[numerical_features] = scaler.transform(x_test[numerical_features])\n",
    "            x_test = [np.absolute(x_test[i]) for i in self.categoricals] + [x_test[numerical_features]]\n",
    "        else:\n",
    "            x_test = self.test_df[self.features]\n",
    "\n",
    "        # fitting with out of fold\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv):\n",
    "            # train test split\n",
    "            x_train, x_val = self.train_df.loc[train_idx, self.features], self.train_df.loc[val_idx, self.features]\n",
    "            y_train, y_val = self.train_df.loc[train_idx, self.target], self.train_df.loc[val_idx, self.target]\n",
    "\n",
    "            # fitting & get feature importance\n",
    "            if self.scaler is not None:\n",
    "                x_train[numerical_features] = scaler.transform(x_train[numerical_features])\n",
    "                x_val[numerical_features] = scaler.transform(x_val[numerical_features])\n",
    "                x_train = [np.absolute(x_train[i]) for i in self.categoricals] + [x_train[numerical_features]]\n",
    "                x_val = [np.absolute(x_val[i]) for i in self.categoricals] + [x_val[numerical_features]]\n",
    "            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n",
    "            model, importance = self.train_model(train_set, val_set)\n",
    "            fi[fold, :] = importance\n",
    "            conv_x_val = self.convert_x(x_val)\n",
    "            y_vals[val_idx] = y_val\n",
    "            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n",
    "            x_test = self.convert_x(x_test)\n",
    "            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n",
    "            print('Partial score of fold {} is: {}'.format(fold, self.calc_metric(y_val, oof_pred[val_idx])))\n",
    "        \n",
    "        # feature importance data frame\n",
    "        fi_df = pd.DataFrame()\n",
    "        for n in np.arange(self.n_splits):\n",
    "            tmp = pd.DataFrame()\n",
    "            tmp[\"features\"] = self.features\n",
    "            tmp[\"importance\"] = fi[n, :]\n",
    "            tmp[\"fold\"] = n\n",
    "            fi_df = pd.concat([fi_df, tmp], ignore_index=True)\n",
    "        gfi = fi_df[[\"features\", \"importance\"]].groupby([\"features\"]).mean().reset_index()\n",
    "        fi_df = fi_df.merge(gfi, on=\"features\", how=\"left\", suffixes=('', '_mean'))\n",
    "\n",
    "        # outputs\n",
    "        loss_score = self.calc_metric(y_vals, oof_pred)\n",
    "        if self.verbose:\n",
    "            print('Our oof loss score is: ', loss_score)\n",
    "        return y_pred, loss_score, model, oof_pred, y_vals, fi_df\n",
    "\n",
    "    def plot_feature_importance(self, rank_range=[1, 50]):\n",
    "        # plot\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 20))\n",
    "        sorted_df = self.fi_df.sort_values(by = \"importance_mean\", ascending=False).reset_index().iloc[self.n_splits * (rank_range[0]-1) : self.n_splits * rank_range[1]]\n",
    "        sns.barplot(data=sorted_df, x =\"importance\", y =\"features\", orient='h')\n",
    "        ax.set_xlabel(\"feature importance\")\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LgbModel(BaseModel):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        model = lgb.train(self.params, train_set, num_boost_round = 5000, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n",
    "        fi = model.feature_importance(importance_type=\"gain\")\n",
    "        return model, fi\n",
    "\n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val, categorical_feature=self.categoricals)\n",
    "        return train_set, val_set\n",
    "\n",
    "    def get_params(self):\n",
    "        # fast fit parameters\n",
    "        params = {\n",
    "          'num_leaves': 127,\n",
    "          'objective': self.task,\n",
    "          'min_data_in_leaf': 50,\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.005,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"verbosity\": -1,\n",
    "          'random_state': 42,\n",
    "         }\n",
    "\n",
    "        # list is here: https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "        if self.task == \"regression\":\n",
    "            params[\"metric\"] = \"rmse\"\n",
    "        elif self.task == \"binary\":\n",
    "            params[\"metric\"] = \"binary_logloss\" # auc\n",
    "        elif self.task == \"multiclass\":\n",
    "            params[\"metric\"] = \"multi_logloss\" # cross_entropy, auc_mu\n",
    "        \n",
    "        # Bayesian Optimization by Optuna\n",
    "        if self.parameter_tuning == True:\n",
    "            # define objective function\n",
    "            def objective(trial):\n",
    "                # train, test split\n",
    "                train_x, test_x, train_y, test_y = train_test_split(self.train_df[self.features], \n",
    "                                                                    self.train_df[self.target],\n",
    "                                                                    test_size=0.3, random_state=self.seed)\n",
    "                dtrain = lgb.Dataset(train_x, train_y, categorical_feature=self.categoricals)\n",
    "                dtest = lgb.Dataset(test_x, test_y, categorical_feature=self.categoricals)\n",
    "\n",
    "                # parameters to be explored\n",
    "                hyperparams = {'num_leaves': trial.suggest_int('num_leaves', 24, 1024),\n",
    "                        'boosting_type': 'gbdt',\n",
    "                        'objective': params[\"objective\"],\n",
    "                        'metric': params[\"metric\"],\n",
    "                        'max_depth': trial.suggest_int('max_depth', 4, 30),\n",
    "                        'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "                        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "                        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "                        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "                        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "                        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "                        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "                        'early_stopping_rounds': 100\n",
    "                        }\n",
    "\n",
    "                # LGB\n",
    "                model = lgb.train(hyperparams, dtrain, valid_sets=dtest, verbose_eval=500)\n",
    "                pred = model.predict(test_x)\n",
    "                if (self.task == \"binary\") | (self.task == \"multiclass\"):\n",
    "                    return log_loss(test_y, pred)\n",
    "                elif self.task == \"regression\":\n",
    "                    return np.sqrt(mean_squared_error(test_y, pred))\n",
    "\n",
    "            # run optimization\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            study.optimize(objective, n_trials=100)\n",
    "\n",
    "            print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "            print('Best trial:')\n",
    "            trial = study.best_trial\n",
    "            print('  Value: {}'.format(trial.value))\n",
    "            print('  Params: ')\n",
    "            for key, value in trial.params.items():\n",
    "                print('    {}: {}'.format(key, value))\n",
    "\n",
    "            params = trial.params\n",
    "\n",
    "            # lower learning rate for better accuracy\n",
    "            params[\"learning_rate\"] = 0.001\n",
    "\n",
    "            # plot history\n",
    "            plot_optimization_history(study)\n",
    "\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2015, 2016, 2017, 2018, 2019], dtype=int64)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"Season\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TourneyDetailedResults.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260, 68)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'result'\n",
    "features = train.columns.values.tolist()\n",
    "dropcols = [target,'DayNum', 'Season','DayZero','T1_TeamID', 'T2_TeamID','T1_Score','T2_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T1_FGM mean', 'T1_FGA mean', 'T1_FGM3 mean', 'T1_FGA3 mean', 'T1_FTM mean', 'T1_FTA mean', 'T1_OR mean', 'T1_DR mean', 'T1_Ast mean', 'T1_TO mean', 'T1_Stl mean', 'T1_Blk mean', 'T1_PF mean', 'T1_opponent_FGM mean', 'T1_opponent_FGA mean', 'T1_opponent_FGM3 mean', 'T1_opponent_FGA3 mean', 'T1_opponent_FTM mean', 'T1_opponent_FTA mean', 'T1_opponent_OR mean', 'T1_opponent_DR mean', 'T1_opponent_Ast mean', 'T1_opponent_TO mean', 'T1_opponent_Stl mean', 'T1_opponent_Blk mean', 'T1_opponent_PF mean', 'T1_PointDiff mean', 'T2_FGM mean', 'T2_FGA mean', 'T2_FGM3 mean', 'T2_FGA3 mean', 'T2_FTM mean', 'T2_FTA mean', 'T2_OR mean', 'T2_DR mean', 'T2_Ast mean', 'T2_TO mean', 'T2_Stl mean', 'T2_Blk mean', 'T2_PF mean', 'T2_opponent_FGM mean', 'T2_opponent_FGA mean', 'T2_opponent_FGM3 mean', 'T2_opponent_FGA3 mean', 'T2_opponent_FTM mean', 'T2_opponent_FTA mean', 'T2_opponent_OR mean', 'T2_opponent_DR mean', 'T2_opponent_Ast mean', 'T2_opponent_TO mean', 'T2_opponent_Stl mean', 'T2_opponent_Blk mean', 'T2_opponent_PF mean', 'T2_PointDiff mean', 'T1_win_ratio_14d', 'T2_win_ratio_14d', 'T1_quality', 'T2_quality', 'T1_seed', 'T2_seed', 'Seed_diff']\n"
     ]
    }
   ],
   "source": [
    "features = [f for f in features if f not in dropcols]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>T1_TeamID</th>\n",
       "      <th>T1_Score</th>\n",
       "      <th>T2_TeamID</th>\n",
       "      <th>T2_Score</th>\n",
       "      <th>result</th>\n",
       "      <th>T1_FGM mean</th>\n",
       "      <th>T1_FGA mean</th>\n",
       "      <th>T1_FGM3 mean</th>\n",
       "      <th>T1_FGA3 mean</th>\n",
       "      <th>T1_FTM mean</th>\n",
       "      <th>T1_FTA mean</th>\n",
       "      <th>T1_OR mean</th>\n",
       "      <th>T1_DR mean</th>\n",
       "      <th>T1_Ast mean</th>\n",
       "      <th>T1_TO mean</th>\n",
       "      <th>T1_Stl mean</th>\n",
       "      <th>T1_Blk mean</th>\n",
       "      <th>T1_PF mean</th>\n",
       "      <th>T1_opponent_FGM mean</th>\n",
       "      <th>T1_opponent_FGA mean</th>\n",
       "      <th>T1_opponent_FGM3 mean</th>\n",
       "      <th>T1_opponent_FGA3 mean</th>\n",
       "      <th>T1_opponent_FTM mean</th>\n",
       "      <th>T1_opponent_FTA mean</th>\n",
       "      <th>T1_opponent_OR mean</th>\n",
       "      <th>T1_opponent_DR mean</th>\n",
       "      <th>T1_opponent_Ast mean</th>\n",
       "      <th>T1_opponent_TO mean</th>\n",
       "      <th>T1_opponent_Stl mean</th>\n",
       "      <th>T1_opponent_Blk mean</th>\n",
       "      <th>T1_opponent_PF mean</th>\n",
       "      <th>T1_PointDiff mean</th>\n",
       "      <th>T2_FGM mean</th>\n",
       "      <th>T2_FGA mean</th>\n",
       "      <th>T2_FGM3 mean</th>\n",
       "      <th>T2_FGA3 mean</th>\n",
       "      <th>T2_FTM mean</th>\n",
       "      <th>T2_FTA mean</th>\n",
       "      <th>T2_OR mean</th>\n",
       "      <th>T2_DR mean</th>\n",
       "      <th>T2_Ast mean</th>\n",
       "      <th>T2_TO mean</th>\n",
       "      <th>T2_Stl mean</th>\n",
       "      <th>T2_Blk mean</th>\n",
       "      <th>T2_PF mean</th>\n",
       "      <th>T2_opponent_FGM mean</th>\n",
       "      <th>T2_opponent_FGA mean</th>\n",
       "      <th>T2_opponent_FGM3 mean</th>\n",
       "      <th>T2_opponent_FGA3 mean</th>\n",
       "      <th>T2_opponent_FTM mean</th>\n",
       "      <th>T2_opponent_FTA mean</th>\n",
       "      <th>T2_opponent_OR mean</th>\n",
       "      <th>T2_opponent_DR mean</th>\n",
       "      <th>T2_opponent_Ast mean</th>\n",
       "      <th>T2_opponent_TO mean</th>\n",
       "      <th>T2_opponent_Stl mean</th>\n",
       "      <th>T2_opponent_Blk mean</th>\n",
       "      <th>T2_opponent_PF mean</th>\n",
       "      <th>T2_PointDiff mean</th>\n",
       "      <th>T1_win_ratio_14d</th>\n",
       "      <th>T2_win_ratio_14d</th>\n",
       "      <th>T1_quality</th>\n",
       "      <th>T2_quality</th>\n",
       "      <th>T1_seed</th>\n",
       "      <th>T2_seed</th>\n",
       "      <th>Seed_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3125</td>\n",
       "      <td>52</td>\n",
       "      <td>3376</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>26.968750</td>\n",
       "      <td>59.687500</td>\n",
       "      <td>10.43750</td>\n",
       "      <td>29.093750</td>\n",
       "      <td>11.312500</td>\n",
       "      <td>16.468750</td>\n",
       "      <td>11.812500</td>\n",
       "      <td>29.156250</td>\n",
       "      <td>16.312500</td>\n",
       "      <td>12.562500</td>\n",
       "      <td>5.562500</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>14.656250</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>60.437500</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>9.343750</td>\n",
       "      <td>13.46875</td>\n",
       "      <td>10.96875</td>\n",
       "      <td>23.312500</td>\n",
       "      <td>11.593750</td>\n",
       "      <td>12.031250</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>17.531250</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>27.433333</td>\n",
       "      <td>63.233333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>18.233333</td>\n",
       "      <td>14.866667</td>\n",
       "      <td>20.533333</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>25.166667</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>16.766667</td>\n",
       "      <td>24.466667</td>\n",
       "      <td>62.133333</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>15.533333</td>\n",
       "      <td>12.766667</td>\n",
       "      <td>17.233333</td>\n",
       "      <td>13.466667</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>11.033333</td>\n",
       "      <td>15.866667</td>\n",
       "      <td>6.766667</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>9.233333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3332</td>\n",
       "      <td>78</td>\n",
       "      <td>3340</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>31.937500</td>\n",
       "      <td>63.625000</td>\n",
       "      <td>9.75000</td>\n",
       "      <td>23.343750</td>\n",
       "      <td>11.531250</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>10.937500</td>\n",
       "      <td>26.343750</td>\n",
       "      <td>19.031250</td>\n",
       "      <td>10.125000</td>\n",
       "      <td>6.906250</td>\n",
       "      <td>2.593750</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>24.218750</td>\n",
       "      <td>60.281250</td>\n",
       "      <td>6.656250</td>\n",
       "      <td>21.562500</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>11.68750</td>\n",
       "      <td>10.03125</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>13.687500</td>\n",
       "      <td>13.218750</td>\n",
       "      <td>4.687500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>14.875000</td>\n",
       "      <td>21.406250</td>\n",
       "      <td>25.967742</td>\n",
       "      <td>60.258065</td>\n",
       "      <td>5.838710</td>\n",
       "      <td>16.806452</td>\n",
       "      <td>12.967742</td>\n",
       "      <td>16.225806</td>\n",
       "      <td>11.064516</td>\n",
       "      <td>28.258065</td>\n",
       "      <td>17.225806</td>\n",
       "      <td>14.741935</td>\n",
       "      <td>9.580645</td>\n",
       "      <td>5.258065</td>\n",
       "      <td>14.935484</td>\n",
       "      <td>22.032258</td>\n",
       "      <td>61.870968</td>\n",
       "      <td>6.548387</td>\n",
       "      <td>21.612903</td>\n",
       "      <td>9.516129</td>\n",
       "      <td>14.290323</td>\n",
       "      <td>13.354839</td>\n",
       "      <td>24.258065</td>\n",
       "      <td>14.548387</td>\n",
       "      <td>15.903226</td>\n",
       "      <td>7.548387</td>\n",
       "      <td>1.806452</td>\n",
       "      <td>16.225806</td>\n",
       "      <td>10.612903</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3281</td>\n",
       "      <td>77</td>\n",
       "      <td>3179</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>22.757576</td>\n",
       "      <td>50.757576</td>\n",
       "      <td>8.30303</td>\n",
       "      <td>22.878788</td>\n",
       "      <td>12.151515</td>\n",
       "      <td>16.424242</td>\n",
       "      <td>9.242424</td>\n",
       "      <td>26.393939</td>\n",
       "      <td>13.969697</td>\n",
       "      <td>16.181818</td>\n",
       "      <td>5.939394</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>17.181818</td>\n",
       "      <td>21.030303</td>\n",
       "      <td>57.787879</td>\n",
       "      <td>4.848485</td>\n",
       "      <td>17.030303</td>\n",
       "      <td>11.030303</td>\n",
       "      <td>15.69697</td>\n",
       "      <td>12.30303</td>\n",
       "      <td>20.242424</td>\n",
       "      <td>8.393939</td>\n",
       "      <td>12.212121</td>\n",
       "      <td>6.757576</td>\n",
       "      <td>1.939394</td>\n",
       "      <td>18.909091</td>\n",
       "      <td>8.030303</td>\n",
       "      <td>28.406250</td>\n",
       "      <td>59.937500</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>24.437500</td>\n",
       "      <td>14.781250</td>\n",
       "      <td>19.343750</td>\n",
       "      <td>11.093750</td>\n",
       "      <td>28.562500</td>\n",
       "      <td>21.093750</td>\n",
       "      <td>17.781250</td>\n",
       "      <td>9.031250</td>\n",
       "      <td>2.562500</td>\n",
       "      <td>17.156250</td>\n",
       "      <td>24.312500</td>\n",
       "      <td>63.156250</td>\n",
       "      <td>7.187500</td>\n",
       "      <td>25.125000</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>11.468750</td>\n",
       "      <td>22.281250</td>\n",
       "      <td>13.593750</td>\n",
       "      <td>16.281250</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>19.562500</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3280</td>\n",
       "      <td>103</td>\n",
       "      <td>3380</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>32.531250</td>\n",
       "      <td>66.156250</td>\n",
       "      <td>5.25000</td>\n",
       "      <td>13.781250</td>\n",
       "      <td>15.781250</td>\n",
       "      <td>21.531250</td>\n",
       "      <td>17.343750</td>\n",
       "      <td>25.468750</td>\n",
       "      <td>16.562500</td>\n",
       "      <td>12.625000</td>\n",
       "      <td>8.656250</td>\n",
       "      <td>5.437500</td>\n",
       "      <td>16.937500</td>\n",
       "      <td>21.093750</td>\n",
       "      <td>55.625000</td>\n",
       "      <td>5.187500</td>\n",
       "      <td>15.562500</td>\n",
       "      <td>10.375000</td>\n",
       "      <td>14.93750</td>\n",
       "      <td>11.03125</td>\n",
       "      <td>18.843750</td>\n",
       "      <td>9.281250</td>\n",
       "      <td>19.656250</td>\n",
       "      <td>5.937500</td>\n",
       "      <td>3.937500</td>\n",
       "      <td>19.968750</td>\n",
       "      <td>28.343750</td>\n",
       "      <td>21.214286</td>\n",
       "      <td>55.750000</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>16.178571</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>18.964286</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>22.857143</td>\n",
       "      <td>11.464286</td>\n",
       "      <td>18.392857</td>\n",
       "      <td>8.642857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.392857</td>\n",
       "      <td>21.071429</td>\n",
       "      <td>50.607143</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>14.392857</td>\n",
       "      <td>15.464286</td>\n",
       "      <td>25.142857</td>\n",
       "      <td>11.535714</td>\n",
       "      <td>24.714286</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>19.321429</td>\n",
       "      <td>8.214286</td>\n",
       "      <td>3.107143</td>\n",
       "      <td>19.285714</td>\n",
       "      <td>-2.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>137</td>\n",
       "      <td>3276</td>\n",
       "      <td>84</td>\n",
       "      <td>3243</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>27.093750</td>\n",
       "      <td>60.437500</td>\n",
       "      <td>4.56250</td>\n",
       "      <td>13.937500</td>\n",
       "      <td>13.218750</td>\n",
       "      <td>18.875000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>25.656250</td>\n",
       "      <td>15.187500</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>7.312500</td>\n",
       "      <td>3.531250</td>\n",
       "      <td>17.156250</td>\n",
       "      <td>23.156250</td>\n",
       "      <td>57.562500</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>18.875000</td>\n",
       "      <td>11.468750</td>\n",
       "      <td>16.84375</td>\n",
       "      <td>10.53125</td>\n",
       "      <td>21.937500</td>\n",
       "      <td>12.687500</td>\n",
       "      <td>16.625000</td>\n",
       "      <td>7.968750</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>8.312500</td>\n",
       "      <td>23.062500</td>\n",
       "      <td>56.718750</td>\n",
       "      <td>5.656250</td>\n",
       "      <td>18.781250</td>\n",
       "      <td>13.031250</td>\n",
       "      <td>18.062500</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>24.437500</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.468750</td>\n",
       "      <td>14.562500</td>\n",
       "      <td>23.031250</td>\n",
       "      <td>60.093750</td>\n",
       "      <td>6.343750</td>\n",
       "      <td>20.156250</td>\n",
       "      <td>11.406250</td>\n",
       "      <td>15.187500</td>\n",
       "      <td>13.375000</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>13.906250</td>\n",
       "      <td>15.937500</td>\n",
       "      <td>8.218750</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  T1_TeamID  T1_Score  T2_TeamID  T2_Score  result  \\\n",
       "0    2019     137       3125        52       3376        74       0   \n",
       "1    2019     137       3332        78       3340        40       1   \n",
       "2    2019     137       3281        77       3179        76       1   \n",
       "3    2019     137       3280       103       3380        46       1   \n",
       "4    2019     137       3276        84       3243        54       1   \n",
       "\n",
       "   T1_FGM mean  T1_FGA mean  T1_FGM3 mean  T1_FGA3 mean  T1_FTM mean  \\\n",
       "0    26.968750    59.687500      10.43750     29.093750    11.312500   \n",
       "1    31.937500    63.625000       9.75000     23.343750    11.531250   \n",
       "2    22.757576    50.757576       8.30303     22.878788    12.151515   \n",
       "3    32.531250    66.156250       5.25000     13.781250    15.781250   \n",
       "4    27.093750    60.437500       4.56250     13.937500    13.218750   \n",
       "\n",
       "   T1_FTA mean  T1_OR mean  T1_DR mean  T1_Ast mean  T1_TO mean  T1_Stl mean  \\\n",
       "0    16.468750   11.812500   29.156250    16.312500   12.562500     5.562500   \n",
       "1    15.062500   10.937500   26.343750    19.031250   10.125000     6.906250   \n",
       "2    16.424242    9.242424   26.393939    13.969697   16.181818     5.939394   \n",
       "3    21.531250   17.343750   25.468750    16.562500   12.625000     8.656250   \n",
       "4    18.875000   13.750000   25.656250    15.187500   16.250000     7.312500   \n",
       "\n",
       "   T1_Blk mean  T1_PF mean  T1_opponent_FGM mean  T1_opponent_FGA mean  \\\n",
       "0     2.125000   14.656250             22.000000             60.437500   \n",
       "1     2.593750   13.000000             24.218750             60.281250   \n",
       "2     3.181818   17.181818             21.030303             57.787879   \n",
       "3     5.437500   16.937500             21.093750             55.625000   \n",
       "4     3.531250   17.156250             23.156250             57.562500   \n",
       "\n",
       "   T1_opponent_FGM3 mean  T1_opponent_FGA3 mean  T1_opponent_FTM mean  \\\n",
       "0               6.250000              20.750000              9.343750   \n",
       "1               6.656250              21.562500              8.656250   \n",
       "2               4.848485              17.030303             11.030303   \n",
       "3               5.187500              15.562500             10.375000   \n",
       "4               5.875000              18.875000             11.468750   \n",
       "\n",
       "   T1_opponent_FTA mean  T1_opponent_OR mean  T1_opponent_DR mean  \\\n",
       "0              13.46875             10.96875            23.312500   \n",
       "1              11.68750             10.03125            20.750000   \n",
       "2              15.69697             12.30303            20.242424   \n",
       "3              14.93750             11.03125            18.843750   \n",
       "4              16.84375             10.53125            21.937500   \n",
       "\n",
       "   T1_opponent_Ast mean  T1_opponent_TO mean  T1_opponent_Stl mean  \\\n",
       "0             11.593750            12.031250              5.625000   \n",
       "1             13.687500            13.218750              4.687500   \n",
       "2              8.393939            12.212121              6.757576   \n",
       "3              9.281250            19.656250              5.937500   \n",
       "4             12.687500            16.625000              7.968750   \n",
       "\n",
       "   T1_opponent_Blk mean  T1_opponent_PF mean  T1_PointDiff mean  T2_FGM mean  \\\n",
       "0              2.875000            17.531250          16.093750    27.433333   \n",
       "1              2.500000            14.875000          21.406250    25.967742   \n",
       "2              1.939394            18.909091           8.030303    28.406250   \n",
       "3              3.937500            19.968750          28.343750    21.214286   \n",
       "4              3.437500            17.750000           8.312500    23.062500   \n",
       "\n",
       "   T2_FGA mean  T2_FGM3 mean  T2_FGA3 mean  T2_FTM mean  T2_FTA mean  \\\n",
       "0    63.233333      6.000000     18.233333    14.866667    20.533333   \n",
       "1    60.258065      5.838710     16.806452    12.967742    16.225806   \n",
       "2    59.937500      8.750000     24.437500    14.781250    19.343750   \n",
       "3    55.750000      4.428571     16.178571    11.750000    18.964286   \n",
       "4    56.718750      5.656250     18.781250    13.031250    18.062500   \n",
       "\n",
       "   T2_OR mean  T2_DR mean  T2_Ast mean  T2_TO mean  T2_Stl mean  T2_Blk mean  \\\n",
       "0   13.833333   25.166667    13.100000   13.600000     8.333333     6.300000   \n",
       "1   11.064516   28.258065    17.225806   14.741935     9.580645     5.258065   \n",
       "2   11.093750   28.562500    21.093750   17.781250     9.031250     2.562500   \n",
       "3   12.750000   22.857143    11.464286   18.392857     8.642857     2.000000   \n",
       "4   10.500000   24.437500    13.000000   15.062500     8.000000     4.468750   \n",
       "\n",
       "   T2_PF mean  T2_opponent_FGM mean  T2_opponent_FGA mean  \\\n",
       "0   16.766667             24.466667             62.133333   \n",
       "1   14.935484             22.032258             61.870968   \n",
       "2   17.156250             24.312500             63.156250   \n",
       "3   22.392857             21.071429             50.607143   \n",
       "4   14.562500             23.031250             60.093750   \n",
       "\n",
       "   T2_opponent_FGM3 mean  T2_opponent_FGA3 mean  T2_opponent_FTM mean  \\\n",
       "0               4.800000              15.533333             12.766667   \n",
       "1               6.548387              21.612903              9.516129   \n",
       "2               7.187500              25.125000             11.250000   \n",
       "3               3.857143              14.392857             15.464286   \n",
       "4               6.343750              20.156250             11.406250   \n",
       "\n",
       "   T2_opponent_FTA mean  T2_opponent_OR mean  T2_opponent_DR mean  \\\n",
       "0             17.233333            13.466667            23.300000   \n",
       "1             14.290323            13.354839            24.258065   \n",
       "2             15.750000            11.468750            22.281250   \n",
       "3             25.142857            11.535714            24.714286   \n",
       "4             15.187500            13.375000            24.750000   \n",
       "\n",
       "   T2_opponent_Ast mean  T2_opponent_TO mean  T2_opponent_Stl mean  \\\n",
       "0             11.033333            15.866667              6.766667   \n",
       "1             14.548387            15.903226              7.548387   \n",
       "2             13.593750            16.281250              8.656250   \n",
       "3             11.500000            19.321429              8.214286   \n",
       "4             13.906250            15.937500              8.218750   \n",
       "\n",
       "   T2_opponent_Blk mean  T2_opponent_PF mean  T2_PointDiff mean  \\\n",
       "0              3.133333            18.900000           9.233333   \n",
       "1              1.806452            16.225806          10.612903   \n",
       "2              2.875000            19.562500          13.281250   \n",
       "3              3.107143            19.285714          -2.857143   \n",
       "4              2.812500            16.500000           1.000000   \n",
       "\n",
       "   T1_win_ratio_14d  T2_win_ratio_14d  T1_quality  T2_quality  T1_seed  \\\n",
       "0          1.000000          1.000000         NaN         NaN       13   \n",
       "1          0.666667          0.200000         NaN         NaN        2   \n",
       "2          0.666667          0.200000         NaN         NaN        7   \n",
       "3          1.000000          0.200000         NaN         NaN        1   \n",
       "4          0.500000          0.333333         NaN         NaN        8   \n",
       "\n",
       "   T2_seed  Seed_diff  \n",
       "0        4          9  \n",
       "1       15        -13  \n",
       "2       10         -3  \n",
       "3       16        -15  \n",
       "4        9         -1  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>LTeamID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Season  WTeamID  LTeamID\n",
       "0  2015_3106_3107    2015     3106     3107\n",
       "1  2015_3106_3110    2015     3106     3110\n",
       "2  2015_3106_3113    2015     3106     3113\n",
       "3  2015_3106_3114    2015     3106     3114\n",
       "4  2015_3106_3116    2015     3106     3116"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2019, 2018, 2016, 2015, 2017, 2014, 2013, 2011, 2010, 2012],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Season\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "test[\"Pred\"] = 0.5\n",
    "pred = np.zeros(test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.603652\tvalid_1's binary_logloss: 0.612027\n",
      "[200]\ttraining's binary_logloss: 0.546805\tvalid_1's binary_logloss: 0.576441\n",
      "[300]\ttraining's binary_logloss: 0.506524\tvalid_1's binary_logloss: 0.549487\n",
      "[400]\ttraining's binary_logloss: 0.47729\tvalid_1's binary_logloss: 0.52886\n",
      "[500]\ttraining's binary_logloss: 0.455531\tvalid_1's binary_logloss: 0.515891\n",
      "[600]\ttraining's binary_logloss: 0.438248\tvalid_1's binary_logloss: 0.510097\n",
      "[700]\ttraining's binary_logloss: 0.424102\tvalid_1's binary_logloss: 0.5065\n",
      "[800]\ttraining's binary_logloss: 0.412149\tvalid_1's binary_logloss: 0.50476\n",
      "[900]\ttraining's binary_logloss: 0.4018\tvalid_1's binary_logloss: 0.502375\n",
      "[1000]\ttraining's binary_logloss: 0.392639\tvalid_1's binary_logloss: 0.500392\n",
      "[1100]\ttraining's binary_logloss: 0.384483\tvalid_1's binary_logloss: 0.499054\n",
      "[1200]\ttraining's binary_logloss: 0.377191\tvalid_1's binary_logloss: 0.497785\n",
      "[1300]\ttraining's binary_logloss: 0.370646\tvalid_1's binary_logloss: 0.496996\n",
      "[1400]\ttraining's binary_logloss: 0.36475\tvalid_1's binary_logloss: 0.496587\n",
      "[1500]\ttraining's binary_logloss: 0.359388\tvalid_1's binary_logloss: 0.495564\n",
      "[1600]\ttraining's binary_logloss: 0.354444\tvalid_1's binary_logloss: 0.494598\n",
      "[1700]\ttraining's binary_logloss: 0.349869\tvalid_1's binary_logloss: 0.493849\n",
      "[1800]\ttraining's binary_logloss: 0.345607\tvalid_1's binary_logloss: 0.493189\n",
      "[1900]\ttraining's binary_logloss: 0.341626\tvalid_1's binary_logloss: 0.492221\n",
      "[2000]\ttraining's binary_logloss: 0.337902\tvalid_1's binary_logloss: 0.491602\n",
      "[2100]\ttraining's binary_logloss: 0.334411\tvalid_1's binary_logloss: 0.490886\n",
      "[2200]\ttraining's binary_logloss: 0.331124\tvalid_1's binary_logloss: 0.490507\n",
      "[2300]\ttraining's binary_logloss: 0.327972\tvalid_1's binary_logloss: 0.48911\n",
      "[2400]\ttraining's binary_logloss: 0.324927\tvalid_1's binary_logloss: 0.487802\n",
      "[2500]\ttraining's binary_logloss: 0.321979\tvalid_1's binary_logloss: 0.487071\n",
      "[2600]\ttraining's binary_logloss: 0.319123\tvalid_1's binary_logloss: 0.486388\n",
      "[2700]\ttraining's binary_logloss: 0.316355\tvalid_1's binary_logloss: 0.485602\n",
      "[2800]\ttraining's binary_logloss: 0.313668\tvalid_1's binary_logloss: 0.485246\n",
      "[2900]\ttraining's binary_logloss: 0.311057\tvalid_1's binary_logloss: 0.484921\n",
      "[3000]\ttraining's binary_logloss: 0.308519\tvalid_1's binary_logloss: 0.484654\n",
      "[3100]\ttraining's binary_logloss: 0.306051\tvalid_1's binary_logloss: 0.484413\n",
      "[3200]\ttraining's binary_logloss: 0.303649\tvalid_1's binary_logloss: 0.484085\n",
      "[3300]\ttraining's binary_logloss: 0.3013\tvalid_1's binary_logloss: 0.483679\n",
      "[3400]\ttraining's binary_logloss: 0.299002\tvalid_1's binary_logloss: 0.483125\n",
      "[3500]\ttraining's binary_logloss: 0.296747\tvalid_1's binary_logloss: 0.482737\n",
      "[3600]\ttraining's binary_logloss: 0.294533\tvalid_1's binary_logloss: 0.482531\n",
      "[3700]\ttraining's binary_logloss: 0.292358\tvalid_1's binary_logloss: 0.482416\n",
      "[3800]\ttraining's binary_logloss: 0.290222\tvalid_1's binary_logloss: 0.482348\n",
      "[3900]\ttraining's binary_logloss: 0.288124\tvalid_1's binary_logloss: 0.482095\n",
      "[4000]\ttraining's binary_logloss: 0.286062\tvalid_1's binary_logloss: 0.482118\n",
      "[4100]\ttraining's binary_logloss: 0.284035\tvalid_1's binary_logloss: 0.482139\n",
      "[4200]\ttraining's binary_logloss: 0.282042\tvalid_1's binary_logloss: 0.482161\n",
      "[4300]\ttraining's binary_logloss: 0.280082\tvalid_1's binary_logloss: 0.482206\n",
      "[4400]\ttraining's binary_logloss: 0.278154\tvalid_1's binary_logloss: 0.482192\n",
      "[4500]\ttraining's binary_logloss: 0.276257\tvalid_1's binary_logloss: 0.482308\n",
      "[4600]\ttraining's binary_logloss: 0.27439\tvalid_1's binary_logloss: 0.482437\n",
      "[4700]\ttraining's binary_logloss: 0.272554\tvalid_1's binary_logloss: 0.482656\n",
      "[4800]\ttraining's binary_logloss: 0.270746\tvalid_1's binary_logloss: 0.482848\n",
      "[4900]\ttraining's binary_logloss: 0.268966\tvalid_1's binary_logloss: 0.483076\n",
      "[5000]\ttraining's binary_logloss: 0.267213\tvalid_1's binary_logloss: 0.483229\n",
      "Partial score of fold 0 is: 0.48322889759106635\n",
      "[100]\ttraining's binary_logloss: 0.547833\tvalid_1's binary_logloss: 0.539045\n",
      "[200]\ttraining's binary_logloss: 0.48275\tvalid_1's binary_logloss: 0.467209\n",
      "[300]\ttraining's binary_logloss: 0.430999\tvalid_1's binary_logloss: 0.426286\n",
      "[400]\ttraining's binary_logloss: 0.396318\tvalid_1's binary_logloss: 0.400075\n",
      "[500]\ttraining's binary_logloss: 0.368705\tvalid_1's binary_logloss: 0.38316\n",
      "[600]\ttraining's binary_logloss: 0.348633\tvalid_1's binary_logloss: 0.37216\n",
      "[700]\ttraining's binary_logloss: 0.332382\tvalid_1's binary_logloss: 0.364483\n",
      "[800]\ttraining's binary_logloss: 0.317646\tvalid_1's binary_logloss: 0.356756\n",
      "[900]\ttraining's binary_logloss: 0.304584\tvalid_1's binary_logloss: 0.350266\n",
      "[1000]\ttraining's binary_logloss: 0.291381\tvalid_1's binary_logloss: 0.34618\n",
      "[1100]\ttraining's binary_logloss: 0.279501\tvalid_1's binary_logloss: 0.343116\n",
      "[1200]\ttraining's binary_logloss: 0.268352\tvalid_1's binary_logloss: 0.339976\n",
      "[1300]\ttraining's binary_logloss: 0.258319\tvalid_1's binary_logloss: 0.337735\n",
      "[1400]\ttraining's binary_logloss: 0.248583\tvalid_1's binary_logloss: 0.33642\n",
      "[1500]\ttraining's binary_logloss: 0.240284\tvalid_1's binary_logloss: 0.33487\n",
      "[1600]\ttraining's binary_logloss: 0.231507\tvalid_1's binary_logloss: 0.334341\n",
      "[1700]\ttraining's binary_logloss: 0.223268\tvalid_1's binary_logloss: 0.334436\n",
      "[1800]\ttraining's binary_logloss: 0.215677\tvalid_1's binary_logloss: 0.334942\n",
      "[1900]\ttraining's binary_logloss: 0.208572\tvalid_1's binary_logloss: 0.335399\n",
      "[2000]\ttraining's binary_logloss: 0.202042\tvalid_1's binary_logloss: 0.336134\n",
      "[2100]\ttraining's binary_logloss: 0.195746\tvalid_1's binary_logloss: 0.337339\n",
      "[2200]\ttraining's binary_logloss: 0.190122\tvalid_1's binary_logloss: 0.338387\n",
      "[2300]\ttraining's binary_logloss: 0.18449\tvalid_1's binary_logloss: 0.339703\n",
      "[2400]\ttraining's binary_logloss: 0.179118\tvalid_1's binary_logloss: 0.341166\n",
      "[2500]\ttraining's binary_logloss: 0.174137\tvalid_1's binary_logloss: 0.342167\n",
      "[2600]\ttraining's binary_logloss: 0.169274\tvalid_1's binary_logloss: 0.343303\n",
      "[2700]\ttraining's binary_logloss: 0.164645\tvalid_1's binary_logloss: 0.344514\n",
      "[2800]\ttraining's binary_logloss: 0.160153\tvalid_1's binary_logloss: 0.345875\n",
      "[2900]\ttraining's binary_logloss: 0.155782\tvalid_1's binary_logloss: 0.34699\n",
      "[3000]\ttraining's binary_logloss: 0.151365\tvalid_1's binary_logloss: 0.348216\n",
      "[3100]\ttraining's binary_logloss: 0.146773\tvalid_1's binary_logloss: 0.350597\n",
      "[3200]\ttraining's binary_logloss: 0.142465\tvalid_1's binary_logloss: 0.352572\n",
      "[3300]\ttraining's binary_logloss: 0.138437\tvalid_1's binary_logloss: 0.353993\n",
      "[3400]\ttraining's binary_logloss: 0.134148\tvalid_1's binary_logloss: 0.35592\n",
      "[3500]\ttraining's binary_logloss: 0.129926\tvalid_1's binary_logloss: 0.358135\n",
      "[3600]\ttraining's binary_logloss: 0.125849\tvalid_1's binary_logloss: 0.36027\n",
      "[3700]\ttraining's binary_logloss: 0.121627\tvalid_1's binary_logloss: 0.361533\n",
      "[3800]\ttraining's binary_logloss: 0.117511\tvalid_1's binary_logloss: 0.363305\n",
      "[3900]\ttraining's binary_logloss: 0.113589\tvalid_1's binary_logloss: 0.365394\n",
      "[4000]\ttraining's binary_logloss: 0.110198\tvalid_1's binary_logloss: 0.367435\n",
      "[4100]\ttraining's binary_logloss: 0.106826\tvalid_1's binary_logloss: 0.369883\n",
      "[4200]\ttraining's binary_logloss: 0.10353\tvalid_1's binary_logloss: 0.372011\n",
      "[4300]\ttraining's binary_logloss: 0.100333\tvalid_1's binary_logloss: 0.373641\n",
      "[4400]\ttraining's binary_logloss: 0.0973547\tvalid_1's binary_logloss: 0.375444\n",
      "[4500]\ttraining's binary_logloss: 0.0945192\tvalid_1's binary_logloss: 0.376904\n",
      "[4600]\ttraining's binary_logloss: 0.0917726\tvalid_1's binary_logloss: 0.378762\n",
      "[4700]\ttraining's binary_logloss: 0.0890177\tvalid_1's binary_logloss: 0.381324\n",
      "[4800]\ttraining's binary_logloss: 0.0864259\tvalid_1's binary_logloss: 0.384892\n",
      "[4900]\ttraining's binary_logloss: 0.0839086\tvalid_1's binary_logloss: 0.387815\n",
      "[5000]\ttraining's binary_logloss: 0.0815932\tvalid_1's binary_logloss: 0.390731\n",
      "Partial score of fold 1 is: 0.39073066974075144\n",
      "[100]\ttraining's binary_logloss: 0.526922\tvalid_1's binary_logloss: 0.578051\n",
      "[200]\ttraining's binary_logloss: 0.443519\tvalid_1's binary_logloss: 0.526102\n",
      "[300]\ttraining's binary_logloss: 0.388693\tvalid_1's binary_logloss: 0.493312\n",
      "[400]\ttraining's binary_logloss: 0.344858\tvalid_1's binary_logloss: 0.471016\n",
      "[500]\ttraining's binary_logloss: 0.313905\tvalid_1's binary_logloss: 0.457573\n",
      "[600]\ttraining's binary_logloss: 0.287996\tvalid_1's binary_logloss: 0.447081\n",
      "[700]\ttraining's binary_logloss: 0.267076\tvalid_1's binary_logloss: 0.444703\n",
      "[800]\ttraining's binary_logloss: 0.249586\tvalid_1's binary_logloss: 0.446731\n",
      "[900]\ttraining's binary_logloss: 0.233664\tvalid_1's binary_logloss: 0.453576\n",
      "[1000]\ttraining's binary_logloss: 0.218591\tvalid_1's binary_logloss: 0.45973\n",
      "[1100]\ttraining's binary_logloss: 0.204506\tvalid_1's binary_logloss: 0.462396\n",
      "[1200]\ttraining's binary_logloss: 0.191282\tvalid_1's binary_logloss: 0.465234\n",
      "[1300]\ttraining's binary_logloss: 0.178666\tvalid_1's binary_logloss: 0.469699\n",
      "[1400]\ttraining's binary_logloss: 0.166592\tvalid_1's binary_logloss: 0.474199\n",
      "[1500]\ttraining's binary_logloss: 0.156473\tvalid_1's binary_logloss: 0.479203\n",
      "[1600]\ttraining's binary_logloss: 0.147068\tvalid_1's binary_logloss: 0.485997\n",
      "[1700]\ttraining's binary_logloss: 0.138375\tvalid_1's binary_logloss: 0.491286\n",
      "[1800]\ttraining's binary_logloss: 0.130635\tvalid_1's binary_logloss: 0.496531\n",
      "[1900]\ttraining's binary_logloss: 0.123544\tvalid_1's binary_logloss: 0.49986\n",
      "[2000]\ttraining's binary_logloss: 0.116903\tvalid_1's binary_logloss: 0.501921\n",
      "[2100]\ttraining's binary_logloss: 0.110916\tvalid_1's binary_logloss: 0.504765\n",
      "[2200]\ttraining's binary_logloss: 0.1055\tvalid_1's binary_logloss: 0.506703\n",
      "[2300]\ttraining's binary_logloss: 0.100303\tvalid_1's binary_logloss: 0.508262\n",
      "[2400]\ttraining's binary_logloss: 0.0955234\tvalid_1's binary_logloss: 0.51065\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-0dfad4fca3bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m lgbm = LgbModel(train, test, target, features, categoricals=[], n_splits=10, \n\u001b[1;32m----> 2\u001b[1;33m                     cv_method=\"TimeSeriesSplit\", group=None, task=\"binary\", scaler=None, verbose=True)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-64-cf9f5488c261>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, train_df, test_df, target, features, categoricals, n_splits, cv_method, group, task, parameter_tuning, seed, scaler, verbose)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moof\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfi_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-cf9f5488c261>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mx_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategoricals\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumerical_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimportance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[0mfi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0mconv_x_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-e61661c008de>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self, train_set, val_set)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mverbosity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mfi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gain\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1976\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1978\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lgbm = LgbModel(train, test, target, features, categoricals=[], n_splits=10, \n",
    "                    cv_method=\"TimeSeriesSplit\", group=None, task=\"binary\", scaler=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 2015...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['T1_FGM mean', 'T1_FGA mean', 'T1_FGM3 mean', 'T1_FGA3 mean',\\n       'T1_FTM mean', 'T1_FTA mean', 'T1_OR mean', 'T1_DR mean', 'T1_Ast mean',\\n       'T1_TO mean', 'T1_Stl mean', 'T1_Blk mean', 'T1_PF mean',\\n       'T1_opponent_FGM mean', 'T1_opponent_FGA mean', 'T1_opponent_FGM3 mean',\\n       'T1_opponent_FGA3 mean', 'T1_opponent_FTM mean', 'T1_opponent_FTA mean',\\n       'T1_opponent_OR mean', 'T1_opponent_DR mean', 'T1_opponent_Ast mean',\\n       'T1_opponent_TO mean', 'T1_opponent_Stl mean', 'T1_opponent_Blk mean',\\n       'T1_opponent_PF mean', 'T1_PointDiff mean', 'T2_FGM mean',\\n       'T2_FGA mean', 'T2_FGM3 mean', 'T2_FGA3 mean', 'T2_FTM mean',\\n       'T2_FTA mean', 'T2_OR mean', 'T2_DR mean', 'T2_Ast mean', 'T2_TO mean',\\n       'T2_Stl mean', 'T2_Blk mean', 'T2_PF mean', 'T2_opponent_FGM mean',\\n       'T2_opponent_FGA mean', 'T2_opponent_FGM3 mean',\\n       'T2_opponent_FGA3 mean', 'T2_opponent_FTM mean', 'T2_opponent_FTA mean',\\n       'T2_opponent_OR mean', 'T2_opponent_DR mean', 'T2_opponent_Ast mean',\\n       'T2_opponent_TO mean', 'T2_opponent_Stl mean', 'T2_opponent_Blk mean',\\n       'T2_opponent_PF mean', 'T2_PointDiff mean', 'T1_win_ratio_14d',\\n       'T2_win_ratio_14d', 'T1_quality', 'T2_quality', 'T1_seed', 'T2_seed',\\n       'Seed_diff'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-324-d4b181826fc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Predicting {season}...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     lgbm = LgbModel(train.loc[train[\"Season\"] < season, :], test.loc[test[\"Season\"] == season, :], target, features, categoricals=[], n_splits=10, \n\u001b[1;32m----> 4\u001b[1;33m                     cv_method=\"TimeSeriesSplit\", group=None, task=\"binary\", scaler=None, verbose=True)\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseason\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Season\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mseason\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Pred\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-313-cf9f5488c261>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, train_df, test_df, target, features, categoricals, n_splits, cv_method, group, task, parameter_tuning, seed, scaler, verbose)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moof\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfi_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-313-cf9f5488c261>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategoricals\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumerical_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;31m# fitting with out of fold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2999\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3000\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3001\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3003\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1175\u001b[0m                 raise KeyError(\n\u001b[0;32m   1176\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[1;32m-> 1177\u001b[1;33m                         \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m                     )\n\u001b[0;32m   1179\u001b[0m                 )\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['T1_FGM mean', 'T1_FGA mean', 'T1_FGM3 mean', 'T1_FGA3 mean',\\n       'T1_FTM mean', 'T1_FTA mean', 'T1_OR mean', 'T1_DR mean', 'T1_Ast mean',\\n       'T1_TO mean', 'T1_Stl mean', 'T1_Blk mean', 'T1_PF mean',\\n       'T1_opponent_FGM mean', 'T1_opponent_FGA mean', 'T1_opponent_FGM3 mean',\\n       'T1_opponent_FGA3 mean', 'T1_opponent_FTM mean', 'T1_opponent_FTA mean',\\n       'T1_opponent_OR mean', 'T1_opponent_DR mean', 'T1_opponent_Ast mean',\\n       'T1_opponent_TO mean', 'T1_opponent_Stl mean', 'T1_opponent_Blk mean',\\n       'T1_opponent_PF mean', 'T1_PointDiff mean', 'T2_FGM mean',\\n       'T2_FGA mean', 'T2_FGM3 mean', 'T2_FGA3 mean', 'T2_FTM mean',\\n       'T2_FTA mean', 'T2_OR mean', 'T2_DR mean', 'T2_Ast mean', 'T2_TO mean',\\n       'T2_Stl mean', 'T2_Blk mean', 'T2_PF mean', 'T2_opponent_FGM mean',\\n       'T2_opponent_FGA mean', 'T2_opponent_FGM3 mean',\\n       'T2_opponent_FGA3 mean', 'T2_opponent_FTM mean', 'T2_opponent_FTA mean',\\n       'T2_opponent_OR mean', 'T2_opponent_DR mean', 'T2_opponent_Ast mean',\\n       'T2_opponent_TO mean', 'T2_opponent_Stl mean', 'T2_opponent_Blk mean',\\n       'T2_opponent_PF mean', 'T2_PointDiff mean', 'T1_win_ratio_14d',\\n       'T2_win_ratio_14d', 'T1_quality', 'T2_quality', 'T1_seed', 'T2_seed',\\n       'Seed_diff'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "for season in test[\"Season\"].unique():\n",
    "    print(f\"Predicting {season}...\")\n",
    "    lgbm = LgbModel(train.loc[train[\"Season\"] < season, :], test.loc[test[\"Season\"] == season, :], target, features, categoricals=[], n_splits=10, \n",
    "                    cv_method=\"TimeSeriesSplit\", group=None, task=\"binary\", scaler=None, verbose=True)\n",
    "    models[season] = lgbm\n",
    "    test.loc[test[\"Season\"] == season, \"Pred\"] = lgbm.y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {'colsample_bytree': 0.8,                 \n",
    "              'learning_rate': 0.001,\n",
    "              'max_depth': 31,\n",
    "              'subsample': 1,\n",
    "              'objective':'binary:logistic',\n",
    "              'eval_metric':'logloss',\n",
    "              'min_child_weight':3,\n",
    "              'gamma':0.25,\n",
    "              'n_estimators':5000\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['Season','T1_TeamID','T2_TeamID','DayNum','T1_Score','T2_Score','DayZero','result'], axis=1)\n",
    "y_train = train.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test.drop(['ID','Season','T1_TeamID','T2_TeamID','Pred'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "[0]\ttrain-logloss:0.692547\tval-logloss:0.692708\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638934\tval-logloss:0.642912\n",
      "[200]\ttrain-logloss:0.592457\tval-logloss:0.602795\n",
      "[300]\ttrain-logloss:0.552037\tval-logloss:0.568086\n",
      "[400]\ttrain-logloss:0.515899\tval-logloss:0.537559\n",
      "[500]\ttrain-logloss:0.483705\tval-logloss:0.511265\n",
      "[600]\ttrain-logloss:0.454875\tval-logloss:0.489368\n",
      "[700]\ttrain-logloss:0.428735\tval-logloss:0.47372\n",
      "[800]\ttrain-logloss:0.405125\tval-logloss:0.460998\n",
      "[900]\ttrain-logloss:0.383709\tval-logloss:0.450587\n",
      "[1000]\ttrain-logloss:0.36412\tval-logloss:0.44037\n",
      "[1100]\ttrain-logloss:0.346216\tval-logloss:0.433046\n",
      "[1200]\ttrain-logloss:0.329966\tval-logloss:0.427181\n",
      "[1300]\ttrain-logloss:0.315171\tval-logloss:0.422101\n",
      "[1400]\ttrain-logloss:0.301329\tval-logloss:0.415972\n",
      "[1500]\ttrain-logloss:0.288466\tval-logloss:0.410323\n",
      "[1600]\ttrain-logloss:0.276612\tval-logloss:0.405686\n",
      "[1700]\ttrain-logloss:0.26554\tval-logloss:0.399215\n",
      "[1800]\ttrain-logloss:0.255159\tval-logloss:0.392996\n",
      "[1900]\ttrain-logloss:0.245483\tval-logloss:0.388775\n",
      "[2000]\ttrain-logloss:0.236438\tval-logloss:0.385722\n",
      "[2100]\ttrain-logloss:0.227855\tval-logloss:0.384241\n",
      "[2200]\ttrain-logloss:0.219844\tval-logloss:0.38373\n",
      "[2300]\ttrain-logloss:0.212217\tval-logloss:0.380888\n",
      "[2400]\ttrain-logloss:0.2049\tval-logloss:0.377619\n",
      "[2500]\ttrain-logloss:0.198131\tval-logloss:0.37592\n",
      "[2600]\ttrain-logloss:0.191775\tval-logloss:0.373932\n",
      "[2700]\ttrain-logloss:0.185786\tval-logloss:0.372481\n",
      "[2800]\ttrain-logloss:0.180153\tval-logloss:0.371244\n",
      "[2900]\ttrain-logloss:0.17483\tval-logloss:0.370691\n",
      "[3000]\ttrain-logloss:0.169845\tval-logloss:0.370377\n",
      "[3100]\ttrain-logloss:0.165132\tval-logloss:0.370254\n",
      "Stopping. Best iteration:\n",
      "[3028]\ttrain-logloss:0.168495\tval-logloss:0.370035\n",
      "\n",
      "Fold: 2\n",
      "[0]\ttrain-logloss:0.692557\tval-logloss:0.692472\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639047\tval-logloss:0.624267\n",
      "[200]\ttrain-logloss:0.592608\tval-logloss:0.568207\n",
      "[300]\ttrain-logloss:0.552112\tval-logloss:0.52139\n",
      "[400]\ttrain-logloss:0.516088\tval-logloss:0.480914\n",
      "[500]\ttrain-logloss:0.483856\tval-logloss:0.444377\n",
      "[600]\ttrain-logloss:0.454997\tval-logloss:0.412689\n",
      "[700]\ttrain-logloss:0.428978\tval-logloss:0.38565\n",
      "[800]\ttrain-logloss:0.405288\tval-logloss:0.363207\n",
      "[900]\ttrain-logloss:0.383756\tval-logloss:0.342597\n",
      "[1000]\ttrain-logloss:0.364215\tval-logloss:0.324492\n",
      "[1100]\ttrain-logloss:0.346315\tval-logloss:0.308909\n",
      "[1200]\ttrain-logloss:0.33001\tval-logloss:0.295711\n",
      "[1300]\ttrain-logloss:0.315031\tval-logloss:0.284597\n",
      "[1400]\ttrain-logloss:0.30126\tval-logloss:0.273351\n",
      "[1500]\ttrain-logloss:0.288442\tval-logloss:0.263702\n",
      "[1600]\ttrain-logloss:0.276561\tval-logloss:0.25502\n",
      "[1700]\ttrain-logloss:0.265538\tval-logloss:0.24656\n",
      "[1800]\ttrain-logloss:0.255138\tval-logloss:0.238832\n",
      "[1900]\ttrain-logloss:0.245467\tval-logloss:0.230546\n",
      "[2000]\ttrain-logloss:0.236222\tval-logloss:0.222854\n",
      "[2100]\ttrain-logloss:0.227562\tval-logloss:0.217029\n",
      "[2200]\ttrain-logloss:0.219431\tval-logloss:0.212674\n",
      "[2300]\ttrain-logloss:0.211921\tval-logloss:0.208078\n",
      "[2400]\ttrain-logloss:0.204874\tval-logloss:0.204431\n",
      "[2500]\ttrain-logloss:0.198178\tval-logloss:0.201046\n",
      "[2600]\ttrain-logloss:0.1918\tval-logloss:0.199376\n",
      "[2700]\ttrain-logloss:0.185849\tval-logloss:0.197152\n",
      "[2800]\ttrain-logloss:0.180218\tval-logloss:0.195065\n",
      "[2900]\ttrain-logloss:0.174966\tval-logloss:0.192357\n",
      "[3000]\ttrain-logloss:0.169957\tval-logloss:0.190185\n",
      "[3100]\ttrain-logloss:0.165227\tval-logloss:0.187705\n",
      "[3200]\ttrain-logloss:0.160763\tval-logloss:0.185817\n",
      "[3300]\ttrain-logloss:0.156501\tval-logloss:0.183757\n",
      "[3400]\ttrain-logloss:0.152471\tval-logloss:0.182212\n",
      "[3500]\ttrain-logloss:0.148601\tval-logloss:0.180139\n",
      "[3600]\ttrain-logloss:0.144887\tval-logloss:0.178744\n",
      "[3700]\ttrain-logloss:0.141283\tval-logloss:0.177767\n",
      "[3800]\ttrain-logloss:0.137861\tval-logloss:0.177009\n",
      "[3900]\ttrain-logloss:0.134592\tval-logloss:0.175693\n",
      "[4000]\ttrain-logloss:0.131475\tval-logloss:0.174195\n",
      "[4100]\ttrain-logloss:0.128485\tval-logloss:0.173288\n",
      "[4200]\ttrain-logloss:0.125612\tval-logloss:0.172718\n",
      "[4300]\ttrain-logloss:0.122886\tval-logloss:0.171707\n",
      "[4400]\ttrain-logloss:0.120257\tval-logloss:0.171134\n",
      "[4500]\ttrain-logloss:0.117755\tval-logloss:0.170493\n",
      "[4600]\ttrain-logloss:0.115373\tval-logloss:0.169845\n",
      "[4700]\ttrain-logloss:0.113072\tval-logloss:0.169476\n",
      "[4800]\ttrain-logloss:0.110891\tval-logloss:0.168937\n",
      "[4900]\ttrain-logloss:0.1088\tval-logloss:0.168453\n",
      "[4999]\ttrain-logloss:0.106763\tval-logloss:0.167981\n",
      "Fold: 3\n",
      "[0]\ttrain-logloss:0.692553\tval-logloss:0.692962\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638544\tval-logloss:0.679942\n",
      "[200]\ttrain-logloss:0.591817\tval-logloss:0.673927\n",
      "[300]\ttrain-logloss:0.551051\tval-logloss:0.67068\n",
      "[400]\ttrain-logloss:0.514846\tval-logloss:0.6708\n",
      "[500]\ttrain-logloss:0.482624\tval-logloss:0.67219\n",
      "Stopping. Best iteration:\n",
      "[416]\ttrain-logloss:0.509456\tval-logloss:0.670187\n",
      "\n",
      "Fold: 4\n",
      "[0]\ttrain-logloss:0.692553\tval-logloss:0.69287\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638877\tval-logloss:0.658399\n",
      "[200]\ttrain-logloss:0.592388\tval-logloss:0.629602\n",
      "[300]\ttrain-logloss:0.551796\tval-logloss:0.606855\n",
      "[400]\ttrain-logloss:0.51576\tval-logloss:0.590279\n",
      "[500]\ttrain-logloss:0.483497\tval-logloss:0.577082\n",
      "[600]\ttrain-logloss:0.454704\tval-logloss:0.566324\n",
      "[700]\ttrain-logloss:0.428691\tval-logloss:0.55815\n",
      "[800]\ttrain-logloss:0.405015\tval-logloss:0.549083\n",
      "[900]\ttrain-logloss:0.383542\tval-logloss:0.54192\n",
      "[1000]\ttrain-logloss:0.363994\tval-logloss:0.536181\n",
      "[1100]\ttrain-logloss:0.346316\tval-logloss:0.532428\n",
      "[1200]\ttrain-logloss:0.330214\tval-logloss:0.527435\n",
      "[1300]\ttrain-logloss:0.315333\tval-logloss:0.522623\n",
      "[1400]\ttrain-logloss:0.301637\tval-logloss:0.518548\n",
      "[1500]\ttrain-logloss:0.288808\tval-logloss:0.514254\n",
      "[1600]\ttrain-logloss:0.276762\tval-logloss:0.512234\n",
      "[1700]\ttrain-logloss:0.265521\tval-logloss:0.510464\n",
      "[1800]\ttrain-logloss:0.255133\tval-logloss:0.50815\n",
      "[1900]\ttrain-logloss:0.245468\tval-logloss:0.506315\n",
      "[2000]\ttrain-logloss:0.236424\tval-logloss:0.504661\n",
      "[2100]\ttrain-logloss:0.227721\tval-logloss:0.501918\n",
      "[2200]\ttrain-logloss:0.219551\tval-logloss:0.498442\n",
      "[2300]\ttrain-logloss:0.211849\tval-logloss:0.495164\n",
      "[2400]\ttrain-logloss:0.204632\tval-logloss:0.492975\n",
      "[2500]\ttrain-logloss:0.197865\tval-logloss:0.490678\n",
      "[2600]\ttrain-logloss:0.191484\tval-logloss:0.487619\n",
      "[2700]\ttrain-logloss:0.185497\tval-logloss:0.48612\n",
      "[2800]\ttrain-logloss:0.179875\tval-logloss:0.484333\n",
      "[2900]\ttrain-logloss:0.174601\tval-logloss:0.48436\n",
      "[3000]\ttrain-logloss:0.169571\tval-logloss:0.483268\n",
      "[3100]\ttrain-logloss:0.164853\tval-logloss:0.481364\n",
      "[3200]\ttrain-logloss:0.160381\tval-logloss:0.480144\n",
      "[3300]\ttrain-logloss:0.156114\tval-logloss:0.478133\n",
      "[3400]\ttrain-logloss:0.152061\tval-logloss:0.477573\n",
      "[3500]\ttrain-logloss:0.148219\tval-logloss:0.477034\n",
      "[3600]\ttrain-logloss:0.144483\tval-logloss:0.475021\n",
      "[3700]\ttrain-logloss:0.140881\tval-logloss:0.472798\n",
      "[3800]\ttrain-logloss:0.137433\tval-logloss:0.469635\n",
      "[3900]\ttrain-logloss:0.134134\tval-logloss:0.468\n",
      "[4000]\ttrain-logloss:0.130999\tval-logloss:0.466468\n",
      "[4100]\ttrain-logloss:0.128034\tval-logloss:0.465869\n",
      "[4200]\ttrain-logloss:0.125178\tval-logloss:0.464645\n",
      "[4300]\ttrain-logloss:0.122442\tval-logloss:0.463382\n",
      "[4400]\ttrain-logloss:0.119801\tval-logloss:0.46281\n",
      "[4500]\ttrain-logloss:0.117293\tval-logloss:0.463507\n",
      "Stopping. Best iteration:\n",
      "[4428]\ttrain-logloss:0.119084\tval-logloss:0.462316\n",
      "\n",
      "Fold: 5\n",
      "[0]\ttrain-logloss:0.692554\tval-logloss:0.692792\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638773\tval-logloss:0.663134\n",
      "[200]\ttrain-logloss:0.59214\tval-logloss:0.641841\n",
      "[300]\ttrain-logloss:0.551551\tval-logloss:0.626503\n",
      "[400]\ttrain-logloss:0.515402\tval-logloss:0.614075\n",
      "[500]\ttrain-logloss:0.48297\tval-logloss:0.60544\n",
      "[600]\ttrain-logloss:0.45393\tval-logloss:0.599557\n",
      "[700]\ttrain-logloss:0.427899\tval-logloss:0.596408\n",
      "[800]\ttrain-logloss:0.404423\tval-logloss:0.595768\n",
      "[900]\ttrain-logloss:0.382998\tval-logloss:0.595871\n",
      "[1000]\ttrain-logloss:0.363623\tval-logloss:0.595669\n",
      "Stopping. Best iteration:\n",
      "[958]\ttrain-logloss:0.371546\tval-logloss:0.594817\n",
      "\n",
      "Fold: 6\n",
      "[0]\ttrain-logloss:0.692565\tval-logloss:0.692561\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638801\tval-logloss:0.647617\n",
      "[200]\ttrain-logloss:0.592274\tval-logloss:0.607558\n",
      "[300]\ttrain-logloss:0.551569\tval-logloss:0.572222\n",
      "[400]\ttrain-logloss:0.515338\tval-logloss:0.539927\n",
      "[500]\ttrain-logloss:0.483145\tval-logloss:0.511708\n",
      "[600]\ttrain-logloss:0.454278\tval-logloss:0.490069\n",
      "[700]\ttrain-logloss:0.428186\tval-logloss:0.473887\n",
      "[800]\ttrain-logloss:0.404491\tval-logloss:0.461351\n",
      "[900]\ttrain-logloss:0.38299\tval-logloss:0.452372\n",
      "[1000]\ttrain-logloss:0.36348\tval-logloss:0.443852\n",
      "[1100]\ttrain-logloss:0.345814\tval-logloss:0.435706\n",
      "[1200]\ttrain-logloss:0.329658\tval-logloss:0.426195\n",
      "[1300]\ttrain-logloss:0.314802\tval-logloss:0.41699\n",
      "[1400]\ttrain-logloss:0.300943\tval-logloss:0.407138\n",
      "[1500]\ttrain-logloss:0.287973\tval-logloss:0.399735\n",
      "[1600]\ttrain-logloss:0.276072\tval-logloss:0.390995\n",
      "[1700]\ttrain-logloss:0.265062\tval-logloss:0.383413\n",
      "[1800]\ttrain-logloss:0.254763\tval-logloss:0.375185\n",
      "[1900]\ttrain-logloss:0.245175\tval-logloss:0.368007\n",
      "[2000]\ttrain-logloss:0.236045\tval-logloss:0.361877\n",
      "[2100]\ttrain-logloss:0.22737\tval-logloss:0.354012\n",
      "[2200]\ttrain-logloss:0.219203\tval-logloss:0.348382\n",
      "[2300]\ttrain-logloss:0.211632\tval-logloss:0.341356\n",
      "[2400]\ttrain-logloss:0.204379\tval-logloss:0.337037\n",
      "[2500]\ttrain-logloss:0.197593\tval-logloss:0.334024\n",
      "[2600]\ttrain-logloss:0.191233\tval-logloss:0.332407\n",
      "[2700]\ttrain-logloss:0.185258\tval-logloss:0.330948\n",
      "[2800]\ttrain-logloss:0.179595\tval-logloss:0.329907\n",
      "[2900]\ttrain-logloss:0.174332\tval-logloss:0.327932\n",
      "[3000]\ttrain-logloss:0.169361\tval-logloss:0.324746\n",
      "[3100]\ttrain-logloss:0.164645\tval-logloss:0.323495\n",
      "[3200]\ttrain-logloss:0.160194\tval-logloss:0.321439\n",
      "[3300]\ttrain-logloss:0.155953\tval-logloss:0.3203\n",
      "[3400]\ttrain-logloss:0.151939\tval-logloss:0.31866\n",
      "[3500]\ttrain-logloss:0.14809\tval-logloss:0.318113\n",
      "[3600]\ttrain-logloss:0.144444\tval-logloss:0.316787\n",
      "[3700]\ttrain-logloss:0.140911\tval-logloss:0.315569\n",
      "[3800]\ttrain-logloss:0.137497\tval-logloss:0.315019\n",
      "[3900]\ttrain-logloss:0.134191\tval-logloss:0.312683\n",
      "[4000]\ttrain-logloss:0.131048\tval-logloss:0.310677\n",
      "[4100]\ttrain-logloss:0.128065\tval-logloss:0.309393\n",
      "[4200]\ttrain-logloss:0.125193\tval-logloss:0.307096\n",
      "[4300]\ttrain-logloss:0.122454\tval-logloss:0.302902\n",
      "[4400]\ttrain-logloss:0.119814\tval-logloss:0.299321\n",
      "[4500]\ttrain-logloss:0.117314\tval-logloss:0.296948\n",
      "[4600]\ttrain-logloss:0.114906\tval-logloss:0.295457\n",
      "[4700]\ttrain-logloss:0.11259\tval-logloss:0.293885\n",
      "[4800]\ttrain-logloss:0.110393\tval-logloss:0.29236\n",
      "[4900]\ttrain-logloss:0.108288\tval-logloss:0.292159\n",
      "Stopping. Best iteration:\n",
      "[4866]\ttrain-logloss:0.108995\tval-logloss:0.291841\n",
      "\n",
      "Fold: 7\n",
      "[0]\ttrain-logloss:0.692556\tval-logloss:0.692963\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638536\tval-logloss:0.675284\n",
      "[200]\ttrain-logloss:0.591879\tval-logloss:0.661645\n",
      "[300]\ttrain-logloss:0.551229\tval-logloss:0.648451\n",
      "[400]\ttrain-logloss:0.514984\tval-logloss:0.63774\n",
      "[500]\ttrain-logloss:0.482664\tval-logloss:0.628294\n",
      "[600]\ttrain-logloss:0.453645\tval-logloss:0.618998\n",
      "[700]\ttrain-logloss:0.427303\tval-logloss:0.61038\n",
      "[800]\ttrain-logloss:0.403634\tval-logloss:0.604356\n",
      "[900]\ttrain-logloss:0.382142\tval-logloss:0.597622\n",
      "[1000]\ttrain-logloss:0.362635\tval-logloss:0.591552\n",
      "[1100]\ttrain-logloss:0.344821\tval-logloss:0.586124\n",
      "[1200]\ttrain-logloss:0.328585\tval-logloss:0.581171\n",
      "[1300]\ttrain-logloss:0.313663\tval-logloss:0.57562\n",
      "[1400]\ttrain-logloss:0.299823\tval-logloss:0.568709\n",
      "[1500]\ttrain-logloss:0.287\tval-logloss:0.563952\n",
      "[1600]\ttrain-logloss:0.274992\tval-logloss:0.56036\n",
      "[1700]\ttrain-logloss:0.263842\tval-logloss:0.556758\n",
      "[1800]\ttrain-logloss:0.253609\tval-logloss:0.554976\n",
      "[1900]\ttrain-logloss:0.244095\tval-logloss:0.555199\n",
      "Stopping. Best iteration:\n",
      "[1811]\ttrain-logloss:0.252535\tval-logloss:0.554823\n",
      "\n",
      "Fold: 8\n",
      "[0]\ttrain-logloss:0.692548\tval-logloss:0.693074\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638288\tval-logloss:0.680326\n",
      "[200]\ttrain-logloss:0.591583\tval-logloss:0.673402\n",
      "[300]\ttrain-logloss:0.550871\tval-logloss:0.669132\n",
      "[400]\ttrain-logloss:0.51469\tval-logloss:0.667976\n",
      "Stopping. Best iteration:\n",
      "[382]\ttrain-logloss:0.520951\tval-logloss:0.666979\n",
      "\n",
      "Fold: 9\n",
      "[0]\ttrain-logloss:0.692565\tval-logloss:0.692557\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.63882\tval-logloss:0.645531\n",
      "[200]\ttrain-logloss:0.592336\tval-logloss:0.605462\n",
      "[300]\ttrain-logloss:0.551827\tval-logloss:0.570406\n",
      "[400]\ttrain-logloss:0.515806\tval-logloss:0.538878\n",
      "[500]\ttrain-logloss:0.483537\tval-logloss:0.509664\n",
      "[600]\ttrain-logloss:0.454623\tval-logloss:0.480022\n",
      "[700]\ttrain-logloss:0.428459\tval-logloss:0.452762\n",
      "[800]\ttrain-logloss:0.404762\tval-logloss:0.426948\n",
      "[900]\ttrain-logloss:0.383434\tval-logloss:0.402198\n",
      "[1000]\ttrain-logloss:0.36395\tval-logloss:0.380244\n",
      "[1100]\ttrain-logloss:0.34621\tval-logloss:0.359608\n",
      "[1200]\ttrain-logloss:0.330017\tval-logloss:0.342666\n",
      "[1300]\ttrain-logloss:0.315149\tval-logloss:0.32765\n",
      "[1400]\ttrain-logloss:0.30132\tval-logloss:0.313978\n",
      "[1500]\ttrain-logloss:0.288579\tval-logloss:0.300075\n",
      "[1600]\ttrain-logloss:0.276737\tval-logloss:0.286757\n",
      "[1700]\ttrain-logloss:0.265673\tval-logloss:0.275182\n",
      "[1800]\ttrain-logloss:0.255222\tval-logloss:0.267823\n",
      "[1900]\ttrain-logloss:0.245401\tval-logloss:0.26078\n",
      "[2000]\ttrain-logloss:0.236092\tval-logloss:0.254323\n",
      "[2100]\ttrain-logloss:0.227475\tval-logloss:0.250045\n",
      "[2200]\ttrain-logloss:0.219381\tval-logloss:0.248606\n",
      "[2300]\ttrain-logloss:0.2117\tval-logloss:0.245242\n",
      "[2400]\ttrain-logloss:0.204466\tval-logloss:0.241105\n",
      "[2500]\ttrain-logloss:0.197616\tval-logloss:0.237385\n",
      "[2600]\ttrain-logloss:0.191305\tval-logloss:0.234818\n",
      "[2700]\ttrain-logloss:0.185311\tval-logloss:0.233555\n",
      "[2800]\ttrain-logloss:0.179683\tval-logloss:0.231735\n",
      "[2900]\ttrain-logloss:0.174359\tval-logloss:0.23095\n",
      "[3000]\ttrain-logloss:0.169369\tval-logloss:0.230642\n",
      "Stopping. Best iteration:\n",
      "[2939]\ttrain-logloss:0.172407\tval-logloss:0.2304\n",
      "\n",
      "Fold: 10\n",
      "[0]\ttrain-logloss:0.692562\tval-logloss:0.692874\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638728\tval-logloss:0.670808\n",
      "[200]\ttrain-logloss:0.592152\tval-logloss:0.654022\n",
      "[300]\ttrain-logloss:0.5514\tval-logloss:0.641618\n",
      "[400]\ttrain-logloss:0.515197\tval-logloss:0.632578\n",
      "[500]\ttrain-logloss:0.482822\tval-logloss:0.622874\n",
      "[600]\ttrain-logloss:0.453736\tval-logloss:0.616263\n",
      "[700]\ttrain-logloss:0.427508\tval-logloss:0.609361\n",
      "[800]\ttrain-logloss:0.403812\tval-logloss:0.600327\n",
      "[900]\ttrain-logloss:0.382179\tval-logloss:0.596038\n",
      "[1000]\ttrain-logloss:0.362399\tval-logloss:0.595169\n",
      "Stopping. Best iteration:\n",
      "[973]\ttrain-logloss:0.367587\tval-logloss:0.594219\n",
      "\n",
      "Fold: 11\n",
      "[0]\ttrain-logloss:0.692564\tval-logloss:0.692542\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638903\tval-logloss:0.644603\n",
      "[200]\ttrain-logloss:0.592523\tval-logloss:0.604677\n",
      "[300]\ttrain-logloss:0.551927\tval-logloss:0.570013\n",
      "[400]\ttrain-logloss:0.515959\tval-logloss:0.541434\n",
      "[500]\ttrain-logloss:0.483788\tval-logloss:0.517225\n",
      "[600]\ttrain-logloss:0.454786\tval-logloss:0.49652\n",
      "[700]\ttrain-logloss:0.428525\tval-logloss:0.476571\n",
      "[800]\ttrain-logloss:0.40478\tval-logloss:0.459499\n",
      "[900]\ttrain-logloss:0.383279\tval-logloss:0.445971\n",
      "[1000]\ttrain-logloss:0.363766\tval-logloss:0.434232\n",
      "[1100]\ttrain-logloss:0.34603\tval-logloss:0.424283\n",
      "[1200]\ttrain-logloss:0.32969\tval-logloss:0.41576\n",
      "[1300]\ttrain-logloss:0.314629\tval-logloss:0.408892\n",
      "[1400]\ttrain-logloss:0.300733\tval-logloss:0.40368\n",
      "[1500]\ttrain-logloss:0.287872\tval-logloss:0.398038\n",
      "[1600]\ttrain-logloss:0.275913\tval-logloss:0.393587\n",
      "[1700]\ttrain-logloss:0.264774\tval-logloss:0.386478\n",
      "[1800]\ttrain-logloss:0.254493\tval-logloss:0.382209\n",
      "[1900]\ttrain-logloss:0.244772\tval-logloss:0.378409\n",
      "[2000]\ttrain-logloss:0.235466\tval-logloss:0.37701\n",
      "[2100]\ttrain-logloss:0.226745\tval-logloss:0.376261\n",
      "[2200]\ttrain-logloss:0.218608\tval-logloss:0.374645\n",
      "[2300]\ttrain-logloss:0.210951\tval-logloss:0.373557\n",
      "[2400]\ttrain-logloss:0.203823\tval-logloss:0.372529\n",
      "[2500]\ttrain-logloss:0.197188\tval-logloss:0.371457\n",
      "[2600]\ttrain-logloss:0.190891\tval-logloss:0.370436\n",
      "Stopping. Best iteration:\n",
      "[2594]\ttrain-logloss:0.191263\tval-logloss:0.370285\n",
      "\n",
      "Fold: 12\n",
      "[0]\ttrain-logloss:0.692557\tval-logloss:0.692583\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638965\tval-logloss:0.642423\n",
      "[200]\ttrain-logloss:0.592473\tval-logloss:0.600594\n",
      "[300]\ttrain-logloss:0.551922\tval-logloss:0.564402\n",
      "[400]\ttrain-logloss:0.515898\tval-logloss:0.533067\n",
      "[500]\ttrain-logloss:0.483712\tval-logloss:0.507464\n",
      "[600]\ttrain-logloss:0.454717\tval-logloss:0.484156\n",
      "[700]\ttrain-logloss:0.428467\tval-logloss:0.464843\n",
      "[800]\ttrain-logloss:0.404675\tval-logloss:0.447835\n",
      "[900]\ttrain-logloss:0.383266\tval-logloss:0.433192\n",
      "[1000]\ttrain-logloss:0.363753\tval-logloss:0.423418\n",
      "[1100]\ttrain-logloss:0.345974\tval-logloss:0.414915\n",
      "[1200]\ttrain-logloss:0.329733\tval-logloss:0.40726\n",
      "[1300]\ttrain-logloss:0.314759\tval-logloss:0.398948\n",
      "[1400]\ttrain-logloss:0.300938\tval-logloss:0.390651\n",
      "[1500]\ttrain-logloss:0.288089\tval-logloss:0.382403\n",
      "[1600]\ttrain-logloss:0.276139\tval-logloss:0.376052\n",
      "[1700]\ttrain-logloss:0.265068\tval-logloss:0.367675\n",
      "[1800]\ttrain-logloss:0.254758\tval-logloss:0.360788\n",
      "[1900]\ttrain-logloss:0.24489\tval-logloss:0.357164\n",
      "[2000]\ttrain-logloss:0.235558\tval-logloss:0.353215\n",
      "[2100]\ttrain-logloss:0.226868\tval-logloss:0.350488\n",
      "[2200]\ttrain-logloss:0.218694\tval-logloss:0.347643\n",
      "[2300]\ttrain-logloss:0.211017\tval-logloss:0.344995\n",
      "[2400]\ttrain-logloss:0.203874\tval-logloss:0.34321\n",
      "[2500]\ttrain-logloss:0.197194\tval-logloss:0.341392\n",
      "[2600]\ttrain-logloss:0.190844\tval-logloss:0.338863\n",
      "[2700]\ttrain-logloss:0.184885\tval-logloss:0.337321\n",
      "[2800]\ttrain-logloss:0.179276\tval-logloss:0.335315\n",
      "[2900]\ttrain-logloss:0.17398\tval-logloss:0.332721\n",
      "[3000]\ttrain-logloss:0.168966\tval-logloss:0.329816\n",
      "[3100]\ttrain-logloss:0.164264\tval-logloss:0.328264\n",
      "[3200]\ttrain-logloss:0.159782\tval-logloss:0.326784\n",
      "[3300]\ttrain-logloss:0.155505\tval-logloss:0.326023\n",
      "[3400]\ttrain-logloss:0.151435\tval-logloss:0.324418\n",
      "[3500]\ttrain-logloss:0.147573\tval-logloss:0.323671\n",
      "[3600]\ttrain-logloss:0.143867\tval-logloss:0.323648\n",
      "[3700]\ttrain-logloss:0.140296\tval-logloss:0.322039\n",
      "[3800]\ttrain-logloss:0.136902\tval-logloss:0.322863\n",
      "Stopping. Best iteration:\n",
      "[3709]\ttrain-logloss:0.139984\tval-logloss:0.321965\n",
      "\n",
      "Fold: 13\n",
      "[0]\ttrain-logloss:0.69256\tval-logloss:0.692646\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638786\tval-logloss:0.651126\n",
      "[200]\ttrain-logloss:0.592248\tval-logloss:0.618207\n",
      "[300]\ttrain-logloss:0.551621\tval-logloss:0.589581\n",
      "[400]\ttrain-logloss:0.515378\tval-logloss:0.567418\n",
      "[500]\ttrain-logloss:0.483076\tval-logloss:0.547499\n",
      "[600]\ttrain-logloss:0.454166\tval-logloss:0.530391\n",
      "[700]\ttrain-logloss:0.427965\tval-logloss:0.51704\n",
      "[800]\ttrain-logloss:0.404174\tval-logloss:0.505774\n",
      "[900]\ttrain-logloss:0.382557\tval-logloss:0.499051\n",
      "[1000]\ttrain-logloss:0.362894\tval-logloss:0.49349\n",
      "[1100]\ttrain-logloss:0.344914\tval-logloss:0.48995\n",
      "[1200]\ttrain-logloss:0.328565\tval-logloss:0.488217\n",
      "[1300]\ttrain-logloss:0.313515\tval-logloss:0.487441\n",
      "[1400]\ttrain-logloss:0.299634\tval-logloss:0.488237\n",
      "Stopping. Best iteration:\n",
      "[1318]\ttrain-logloss:0.310923\tval-logloss:0.487379\n",
      "\n",
      "Fold: 14\n",
      "[0]\ttrain-logloss:0.692562\tval-logloss:0.692782\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638779\tval-logloss:0.654365\n",
      "[200]\ttrain-logloss:0.592232\tval-logloss:0.621367\n",
      "[300]\ttrain-logloss:0.551621\tval-logloss:0.592836\n",
      "[400]\ttrain-logloss:0.515548\tval-logloss:0.568738\n",
      "[500]\ttrain-logloss:0.483227\tval-logloss:0.549872\n",
      "[600]\ttrain-logloss:0.454273\tval-logloss:0.533206\n",
      "[700]\ttrain-logloss:0.428029\tval-logloss:0.518815\n",
      "[800]\ttrain-logloss:0.404264\tval-logloss:0.506619\n",
      "[900]\ttrain-logloss:0.382802\tval-logloss:0.500568\n",
      "[1000]\ttrain-logloss:0.3633\tval-logloss:0.494465\n",
      "[1100]\ttrain-logloss:0.345444\tval-logloss:0.489433\n",
      "[1200]\ttrain-logloss:0.329046\tval-logloss:0.486286\n",
      "[1300]\ttrain-logloss:0.313987\tval-logloss:0.483679\n",
      "[1400]\ttrain-logloss:0.30005\tval-logloss:0.482334\n",
      "[1500]\ttrain-logloss:0.286963\tval-logloss:0.480831\n",
      "[1600]\ttrain-logloss:0.274916\tval-logloss:0.480651\n",
      "Stopping. Best iteration:\n",
      "[1561]\ttrain-logloss:0.279515\tval-logloss:0.479941\n",
      "\n",
      "Fold: 15\n",
      "[0]\ttrain-logloss:0.692561\tval-logloss:0.692465\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639343\tval-logloss:0.640609\n",
      "[200]\ttrain-logloss:0.593072\tval-logloss:0.59647\n",
      "[300]\ttrain-logloss:0.5525\tval-logloss:0.556988\n",
      "[400]\ttrain-logloss:0.51645\tval-logloss:0.521088\n",
      "[500]\ttrain-logloss:0.484253\tval-logloss:0.490529\n",
      "[600]\ttrain-logloss:0.455463\tval-logloss:0.464023\n",
      "[700]\ttrain-logloss:0.429409\tval-logloss:0.443444\n",
      "[800]\ttrain-logloss:0.405798\tval-logloss:0.421944\n",
      "[900]\ttrain-logloss:0.384394\tval-logloss:0.402535\n",
      "[1000]\ttrain-logloss:0.364877\tval-logloss:0.384861\n",
      "[1100]\ttrain-logloss:0.347095\tval-logloss:0.36899\n",
      "[1200]\ttrain-logloss:0.330995\tval-logloss:0.355006\n",
      "[1300]\ttrain-logloss:0.316226\tval-logloss:0.34349\n",
      "[1400]\ttrain-logloss:0.302498\tval-logloss:0.333155\n",
      "[1500]\ttrain-logloss:0.28966\tval-logloss:0.321724\n",
      "[1600]\ttrain-logloss:0.277745\tval-logloss:0.312845\n",
      "[1700]\ttrain-logloss:0.266479\tval-logloss:0.304064\n",
      "[1800]\ttrain-logloss:0.256112\tval-logloss:0.294649\n",
      "[1900]\ttrain-logloss:0.24638\tval-logloss:0.287605\n",
      "[2000]\ttrain-logloss:0.23724\tval-logloss:0.280989\n",
      "[2100]\ttrain-logloss:0.2286\tval-logloss:0.276301\n",
      "[2200]\ttrain-logloss:0.220496\tval-logloss:0.274463\n",
      "[2300]\ttrain-logloss:0.212843\tval-logloss:0.269997\n",
      "[2400]\ttrain-logloss:0.20563\tval-logloss:0.264907\n",
      "[2500]\ttrain-logloss:0.1988\tval-logloss:0.260736\n",
      "[2600]\ttrain-logloss:0.192375\tval-logloss:0.257271\n",
      "[2700]\ttrain-logloss:0.186382\tval-logloss:0.253592\n",
      "[2800]\ttrain-logloss:0.180727\tval-logloss:0.250387\n",
      "[2900]\ttrain-logloss:0.175349\tval-logloss:0.24637\n",
      "[3000]\ttrain-logloss:0.170273\tval-logloss:0.24312\n",
      "[3100]\ttrain-logloss:0.16552\tval-logloss:0.239675\n",
      "[3200]\ttrain-logloss:0.160962\tval-logloss:0.236565\n",
      "[3300]\ttrain-logloss:0.156677\tval-logloss:0.233178\n",
      "[3400]\ttrain-logloss:0.152587\tval-logloss:0.229411\n",
      "[3500]\ttrain-logloss:0.148728\tval-logloss:0.226407\n",
      "[3600]\ttrain-logloss:0.145007\tval-logloss:0.223707\n",
      "[3700]\ttrain-logloss:0.141445\tval-logloss:0.220867\n",
      "[3800]\ttrain-logloss:0.138023\tval-logloss:0.218293\n",
      "[3900]\ttrain-logloss:0.134699\tval-logloss:0.215927\n",
      "[4000]\ttrain-logloss:0.131551\tval-logloss:0.214409\n",
      "[4100]\ttrain-logloss:0.128528\tval-logloss:0.212987\n",
      "[4200]\ttrain-logloss:0.125643\tval-logloss:0.211947\n",
      "[4300]\ttrain-logloss:0.122929\tval-logloss:0.21166\n",
      "Stopping. Best iteration:\n",
      "[4261]\ttrain-logloss:0.12396\tval-logloss:0.211171\n",
      "\n",
      "Fold: 16\n",
      "[0]\ttrain-logloss:0.692563\tval-logloss:0.692609\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639171\tval-logloss:0.652501\n",
      "[200]\ttrain-logloss:0.592665\tval-logloss:0.619675\n",
      "[300]\ttrain-logloss:0.552139\tval-logloss:0.593217\n",
      "[400]\ttrain-logloss:0.516024\tval-logloss:0.570744\n",
      "[500]\ttrain-logloss:0.48394\tval-logloss:0.551521\n",
      "[600]\ttrain-logloss:0.45501\tval-logloss:0.530336\n",
      "[700]\ttrain-logloss:0.428786\tval-logloss:0.511972\n",
      "[800]\ttrain-logloss:0.405089\tval-logloss:0.499564\n",
      "[900]\ttrain-logloss:0.383466\tval-logloss:0.49013\n",
      "[1000]\ttrain-logloss:0.363856\tval-logloss:0.483596\n",
      "[1100]\ttrain-logloss:0.345978\tval-logloss:0.480053\n",
      "[1200]\ttrain-logloss:0.329677\tval-logloss:0.476232\n",
      "[1300]\ttrain-logloss:0.314735\tval-logloss:0.472502\n",
      "[1400]\ttrain-logloss:0.300944\tval-logloss:0.470084\n",
      "[1500]\ttrain-logloss:0.288071\tval-logloss:0.467849\n",
      "[1600]\ttrain-logloss:0.276125\tval-logloss:0.466288\n",
      "Stopping. Best iteration:\n",
      "[1598]\ttrain-logloss:0.276365\tval-logloss:0.466118\n",
      "\n",
      "Fold: 17\n",
      "[0]\ttrain-logloss:0.692557\tval-logloss:0.692833\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638653\tval-logloss:0.665804\n",
      "[200]\ttrain-logloss:0.592079\tval-logloss:0.645507\n",
      "[300]\ttrain-logloss:0.551341\tval-logloss:0.630028\n",
      "[400]\ttrain-logloss:0.515152\tval-logloss:0.61632\n",
      "[500]\ttrain-logloss:0.482817\tval-logloss:0.604204\n",
      "[600]\ttrain-logloss:0.453725\tval-logloss:0.594931\n",
      "[700]\ttrain-logloss:0.427521\tval-logloss:0.587263\n",
      "[800]\ttrain-logloss:0.403705\tval-logloss:0.583924\n",
      "[900]\ttrain-logloss:0.382126\tval-logloss:0.584012\n",
      "Stopping. Best iteration:\n",
      "[835]\ttrain-logloss:0.395891\tval-logloss:0.582949\n",
      "\n",
      "Fold: 18\n",
      "[0]\ttrain-logloss:0.692566\tval-logloss:0.692512\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639204\tval-logloss:0.629663\n",
      "[200]\ttrain-logloss:0.592833\tval-logloss:0.575724\n",
      "[300]\ttrain-logloss:0.552317\tval-logloss:0.529313\n",
      "[400]\ttrain-logloss:0.516226\tval-logloss:0.488416\n",
      "[500]\ttrain-logloss:0.483877\tval-logloss:0.452752\n",
      "[600]\ttrain-logloss:0.454804\tval-logloss:0.421049\n",
      "[700]\ttrain-logloss:0.428694\tval-logloss:0.391411\n",
      "[800]\ttrain-logloss:0.405166\tval-logloss:0.363145\n",
      "[900]\ttrain-logloss:0.383882\tval-logloss:0.337851\n",
      "[1000]\ttrain-logloss:0.364536\tval-logloss:0.31284\n",
      "[1100]\ttrain-logloss:0.347004\tval-logloss:0.290882\n",
      "[1200]\ttrain-logloss:0.330919\tval-logloss:0.270857\n",
      "[1300]\ttrain-logloss:0.31614\tval-logloss:0.253455\n",
      "[1400]\ttrain-logloss:0.302394\tval-logloss:0.237702\n",
      "[1500]\ttrain-logloss:0.289601\tval-logloss:0.222435\n",
      "[1600]\ttrain-logloss:0.277719\tval-logloss:0.208894\n",
      "[1700]\ttrain-logloss:0.266543\tval-logloss:0.196102\n",
      "[1800]\ttrain-logloss:0.256054\tval-logloss:0.184246\n",
      "[1900]\ttrain-logloss:0.246326\tval-logloss:0.17385\n",
      "[2000]\ttrain-logloss:0.237021\tval-logloss:0.165228\n",
      "[2100]\ttrain-logloss:0.22835\tval-logloss:0.158109\n",
      "[2200]\ttrain-logloss:0.220204\tval-logloss:0.15176\n",
      "[2300]\ttrain-logloss:0.212543\tval-logloss:0.146666\n",
      "[2400]\ttrain-logloss:0.205277\tval-logloss:0.140682\n",
      "[2500]\ttrain-logloss:0.198492\tval-logloss:0.135171\n",
      "[2600]\ttrain-logloss:0.192132\tval-logloss:0.129637\n",
      "[2700]\ttrain-logloss:0.18615\tval-logloss:0.124665\n",
      "[2800]\ttrain-logloss:0.180517\tval-logloss:0.119476\n",
      "[2900]\ttrain-logloss:0.175161\tval-logloss:0.114886\n",
      "[3000]\ttrain-logloss:0.170082\tval-logloss:0.11075\n",
      "[3100]\ttrain-logloss:0.165272\tval-logloss:0.10701\n",
      "[3200]\ttrain-logloss:0.160744\tval-logloss:0.10343\n",
      "[3300]\ttrain-logloss:0.156463\tval-logloss:0.100096\n",
      "[3400]\ttrain-logloss:0.152382\tval-logloss:0.097065\n",
      "[3500]\ttrain-logloss:0.148481\tval-logloss:0.094679\n",
      "[3600]\ttrain-logloss:0.144751\tval-logloss:0.092592\n",
      "[3700]\ttrain-logloss:0.141174\tval-logloss:0.090719\n",
      "[3800]\ttrain-logloss:0.137742\tval-logloss:0.089022\n",
      "[3900]\ttrain-logloss:0.134417\tval-logloss:0.087555\n",
      "[4000]\ttrain-logloss:0.131256\tval-logloss:0.086131\n",
      "[4100]\ttrain-logloss:0.128247\tval-logloss:0.084955\n",
      "[4200]\ttrain-logloss:0.125385\tval-logloss:0.084023\n",
      "[4300]\ttrain-logloss:0.122657\tval-logloss:0.083029\n",
      "[4400]\ttrain-logloss:0.120085\tval-logloss:0.081964\n",
      "[4500]\ttrain-logloss:0.11756\tval-logloss:0.08109\n",
      "[4600]\ttrain-logloss:0.115146\tval-logloss:0.08057\n",
      "[4700]\ttrain-logloss:0.112823\tval-logloss:0.08022\n",
      "[4800]\ttrain-logloss:0.110572\tval-logloss:0.079836\n",
      "[4900]\ttrain-logloss:0.108447\tval-logloss:0.079583\n",
      "[4999]\ttrain-logloss:0.106423\tval-logloss:0.079473\n",
      "Fold: 19\n",
      "[0]\ttrain-logloss:0.692563\tval-logloss:0.692596\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638987\tval-logloss:0.645133\n",
      "[200]\ttrain-logloss:0.592487\tval-logloss:0.603988\n",
      "[300]\ttrain-logloss:0.551915\tval-logloss:0.567696\n",
      "[400]\ttrain-logloss:0.515793\tval-logloss:0.535514\n",
      "[500]\ttrain-logloss:0.483574\tval-logloss:0.506964\n",
      "[600]\ttrain-logloss:0.454622\tval-logloss:0.48018\n",
      "[700]\ttrain-logloss:0.42849\tval-logloss:0.456995\n",
      "[800]\ttrain-logloss:0.404691\tval-logloss:0.435438\n",
      "[900]\ttrain-logloss:0.383397\tval-logloss:0.415768\n",
      "[1000]\ttrain-logloss:0.364044\tval-logloss:0.401812\n",
      "[1100]\ttrain-logloss:0.346435\tval-logloss:0.388713\n",
      "[1200]\ttrain-logloss:0.330305\tval-logloss:0.376986\n",
      "[1300]\ttrain-logloss:0.315384\tval-logloss:0.366625\n",
      "[1400]\ttrain-logloss:0.301584\tval-logloss:0.357129\n",
      "[1500]\ttrain-logloss:0.288895\tval-logloss:0.346696\n",
      "[1600]\ttrain-logloss:0.276997\tval-logloss:0.338159\n",
      "[1700]\ttrain-logloss:0.265718\tval-logloss:0.331637\n",
      "[1800]\ttrain-logloss:0.255246\tval-logloss:0.328029\n",
      "[1900]\ttrain-logloss:0.245195\tval-logloss:0.323586\n",
      "[2000]\ttrain-logloss:0.235835\tval-logloss:0.319805\n",
      "[2100]\ttrain-logloss:0.227152\tval-logloss:0.316045\n",
      "[2200]\ttrain-logloss:0.218963\tval-logloss:0.31199\n",
      "[2300]\ttrain-logloss:0.211248\tval-logloss:0.308844\n",
      "[2400]\ttrain-logloss:0.204088\tval-logloss:0.306234\n",
      "[2500]\ttrain-logloss:0.197346\tval-logloss:0.304651\n",
      "[2600]\ttrain-logloss:0.190999\tval-logloss:0.303456\n",
      "[2700]\ttrain-logloss:0.185028\tval-logloss:0.300551\n",
      "[2800]\ttrain-logloss:0.179398\tval-logloss:0.299118\n",
      "[2900]\ttrain-logloss:0.174083\tval-logloss:0.297424\n",
      "[3000]\ttrain-logloss:0.169006\tval-logloss:0.295477\n",
      "[3100]\ttrain-logloss:0.164288\tval-logloss:0.293983\n",
      "[3200]\ttrain-logloss:0.159795\tval-logloss:0.293693\n",
      "[3300]\ttrain-logloss:0.155527\tval-logloss:0.291721\n",
      "[3400]\ttrain-logloss:0.151482\tval-logloss:0.290045\n",
      "[3500]\ttrain-logloss:0.147641\tval-logloss:0.288791\n",
      "[3600]\ttrain-logloss:0.143951\tval-logloss:0.287866\n",
      "[3700]\ttrain-logloss:0.140383\tval-logloss:0.287284\n",
      "[3800]\ttrain-logloss:0.137033\tval-logloss:0.28726\n",
      "Stopping. Best iteration:\n",
      "[3703]\ttrain-logloss:0.140282\tval-logloss:0.287185\n",
      "\n",
      "Fold: 20\n",
      "[0]\ttrain-logloss:0.692563\tval-logloss:0.69273\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638939\tval-logloss:0.6558\n",
      "[200]\ttrain-logloss:0.592403\tval-logloss:0.622056\n",
      "[300]\ttrain-logloss:0.55186\tval-logloss:0.590572\n",
      "[400]\ttrain-logloss:0.515741\tval-logloss:0.565943\n",
      "[500]\ttrain-logloss:0.483581\tval-logloss:0.545894\n",
      "[600]\ttrain-logloss:0.454688\tval-logloss:0.527291\n",
      "[700]\ttrain-logloss:0.428533\tval-logloss:0.511892\n",
      "[800]\ttrain-logloss:0.404759\tval-logloss:0.495216\n",
      "[900]\ttrain-logloss:0.383134\tval-logloss:0.481535\n",
      "[1000]\ttrain-logloss:0.363478\tval-logloss:0.469333\n",
      "[1100]\ttrain-logloss:0.345754\tval-logloss:0.456182\n",
      "[1200]\ttrain-logloss:0.329537\tval-logloss:0.444342\n",
      "[1300]\ttrain-logloss:0.314663\tval-logloss:0.431829\n",
      "[1400]\ttrain-logloss:0.300757\tval-logloss:0.422292\n",
      "[1500]\ttrain-logloss:0.287918\tval-logloss:0.411491\n",
      "[1600]\ttrain-logloss:0.276018\tval-logloss:0.402152\n",
      "[1700]\ttrain-logloss:0.264894\tval-logloss:0.394435\n",
      "[1800]\ttrain-logloss:0.254496\tval-logloss:0.386979\n",
      "[1900]\ttrain-logloss:0.244754\tval-logloss:0.383268\n",
      "Stopping. Best iteration:\n",
      "[1881]\ttrain-logloss:0.246632\tval-logloss:0.382706\n",
      "\n",
      "Fold: 21\n",
      "[0]\ttrain-logloss:0.692557\tval-logloss:0.692509\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639098\tval-logloss:0.638511\n",
      "[200]\ttrain-logloss:0.592728\tval-logloss:0.592627\n",
      "[300]\ttrain-logloss:0.552286\tval-logloss:0.558551\n",
      "[400]\ttrain-logloss:0.516301\tval-logloss:0.528762\n",
      "[500]\ttrain-logloss:0.484207\tval-logloss:0.500108\n",
      "[600]\ttrain-logloss:0.45528\tval-logloss:0.473095\n",
      "[700]\ttrain-logloss:0.429177\tval-logloss:0.447681\n",
      "[800]\ttrain-logloss:0.405586\tval-logloss:0.426158\n",
      "[900]\ttrain-logloss:0.38415\tval-logloss:0.408243\n",
      "[1000]\ttrain-logloss:0.364719\tval-logloss:0.392371\n",
      "[1100]\ttrain-logloss:0.346906\tval-logloss:0.378772\n",
      "[1200]\ttrain-logloss:0.330664\tval-logloss:0.36774\n",
      "[1300]\ttrain-logloss:0.315769\tval-logloss:0.356356\n",
      "[1400]\ttrain-logloss:0.302042\tval-logloss:0.347944\n",
      "[1500]\ttrain-logloss:0.289248\tval-logloss:0.340858\n",
      "[1600]\ttrain-logloss:0.277311\tval-logloss:0.335526\n",
      "[1700]\ttrain-logloss:0.266119\tval-logloss:0.329271\n",
      "[1800]\ttrain-logloss:0.25576\tval-logloss:0.325563\n",
      "[1900]\ttrain-logloss:0.246042\tval-logloss:0.322039\n",
      "[2000]\ttrain-logloss:0.236678\tval-logloss:0.316694\n",
      "[2100]\ttrain-logloss:0.227969\tval-logloss:0.310656\n",
      "[2200]\ttrain-logloss:0.219799\tval-logloss:0.307173\n",
      "[2300]\ttrain-logloss:0.21211\tval-logloss:0.305832\n",
      "[2400]\ttrain-logloss:0.204896\tval-logloss:0.305055\n",
      "[2500]\ttrain-logloss:0.198175\tval-logloss:0.304003\n",
      "[2600]\ttrain-logloss:0.191836\tval-logloss:0.302922\n",
      "[2700]\ttrain-logloss:0.185817\tval-logloss:0.301717\n",
      "Stopping. Best iteration:\n",
      "[2684]\ttrain-logloss:0.18676\tval-logloss:0.301584\n",
      "\n",
      "Fold: 22\n",
      "[0]\ttrain-logloss:0.692561\tval-logloss:0.692517\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638999\tval-logloss:0.637437\n",
      "[200]\ttrain-logloss:0.59274\tval-logloss:0.588959\n",
      "[300]\ttrain-logloss:0.552258\tval-logloss:0.548476\n",
      "[400]\ttrain-logloss:0.516355\tval-logloss:0.510752\n",
      "[500]\ttrain-logloss:0.484292\tval-logloss:0.477672\n",
      "[600]\ttrain-logloss:0.455499\tval-logloss:0.44811\n",
      "[700]\ttrain-logloss:0.429507\tval-logloss:0.421169\n",
      "[800]\ttrain-logloss:0.40582\tval-logloss:0.395868\n",
      "[900]\ttrain-logloss:0.384368\tval-logloss:0.373323\n",
      "[1000]\ttrain-logloss:0.364763\tval-logloss:0.356252\n",
      "[1100]\ttrain-logloss:0.347014\tval-logloss:0.339438\n",
      "[1200]\ttrain-logloss:0.330795\tval-logloss:0.324336\n",
      "[1300]\ttrain-logloss:0.315804\tval-logloss:0.311236\n",
      "[1400]\ttrain-logloss:0.301947\tval-logloss:0.299063\n",
      "[1500]\ttrain-logloss:0.28909\tval-logloss:0.287583\n",
      "[1600]\ttrain-logloss:0.277026\tval-logloss:0.276655\n",
      "[1700]\ttrain-logloss:0.265864\tval-logloss:0.265892\n",
      "[1800]\ttrain-logloss:0.255539\tval-logloss:0.25625\n",
      "[1900]\ttrain-logloss:0.245814\tval-logloss:0.250316\n",
      "[2000]\ttrain-logloss:0.2367\tval-logloss:0.243173\n",
      "[2100]\ttrain-logloss:0.228\tval-logloss:0.236781\n",
      "[2200]\ttrain-logloss:0.219902\tval-logloss:0.231741\n",
      "[2300]\ttrain-logloss:0.21239\tval-logloss:0.22751\n",
      "[2400]\ttrain-logloss:0.2053\tval-logloss:0.2233\n",
      "[2500]\ttrain-logloss:0.198585\tval-logloss:0.218865\n",
      "[2600]\ttrain-logloss:0.192264\tval-logloss:0.215228\n",
      "[2700]\ttrain-logloss:0.18623\tval-logloss:0.212322\n",
      "[2800]\ttrain-logloss:0.180522\tval-logloss:0.210054\n",
      "[2900]\ttrain-logloss:0.175105\tval-logloss:0.207977\n",
      "[3000]\ttrain-logloss:0.17005\tval-logloss:0.207225\n",
      "[3100]\ttrain-logloss:0.165284\tval-logloss:0.205759\n",
      "[3200]\ttrain-logloss:0.160719\tval-logloss:0.204967\n",
      "[3300]\ttrain-logloss:0.156433\tval-logloss:0.20397\n",
      "[3400]\ttrain-logloss:0.152367\tval-logloss:0.20282\n",
      "[3500]\ttrain-logloss:0.148495\tval-logloss:0.20184\n",
      "[3600]\ttrain-logloss:0.144758\tval-logloss:0.20092\n",
      "[3700]\ttrain-logloss:0.141179\tval-logloss:0.200676\n",
      "[3800]\ttrain-logloss:0.137788\tval-logloss:0.200237\n",
      "[3900]\ttrain-logloss:0.134496\tval-logloss:0.200568\n",
      "Stopping. Best iteration:\n",
      "[3820]\ttrain-logloss:0.137103\tval-logloss:0.200119\n",
      "\n",
      "Fold: 23\n",
      "[0]\ttrain-logloss:0.692557\tval-logloss:0.692542\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638954\tval-logloss:0.641144\n",
      "[200]\ttrain-logloss:0.592638\tval-logloss:0.596452\n",
      "[300]\ttrain-logloss:0.552159\tval-logloss:0.561912\n",
      "[400]\ttrain-logloss:0.516217\tval-logloss:0.531955\n",
      "[500]\ttrain-logloss:0.484049\tval-logloss:0.507215\n",
      "[600]\ttrain-logloss:0.455251\tval-logloss:0.484975\n",
      "[700]\ttrain-logloss:0.429229\tval-logloss:0.463549\n",
      "[800]\ttrain-logloss:0.405598\tval-logloss:0.442931\n",
      "[900]\ttrain-logloss:0.384038\tval-logloss:0.426496\n",
      "[1000]\ttrain-logloss:0.364451\tval-logloss:0.413753\n",
      "[1100]\ttrain-logloss:0.346599\tval-logloss:0.402984\n",
      "[1200]\ttrain-logloss:0.330343\tval-logloss:0.393224\n",
      "[1300]\ttrain-logloss:0.315433\tval-logloss:0.384324\n",
      "[1400]\ttrain-logloss:0.301641\tval-logloss:0.376431\n",
      "[1500]\ttrain-logloss:0.288804\tval-logloss:0.368281\n",
      "[1600]\ttrain-logloss:0.276825\tval-logloss:0.362977\n",
      "[1700]\ttrain-logloss:0.265563\tval-logloss:0.357347\n",
      "[1800]\ttrain-logloss:0.255094\tval-logloss:0.352996\n",
      "[1900]\ttrain-logloss:0.245275\tval-logloss:0.347539\n",
      "[2000]\ttrain-logloss:0.236178\tval-logloss:0.343385\n",
      "[2100]\ttrain-logloss:0.227668\tval-logloss:0.338945\n",
      "[2200]\ttrain-logloss:0.219537\tval-logloss:0.33382\n",
      "[2300]\ttrain-logloss:0.211921\tval-logloss:0.32955\n",
      "[2400]\ttrain-logloss:0.20479\tval-logloss:0.326519\n",
      "[2500]\ttrain-logloss:0.197984\tval-logloss:0.323579\n",
      "[2600]\ttrain-logloss:0.1916\tval-logloss:0.321299\n",
      "[2700]\ttrain-logloss:0.185601\tval-logloss:0.319477\n",
      "[2800]\ttrain-logloss:0.179889\tval-logloss:0.318873\n",
      "[2900]\ttrain-logloss:0.174553\tval-logloss:0.31758\n",
      "[3000]\ttrain-logloss:0.169509\tval-logloss:0.316962\n",
      "[3100]\ttrain-logloss:0.164777\tval-logloss:0.316137\n",
      "[3200]\ttrain-logloss:0.160259\tval-logloss:0.315385\n",
      "Stopping. Best iteration:\n",
      "[3189]\ttrain-logloss:0.160735\tval-logloss:0.315203\n",
      "\n",
      "Fold: 24\n",
      "[0]\ttrain-logloss:0.692567\tval-logloss:0.692509\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639148\tval-logloss:0.630608\n",
      "[200]\ttrain-logloss:0.592797\tval-logloss:0.579445\n",
      "[300]\ttrain-logloss:0.552467\tval-logloss:0.53708\n",
      "[400]\ttrain-logloss:0.516614\tval-logloss:0.498579\n",
      "[500]\ttrain-logloss:0.484543\tval-logloss:0.464082\n",
      "[600]\ttrain-logloss:0.455753\tval-logloss:0.433493\n",
      "[700]\ttrain-logloss:0.429788\tval-logloss:0.405794\n",
      "[800]\ttrain-logloss:0.406206\tval-logloss:0.381105\n",
      "[900]\ttrain-logloss:0.38484\tval-logloss:0.359805\n",
      "[1000]\ttrain-logloss:0.365331\tval-logloss:0.341925\n",
      "[1100]\ttrain-logloss:0.347576\tval-logloss:0.326598\n",
      "[1200]\ttrain-logloss:0.331424\tval-logloss:0.31313\n",
      "[1300]\ttrain-logloss:0.316547\tval-logloss:0.301718\n",
      "[1400]\ttrain-logloss:0.302705\tval-logloss:0.291418\n",
      "[1500]\ttrain-logloss:0.289855\tval-logloss:0.281719\n",
      "[1600]\ttrain-logloss:0.277846\tval-logloss:0.273536\n",
      "[1700]\ttrain-logloss:0.266706\tval-logloss:0.266175\n",
      "[1800]\ttrain-logloss:0.256308\tval-logloss:0.258893\n",
      "[1900]\ttrain-logloss:0.24668\tval-logloss:0.252986\n",
      "[2000]\ttrain-logloss:0.237519\tval-logloss:0.247171\n",
      "[2100]\ttrain-logloss:0.22879\tval-logloss:0.242045\n",
      "[2200]\ttrain-logloss:0.220608\tval-logloss:0.237092\n",
      "[2300]\ttrain-logloss:0.212928\tval-logloss:0.233582\n",
      "[2400]\ttrain-logloss:0.205709\tval-logloss:0.23165\n",
      "[2500]\ttrain-logloss:0.198864\tval-logloss:0.230441\n",
      "[2600]\ttrain-logloss:0.192509\tval-logloss:0.2293\n",
      "[2700]\ttrain-logloss:0.186545\tval-logloss:0.22833\n",
      "[2800]\ttrain-logloss:0.180859\tval-logloss:0.227219\n",
      "[2900]\ttrain-logloss:0.175454\tval-logloss:0.226397\n",
      "[3000]\ttrain-logloss:0.17037\tval-logloss:0.224768\n",
      "[3100]\ttrain-logloss:0.165552\tval-logloss:0.223438\n",
      "[3200]\ttrain-logloss:0.16102\tval-logloss:0.222676\n",
      "[3300]\ttrain-logloss:0.156714\tval-logloss:0.22164\n",
      "[3400]\ttrain-logloss:0.152636\tval-logloss:0.221439\n",
      "[3500]\ttrain-logloss:0.148742\tval-logloss:0.221401\n",
      "Stopping. Best iteration:\n",
      "[3478]\ttrain-logloss:0.149575\tval-logloss:0.221203\n",
      "\n",
      "Fold: 25\n",
      "[0]\ttrain-logloss:0.692555\tval-logloss:0.692636\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638925\tval-logloss:0.649303\n",
      "[200]\ttrain-logloss:0.592443\tval-logloss:0.612835\n",
      "[300]\ttrain-logloss:0.551788\tval-logloss:0.582937\n",
      "[400]\ttrain-logloss:0.515816\tval-logloss:0.556852\n",
      "[500]\ttrain-logloss:0.483736\tval-logloss:0.534378\n",
      "[600]\ttrain-logloss:0.454912\tval-logloss:0.514866\n",
      "[700]\ttrain-logloss:0.42901\tval-logloss:0.496292\n",
      "[800]\ttrain-logloss:0.405432\tval-logloss:0.480274\n",
      "[900]\ttrain-logloss:0.38412\tval-logloss:0.465511\n",
      "[1000]\ttrain-logloss:0.364733\tval-logloss:0.451532\n",
      "[1100]\ttrain-logloss:0.347057\tval-logloss:0.439248\n",
      "[1200]\ttrain-logloss:0.330828\tval-logloss:0.430539\n",
      "[1300]\ttrain-logloss:0.315989\tval-logloss:0.421196\n",
      "[1400]\ttrain-logloss:0.302278\tval-logloss:0.411806\n",
      "[1500]\ttrain-logloss:0.28951\tval-logloss:0.403313\n",
      "[1600]\ttrain-logloss:0.277551\tval-logloss:0.396909\n",
      "[1700]\ttrain-logloss:0.266294\tval-logloss:0.392308\n",
      "[1800]\ttrain-logloss:0.255851\tval-logloss:0.387934\n",
      "[1900]\ttrain-logloss:0.245997\tval-logloss:0.38385\n",
      "[2000]\ttrain-logloss:0.236723\tval-logloss:0.378806\n",
      "[2100]\ttrain-logloss:0.228124\tval-logloss:0.374878\n",
      "[2200]\ttrain-logloss:0.220138\tval-logloss:0.371698\n",
      "[2300]\ttrain-logloss:0.212498\tval-logloss:0.368417\n",
      "[2400]\ttrain-logloss:0.205328\tval-logloss:0.365983\n",
      "[2500]\ttrain-logloss:0.198464\tval-logloss:0.362375\n",
      "[2600]\ttrain-logloss:0.192038\tval-logloss:0.359967\n",
      "[2700]\ttrain-logloss:0.185982\tval-logloss:0.358362\n",
      "[2800]\ttrain-logloss:0.180264\tval-logloss:0.355809\n",
      "[2900]\ttrain-logloss:0.174886\tval-logloss:0.354236\n",
      "[3000]\ttrain-logloss:0.169791\tval-logloss:0.352919\n",
      "[3100]\ttrain-logloss:0.165017\tval-logloss:0.351745\n",
      "[3200]\ttrain-logloss:0.160485\tval-logloss:0.349373\n",
      "[3300]\ttrain-logloss:0.156132\tval-logloss:0.348531\n",
      "[3400]\ttrain-logloss:0.151992\tval-logloss:0.348106\n",
      "[3500]\ttrain-logloss:0.148055\tval-logloss:0.347783\n",
      "Stopping. Best iteration:\n",
      "[3481]\ttrain-logloss:0.148791\tval-logloss:0.347451\n",
      "\n",
      "Fold: 26\n",
      "[0]\ttrain-logloss:0.692544\tval-logloss:0.692908\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638862\tval-logloss:0.663153\n",
      "[200]\ttrain-logloss:0.592361\tval-logloss:0.635018\n",
      "[300]\ttrain-logloss:0.551756\tval-logloss:0.612782\n",
      "[400]\ttrain-logloss:0.515567\tval-logloss:0.594474\n",
      "[500]\ttrain-logloss:0.483387\tval-logloss:0.578482\n",
      "[600]\ttrain-logloss:0.454467\tval-logloss:0.562203\n",
      "[700]\ttrain-logloss:0.42835\tval-logloss:0.547936\n",
      "[800]\ttrain-logloss:0.404674\tval-logloss:0.537217\n",
      "[900]\ttrain-logloss:0.383139\tval-logloss:0.527096\n",
      "[1000]\ttrain-logloss:0.3637\tval-logloss:0.518238\n",
      "[1100]\ttrain-logloss:0.345959\tval-logloss:0.511143\n",
      "[1200]\ttrain-logloss:0.329762\tval-logloss:0.504168\n",
      "[1300]\ttrain-logloss:0.314884\tval-logloss:0.497794\n",
      "[1400]\ttrain-logloss:0.301115\tval-logloss:0.493648\n",
      "[1500]\ttrain-logloss:0.288279\tval-logloss:0.490728\n",
      "[1600]\ttrain-logloss:0.276347\tval-logloss:0.486486\n",
      "[1700]\ttrain-logloss:0.265217\tval-logloss:0.481811\n",
      "[1800]\ttrain-logloss:0.254799\tval-logloss:0.477268\n",
      "[1900]\ttrain-logloss:0.245101\tval-logloss:0.473105\n",
      "[2000]\ttrain-logloss:0.235736\tval-logloss:0.468914\n",
      "[2100]\ttrain-logloss:0.227003\tval-logloss:0.466749\n",
      "[2200]\ttrain-logloss:0.218892\tval-logloss:0.466333\n",
      "[2300]\ttrain-logloss:0.211302\tval-logloss:0.464091\n",
      "[2400]\ttrain-logloss:0.204163\tval-logloss:0.461948\n",
      "[2500]\ttrain-logloss:0.197408\tval-logloss:0.457974\n",
      "[2600]\ttrain-logloss:0.191122\tval-logloss:0.456939\n",
      "Stopping. Best iteration:\n",
      "[2565]\ttrain-logloss:0.193302\tval-logloss:0.456465\n",
      "\n",
      "Fold: 27\n",
      "[0]\ttrain-logloss:0.692555\tval-logloss:0.692951\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638916\tval-logloss:0.677508\n",
      "[200]\ttrain-logloss:0.592354\tval-logloss:0.663901\n",
      "[300]\ttrain-logloss:0.551766\tval-logloss:0.651182\n",
      "[400]\ttrain-logloss:0.515708\tval-logloss:0.64244\n",
      "[500]\ttrain-logloss:0.483487\tval-logloss:0.635491\n",
      "[600]\ttrain-logloss:0.454434\tval-logloss:0.628257\n",
      "[700]\ttrain-logloss:0.42821\tval-logloss:0.620924\n",
      "[800]\ttrain-logloss:0.404442\tval-logloss:0.610581\n",
      "[900]\ttrain-logloss:0.382887\tval-logloss:0.601616\n",
      "[1000]\ttrain-logloss:0.363305\tval-logloss:0.595149\n",
      "[1100]\ttrain-logloss:0.34545\tval-logloss:0.59246\n",
      "[1200]\ttrain-logloss:0.32908\tval-logloss:0.590502\n",
      "[1300]\ttrain-logloss:0.313994\tval-logloss:0.587571\n",
      "[1400]\ttrain-logloss:0.300156\tval-logloss:0.58453\n",
      "[1500]\ttrain-logloss:0.287393\tval-logloss:0.584742\n",
      "Stopping. Best iteration:\n",
      "[1400]\ttrain-logloss:0.300156\tval-logloss:0.58453\n",
      "\n",
      "Fold: 28\n",
      "[0]\ttrain-logloss:0.692557\tval-logloss:0.692733\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638862\tval-logloss:0.66293\n",
      "[200]\ttrain-logloss:0.592374\tval-logloss:0.641285\n",
      "[300]\ttrain-logloss:0.55171\tval-logloss:0.624262\n",
      "[400]\ttrain-logloss:0.515701\tval-logloss:0.608627\n",
      "[500]\ttrain-logloss:0.483586\tval-logloss:0.595465\n",
      "[600]\ttrain-logloss:0.454661\tval-logloss:0.581001\n",
      "[700]\ttrain-logloss:0.428545\tval-logloss:0.567935\n",
      "[800]\ttrain-logloss:0.404827\tval-logloss:0.557674\n",
      "[900]\ttrain-logloss:0.383216\tval-logloss:0.549124\n",
      "[1000]\ttrain-logloss:0.363614\tval-logloss:0.543181\n",
      "[1100]\ttrain-logloss:0.345854\tval-logloss:0.539951\n",
      "[1200]\ttrain-logloss:0.329666\tval-logloss:0.53695\n",
      "[1300]\ttrain-logloss:0.314719\tval-logloss:0.53545\n",
      "[1400]\ttrain-logloss:0.300965\tval-logloss:0.534993\n",
      "[1500]\ttrain-logloss:0.288208\tval-logloss:0.532448\n",
      "[1600]\ttrain-logloss:0.276385\tval-logloss:0.528172\n",
      "[1700]\ttrain-logloss:0.265401\tval-logloss:0.525293\n",
      "[1800]\ttrain-logloss:0.255243\tval-logloss:0.525108\n",
      "Stopping. Best iteration:\n",
      "[1735]\ttrain-logloss:0.261784\tval-logloss:0.524531\n",
      "\n",
      "Fold: 29\n",
      "[0]\ttrain-logloss:0.692551\tval-logloss:0.693442\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638348\tval-logloss:0.718721\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-logloss:0.692551\tval-logloss:0.693442\n",
      "\n",
      "Fold: 30\n",
      "[0]\ttrain-logloss:0.692553\tval-logloss:0.692659\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638935\tval-logloss:0.650685\n",
      "[200]\ttrain-logloss:0.592442\tval-logloss:0.615637\n",
      "[300]\ttrain-logloss:0.55191\tval-logloss:0.586412\n",
      "[400]\ttrain-logloss:0.515923\tval-logloss:0.561278\n",
      "[500]\ttrain-logloss:0.483863\tval-logloss:0.538609\n",
      "[600]\ttrain-logloss:0.454918\tval-logloss:0.518341\n",
      "[700]\ttrain-logloss:0.428839\tval-logloss:0.500389\n",
      "[800]\ttrain-logloss:0.405084\tval-logloss:0.484646\n",
      "[900]\ttrain-logloss:0.383614\tval-logloss:0.471835\n",
      "[1000]\ttrain-logloss:0.36414\tval-logloss:0.461503\n",
      "[1100]\ttrain-logloss:0.346434\tval-logloss:0.456435\n",
      "[1200]\ttrain-logloss:0.330276\tval-logloss:0.450559\n",
      "[1300]\ttrain-logloss:0.315444\tval-logloss:0.445918\n",
      "[1400]\ttrain-logloss:0.301716\tval-logloss:0.441148\n",
      "[1500]\ttrain-logloss:0.288907\tval-logloss:0.438272\n",
      "[1600]\ttrain-logloss:0.27694\tval-logloss:0.435368\n",
      "[1700]\ttrain-logloss:0.265758\tval-logloss:0.434324\n",
      "[1800]\ttrain-logloss:0.255339\tval-logloss:0.432569\n",
      "[1900]\ttrain-logloss:0.245617\tval-logloss:0.432598\n",
      "[2000]\ttrain-logloss:0.236585\tval-logloss:0.431479\n",
      "Stopping. Best iteration:\n",
      "[1994]\ttrain-logloss:0.237123\tval-logloss:0.431237\n",
      "\n",
      "Fold: 31\n",
      "[0]\ttrain-logloss:0.692559\tval-logloss:0.692763\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.63889\tval-logloss:0.647397\n",
      "[200]\ttrain-logloss:0.592421\tval-logloss:0.607464\n",
      "[300]\ttrain-logloss:0.551887\tval-logloss:0.575041\n",
      "[400]\ttrain-logloss:0.515901\tval-logloss:0.546198\n",
      "[500]\ttrain-logloss:0.483679\tval-logloss:0.525187\n",
      "[600]\ttrain-logloss:0.454747\tval-logloss:0.505066\n",
      "[700]\ttrain-logloss:0.428599\tval-logloss:0.48702\n",
      "[800]\ttrain-logloss:0.404947\tval-logloss:0.470958\n",
      "[900]\ttrain-logloss:0.383505\tval-logloss:0.456735\n",
      "[1000]\ttrain-logloss:0.364019\tval-logloss:0.44379\n",
      "[1100]\ttrain-logloss:0.34617\tval-logloss:0.434623\n",
      "[1200]\ttrain-logloss:0.329919\tval-logloss:0.427983\n",
      "[1300]\ttrain-logloss:0.314988\tval-logloss:0.42178\n",
      "[1400]\ttrain-logloss:0.301307\tval-logloss:0.416227\n",
      "[1500]\ttrain-logloss:0.288583\tval-logloss:0.412532\n",
      "[1600]\ttrain-logloss:0.276647\tval-logloss:0.408352\n",
      "[1700]\ttrain-logloss:0.265493\tval-logloss:0.402514\n",
      "[1800]\ttrain-logloss:0.255149\tval-logloss:0.396872\n",
      "[1900]\ttrain-logloss:0.245422\tval-logloss:0.393552\n",
      "[2000]\ttrain-logloss:0.23633\tval-logloss:0.389972\n",
      "[2100]\ttrain-logloss:0.227756\tval-logloss:0.385543\n",
      "[2200]\ttrain-logloss:0.219663\tval-logloss:0.381564\n",
      "[2300]\ttrain-logloss:0.212085\tval-logloss:0.377972\n",
      "[2400]\ttrain-logloss:0.204766\tval-logloss:0.376168\n",
      "[2500]\ttrain-logloss:0.197918\tval-logloss:0.374433\n",
      "[2600]\ttrain-logloss:0.191454\tval-logloss:0.373309\n",
      "[2700]\ttrain-logloss:0.18544\tval-logloss:0.372391\n",
      "[2800]\ttrain-logloss:0.179786\tval-logloss:0.372563\n",
      "Stopping. Best iteration:\n",
      "[2712]\ttrain-logloss:0.184739\tval-logloss:0.372231\n",
      "\n",
      "Fold: 32\n",
      "[0]\ttrain-logloss:0.692558\tval-logloss:0.692539\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639115\tval-logloss:0.638615\n",
      "[200]\ttrain-logloss:0.592856\tval-logloss:0.592521\n",
      "[300]\ttrain-logloss:0.552354\tval-logloss:0.553382\n",
      "[400]\ttrain-logloss:0.516439\tval-logloss:0.518698\n",
      "[500]\ttrain-logloss:0.48439\tval-logloss:0.488273\n",
      "[600]\ttrain-logloss:0.455524\tval-logloss:0.46173\n",
      "[700]\ttrain-logloss:0.429518\tval-logloss:0.438509\n",
      "[800]\ttrain-logloss:0.405957\tval-logloss:0.420139\n",
      "[900]\ttrain-logloss:0.384513\tval-logloss:0.405439\n",
      "[1000]\ttrain-logloss:0.365118\tval-logloss:0.392611\n",
      "[1100]\ttrain-logloss:0.347437\tval-logloss:0.380096\n",
      "[1200]\ttrain-logloss:0.331225\tval-logloss:0.370697\n",
      "[1300]\ttrain-logloss:0.316314\tval-logloss:0.362658\n",
      "[1400]\ttrain-logloss:0.302513\tval-logloss:0.354904\n",
      "[1500]\ttrain-logloss:0.289526\tval-logloss:0.350265\n",
      "[1600]\ttrain-logloss:0.277479\tval-logloss:0.346416\n",
      "[1700]\ttrain-logloss:0.266229\tval-logloss:0.342273\n",
      "[1800]\ttrain-logloss:0.255765\tval-logloss:0.33823\n",
      "[1900]\ttrain-logloss:0.246071\tval-logloss:0.334476\n",
      "[2000]\ttrain-logloss:0.237044\tval-logloss:0.332644\n",
      "[2100]\ttrain-logloss:0.228327\tval-logloss:0.327415\n",
      "[2200]\ttrain-logloss:0.220109\tval-logloss:0.322381\n",
      "[2300]\ttrain-logloss:0.212541\tval-logloss:0.315795\n",
      "[2400]\ttrain-logloss:0.205377\tval-logloss:0.309197\n",
      "[2500]\ttrain-logloss:0.198672\tval-logloss:0.304133\n",
      "[2600]\ttrain-logloss:0.192377\tval-logloss:0.299244\n",
      "[2700]\ttrain-logloss:0.18644\tval-logloss:0.294018\n",
      "[2800]\ttrain-logloss:0.18086\tval-logloss:0.289067\n",
      "[2900]\ttrain-logloss:0.175534\tval-logloss:0.284643\n",
      "[3000]\ttrain-logloss:0.170509\tval-logloss:0.279874\n",
      "[3100]\ttrain-logloss:0.165746\tval-logloss:0.276386\n",
      "[3200]\ttrain-logloss:0.161206\tval-logloss:0.272677\n",
      "[3300]\ttrain-logloss:0.156897\tval-logloss:0.269849\n",
      "[3400]\ttrain-logloss:0.152833\tval-logloss:0.267288\n",
      "[3500]\ttrain-logloss:0.14896\tval-logloss:0.26427\n",
      "[3600]\ttrain-logloss:0.145212\tval-logloss:0.262355\n",
      "[3700]\ttrain-logloss:0.141623\tval-logloss:0.260778\n",
      "[3800]\ttrain-logloss:0.138164\tval-logloss:0.259035\n",
      "[3900]\ttrain-logloss:0.134831\tval-logloss:0.257873\n",
      "[4000]\ttrain-logloss:0.131639\tval-logloss:0.256631\n",
      "[4100]\ttrain-logloss:0.128639\tval-logloss:0.25503\n",
      "[4200]\ttrain-logloss:0.125733\tval-logloss:0.252799\n",
      "[4300]\ttrain-logloss:0.122947\tval-logloss:0.251383\n",
      "[4400]\ttrain-logloss:0.120309\tval-logloss:0.25042\n",
      "[4500]\ttrain-logloss:0.117785\tval-logloss:0.249558\n",
      "[4600]\ttrain-logloss:0.115378\tval-logloss:0.248247\n",
      "[4700]\ttrain-logloss:0.113072\tval-logloss:0.247568\n",
      "[4800]\ttrain-logloss:0.110849\tval-logloss:0.247285\n",
      "[4900]\ttrain-logloss:0.108706\tval-logloss:0.247488\n",
      "Stopping. Best iteration:\n",
      "[4825]\ttrain-logloss:0.110312\tval-logloss:0.246965\n",
      "\n",
      "Fold: 33\n",
      "[0]\ttrain-logloss:0.692563\tval-logloss:0.692659\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639091\tval-logloss:0.639985\n",
      "[200]\ttrain-logloss:0.592703\tval-logloss:0.593048\n",
      "[300]\ttrain-logloss:0.552174\tval-logloss:0.552002\n",
      "[400]\ttrain-logloss:0.516246\tval-logloss:0.514882\n",
      "[500]\ttrain-logloss:0.48415\tval-logloss:0.481823\n",
      "[600]\ttrain-logloss:0.455302\tval-logloss:0.453481\n",
      "[700]\ttrain-logloss:0.429338\tval-logloss:0.430887\n",
      "[800]\ttrain-logloss:0.405625\tval-logloss:0.409984\n",
      "[900]\ttrain-logloss:0.384134\tval-logloss:0.392836\n",
      "[1000]\ttrain-logloss:0.364615\tval-logloss:0.376977\n",
      "[1100]\ttrain-logloss:0.346858\tval-logloss:0.364657\n",
      "[1200]\ttrain-logloss:0.330662\tval-logloss:0.35231\n",
      "[1300]\ttrain-logloss:0.31578\tval-logloss:0.343144\n",
      "[1400]\ttrain-logloss:0.302005\tval-logloss:0.334183\n",
      "[1500]\ttrain-logloss:0.28919\tval-logloss:0.325882\n",
      "[1600]\ttrain-logloss:0.277227\tval-logloss:0.319277\n",
      "[1700]\ttrain-logloss:0.266078\tval-logloss:0.313226\n",
      "[1800]\ttrain-logloss:0.255709\tval-logloss:0.310232\n",
      "[1900]\ttrain-logloss:0.245911\tval-logloss:0.306342\n",
      "[2000]\ttrain-logloss:0.236638\tval-logloss:0.303236\n",
      "[2100]\ttrain-logloss:0.22788\tval-logloss:0.300009\n",
      "[2200]\ttrain-logloss:0.21967\tval-logloss:0.298569\n",
      "[2300]\ttrain-logloss:0.211937\tval-logloss:0.294837\n",
      "[2400]\ttrain-logloss:0.204716\tval-logloss:0.290348\n",
      "[2500]\ttrain-logloss:0.197903\tval-logloss:0.285232\n",
      "[2600]\ttrain-logloss:0.191503\tval-logloss:0.280731\n",
      "[2700]\ttrain-logloss:0.18558\tval-logloss:0.277081\n",
      "[2800]\ttrain-logloss:0.179959\tval-logloss:0.273578\n",
      "[2900]\ttrain-logloss:0.174602\tval-logloss:0.270656\n",
      "[3000]\ttrain-logloss:0.169578\tval-logloss:0.268507\n",
      "[3100]\ttrain-logloss:0.16478\tval-logloss:0.267539\n",
      "[3200]\ttrain-logloss:0.160218\tval-logloss:0.265198\n",
      "[3300]\ttrain-logloss:0.155914\tval-logloss:0.263423\n",
      "[3400]\ttrain-logloss:0.15183\tval-logloss:0.260868\n",
      "[3500]\ttrain-logloss:0.147958\tval-logloss:0.259224\n",
      "[3600]\ttrain-logloss:0.144271\tval-logloss:0.257834\n",
      "[3700]\ttrain-logloss:0.140724\tval-logloss:0.256034\n",
      "[3800]\ttrain-logloss:0.137347\tval-logloss:0.254212\n",
      "[3900]\ttrain-logloss:0.134065\tval-logloss:0.251955\n",
      "[4000]\ttrain-logloss:0.130967\tval-logloss:0.250713\n",
      "[4100]\ttrain-logloss:0.128022\tval-logloss:0.24911\n",
      "[4200]\ttrain-logloss:0.125188\tval-logloss:0.248685\n",
      "[4300]\ttrain-logloss:0.122507\tval-logloss:0.248139\n",
      "[4400]\ttrain-logloss:0.119973\tval-logloss:0.24685\n",
      "[4500]\ttrain-logloss:0.117502\tval-logloss:0.245904\n",
      "[4600]\ttrain-logloss:0.115144\tval-logloss:0.243605\n",
      "[4700]\ttrain-logloss:0.112863\tval-logloss:0.24126\n",
      "[4800]\ttrain-logloss:0.110672\tval-logloss:0.240049\n",
      "[4900]\ttrain-logloss:0.108539\tval-logloss:0.23858\n",
      "[4999]\ttrain-logloss:0.10649\tval-logloss:0.237222\n",
      "Fold: 34\n",
      "[0]\ttrain-logloss:0.692563\tval-logloss:0.692585\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639226\tval-logloss:0.635193\n",
      "[200]\ttrain-logloss:0.592942\tval-logloss:0.584713\n",
      "[300]\ttrain-logloss:0.552529\tval-logloss:0.541731\n",
      "[400]\ttrain-logloss:0.51645\tval-logloss:0.505193\n",
      "[500]\ttrain-logloss:0.484239\tval-logloss:0.472719\n",
      "[600]\ttrain-logloss:0.455433\tval-logloss:0.445286\n",
      "[700]\ttrain-logloss:0.42934\tval-logloss:0.420556\n",
      "[800]\ttrain-logloss:0.405626\tval-logloss:0.398618\n",
      "[900]\ttrain-logloss:0.384175\tval-logloss:0.380084\n",
      "[1000]\ttrain-logloss:0.364743\tval-logloss:0.363066\n",
      "[1100]\ttrain-logloss:0.347061\tval-logloss:0.3475\n",
      "[1200]\ttrain-logloss:0.330935\tval-logloss:0.333829\n",
      "[1300]\ttrain-logloss:0.316021\tval-logloss:0.320654\n",
      "[1400]\ttrain-logloss:0.302224\tval-logloss:0.30858\n",
      "[1500]\ttrain-logloss:0.289343\tval-logloss:0.298758\n",
      "[1600]\ttrain-logloss:0.2773\tval-logloss:0.29109\n",
      "[1700]\ttrain-logloss:0.265957\tval-logloss:0.281831\n",
      "[1800]\ttrain-logloss:0.255511\tval-logloss:0.273316\n",
      "[1900]\ttrain-logloss:0.245858\tval-logloss:0.266642\n",
      "[2000]\ttrain-logloss:0.236654\tval-logloss:0.260039\n",
      "[2100]\ttrain-logloss:0.227877\tval-logloss:0.252999\n",
      "[2200]\ttrain-logloss:0.219764\tval-logloss:0.246723\n",
      "[2300]\ttrain-logloss:0.212161\tval-logloss:0.240869\n",
      "[2400]\ttrain-logloss:0.204931\tval-logloss:0.234777\n",
      "[2500]\ttrain-logloss:0.198165\tval-logloss:0.229615\n",
      "[2600]\ttrain-logloss:0.191792\tval-logloss:0.224565\n",
      "[2700]\ttrain-logloss:0.185823\tval-logloss:0.220751\n",
      "[2800]\ttrain-logloss:0.180198\tval-logloss:0.217605\n",
      "[2900]\ttrain-logloss:0.1749\tval-logloss:0.215044\n",
      "[3000]\ttrain-logloss:0.169899\tval-logloss:0.212251\n",
      "[3100]\ttrain-logloss:0.165117\tval-logloss:0.20979\n",
      "[3200]\ttrain-logloss:0.160575\tval-logloss:0.206589\n",
      "[3300]\ttrain-logloss:0.156319\tval-logloss:0.204128\n",
      "[3400]\ttrain-logloss:0.152263\tval-logloss:0.202337\n",
      "[3500]\ttrain-logloss:0.14839\tval-logloss:0.201017\n",
      "[3600]\ttrain-logloss:0.144666\tval-logloss:0.199443\n",
      "[3700]\ttrain-logloss:0.141068\tval-logloss:0.197803\n",
      "[3800]\ttrain-logloss:0.137627\tval-logloss:0.196047\n",
      "[3900]\ttrain-logloss:0.13433\tval-logloss:0.194387\n",
      "[4000]\ttrain-logloss:0.131179\tval-logloss:0.192472\n",
      "[4100]\ttrain-logloss:0.12819\tval-logloss:0.190179\n",
      "[4200]\ttrain-logloss:0.125332\tval-logloss:0.187085\n",
      "[4300]\ttrain-logloss:0.122616\tval-logloss:0.184959\n",
      "[4400]\ttrain-logloss:0.11999\tval-logloss:0.183659\n",
      "[4500]\ttrain-logloss:0.117455\tval-logloss:0.181148\n",
      "[4600]\ttrain-logloss:0.115034\tval-logloss:0.179567\n",
      "[4700]\ttrain-logloss:0.112746\tval-logloss:0.177815\n",
      "[4800]\ttrain-logloss:0.110549\tval-logloss:0.175967\n",
      "[4900]\ttrain-logloss:0.108436\tval-logloss:0.174849\n",
      "[4999]\ttrain-logloss:0.106413\tval-logloss:0.174121\n",
      "Fold: 35\n",
      "[0]\ttrain-logloss:0.692555\tval-logloss:0.692535\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638837\tval-logloss:0.649618\n",
      "[200]\ttrain-logloss:0.592388\tval-logloss:0.611892\n",
      "[300]\ttrain-logloss:0.55195\tval-logloss:0.579812\n",
      "[400]\ttrain-logloss:0.515932\tval-logloss:0.550515\n",
      "[500]\ttrain-logloss:0.483848\tval-logloss:0.524429\n",
      "[600]\ttrain-logloss:0.454983\tval-logloss:0.500755\n",
      "[700]\ttrain-logloss:0.428849\tval-logloss:0.480413\n",
      "[800]\ttrain-logloss:0.40516\tval-logloss:0.462352\n",
      "[900]\ttrain-logloss:0.383771\tval-logloss:0.447506\n",
      "[1000]\ttrain-logloss:0.364245\tval-logloss:0.434385\n",
      "[1100]\ttrain-logloss:0.346452\tval-logloss:0.421814\n",
      "[1200]\ttrain-logloss:0.330198\tval-logloss:0.410628\n",
      "[1300]\ttrain-logloss:0.315289\tval-logloss:0.400708\n",
      "[1400]\ttrain-logloss:0.301506\tval-logloss:0.389828\n",
      "[1500]\ttrain-logloss:0.288607\tval-logloss:0.379755\n",
      "[1600]\ttrain-logloss:0.276667\tval-logloss:0.370648\n",
      "[1700]\ttrain-logloss:0.265502\tval-logloss:0.361908\n",
      "[1800]\ttrain-logloss:0.255131\tval-logloss:0.35486\n",
      "[1900]\ttrain-logloss:0.245276\tval-logloss:0.347225\n",
      "[2000]\ttrain-logloss:0.236031\tval-logloss:0.339543\n",
      "[2100]\ttrain-logloss:0.227428\tval-logloss:0.333828\n",
      "[2200]\ttrain-logloss:0.219295\tval-logloss:0.329258\n",
      "[2300]\ttrain-logloss:0.21171\tval-logloss:0.325187\n",
      "[2400]\ttrain-logloss:0.204568\tval-logloss:0.322269\n",
      "[2500]\ttrain-logloss:0.197806\tval-logloss:0.320218\n",
      "[2600]\ttrain-logloss:0.191409\tval-logloss:0.31787\n",
      "[2700]\ttrain-logloss:0.185392\tval-logloss:0.314748\n",
      "[2800]\ttrain-logloss:0.179714\tval-logloss:0.311811\n",
      "[2900]\ttrain-logloss:0.174397\tval-logloss:0.310201\n",
      "[3000]\ttrain-logloss:0.169367\tval-logloss:0.307574\n",
      "[3100]\ttrain-logloss:0.164666\tval-logloss:0.305786\n",
      "[3200]\ttrain-logloss:0.160161\tval-logloss:0.304075\n",
      "[3300]\ttrain-logloss:0.15583\tval-logloss:0.302687\n",
      "[3400]\ttrain-logloss:0.151758\tval-logloss:0.30136\n",
      "[3500]\ttrain-logloss:0.147884\tval-logloss:0.300404\n",
      "[3600]\ttrain-logloss:0.144244\tval-logloss:0.299602\n",
      "[3700]\ttrain-logloss:0.140757\tval-logloss:0.298879\n",
      "[3800]\ttrain-logloss:0.137398\tval-logloss:0.298508\n",
      "[3900]\ttrain-logloss:0.134126\tval-logloss:0.298449\n",
      "[4000]\ttrain-logloss:0.130998\tval-logloss:0.297869\n",
      "[4100]\ttrain-logloss:0.12797\tval-logloss:0.297754\n",
      "Stopping. Best iteration:\n",
      "[4024]\ttrain-logloss:0.130256\tval-logloss:0.297552\n",
      "\n",
      "Fold: 36\n",
      "[0]\ttrain-logloss:0.692551\tval-logloss:0.69298\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638608\tval-logloss:0.679861\n",
      "[200]\ttrain-logloss:0.591726\tval-logloss:0.670995\n",
      "[300]\ttrain-logloss:0.550993\tval-logloss:0.664558\n",
      "[400]\ttrain-logloss:0.514763\tval-logloss:0.660128\n",
      "[500]\ttrain-logloss:0.482348\tval-logloss:0.658423\n",
      "[600]\ttrain-logloss:0.453379\tval-logloss:0.656772\n",
      "[700]\ttrain-logloss:0.427238\tval-logloss:0.655602\n",
      "[800]\ttrain-logloss:0.403695\tval-logloss:0.655813\n",
      "Stopping. Best iteration:\n",
      "[752]\ttrain-logloss:0.414686\tval-logloss:0.654845\n",
      "\n",
      "Fold: 37\n",
      "[0]\ttrain-logloss:0.692565\tval-logloss:0.692856\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638915\tval-logloss:0.672679\n",
      "[200]\ttrain-logloss:0.592324\tval-logloss:0.653027\n",
      "[300]\ttrain-logloss:0.551786\tval-logloss:0.636241\n",
      "[400]\ttrain-logloss:0.515593\tval-logloss:0.623288\n",
      "[500]\ttrain-logloss:0.483259\tval-logloss:0.614087\n",
      "[600]\ttrain-logloss:0.454357\tval-logloss:0.603197\n",
      "[700]\ttrain-logloss:0.428182\tval-logloss:0.59216\n",
      "[800]\ttrain-logloss:0.404616\tval-logloss:0.584405\n",
      "[900]\ttrain-logloss:0.383337\tval-logloss:0.578958\n",
      "[1000]\ttrain-logloss:0.364048\tval-logloss:0.576412\n",
      "[1100]\ttrain-logloss:0.34623\tval-logloss:0.575025\n",
      "[1200]\ttrain-logloss:0.329962\tval-logloss:0.573768\n",
      "[1300]\ttrain-logloss:0.31492\tval-logloss:0.571375\n",
      "[1400]\ttrain-logloss:0.301053\tval-logloss:0.567188\n",
      "[1500]\ttrain-logloss:0.288143\tval-logloss:0.561757\n",
      "[1600]\ttrain-logloss:0.276273\tval-logloss:0.55926\n",
      "[1700]\ttrain-logloss:0.265137\tval-logloss:0.557108\n",
      "[1800]\ttrain-logloss:0.254749\tval-logloss:0.555627\n",
      "[1900]\ttrain-logloss:0.245055\tval-logloss:0.555554\n",
      "Stopping. Best iteration:\n",
      "[1845]\ttrain-logloss:0.250281\tval-logloss:0.554891\n",
      "\n",
      "Fold: 38\n",
      "[0]\ttrain-logloss:0.692555\tval-logloss:0.692801\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638889\tval-logloss:0.664839\n",
      "[200]\ttrain-logloss:0.592331\tval-logloss:0.64034\n",
      "[300]\ttrain-logloss:0.551583\tval-logloss:0.619084\n",
      "[400]\ttrain-logloss:0.51527\tval-logloss:0.599031\n",
      "[500]\ttrain-logloss:0.482911\tval-logloss:0.583036\n",
      "[600]\ttrain-logloss:0.453869\tval-logloss:0.567427\n",
      "[700]\ttrain-logloss:0.427656\tval-logloss:0.549598\n",
      "[800]\ttrain-logloss:0.403907\tval-logloss:0.533224\n",
      "[900]\ttrain-logloss:0.382406\tval-logloss:0.519327\n",
      "[1000]\ttrain-logloss:0.363071\tval-logloss:0.506361\n",
      "[1100]\ttrain-logloss:0.34532\tval-logloss:0.496446\n",
      "[1200]\ttrain-logloss:0.329155\tval-logloss:0.487533\n",
      "[1300]\ttrain-logloss:0.314315\tval-logloss:0.480776\n",
      "[1400]\ttrain-logloss:0.300622\tval-logloss:0.47487\n",
      "[1500]\ttrain-logloss:0.287911\tval-logloss:0.470298\n",
      "[1600]\ttrain-logloss:0.27607\tval-logloss:0.464551\n",
      "[1700]\ttrain-logloss:0.265028\tval-logloss:0.459245\n",
      "[1800]\ttrain-logloss:0.254766\tval-logloss:0.454992\n",
      "[1900]\ttrain-logloss:0.245173\tval-logloss:0.449888\n",
      "[2000]\ttrain-logloss:0.236174\tval-logloss:0.444163\n",
      "[2100]\ttrain-logloss:0.227611\tval-logloss:0.438918\n",
      "[2200]\ttrain-logloss:0.219579\tval-logloss:0.431764\n",
      "[2300]\ttrain-logloss:0.211981\tval-logloss:0.426092\n",
      "[2400]\ttrain-logloss:0.204808\tval-logloss:0.419048\n",
      "[2500]\ttrain-logloss:0.197996\tval-logloss:0.410819\n",
      "[2600]\ttrain-logloss:0.191613\tval-logloss:0.404439\n",
      "[2700]\ttrain-logloss:0.185659\tval-logloss:0.397962\n",
      "[2800]\ttrain-logloss:0.18003\tval-logloss:0.390587\n",
      "[2900]\ttrain-logloss:0.174726\tval-logloss:0.38554\n",
      "[3000]\ttrain-logloss:0.169703\tval-logloss:0.380349\n",
      "[3100]\ttrain-logloss:0.165007\tval-logloss:0.375742\n",
      "[3200]\ttrain-logloss:0.160512\tval-logloss:0.369824\n",
      "[3300]\ttrain-logloss:0.156233\tval-logloss:0.365184\n",
      "[3400]\ttrain-logloss:0.152141\tval-logloss:0.361831\n",
      "[3500]\ttrain-logloss:0.148218\tval-logloss:0.358001\n",
      "[3600]\ttrain-logloss:0.144517\tval-logloss:0.353913\n",
      "[3700]\ttrain-logloss:0.140922\tval-logloss:0.349781\n",
      "[3800]\ttrain-logloss:0.137426\tval-logloss:0.34528\n",
      "[3900]\ttrain-logloss:0.134079\tval-logloss:0.340679\n",
      "[4000]\ttrain-logloss:0.13092\tval-logloss:0.337902\n",
      "[4100]\ttrain-logloss:0.127897\tval-logloss:0.335282\n",
      "[4200]\ttrain-logloss:0.124994\tval-logloss:0.33265\n",
      "[4300]\ttrain-logloss:0.122288\tval-logloss:0.330207\n",
      "[4400]\ttrain-logloss:0.119705\tval-logloss:0.327276\n",
      "[4500]\ttrain-logloss:0.117138\tval-logloss:0.324766\n",
      "[4600]\ttrain-logloss:0.114738\tval-logloss:0.321821\n",
      "[4700]\ttrain-logloss:0.112395\tval-logloss:0.318855\n",
      "[4800]\ttrain-logloss:0.110132\tval-logloss:0.316795\n",
      "[4900]\ttrain-logloss:0.108007\tval-logloss:0.314321\n",
      "[4999]\ttrain-logloss:0.105979\tval-logloss:0.312886\n",
      "Fold: 39\n",
      "[0]\ttrain-logloss:0.692552\tval-logloss:0.69311\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638434\tval-logloss:0.688371\n",
      "[200]\ttrain-logloss:0.591413\tval-logloss:0.684422\n",
      "[300]\ttrain-logloss:0.55042\tval-logloss:0.683327\n",
      "[400]\ttrain-logloss:0.514093\tval-logloss:0.683258\n",
      "[500]\ttrain-logloss:0.481649\tval-logloss:0.685214\n",
      "Stopping. Best iteration:\n",
      "[404]\ttrain-logloss:0.512722\tval-logloss:0.68314\n",
      "\n",
      "Fold: 40\n",
      "[0]\ttrain-logloss:0.692567\tval-logloss:0.692515\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639167\tval-logloss:0.634061\n",
      "[200]\ttrain-logloss:0.592799\tval-logloss:0.589253\n",
      "[300]\ttrain-logloss:0.552248\tval-logloss:0.550177\n",
      "[400]\ttrain-logloss:0.516241\tval-logloss:0.517992\n",
      "[500]\ttrain-logloss:0.484133\tval-logloss:0.487974\n",
      "[600]\ttrain-logloss:0.455304\tval-logloss:0.463618\n",
      "[700]\ttrain-logloss:0.429177\tval-logloss:0.440096\n",
      "[800]\ttrain-logloss:0.405539\tval-logloss:0.420571\n",
      "[900]\ttrain-logloss:0.384086\tval-logloss:0.400725\n",
      "[1000]\ttrain-logloss:0.364542\tval-logloss:0.384103\n",
      "[1100]\ttrain-logloss:0.34681\tval-logloss:0.369438\n",
      "[1200]\ttrain-logloss:0.330548\tval-logloss:0.356389\n",
      "[1300]\ttrain-logloss:0.315632\tval-logloss:0.344978\n",
      "[1400]\ttrain-logloss:0.301784\tval-logloss:0.336209\n",
      "[1500]\ttrain-logloss:0.288979\tval-logloss:0.327742\n",
      "[1600]\ttrain-logloss:0.277046\tval-logloss:0.31893\n",
      "[1700]\ttrain-logloss:0.265882\tval-logloss:0.30849\n",
      "[1800]\ttrain-logloss:0.25552\tval-logloss:0.299542\n",
      "[1900]\ttrain-logloss:0.245756\tval-logloss:0.290827\n",
      "[2000]\ttrain-logloss:0.236424\tval-logloss:0.28383\n",
      "[2100]\ttrain-logloss:0.227725\tval-logloss:0.277036\n",
      "[2200]\ttrain-logloss:0.219617\tval-logloss:0.271185\n",
      "[2300]\ttrain-logloss:0.211935\tval-logloss:0.265956\n",
      "[2400]\ttrain-logloss:0.204786\tval-logloss:0.26149\n",
      "[2500]\ttrain-logloss:0.198119\tval-logloss:0.257494\n",
      "[2600]\ttrain-logloss:0.191745\tval-logloss:0.253658\n",
      "[2700]\ttrain-logloss:0.185775\tval-logloss:0.250365\n",
      "[2800]\ttrain-logloss:0.180146\tval-logloss:0.247823\n",
      "[2900]\ttrain-logloss:0.174822\tval-logloss:0.244559\n",
      "[3000]\ttrain-logloss:0.169812\tval-logloss:0.240849\n",
      "[3100]\ttrain-logloss:0.165038\tval-logloss:0.238119\n",
      "[3200]\ttrain-logloss:0.160531\tval-logloss:0.23547\n",
      "[3300]\ttrain-logloss:0.156219\tval-logloss:0.233389\n",
      "[3400]\ttrain-logloss:0.152133\tval-logloss:0.230331\n",
      "[3500]\ttrain-logloss:0.148275\tval-logloss:0.228796\n",
      "[3600]\ttrain-logloss:0.144586\tval-logloss:0.226867\n",
      "[3700]\ttrain-logloss:0.141041\tval-logloss:0.224472\n",
      "[3800]\ttrain-logloss:0.137615\tval-logloss:0.223349\n",
      "[3900]\ttrain-logloss:0.134317\tval-logloss:0.221861\n",
      "[4000]\ttrain-logloss:0.131168\tval-logloss:0.220197\n",
      "[4100]\ttrain-logloss:0.128207\tval-logloss:0.218399\n",
      "[4200]\ttrain-logloss:0.125344\tval-logloss:0.216456\n",
      "[4300]\ttrain-logloss:0.12266\tval-logloss:0.215167\n",
      "[4400]\ttrain-logloss:0.120068\tval-logloss:0.213139\n",
      "[4500]\ttrain-logloss:0.117583\tval-logloss:0.211907\n",
      "[4600]\ttrain-logloss:0.115222\tval-logloss:0.210002\n",
      "[4700]\ttrain-logloss:0.112946\tval-logloss:0.208415\n",
      "[4800]\ttrain-logloss:0.110756\tval-logloss:0.207432\n",
      "[4900]\ttrain-logloss:0.108652\tval-logloss:0.206214\n",
      "[4999]\ttrain-logloss:0.106604\tval-logloss:0.205177\n",
      "Fold: 41\n",
      "[0]\ttrain-logloss:0.692563\tval-logloss:0.692472\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639179\tval-logloss:0.631005\n",
      "[200]\ttrain-logloss:0.592786\tval-logloss:0.581174\n",
      "[300]\ttrain-logloss:0.552223\tval-logloss:0.537587\n",
      "[400]\ttrain-logloss:0.51631\tval-logloss:0.499832\n",
      "[500]\ttrain-logloss:0.484208\tval-logloss:0.463943\n",
      "[600]\ttrain-logloss:0.455382\tval-logloss:0.435086\n",
      "[700]\ttrain-logloss:0.429318\tval-logloss:0.409446\n",
      "[800]\ttrain-logloss:0.405654\tval-logloss:0.387773\n",
      "[900]\ttrain-logloss:0.384179\tval-logloss:0.367926\n",
      "[1000]\ttrain-logloss:0.364749\tval-logloss:0.350395\n",
      "[1100]\ttrain-logloss:0.346963\tval-logloss:0.333748\n",
      "[1200]\ttrain-logloss:0.330789\tval-logloss:0.319698\n",
      "[1300]\ttrain-logloss:0.315953\tval-logloss:0.307717\n",
      "[1400]\ttrain-logloss:0.302122\tval-logloss:0.297182\n",
      "[1500]\ttrain-logloss:0.289299\tval-logloss:0.286291\n",
      "[1600]\ttrain-logloss:0.277274\tval-logloss:0.275927\n",
      "[1700]\ttrain-logloss:0.265983\tval-logloss:0.266378\n",
      "[1800]\ttrain-logloss:0.255557\tval-logloss:0.257391\n",
      "[1900]\ttrain-logloss:0.245807\tval-logloss:0.250464\n",
      "[2000]\ttrain-logloss:0.236533\tval-logloss:0.244232\n",
      "[2100]\ttrain-logloss:0.227815\tval-logloss:0.237921\n",
      "[2200]\ttrain-logloss:0.219548\tval-logloss:0.231901\n",
      "[2300]\ttrain-logloss:0.211846\tval-logloss:0.225647\n",
      "[2400]\ttrain-logloss:0.204758\tval-logloss:0.220681\n",
      "[2500]\ttrain-logloss:0.198033\tval-logloss:0.215889\n",
      "[2600]\ttrain-logloss:0.191719\tval-logloss:0.213645\n",
      "[2700]\ttrain-logloss:0.185703\tval-logloss:0.21097\n",
      "[2800]\ttrain-logloss:0.180113\tval-logloss:0.208577\n",
      "[2900]\ttrain-logloss:0.174839\tval-logloss:0.205601\n",
      "[3000]\ttrain-logloss:0.169815\tval-logloss:0.203345\n",
      "[3100]\ttrain-logloss:0.165069\tval-logloss:0.200758\n",
      "[3200]\ttrain-logloss:0.160552\tval-logloss:0.198339\n",
      "[3300]\ttrain-logloss:0.156276\tval-logloss:0.195367\n",
      "[3400]\ttrain-logloss:0.152217\tval-logloss:0.193085\n",
      "[3500]\ttrain-logloss:0.148383\tval-logloss:0.190296\n",
      "[3600]\ttrain-logloss:0.144683\tval-logloss:0.188481\n",
      "[3700]\ttrain-logloss:0.141115\tval-logloss:0.186239\n",
      "[3800]\ttrain-logloss:0.137692\tval-logloss:0.184085\n",
      "[3900]\ttrain-logloss:0.134386\tval-logloss:0.182723\n",
      "[4000]\ttrain-logloss:0.131265\tval-logloss:0.181357\n",
      "[4100]\ttrain-logloss:0.128269\tval-logloss:0.179275\n",
      "[4200]\ttrain-logloss:0.12543\tval-logloss:0.177599\n",
      "[4300]\ttrain-logloss:0.122732\tval-logloss:0.175902\n",
      "[4400]\ttrain-logloss:0.120178\tval-logloss:0.173437\n",
      "[4500]\ttrain-logloss:0.117707\tval-logloss:0.171927\n",
      "[4600]\ttrain-logloss:0.115344\tval-logloss:0.169888\n",
      "[4700]\ttrain-logloss:0.11305\tval-logloss:0.167571\n",
      "[4800]\ttrain-logloss:0.110837\tval-logloss:0.16608\n",
      "[4900]\ttrain-logloss:0.108747\tval-logloss:0.164817\n",
      "[4999]\ttrain-logloss:0.106742\tval-logloss:0.163788\n",
      "Fold: 42\n",
      "[0]\ttrain-logloss:0.692558\tval-logloss:0.692963\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638794\tval-logloss:0.66484\n",
      "[200]\ttrain-logloss:0.592247\tval-logloss:0.641209\n",
      "[300]\ttrain-logloss:0.551643\tval-logloss:0.625919\n",
      "[400]\ttrain-logloss:0.515657\tval-logloss:0.610435\n",
      "[500]\ttrain-logloss:0.483443\tval-logloss:0.597355\n",
      "[600]\ttrain-logloss:0.454505\tval-logloss:0.584501\n",
      "[700]\ttrain-logloss:0.428332\tval-logloss:0.572544\n",
      "[800]\ttrain-logloss:0.404725\tval-logloss:0.563325\n",
      "[900]\ttrain-logloss:0.383184\tval-logloss:0.556944\n",
      "[1000]\ttrain-logloss:0.363619\tval-logloss:0.552505\n",
      "[1100]\ttrain-logloss:0.345748\tval-logloss:0.550462\n",
      "Stopping. Best iteration:\n",
      "[1075]\ttrain-logloss:0.350079\tval-logloss:0.549628\n",
      "\n",
      "Fold: 43\n",
      "[0]\ttrain-logloss:0.692558\tval-logloss:0.69275\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.63888\tval-logloss:0.658831\n",
      "[200]\ttrain-logloss:0.592363\tval-logloss:0.630461\n",
      "[300]\ttrain-logloss:0.551821\tval-logloss:0.608562\n",
      "[400]\ttrain-logloss:0.515812\tval-logloss:0.587601\n",
      "[500]\ttrain-logloss:0.483668\tval-logloss:0.569866\n",
      "[600]\ttrain-logloss:0.454904\tval-logloss:0.554339\n",
      "[700]\ttrain-logloss:0.428905\tval-logloss:0.538878\n",
      "[800]\ttrain-logloss:0.405245\tval-logloss:0.525533\n",
      "[900]\ttrain-logloss:0.383839\tval-logloss:0.512931\n",
      "[1000]\ttrain-logloss:0.364198\tval-logloss:0.506666\n",
      "[1100]\ttrain-logloss:0.346341\tval-logloss:0.504076\n",
      "[1200]\ttrain-logloss:0.330046\tval-logloss:0.500456\n",
      "[1300]\ttrain-logloss:0.315123\tval-logloss:0.496937\n",
      "[1400]\ttrain-logloss:0.301288\tval-logloss:0.494231\n",
      "[1500]\ttrain-logloss:0.288236\tval-logloss:0.492926\n",
      "[1600]\ttrain-logloss:0.276163\tval-logloss:0.493215\n",
      "Stopping. Best iteration:\n",
      "[1514]\ttrain-logloss:0.286482\tval-logloss:0.492677\n",
      "\n",
      "Fold: 44\n",
      "[0]\ttrain-logloss:0.692552\tval-logloss:0.692531\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639019\tval-logloss:0.631673\n",
      "[200]\ttrain-logloss:0.592661\tval-logloss:0.579912\n",
      "[300]\ttrain-logloss:0.552222\tval-logloss:0.53563\n",
      "[400]\ttrain-logloss:0.516301\tval-logloss:0.495362\n",
      "[500]\ttrain-logloss:0.484138\tval-logloss:0.460211\n",
      "[600]\ttrain-logloss:0.455203\tval-logloss:0.430662\n",
      "[700]\ttrain-logloss:0.428996\tval-logloss:0.404085\n",
      "[800]\ttrain-logloss:0.405287\tval-logloss:0.382634\n",
      "[900]\ttrain-logloss:0.383702\tval-logloss:0.364947\n",
      "[1000]\ttrain-logloss:0.364175\tval-logloss:0.34871\n",
      "[1100]\ttrain-logloss:0.346525\tval-logloss:0.333842\n",
      "[1200]\ttrain-logloss:0.330301\tval-logloss:0.321766\n",
      "[1300]\ttrain-logloss:0.315305\tval-logloss:0.310556\n",
      "[1400]\ttrain-logloss:0.301376\tval-logloss:0.301108\n",
      "[1500]\ttrain-logloss:0.288381\tval-logloss:0.291907\n",
      "[1600]\ttrain-logloss:0.276314\tval-logloss:0.284583\n",
      "[1700]\ttrain-logloss:0.265103\tval-logloss:0.278863\n",
      "[1800]\ttrain-logloss:0.254783\tval-logloss:0.274339\n",
      "[1900]\ttrain-logloss:0.245134\tval-logloss:0.270175\n",
      "[2000]\ttrain-logloss:0.236012\tval-logloss:0.266724\n",
      "[2100]\ttrain-logloss:0.227388\tval-logloss:0.263751\n",
      "[2200]\ttrain-logloss:0.219305\tval-logloss:0.260563\n",
      "[2300]\ttrain-logloss:0.211767\tval-logloss:0.259767\n",
      "[2400]\ttrain-logloss:0.204479\tval-logloss:0.259417\n",
      "[2500]\ttrain-logloss:0.197697\tval-logloss:0.256651\n",
      "[2600]\ttrain-logloss:0.191302\tval-logloss:0.254971\n",
      "[2700]\ttrain-logloss:0.185322\tval-logloss:0.253186\n",
      "[2800]\ttrain-logloss:0.17966\tval-logloss:0.251402\n",
      "[2900]\ttrain-logloss:0.174363\tval-logloss:0.25086\n",
      "[3000]\ttrain-logloss:0.169314\tval-logloss:0.249552\n",
      "[3100]\ttrain-logloss:0.164522\tval-logloss:0.248968\n",
      "[3200]\ttrain-logloss:0.16001\tval-logloss:0.248906\n",
      "Stopping. Best iteration:\n",
      "[3123]\ttrain-logloss:0.163471\tval-logloss:0.248712\n",
      "\n",
      "Fold: 45\n",
      "[0]\ttrain-logloss:0.692547\tval-logloss:0.693157\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638445\tval-logloss:0.687024\n",
      "[200]\ttrain-logloss:0.591632\tval-logloss:0.678752\n",
      "[300]\ttrain-logloss:0.550882\tval-logloss:0.674158\n",
      "[400]\ttrain-logloss:0.514544\tval-logloss:0.66992\n",
      "[500]\ttrain-logloss:0.482258\tval-logloss:0.668505\n",
      "Stopping. Best iteration:\n",
      "[462]\ttrain-logloss:0.494162\tval-logloss:0.667972\n",
      "\n",
      "Fold: 46\n",
      "[0]\ttrain-logloss:0.692554\tval-logloss:0.692727\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638856\tval-logloss:0.659252\n",
      "[200]\ttrain-logloss:0.592321\tval-logloss:0.632464\n",
      "[300]\ttrain-logloss:0.551718\tval-logloss:0.608882\n",
      "[400]\ttrain-logloss:0.515543\tval-logloss:0.588443\n",
      "[500]\ttrain-logloss:0.48324\tval-logloss:0.573554\n",
      "[600]\ttrain-logloss:0.45404\tval-logloss:0.565177\n",
      "[700]\ttrain-logloss:0.42777\tval-logloss:0.559213\n",
      "[800]\ttrain-logloss:0.403989\tval-logloss:0.557876\n",
      "Stopping. Best iteration:\n",
      "[798]\ttrain-logloss:0.404441\tval-logloss:0.557742\n",
      "\n",
      "Fold: 47\n",
      "[0]\ttrain-logloss:0.692559\tval-logloss:0.692617\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638889\tval-logloss:0.662953\n",
      "[200]\ttrain-logloss:0.592464\tval-logloss:0.641481\n",
      "[300]\ttrain-logloss:0.552099\tval-logloss:0.62588\n",
      "[400]\ttrain-logloss:0.515953\tval-logloss:0.612645\n",
      "[500]\ttrain-logloss:0.483827\tval-logloss:0.600178\n",
      "[600]\ttrain-logloss:0.45496\tval-logloss:0.59002\n",
      "[700]\ttrain-logloss:0.428771\tval-logloss:0.582861\n",
      "[800]\ttrain-logloss:0.405123\tval-logloss:0.575534\n",
      "[900]\ttrain-logloss:0.383636\tval-logloss:0.570333\n",
      "[1000]\ttrain-logloss:0.363935\tval-logloss:0.563922\n",
      "[1100]\ttrain-logloss:0.345969\tval-logloss:0.56049\n",
      "[1200]\ttrain-logloss:0.329534\tval-logloss:0.558963\n",
      "Stopping. Best iteration:\n",
      "[1174]\ttrain-logloss:0.333641\tval-logloss:0.558506\n",
      "\n",
      "Fold: 48\n",
      "[0]\ttrain-logloss:0.692555\tval-logloss:0.692746\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638765\tval-logloss:0.659531\n",
      "[200]\ttrain-logloss:0.592208\tval-logloss:0.634108\n",
      "[300]\ttrain-logloss:0.551589\tval-logloss:0.613444\n",
      "[400]\ttrain-logloss:0.5155\tval-logloss:0.597017\n",
      "[500]\ttrain-logloss:0.48349\tval-logloss:0.585249\n",
      "[600]\ttrain-logloss:0.45464\tval-logloss:0.573128\n",
      "[700]\ttrain-logloss:0.428544\tval-logloss:0.56629\n",
      "[800]\ttrain-logloss:0.404931\tval-logloss:0.560863\n",
      "[900]\ttrain-logloss:0.383364\tval-logloss:0.556333\n",
      "[1000]\ttrain-logloss:0.363801\tval-logloss:0.553465\n",
      "[1100]\ttrain-logloss:0.346037\tval-logloss:0.551523\n",
      "[1200]\ttrain-logloss:0.329915\tval-logloss:0.551428\n",
      "[1300]\ttrain-logloss:0.315056\tval-logloss:0.551155\n",
      "[1400]\ttrain-logloss:0.301262\tval-logloss:0.552318\n",
      "Stopping. Best iteration:\n",
      "[1337]\ttrain-logloss:0.309804\tval-logloss:0.550711\n",
      "\n",
      "Fold: 49\n",
      "[0]\ttrain-logloss:0.692549\tval-logloss:0.692551\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638889\tval-logloss:0.642286\n",
      "[200]\ttrain-logloss:0.592503\tval-logloss:0.601131\n",
      "[300]\ttrain-logloss:0.552109\tval-logloss:0.567541\n",
      "[400]\ttrain-logloss:0.516333\tval-logloss:0.53669\n",
      "[500]\ttrain-logloss:0.484393\tval-logloss:0.510668\n",
      "[600]\ttrain-logloss:0.455539\tval-logloss:0.489754\n",
      "[700]\ttrain-logloss:0.429486\tval-logloss:0.470936\n",
      "[800]\ttrain-logloss:0.405779\tval-logloss:0.453359\n",
      "[900]\ttrain-logloss:0.384369\tval-logloss:0.437508\n",
      "[1000]\ttrain-logloss:0.364819\tval-logloss:0.422835\n",
      "[1100]\ttrain-logloss:0.347063\tval-logloss:0.409104\n",
      "[1200]\ttrain-logloss:0.330871\tval-logloss:0.39677\n",
      "[1300]\ttrain-logloss:0.31609\tval-logloss:0.386195\n",
      "[1400]\ttrain-logloss:0.302364\tval-logloss:0.378265\n",
      "[1500]\ttrain-logloss:0.289537\tval-logloss:0.368865\n",
      "[1600]\ttrain-logloss:0.277544\tval-logloss:0.361211\n",
      "[1700]\ttrain-logloss:0.266333\tval-logloss:0.353889\n",
      "[1800]\ttrain-logloss:0.255837\tval-logloss:0.348016\n",
      "[1900]\ttrain-logloss:0.246104\tval-logloss:0.343022\n",
      "[2000]\ttrain-logloss:0.236698\tval-logloss:0.339807\n",
      "[2100]\ttrain-logloss:0.227964\tval-logloss:0.337983\n",
      "[2200]\ttrain-logloss:0.219812\tval-logloss:0.335851\n",
      "[2300]\ttrain-logloss:0.212169\tval-logloss:0.332229\n",
      "[2400]\ttrain-logloss:0.204846\tval-logloss:0.330254\n",
      "[2500]\ttrain-logloss:0.197951\tval-logloss:0.32898\n",
      "[2600]\ttrain-logloss:0.191553\tval-logloss:0.327949\n",
      "[2700]\ttrain-logloss:0.185557\tval-logloss:0.326234\n",
      "[2800]\ttrain-logloss:0.179901\tval-logloss:0.325702\n",
      "[2900]\ttrain-logloss:0.174572\tval-logloss:0.32419\n",
      "[3000]\ttrain-logloss:0.169557\tval-logloss:0.323339\n",
      "[3100]\ttrain-logloss:0.164808\tval-logloss:0.323\n",
      "Stopping. Best iteration:\n",
      "[3092]\ttrain-logloss:0.165182\tval-logloss:0.322893\n",
      "\n",
      "Fold: 50\n",
      "[0]\ttrain-logloss:0.69255\tval-logloss:0.692542\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638784\tval-logloss:0.645163\n",
      "[200]\ttrain-logloss:0.592216\tval-logloss:0.604723\n",
      "[300]\ttrain-logloss:0.551703\tval-logloss:0.571043\n",
      "[400]\ttrain-logloss:0.515605\tval-logloss:0.540731\n",
      "[500]\ttrain-logloss:0.483444\tval-logloss:0.515862\n",
      "[600]\ttrain-logloss:0.45455\tval-logloss:0.493232\n",
      "[700]\ttrain-logloss:0.428448\tval-logloss:0.472331\n",
      "[800]\ttrain-logloss:0.404635\tval-logloss:0.455228\n",
      "[900]\ttrain-logloss:0.383087\tval-logloss:0.43891\n",
      "[1000]\ttrain-logloss:0.363486\tval-logloss:0.426319\n",
      "[1100]\ttrain-logloss:0.345589\tval-logloss:0.414616\n",
      "[1200]\ttrain-logloss:0.329372\tval-logloss:0.404676\n",
      "[1300]\ttrain-logloss:0.31446\tval-logloss:0.396384\n",
      "[1400]\ttrain-logloss:0.300661\tval-logloss:0.388109\n",
      "[1500]\ttrain-logloss:0.28784\tval-logloss:0.382164\n",
      "[1600]\ttrain-logloss:0.275917\tval-logloss:0.375597\n",
      "[1700]\ttrain-logloss:0.264845\tval-logloss:0.370363\n",
      "[1800]\ttrain-logloss:0.254547\tval-logloss:0.366935\n",
      "[1900]\ttrain-logloss:0.244933\tval-logloss:0.363775\n",
      "[2000]\ttrain-logloss:0.235821\tval-logloss:0.362214\n",
      "[2100]\ttrain-logloss:0.227149\tval-logloss:0.36111\n",
      "[2200]\ttrain-logloss:0.218937\tval-logloss:0.361446\n",
      "Stopping. Best iteration:\n",
      "[2114]\ttrain-logloss:0.225955\tval-logloss:0.360688\n",
      "\n",
      "Fold: 51\n",
      "[0]\ttrain-logloss:0.692555\tval-logloss:0.692599\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638906\tval-logloss:0.640122\n",
      "[200]\ttrain-logloss:0.592518\tval-logloss:0.597429\n",
      "[300]\ttrain-logloss:0.552213\tval-logloss:0.560537\n",
      "[400]\ttrain-logloss:0.516334\tval-logloss:0.52705\n",
      "[500]\ttrain-logloss:0.484201\tval-logloss:0.501639\n",
      "[600]\ttrain-logloss:0.455212\tval-logloss:0.481608\n",
      "[700]\ttrain-logloss:0.42905\tval-logloss:0.464916\n",
      "[800]\ttrain-logloss:0.405242\tval-logloss:0.450498\n",
      "[900]\ttrain-logloss:0.383621\tval-logloss:0.437006\n",
      "[1000]\ttrain-logloss:0.364009\tval-logloss:0.42443\n",
      "[1100]\ttrain-logloss:0.346124\tval-logloss:0.412404\n",
      "[1200]\ttrain-logloss:0.32995\tval-logloss:0.403393\n",
      "[1300]\ttrain-logloss:0.315031\tval-logloss:0.394343\n",
      "[1400]\ttrain-logloss:0.301289\tval-logloss:0.385488\n",
      "[1500]\ttrain-logloss:0.288524\tval-logloss:0.379088\n",
      "[1600]\ttrain-logloss:0.276606\tval-logloss:0.372999\n",
      "[1700]\ttrain-logloss:0.265409\tval-logloss:0.368381\n",
      "[1800]\ttrain-logloss:0.255053\tval-logloss:0.365348\n",
      "[1900]\ttrain-logloss:0.245404\tval-logloss:0.361421\n",
      "[2000]\ttrain-logloss:0.236463\tval-logloss:0.356963\n",
      "[2100]\ttrain-logloss:0.227936\tval-logloss:0.350716\n",
      "[2200]\ttrain-logloss:0.219906\tval-logloss:0.342934\n",
      "[2300]\ttrain-logloss:0.212312\tval-logloss:0.337295\n",
      "[2400]\ttrain-logloss:0.205174\tval-logloss:0.334028\n",
      "[2500]\ttrain-logloss:0.198426\tval-logloss:0.330637\n",
      "[2600]\ttrain-logloss:0.192027\tval-logloss:0.327856\n",
      "[2700]\ttrain-logloss:0.185999\tval-logloss:0.326522\n",
      "[2800]\ttrain-logloss:0.180379\tval-logloss:0.32383\n",
      "[2900]\ttrain-logloss:0.175006\tval-logloss:0.322149\n",
      "[3000]\ttrain-logloss:0.169949\tval-logloss:0.320945\n",
      "[3100]\ttrain-logloss:0.165216\tval-logloss:0.318994\n",
      "[3200]\ttrain-logloss:0.160691\tval-logloss:0.317844\n",
      "[3300]\ttrain-logloss:0.15639\tval-logloss:0.315737\n",
      "[3400]\ttrain-logloss:0.152336\tval-logloss:0.31229\n",
      "[3500]\ttrain-logloss:0.148466\tval-logloss:0.310186\n",
      "[3600]\ttrain-logloss:0.144757\tval-logloss:0.308884\n",
      "[3700]\ttrain-logloss:0.141181\tval-logloss:0.307641\n",
      "[3800]\ttrain-logloss:0.137756\tval-logloss:0.306447\n",
      "Stopping. Best iteration:\n",
      "[3797]\ttrain-logloss:0.137854\tval-logloss:0.306338\n",
      "\n",
      "Fold: 52\n",
      "[0]\ttrain-logloss:0.692551\tval-logloss:0.692585\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638577\tval-logloss:0.652185\n",
      "[200]\ttrain-logloss:0.591963\tval-logloss:0.622244\n",
      "[300]\ttrain-logloss:0.551366\tval-logloss:0.595758\n",
      "[400]\ttrain-logloss:0.515288\tval-logloss:0.576323\n",
      "[500]\ttrain-logloss:0.483042\tval-logloss:0.560049\n",
      "[600]\ttrain-logloss:0.454127\tval-logloss:0.544559\n",
      "[700]\ttrain-logloss:0.42812\tval-logloss:0.534721\n",
      "[800]\ttrain-logloss:0.404517\tval-logloss:0.526186\n",
      "[900]\ttrain-logloss:0.383068\tval-logloss:0.517606\n",
      "[1000]\ttrain-logloss:0.363579\tval-logloss:0.5117\n",
      "[1100]\ttrain-logloss:0.34593\tval-logloss:0.512038\n",
      "[1200]\ttrain-logloss:0.32977\tval-logloss:0.512918\n",
      "Stopping. Best iteration:\n",
      "[1119]\ttrain-logloss:0.342726\tval-logloss:0.511132\n",
      "\n",
      "Fold: 53\n",
      "[0]\ttrain-logloss:0.692564\tval-logloss:0.692497\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638978\tval-logloss:0.636806\n",
      "[200]\ttrain-logloss:0.592689\tval-logloss:0.588854\n",
      "[300]\ttrain-logloss:0.552256\tval-logloss:0.547942\n",
      "[400]\ttrain-logloss:0.516338\tval-logloss:0.514611\n",
      "[500]\ttrain-logloss:0.484307\tval-logloss:0.486561\n",
      "[600]\ttrain-logloss:0.455393\tval-logloss:0.462918\n",
      "[700]\ttrain-logloss:0.429274\tval-logloss:0.442275\n",
      "[800]\ttrain-logloss:0.405546\tval-logloss:0.425949\n",
      "[900]\ttrain-logloss:0.384045\tval-logloss:0.413922\n",
      "[1000]\ttrain-logloss:0.364489\tval-logloss:0.401244\n",
      "[1100]\ttrain-logloss:0.34678\tval-logloss:0.390973\n",
      "[1200]\ttrain-logloss:0.330587\tval-logloss:0.382347\n",
      "[1300]\ttrain-logloss:0.315789\tval-logloss:0.373747\n",
      "[1400]\ttrain-logloss:0.302017\tval-logloss:0.366366\n",
      "[1500]\ttrain-logloss:0.289046\tval-logloss:0.360698\n",
      "[1600]\ttrain-logloss:0.277025\tval-logloss:0.35544\n",
      "[1700]\ttrain-logloss:0.265901\tval-logloss:0.352075\n",
      "[1800]\ttrain-logloss:0.255562\tval-logloss:0.347063\n",
      "[1900]\ttrain-logloss:0.245823\tval-logloss:0.340791\n",
      "[2000]\ttrain-logloss:0.236639\tval-logloss:0.334856\n",
      "[2100]\ttrain-logloss:0.228042\tval-logloss:0.33081\n",
      "[2200]\ttrain-logloss:0.22003\tval-logloss:0.326683\n",
      "[2300]\ttrain-logloss:0.212508\tval-logloss:0.324833\n",
      "[2400]\ttrain-logloss:0.205305\tval-logloss:0.32143\n",
      "[2500]\ttrain-logloss:0.198488\tval-logloss:0.318913\n",
      "[2600]\ttrain-logloss:0.192041\tval-logloss:0.316705\n",
      "[2700]\ttrain-logloss:0.186023\tval-logloss:0.315005\n",
      "[2800]\ttrain-logloss:0.180392\tval-logloss:0.313178\n",
      "[2900]\ttrain-logloss:0.17503\tval-logloss:0.311856\n",
      "[3000]\ttrain-logloss:0.170004\tval-logloss:0.311001\n",
      "[3100]\ttrain-logloss:0.165224\tval-logloss:0.310331\n",
      "[3200]\ttrain-logloss:0.160727\tval-logloss:0.309369\n",
      "[3300]\ttrain-logloss:0.156444\tval-logloss:0.309296\n",
      "Stopping. Best iteration:\n",
      "[3213]\ttrain-logloss:0.160171\tval-logloss:0.309214\n",
      "\n",
      "Fold: 54\n",
      "[0]\ttrain-logloss:0.69255\tval-logloss:0.692989\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638616\tval-logloss:0.682558\n",
      "[200]\ttrain-logloss:0.591946\tval-logloss:0.675322\n",
      "[300]\ttrain-logloss:0.551215\tval-logloss:0.6711\n",
      "[400]\ttrain-logloss:0.515096\tval-logloss:0.666673\n",
      "[500]\ttrain-logloss:0.482749\tval-logloss:0.661838\n",
      "[600]\ttrain-logloss:0.453773\tval-logloss:0.660183\n",
      "Stopping. Best iteration:\n",
      "[579]\ttrain-logloss:0.459637\tval-logloss:0.659815\n",
      "\n",
      "Fold: 55\n",
      "[0]\ttrain-logloss:0.692556\tval-logloss:0.692852\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638915\tval-logloss:0.6658\n",
      "[200]\ttrain-logloss:0.592286\tval-logloss:0.6453\n",
      "[300]\ttrain-logloss:0.551556\tval-logloss:0.632261\n",
      "[400]\ttrain-logloss:0.515321\tval-logloss:0.629672\n",
      "[500]\ttrain-logloss:0.483003\tval-logloss:0.62624\n",
      "[600]\ttrain-logloss:0.45406\tval-logloss:0.62358\n",
      "[700]\ttrain-logloss:0.427896\tval-logloss:0.622739\n",
      "[800]\ttrain-logloss:0.404223\tval-logloss:0.623014\n",
      "Stopping. Best iteration:\n",
      "[718]\ttrain-logloss:0.423454\tval-logloss:0.622577\n",
      "\n",
      "Fold: 56\n",
      "[0]\ttrain-logloss:0.692555\tval-logloss:0.692793\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638712\tval-logloss:0.666182\n",
      "[200]\ttrain-logloss:0.592009\tval-logloss:0.644064\n",
      "[300]\ttrain-logloss:0.551285\tval-logloss:0.627043\n",
      "[400]\ttrain-logloss:0.515003\tval-logloss:0.614112\n",
      "[500]\ttrain-logloss:0.482783\tval-logloss:0.603208\n",
      "[600]\ttrain-logloss:0.453707\tval-logloss:0.596176\n",
      "[700]\ttrain-logloss:0.427585\tval-logloss:0.590651\n",
      "[800]\ttrain-logloss:0.403875\tval-logloss:0.585821\n",
      "[900]\ttrain-logloss:0.382504\tval-logloss:0.580997\n",
      "[1000]\ttrain-logloss:0.363081\tval-logloss:0.578971\n",
      "[1100]\ttrain-logloss:0.345291\tval-logloss:0.578819\n",
      "Stopping. Best iteration:\n",
      "[1032]\ttrain-logloss:0.357224\tval-logloss:0.577781\n",
      "\n",
      "Fold: 57\n",
      "[0]\ttrain-logloss:0.692559\tval-logloss:0.69309\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638995\tval-logloss:0.691484\n",
      "[200]\ttrain-logloss:0.592505\tval-logloss:0.692658\n",
      "Stopping. Best iteration:\n",
      "[110]\ttrain-logloss:0.634039\tval-logloss:0.691133\n",
      "\n",
      "Fold: 58\n",
      "[0]\ttrain-logloss:0.692551\tval-logloss:0.692827\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638716\tval-logloss:0.675574\n",
      "[200]\ttrain-logloss:0.592055\tval-logloss:0.665783\n",
      "[300]\ttrain-logloss:0.551192\tval-logloss:0.659461\n",
      "[400]\ttrain-logloss:0.515012\tval-logloss:0.652757\n",
      "[500]\ttrain-logloss:0.48277\tval-logloss:0.647968\n",
      "[600]\ttrain-logloss:0.453919\tval-logloss:0.642735\n",
      "[700]\ttrain-logloss:0.427721\tval-logloss:0.637339\n",
      "[800]\ttrain-logloss:0.40411\tval-logloss:0.633317\n",
      "[900]\ttrain-logloss:0.382624\tval-logloss:0.631187\n",
      "[1000]\ttrain-logloss:0.363205\tval-logloss:0.629442\n",
      "[1100]\ttrain-logloss:0.345639\tval-logloss:0.628319\n",
      "[1200]\ttrain-logloss:0.32953\tval-logloss:0.627335\n",
      "Stopping. Best iteration:\n",
      "[1184]\ttrain-logloss:0.332045\tval-logloss:0.627054\n",
      "\n",
      "Fold: 59\n",
      "[0]\ttrain-logloss:0.69256\tval-logloss:0.692493\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638858\tval-logloss:0.63615\n",
      "[200]\ttrain-logloss:0.59246\tval-logloss:0.590315\n",
      "[300]\ttrain-logloss:0.551888\tval-logloss:0.553218\n",
      "[400]\ttrain-logloss:0.515902\tval-logloss:0.521267\n",
      "[500]\ttrain-logloss:0.48371\tval-logloss:0.492347\n",
      "[600]\ttrain-logloss:0.454803\tval-logloss:0.464515\n",
      "[700]\ttrain-logloss:0.428678\tval-logloss:0.438785\n",
      "[800]\ttrain-logloss:0.404978\tval-logloss:0.418055\n",
      "[900]\ttrain-logloss:0.383542\tval-logloss:0.401913\n",
      "[1000]\ttrain-logloss:0.364245\tval-logloss:0.388225\n",
      "[1100]\ttrain-logloss:0.346597\tval-logloss:0.375139\n",
      "[1200]\ttrain-logloss:0.330418\tval-logloss:0.365239\n",
      "[1300]\ttrain-logloss:0.315455\tval-logloss:0.35489\n",
      "[1400]\ttrain-logloss:0.301616\tval-logloss:0.345161\n",
      "[1500]\ttrain-logloss:0.288791\tval-logloss:0.33583\n",
      "[1600]\ttrain-logloss:0.27683\tval-logloss:0.327155\n",
      "[1700]\ttrain-logloss:0.26563\tval-logloss:0.317364\n",
      "[1800]\ttrain-logloss:0.255249\tval-logloss:0.307722\n",
      "[1900]\ttrain-logloss:0.245317\tval-logloss:0.301919\n",
      "[2000]\ttrain-logloss:0.235961\tval-logloss:0.29759\n",
      "[2100]\ttrain-logloss:0.227267\tval-logloss:0.293159\n",
      "[2200]\ttrain-logloss:0.21918\tval-logloss:0.288793\n",
      "[2300]\ttrain-logloss:0.211663\tval-logloss:0.284714\n",
      "[2400]\ttrain-logloss:0.204565\tval-logloss:0.281764\n",
      "[2500]\ttrain-logloss:0.197753\tval-logloss:0.278453\n",
      "[2600]\ttrain-logloss:0.191409\tval-logloss:0.275207\n",
      "[2700]\ttrain-logloss:0.185414\tval-logloss:0.270905\n",
      "[2800]\ttrain-logloss:0.179795\tval-logloss:0.266354\n",
      "[2900]\ttrain-logloss:0.174517\tval-logloss:0.261921\n",
      "[3000]\ttrain-logloss:0.169539\tval-logloss:0.258875\n",
      "[3100]\ttrain-logloss:0.164781\tval-logloss:0.256414\n",
      "[3200]\ttrain-logloss:0.160289\tval-logloss:0.253095\n",
      "[3300]\ttrain-logloss:0.156019\tval-logloss:0.249975\n",
      "[3400]\ttrain-logloss:0.152008\tval-logloss:0.246855\n",
      "[3500]\ttrain-logloss:0.148139\tval-logloss:0.244727\n",
      "[3600]\ttrain-logloss:0.144445\tval-logloss:0.243227\n",
      "[3700]\ttrain-logloss:0.140863\tval-logloss:0.240415\n",
      "[3800]\ttrain-logloss:0.13742\tval-logloss:0.239164\n",
      "[3900]\ttrain-logloss:0.13413\tval-logloss:0.237427\n",
      "[4000]\ttrain-logloss:0.130991\tval-logloss:0.236153\n",
      "[4100]\ttrain-logloss:0.128026\tval-logloss:0.234618\n",
      "[4200]\ttrain-logloss:0.125175\tval-logloss:0.232725\n",
      "[4300]\ttrain-logloss:0.122522\tval-logloss:0.231398\n",
      "[4400]\ttrain-logloss:0.119964\tval-logloss:0.230423\n",
      "[4500]\ttrain-logloss:0.117483\tval-logloss:0.229145\n",
      "[4600]\ttrain-logloss:0.115075\tval-logloss:0.227681\n",
      "[4700]\ttrain-logloss:0.112793\tval-logloss:0.226052\n",
      "[4800]\ttrain-logloss:0.110585\tval-logloss:0.225183\n",
      "[4900]\ttrain-logloss:0.108487\tval-logloss:0.224288\n",
      "[4999]\ttrain-logloss:0.106486\tval-logloss:0.22298\n",
      "Fold: 60\n",
      "[0]\ttrain-logloss:0.692547\tval-logloss:0.692864\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.6384\tval-logloss:0.671353\n",
      "[200]\ttrain-logloss:0.591536\tval-logloss:0.652439\n",
      "[300]\ttrain-logloss:0.550813\tval-logloss:0.638497\n",
      "[400]\ttrain-logloss:0.514673\tval-logloss:0.626948\n",
      "[500]\ttrain-logloss:0.482576\tval-logloss:0.616506\n",
      "[600]\ttrain-logloss:0.453583\tval-logloss:0.604118\n",
      "[700]\ttrain-logloss:0.427473\tval-logloss:0.592185\n",
      "[800]\ttrain-logloss:0.403869\tval-logloss:0.579928\n",
      "[900]\ttrain-logloss:0.382461\tval-logloss:0.571919\n",
      "[1000]\ttrain-logloss:0.363053\tval-logloss:0.563541\n",
      "[1100]\ttrain-logloss:0.345459\tval-logloss:0.556216\n",
      "[1200]\ttrain-logloss:0.329351\tval-logloss:0.550623\n",
      "[1300]\ttrain-logloss:0.314426\tval-logloss:0.545155\n",
      "[1400]\ttrain-logloss:0.300641\tval-logloss:0.539661\n",
      "[1500]\ttrain-logloss:0.287892\tval-logloss:0.5343\n",
      "[1600]\ttrain-logloss:0.276081\tval-logloss:0.52976\n",
      "[1700]\ttrain-logloss:0.264989\tval-logloss:0.524456\n",
      "[1800]\ttrain-logloss:0.254669\tval-logloss:0.51881\n",
      "[1900]\ttrain-logloss:0.244989\tval-logloss:0.515566\n",
      "[2000]\ttrain-logloss:0.236004\tval-logloss:0.512646\n",
      "[2100]\ttrain-logloss:0.227461\tval-logloss:0.51024\n",
      "[2200]\ttrain-logloss:0.219356\tval-logloss:0.508882\n",
      "[2300]\ttrain-logloss:0.211704\tval-logloss:0.506971\n",
      "[2400]\ttrain-logloss:0.204499\tval-logloss:0.505865\n",
      "[2500]\ttrain-logloss:0.197714\tval-logloss:0.504283\n",
      "[2600]\ttrain-logloss:0.191345\tval-logloss:0.503114\n",
      "[2700]\ttrain-logloss:0.185382\tval-logloss:0.503841\n",
      "Stopping. Best iteration:\n",
      "[2630]\ttrain-logloss:0.189517\tval-logloss:0.502883\n",
      "\n",
      "Fold: 61\n",
      "[0]\ttrain-logloss:0.692554\tval-logloss:0.692542\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639051\tval-logloss:0.634979\n",
      "[200]\ttrain-logloss:0.592653\tval-logloss:0.584303\n",
      "[300]\ttrain-logloss:0.552165\tval-logloss:0.541287\n",
      "[400]\ttrain-logloss:0.516191\tval-logloss:0.504645\n",
      "[500]\ttrain-logloss:0.484085\tval-logloss:0.472341\n",
      "[600]\ttrain-logloss:0.45521\tval-logloss:0.445068\n",
      "[700]\ttrain-logloss:0.429115\tval-logloss:0.422226\n",
      "[800]\ttrain-logloss:0.405497\tval-logloss:0.402747\n",
      "[900]\ttrain-logloss:0.383934\tval-logloss:0.385068\n",
      "[1000]\ttrain-logloss:0.364351\tval-logloss:0.371616\n",
      "[1100]\ttrain-logloss:0.346566\tval-logloss:0.358604\n",
      "[1200]\ttrain-logloss:0.330343\tval-logloss:0.348281\n",
      "[1300]\ttrain-logloss:0.315457\tval-logloss:0.33718\n",
      "[1400]\ttrain-logloss:0.301761\tval-logloss:0.326401\n",
      "[1500]\ttrain-logloss:0.288953\tval-logloss:0.316078\n",
      "[1600]\ttrain-logloss:0.277003\tval-logloss:0.306682\n",
      "[1700]\ttrain-logloss:0.265874\tval-logloss:0.298143\n",
      "[1800]\ttrain-logloss:0.255491\tval-logloss:0.290736\n",
      "[1900]\ttrain-logloss:0.245674\tval-logloss:0.284651\n",
      "[2000]\ttrain-logloss:0.23634\tval-logloss:0.279892\n",
      "[2100]\ttrain-logloss:0.227677\tval-logloss:0.275939\n",
      "[2200]\ttrain-logloss:0.219592\tval-logloss:0.274227\n",
      "[2300]\ttrain-logloss:0.212028\tval-logloss:0.272037\n",
      "[2400]\ttrain-logloss:0.204842\tval-logloss:0.26859\n",
      "[2500]\ttrain-logloss:0.198107\tval-logloss:0.264618\n",
      "[2600]\ttrain-logloss:0.191755\tval-logloss:0.261005\n",
      "[2700]\ttrain-logloss:0.18581\tval-logloss:0.258265\n",
      "[2800]\ttrain-logloss:0.1802\tval-logloss:0.255673\n",
      "[2900]\ttrain-logloss:0.174955\tval-logloss:0.252814\n",
      "[3000]\ttrain-logloss:0.169912\tval-logloss:0.251367\n",
      "[3100]\ttrain-logloss:0.165112\tval-logloss:0.249306\n",
      "[3200]\ttrain-logloss:0.160576\tval-logloss:0.247874\n",
      "[3300]\ttrain-logloss:0.156275\tval-logloss:0.246139\n",
      "[3400]\ttrain-logloss:0.152224\tval-logloss:0.244801\n",
      "[3500]\ttrain-logloss:0.148367\tval-logloss:0.243841\n",
      "[3600]\ttrain-logloss:0.144662\tval-logloss:0.24277\n",
      "[3700]\ttrain-logloss:0.14113\tval-logloss:0.242397\n",
      "[3800]\ttrain-logloss:0.137675\tval-logloss:0.241581\n",
      "[3900]\ttrain-logloss:0.134343\tval-logloss:0.240457\n",
      "[4000]\ttrain-logloss:0.131206\tval-logloss:0.23983\n",
      "[4100]\ttrain-logloss:0.128224\tval-logloss:0.239174\n",
      "[4200]\ttrain-logloss:0.125383\tval-logloss:0.238597\n",
      "[4300]\ttrain-logloss:0.122712\tval-logloss:0.237279\n",
      "[4400]\ttrain-logloss:0.120157\tval-logloss:0.236289\n",
      "[4500]\ttrain-logloss:0.117681\tval-logloss:0.234643\n",
      "[4600]\ttrain-logloss:0.115284\tval-logloss:0.232916\n",
      "[4700]\ttrain-logloss:0.112965\tval-logloss:0.230557\n",
      "[4800]\ttrain-logloss:0.110739\tval-logloss:0.228838\n",
      "[4900]\ttrain-logloss:0.10861\tval-logloss:0.227188\n",
      "[4999]\ttrain-logloss:0.106608\tval-logloss:0.226793\n",
      "Fold: 62\n",
      "[0]\ttrain-logloss:0.692561\tval-logloss:0.692673\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638963\tval-logloss:0.639513\n",
      "[200]\ttrain-logloss:0.592691\tval-logloss:0.594108\n",
      "[300]\ttrain-logloss:0.552215\tval-logloss:0.556799\n",
      "[400]\ttrain-logloss:0.516209\tval-logloss:0.521815\n",
      "[500]\ttrain-logloss:0.484073\tval-logloss:0.491899\n",
      "[600]\ttrain-logloss:0.455303\tval-logloss:0.46518\n",
      "[700]\ttrain-logloss:0.429276\tval-logloss:0.442607\n",
      "[800]\ttrain-logloss:0.405641\tval-logloss:0.423391\n",
      "[900]\ttrain-logloss:0.384252\tval-logloss:0.406047\n",
      "[1000]\ttrain-logloss:0.364783\tval-logloss:0.391304\n",
      "[1100]\ttrain-logloss:0.347102\tval-logloss:0.38046\n",
      "[1200]\ttrain-logloss:0.330974\tval-logloss:0.370431\n",
      "[1300]\ttrain-logloss:0.316016\tval-logloss:0.360693\n",
      "[1400]\ttrain-logloss:0.302297\tval-logloss:0.352362\n",
      "[1500]\ttrain-logloss:0.289344\tval-logloss:0.346689\n",
      "[1600]\ttrain-logloss:0.277318\tval-logloss:0.341489\n",
      "[1700]\ttrain-logloss:0.266099\tval-logloss:0.337059\n",
      "[1800]\ttrain-logloss:0.255676\tval-logloss:0.333519\n",
      "[1900]\ttrain-logloss:0.245835\tval-logloss:0.333459\n",
      "[2000]\ttrain-logloss:0.236472\tval-logloss:0.332348\n",
      "[2100]\ttrain-logloss:0.227808\tval-logloss:0.331938\n",
      "[2200]\ttrain-logloss:0.219601\tval-logloss:0.332783\n",
      "Stopping. Best iteration:\n",
      "[2142]\ttrain-logloss:0.224329\tval-logloss:0.331462\n",
      "\n",
      "Fold: 63\n",
      "[0]\ttrain-logloss:0.692553\tval-logloss:0.692621\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638967\tval-logloss:0.64015\n",
      "[200]\ttrain-logloss:0.592569\tval-logloss:0.595653\n",
      "[300]\ttrain-logloss:0.552127\tval-logloss:0.55805\n",
      "[400]\ttrain-logloss:0.516071\tval-logloss:0.524898\n",
      "[500]\ttrain-logloss:0.483965\tval-logloss:0.495252\n",
      "[600]\ttrain-logloss:0.455153\tval-logloss:0.46969\n",
      "[700]\ttrain-logloss:0.429132\tval-logloss:0.446419\n",
      "[800]\ttrain-logloss:0.405406\tval-logloss:0.427362\n",
      "[900]\ttrain-logloss:0.384059\tval-logloss:0.410237\n",
      "[1000]\ttrain-logloss:0.364536\tval-logloss:0.396089\n",
      "[1100]\ttrain-logloss:0.346848\tval-logloss:0.383408\n",
      "[1200]\ttrain-logloss:0.330714\tval-logloss:0.373801\n",
      "[1300]\ttrain-logloss:0.31583\tval-logloss:0.3643\n",
      "[1400]\ttrain-logloss:0.302015\tval-logloss:0.356441\n",
      "[1500]\ttrain-logloss:0.28905\tval-logloss:0.351043\n",
      "[1600]\ttrain-logloss:0.276979\tval-logloss:0.345705\n",
      "[1700]\ttrain-logloss:0.265787\tval-logloss:0.341827\n",
      "[1800]\ttrain-logloss:0.255343\tval-logloss:0.339542\n",
      "[1900]\ttrain-logloss:0.245565\tval-logloss:0.336666\n",
      "[2000]\ttrain-logloss:0.236368\tval-logloss:0.334227\n",
      "[2100]\ttrain-logloss:0.22771\tval-logloss:0.334635\n",
      "Stopping. Best iteration:\n",
      "[2030]\ttrain-logloss:0.233717\tval-logloss:0.333952\n",
      "\n",
      "Fold: 64\n",
      "[0]\ttrain-logloss:0.692556\tval-logloss:0.692694\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638813\tval-logloss:0.65556\n",
      "[200]\ttrain-logloss:0.592244\tval-logloss:0.626119\n",
      "[300]\ttrain-logloss:0.551709\tval-logloss:0.600023\n",
      "[400]\ttrain-logloss:0.515574\tval-logloss:0.580605\n",
      "[500]\ttrain-logloss:0.483281\tval-logloss:0.563576\n",
      "[600]\ttrain-logloss:0.454396\tval-logloss:0.548768\n",
      "[700]\ttrain-logloss:0.428309\tval-logloss:0.537945\n",
      "[800]\ttrain-logloss:0.404775\tval-logloss:0.531828\n",
      "[900]\ttrain-logloss:0.383435\tval-logloss:0.52583\n",
      "[1000]\ttrain-logloss:0.36389\tval-logloss:0.51947\n",
      "[1100]\ttrain-logloss:0.346122\tval-logloss:0.515045\n",
      "[1200]\ttrain-logloss:0.329912\tval-logloss:0.513738\n",
      "[1300]\ttrain-logloss:0.314856\tval-logloss:0.512802\n",
      "[1400]\ttrain-logloss:0.301089\tval-logloss:0.511505\n",
      "[1500]\ttrain-logloss:0.288162\tval-logloss:0.51066\n",
      "[1600]\ttrain-logloss:0.276048\tval-logloss:0.508313\n",
      "[1700]\ttrain-logloss:0.264932\tval-logloss:0.508983\n",
      "Stopping. Best iteration:\n",
      "[1619]\ttrain-logloss:0.273857\tval-logloss:0.508105\n",
      "\n",
      "Fold: 65\n",
      "[0]\ttrain-logloss:0.692553\tval-logloss:0.69281\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638686\tval-logloss:0.660419\n",
      "[200]\ttrain-logloss:0.59205\tval-logloss:0.632987\n",
      "[300]\ttrain-logloss:0.551374\tval-logloss:0.610661\n",
      "[400]\ttrain-logloss:0.515197\tval-logloss:0.590142\n",
      "[500]\ttrain-logloss:0.483048\tval-logloss:0.574739\n",
      "[600]\ttrain-logloss:0.454127\tval-logloss:0.564653\n",
      "[700]\ttrain-logloss:0.427968\tval-logloss:0.554862\n",
      "[800]\ttrain-logloss:0.404185\tval-logloss:0.545585\n",
      "[900]\ttrain-logloss:0.382615\tval-logloss:0.537227\n",
      "[1000]\ttrain-logloss:0.36301\tval-logloss:0.533043\n",
      "[1100]\ttrain-logloss:0.34512\tval-logloss:0.530383\n",
      "[1200]\ttrain-logloss:0.328925\tval-logloss:0.528477\n",
      "[1300]\ttrain-logloss:0.314134\tval-logloss:0.528564\n",
      "Stopping. Best iteration:\n",
      "[1211]\ttrain-logloss:0.327232\tval-logloss:0.528257\n",
      "\n",
      "Fold: 66\n",
      "[0]\ttrain-logloss:0.692559\tval-logloss:0.692808\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.63889\tval-logloss:0.656331\n",
      "[200]\ttrain-logloss:0.592418\tval-logloss:0.624676\n",
      "[300]\ttrain-logloss:0.551859\tval-logloss:0.597842\n",
      "[400]\ttrain-logloss:0.515941\tval-logloss:0.572129\n",
      "[500]\ttrain-logloss:0.483656\tval-logloss:0.548979\n",
      "[600]\ttrain-logloss:0.454622\tval-logloss:0.527764\n",
      "[700]\ttrain-logloss:0.42834\tval-logloss:0.51016\n",
      "[800]\ttrain-logloss:0.404459\tval-logloss:0.494655\n",
      "[900]\ttrain-logloss:0.38286\tval-logloss:0.484339\n",
      "[1000]\ttrain-logloss:0.36319\tval-logloss:0.476898\n",
      "[1100]\ttrain-logloss:0.345244\tval-logloss:0.470026\n",
      "[1200]\ttrain-logloss:0.328934\tval-logloss:0.463638\n",
      "[1300]\ttrain-logloss:0.314057\tval-logloss:0.457976\n",
      "[1400]\ttrain-logloss:0.300305\tval-logloss:0.453468\n",
      "[1500]\ttrain-logloss:0.287507\tval-logloss:0.449131\n",
      "[1600]\ttrain-logloss:0.275648\tval-logloss:0.44474\n",
      "[1700]\ttrain-logloss:0.264546\tval-logloss:0.441305\n",
      "[1800]\ttrain-logloss:0.254177\tval-logloss:0.439532\n",
      "[1900]\ttrain-logloss:0.244465\tval-logloss:0.437085\n",
      "[2000]\ttrain-logloss:0.235324\tval-logloss:0.433899\n",
      "[2100]\ttrain-logloss:0.226732\tval-logloss:0.431171\n",
      "[2200]\ttrain-logloss:0.218598\tval-logloss:0.427058\n",
      "[2300]\ttrain-logloss:0.210961\tval-logloss:0.423836\n",
      "[2400]\ttrain-logloss:0.203819\tval-logloss:0.419894\n",
      "[2500]\ttrain-logloss:0.197063\tval-logloss:0.416869\n",
      "[2600]\ttrain-logloss:0.190708\tval-logloss:0.414581\n",
      "[2700]\ttrain-logloss:0.184703\tval-logloss:0.412371\n",
      "[2800]\ttrain-logloss:0.179088\tval-logloss:0.410467\n",
      "[2900]\ttrain-logloss:0.173812\tval-logloss:0.40823\n",
      "[3000]\ttrain-logloss:0.168802\tval-logloss:0.405449\n",
      "[3100]\ttrain-logloss:0.164143\tval-logloss:0.403437\n",
      "[3200]\ttrain-logloss:0.159699\tval-logloss:0.400747\n",
      "[3300]\ttrain-logloss:0.155441\tval-logloss:0.397987\n",
      "[3400]\ttrain-logloss:0.151435\tval-logloss:0.395613\n",
      "[3500]\ttrain-logloss:0.147584\tval-logloss:0.393887\n",
      "[3600]\ttrain-logloss:0.14386\tval-logloss:0.391613\n",
      "[3700]\ttrain-logloss:0.140302\tval-logloss:0.388681\n",
      "[3800]\ttrain-logloss:0.136923\tval-logloss:0.385715\n",
      "[3900]\ttrain-logloss:0.133648\tval-logloss:0.382468\n",
      "[4000]\ttrain-logloss:0.130551\tval-logloss:0.379471\n",
      "[4100]\ttrain-logloss:0.12758\tval-logloss:0.377123\n",
      "[4200]\ttrain-logloss:0.124727\tval-logloss:0.375388\n",
      "[4300]\ttrain-logloss:0.121987\tval-logloss:0.374209\n",
      "[4400]\ttrain-logloss:0.119371\tval-logloss:0.373028\n",
      "[4500]\ttrain-logloss:0.116909\tval-logloss:0.371956\n",
      "[4600]\ttrain-logloss:0.114567\tval-logloss:0.371755\n",
      "Stopping. Best iteration:\n",
      "[4593]\ttrain-logloss:0.114726\tval-logloss:0.371641\n",
      "\n",
      "Fold: 67\n",
      "[0]\ttrain-logloss:0.692556\tval-logloss:0.692604\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639113\tval-logloss:0.64153\n",
      "[200]\ttrain-logloss:0.592804\tval-logloss:0.597954\n",
      "[300]\ttrain-logloss:0.552219\tval-logloss:0.561637\n",
      "[400]\ttrain-logloss:0.516151\tval-logloss:0.53127\n",
      "[500]\ttrain-logloss:0.483751\tval-logloss:0.505957\n",
      "[600]\ttrain-logloss:0.454749\tval-logloss:0.482428\n",
      "[700]\ttrain-logloss:0.428615\tval-logloss:0.459269\n",
      "[800]\ttrain-logloss:0.404952\tval-logloss:0.438573\n",
      "[900]\ttrain-logloss:0.383558\tval-logloss:0.419798\n",
      "[1000]\ttrain-logloss:0.364122\tval-logloss:0.399986\n",
      "[1100]\ttrain-logloss:0.346415\tval-logloss:0.382758\n",
      "[1200]\ttrain-logloss:0.330239\tval-logloss:0.369288\n",
      "[1300]\ttrain-logloss:0.315435\tval-logloss:0.356628\n",
      "[1400]\ttrain-logloss:0.301642\tval-logloss:0.344063\n",
      "[1500]\ttrain-logloss:0.288738\tval-logloss:0.333586\n",
      "[1600]\ttrain-logloss:0.276709\tval-logloss:0.323788\n",
      "[1700]\ttrain-logloss:0.26552\tval-logloss:0.314243\n",
      "[1800]\ttrain-logloss:0.255052\tval-logloss:0.305168\n",
      "[1900]\ttrain-logloss:0.24513\tval-logloss:0.299479\n",
      "[2000]\ttrain-logloss:0.235823\tval-logloss:0.294862\n",
      "[2100]\ttrain-logloss:0.227183\tval-logloss:0.290542\n",
      "[2200]\ttrain-logloss:0.21911\tval-logloss:0.285821\n",
      "[2300]\ttrain-logloss:0.211523\tval-logloss:0.280845\n",
      "[2400]\ttrain-logloss:0.204372\tval-logloss:0.276854\n",
      "[2500]\ttrain-logloss:0.197676\tval-logloss:0.275106\n",
      "[2600]\ttrain-logloss:0.191398\tval-logloss:0.27231\n",
      "[2700]\ttrain-logloss:0.185479\tval-logloss:0.270881\n",
      "[2800]\ttrain-logloss:0.179866\tval-logloss:0.269976\n",
      "[2900]\ttrain-logloss:0.174559\tval-logloss:0.26866\n",
      "[3000]\ttrain-logloss:0.169526\tval-logloss:0.26617\n",
      "[3100]\ttrain-logloss:0.16476\tval-logloss:0.264247\n",
      "[3200]\ttrain-logloss:0.160255\tval-logloss:0.261978\n",
      "[3300]\ttrain-logloss:0.155972\tval-logloss:0.259717\n",
      "[3400]\ttrain-logloss:0.151897\tval-logloss:0.25699\n",
      "[3500]\ttrain-logloss:0.148032\tval-logloss:0.256082\n",
      "[3600]\ttrain-logloss:0.144336\tval-logloss:0.25412\n",
      "[3700]\ttrain-logloss:0.140796\tval-logloss:0.25275\n",
      "[3800]\ttrain-logloss:0.137366\tval-logloss:0.252368\n",
      "[3900]\ttrain-logloss:0.134062\tval-logloss:0.250874\n",
      "[4000]\ttrain-logloss:0.130937\tval-logloss:0.250194\n",
      "[4100]\ttrain-logloss:0.127951\tval-logloss:0.249263\n",
      "Stopping. Best iteration:\n",
      "[4089]\ttrain-logloss:0.128272\tval-logloss:0.249158\n",
      "\n",
      "Fold: 68\n",
      "[0]\ttrain-logloss:0.692566\tval-logloss:0.692524\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638994\tval-logloss:0.644012\n",
      "[200]\ttrain-logloss:0.592539\tval-logloss:0.600229\n",
      "[300]\ttrain-logloss:0.552023\tval-logloss:0.56326\n",
      "[400]\ttrain-logloss:0.515943\tval-logloss:0.530041\n",
      "[500]\ttrain-logloss:0.483729\tval-logloss:0.500703\n",
      "[600]\ttrain-logloss:0.45473\tval-logloss:0.47624\n",
      "[700]\ttrain-logloss:0.428554\tval-logloss:0.455665\n",
      "[800]\ttrain-logloss:0.404933\tval-logloss:0.439039\n",
      "[900]\ttrain-logloss:0.383637\tval-logloss:0.421388\n",
      "[1000]\ttrain-logloss:0.364174\tval-logloss:0.406269\n",
      "[1100]\ttrain-logloss:0.346537\tval-logloss:0.392655\n",
      "[1200]\ttrain-logloss:0.330392\tval-logloss:0.379935\n",
      "[1300]\ttrain-logloss:0.315397\tval-logloss:0.370197\n",
      "[1400]\ttrain-logloss:0.301572\tval-logloss:0.35913\n",
      "[1500]\ttrain-logloss:0.288569\tval-logloss:0.347291\n",
      "[1600]\ttrain-logloss:0.276477\tval-logloss:0.338565\n",
      "[1700]\ttrain-logloss:0.265239\tval-logloss:0.331342\n",
      "[1800]\ttrain-logloss:0.254771\tval-logloss:0.325387\n",
      "[1900]\ttrain-logloss:0.24483\tval-logloss:0.323329\n",
      "[2000]\ttrain-logloss:0.235529\tval-logloss:0.321666\n",
      "[2100]\ttrain-logloss:0.226818\tval-logloss:0.318791\n",
      "[2200]\ttrain-logloss:0.218644\tval-logloss:0.316352\n",
      "[2300]\ttrain-logloss:0.211027\tval-logloss:0.315035\n",
      "[2400]\ttrain-logloss:0.203893\tval-logloss:0.31385\n",
      "[2500]\ttrain-logloss:0.197163\tval-logloss:0.313956\n",
      "Stopping. Best iteration:\n",
      "[2426]\ttrain-logloss:0.202109\tval-logloss:0.313284\n",
      "\n",
      "Fold: 69\n",
      "[0]\ttrain-logloss:0.692561\tval-logloss:0.692714\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.63868\tval-logloss:0.652946\n",
      "[200]\ttrain-logloss:0.592041\tval-logloss:0.620642\n",
      "[300]\ttrain-logloss:0.551349\tval-logloss:0.592337\n",
      "[400]\ttrain-logloss:0.51525\tval-logloss:0.567457\n",
      "[500]\ttrain-logloss:0.483064\tval-logloss:0.545454\n",
      "[600]\ttrain-logloss:0.454116\tval-logloss:0.524465\n",
      "[700]\ttrain-logloss:0.428045\tval-logloss:0.50362\n",
      "[800]\ttrain-logloss:0.404407\tval-logloss:0.485485\n",
      "[900]\ttrain-logloss:0.382936\tval-logloss:0.468848\n",
      "[1000]\ttrain-logloss:0.363328\tval-logloss:0.455906\n",
      "[1100]\ttrain-logloss:0.345403\tval-logloss:0.445463\n",
      "[1200]\ttrain-logloss:0.329192\tval-logloss:0.437848\n",
      "[1300]\ttrain-logloss:0.314293\tval-logloss:0.42864\n",
      "[1400]\ttrain-logloss:0.300507\tval-logloss:0.418757\n",
      "[1500]\ttrain-logloss:0.287715\tval-logloss:0.410014\n",
      "[1600]\ttrain-logloss:0.275802\tval-logloss:0.403136\n",
      "[1700]\ttrain-logloss:0.264619\tval-logloss:0.394678\n",
      "[1800]\ttrain-logloss:0.254216\tval-logloss:0.387069\n",
      "[1900]\ttrain-logloss:0.244392\tval-logloss:0.380012\n",
      "[2000]\ttrain-logloss:0.235153\tval-logloss:0.375416\n",
      "[2100]\ttrain-logloss:0.226488\tval-logloss:0.370511\n",
      "[2200]\ttrain-logloss:0.218347\tval-logloss:0.36494\n",
      "[2300]\ttrain-logloss:0.210806\tval-logloss:0.359221\n",
      "[2400]\ttrain-logloss:0.203685\tval-logloss:0.353265\n",
      "[2500]\ttrain-logloss:0.196958\tval-logloss:0.348677\n",
      "[2600]\ttrain-logloss:0.190667\tval-logloss:0.343807\n",
      "[2700]\ttrain-logloss:0.184788\tval-logloss:0.340713\n",
      "[2800]\ttrain-logloss:0.17915\tval-logloss:0.337431\n",
      "[2900]\ttrain-logloss:0.173842\tval-logloss:0.335071\n",
      "[3000]\ttrain-logloss:0.168869\tval-logloss:0.332739\n",
      "[3100]\ttrain-logloss:0.164171\tval-logloss:0.330533\n",
      "[3200]\ttrain-logloss:0.159677\tval-logloss:0.32834\n",
      "[3300]\ttrain-logloss:0.155411\tval-logloss:0.32636\n",
      "[3400]\ttrain-logloss:0.151367\tval-logloss:0.324338\n",
      "[3500]\ttrain-logloss:0.147519\tval-logloss:0.322031\n",
      "[3600]\ttrain-logloss:0.143806\tval-logloss:0.319467\n",
      "[3700]\ttrain-logloss:0.140322\tval-logloss:0.316579\n",
      "[3800]\ttrain-logloss:0.136924\tval-logloss:0.315142\n",
      "[3900]\ttrain-logloss:0.133656\tval-logloss:0.31475\n",
      "[4000]\ttrain-logloss:0.130541\tval-logloss:0.314031\n",
      "[4100]\ttrain-logloss:0.127589\tval-logloss:0.313355\n",
      "[4200]\ttrain-logloss:0.124767\tval-logloss:0.31222\n",
      "[4300]\ttrain-logloss:0.12208\tval-logloss:0.311279\n",
      "[4400]\ttrain-logloss:0.119533\tval-logloss:0.309464\n",
      "[4500]\ttrain-logloss:0.117013\tval-logloss:0.307847\n",
      "[4600]\ttrain-logloss:0.114649\tval-logloss:0.306495\n",
      "[4700]\ttrain-logloss:0.112365\tval-logloss:0.305665\n",
      "[4800]\ttrain-logloss:0.110174\tval-logloss:0.305111\n",
      "[4900]\ttrain-logloss:0.108111\tval-logloss:0.303501\n",
      "[4999]\ttrain-logloss:0.106067\tval-logloss:0.30268\n",
      "Fold: 70\n",
      "[0]\ttrain-logloss:0.692551\tval-logloss:0.692634\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638955\tval-logloss:0.642675\n",
      "[200]\ttrain-logloss:0.592588\tval-logloss:0.598766\n",
      "[300]\ttrain-logloss:0.552116\tval-logloss:0.561737\n",
      "[400]\ttrain-logloss:0.516191\tval-logloss:0.527296\n",
      "[500]\ttrain-logloss:0.48413\tval-logloss:0.499038\n",
      "[600]\ttrain-logloss:0.455289\tval-logloss:0.473618\n",
      "[700]\ttrain-logloss:0.429292\tval-logloss:0.452422\n",
      "[800]\ttrain-logloss:0.405566\tval-logloss:0.433829\n",
      "[900]\ttrain-logloss:0.384004\tval-logloss:0.417327\n",
      "[1000]\ttrain-logloss:0.364374\tval-logloss:0.401197\n",
      "[1100]\ttrain-logloss:0.346459\tval-logloss:0.384735\n",
      "[1200]\ttrain-logloss:0.330284\tval-logloss:0.370119\n",
      "[1300]\ttrain-logloss:0.315452\tval-logloss:0.357223\n",
      "[1400]\ttrain-logloss:0.30177\tval-logloss:0.346344\n",
      "[1500]\ttrain-logloss:0.289054\tval-logloss:0.335312\n",
      "[1600]\ttrain-logloss:0.277134\tval-logloss:0.327931\n",
      "[1700]\ttrain-logloss:0.265991\tval-logloss:0.32138\n",
      "[1800]\ttrain-logloss:0.255594\tval-logloss:0.316743\n",
      "[1900]\ttrain-logloss:0.245941\tval-logloss:0.311975\n",
      "[2000]\ttrain-logloss:0.236922\tval-logloss:0.30716\n",
      "[2100]\ttrain-logloss:0.228221\tval-logloss:0.303363\n",
      "[2200]\ttrain-logloss:0.220071\tval-logloss:0.303493\n",
      "Stopping. Best iteration:\n",
      "[2147]\ttrain-logloss:0.224299\tval-logloss:0.302189\n",
      "\n",
      "Fold: 71\n",
      "[0]\ttrain-logloss:0.692564\tval-logloss:0.692414\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639014\tval-logloss:0.630152\n",
      "[200]\ttrain-logloss:0.592626\tval-logloss:0.582039\n",
      "[300]\ttrain-logloss:0.552196\tval-logloss:0.540595\n",
      "[400]\ttrain-logloss:0.516306\tval-logloss:0.504889\n",
      "[500]\ttrain-logloss:0.484201\tval-logloss:0.472552\n",
      "[600]\ttrain-logloss:0.455323\tval-logloss:0.446383\n",
      "[700]\ttrain-logloss:0.429287\tval-logloss:0.423722\n",
      "[800]\ttrain-logloss:0.405559\tval-logloss:0.402837\n",
      "[900]\ttrain-logloss:0.384117\tval-logloss:0.384922\n",
      "[1000]\ttrain-logloss:0.364632\tval-logloss:0.36798\n",
      "[1100]\ttrain-logloss:0.346821\tval-logloss:0.351599\n",
      "[1200]\ttrain-logloss:0.330544\tval-logloss:0.336457\n",
      "[1300]\ttrain-logloss:0.315585\tval-logloss:0.323618\n",
      "[1400]\ttrain-logloss:0.301765\tval-logloss:0.311828\n",
      "[1500]\ttrain-logloss:0.288857\tval-logloss:0.2995\n",
      "[1600]\ttrain-logloss:0.276844\tval-logloss:0.287816\n",
      "[1700]\ttrain-logloss:0.265642\tval-logloss:0.278567\n",
      "[1800]\ttrain-logloss:0.255257\tval-logloss:0.270304\n",
      "[1900]\ttrain-logloss:0.245546\tval-logloss:0.263469\n",
      "[2000]\ttrain-logloss:0.23639\tval-logloss:0.257745\n",
      "[2100]\ttrain-logloss:0.227641\tval-logloss:0.253151\n",
      "[2200]\ttrain-logloss:0.219456\tval-logloss:0.249221\n",
      "[2300]\ttrain-logloss:0.211904\tval-logloss:0.247464\n",
      "[2400]\ttrain-logloss:0.204666\tval-logloss:0.245581\n",
      "[2500]\ttrain-logloss:0.197885\tval-logloss:0.243944\n",
      "[2600]\ttrain-logloss:0.191516\tval-logloss:0.241623\n",
      "[2700]\ttrain-logloss:0.185571\tval-logloss:0.240567\n",
      "[2800]\ttrain-logloss:0.179935\tval-logloss:0.239339\n",
      "[2900]\ttrain-logloss:0.17466\tval-logloss:0.238462\n",
      "[3000]\ttrain-logloss:0.169639\tval-logloss:0.237628\n",
      "[3100]\ttrain-logloss:0.164934\tval-logloss:0.236061\n",
      "[3200]\ttrain-logloss:0.160441\tval-logloss:0.235371\n",
      "[3300]\ttrain-logloss:0.156171\tval-logloss:0.234765\n",
      "[3400]\ttrain-logloss:0.152136\tval-logloss:0.234628\n",
      "[3500]\ttrain-logloss:0.148236\tval-logloss:0.234406\n",
      "[3600]\ttrain-logloss:0.144528\tval-logloss:0.233442\n",
      "[3700]\ttrain-logloss:0.140947\tval-logloss:0.232921\n",
      "[3800]\ttrain-logloss:0.137562\tval-logloss:0.232606\n",
      "Stopping. Best iteration:\n",
      "[3761]\ttrain-logloss:0.138876\tval-logloss:0.232502\n",
      "\n",
      "Fold: 72\n",
      "[0]\ttrain-logloss:0.692555\tval-logloss:0.692751\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.6387\tval-logloss:0.651876\n",
      "[200]\ttrain-logloss:0.592104\tval-logloss:0.616747\n",
      "[300]\ttrain-logloss:0.551559\tval-logloss:0.587975\n",
      "[400]\ttrain-logloss:0.515342\tval-logloss:0.563335\n",
      "[500]\ttrain-logloss:0.483109\tval-logloss:0.541883\n",
      "[600]\ttrain-logloss:0.454102\tval-logloss:0.523642\n",
      "[700]\ttrain-logloss:0.428085\tval-logloss:0.509042\n",
      "[800]\ttrain-logloss:0.404428\tval-logloss:0.496217\n",
      "[900]\ttrain-logloss:0.382903\tval-logloss:0.486309\n",
      "[1000]\ttrain-logloss:0.363253\tval-logloss:0.479823\n",
      "[1100]\ttrain-logloss:0.345254\tval-logloss:0.473973\n",
      "[1200]\ttrain-logloss:0.328864\tval-logloss:0.469359\n",
      "[1300]\ttrain-logloss:0.313907\tval-logloss:0.465322\n",
      "[1400]\ttrain-logloss:0.300071\tval-logloss:0.462274\n",
      "[1500]\ttrain-logloss:0.287338\tval-logloss:0.460608\n",
      "[1600]\ttrain-logloss:0.275477\tval-logloss:0.460774\n",
      "Stopping. Best iteration:\n",
      "[1525]\ttrain-logloss:0.28431\tval-logloss:0.46029\n",
      "\n",
      "Fold: 73\n",
      "[0]\ttrain-logloss:0.692549\tval-logloss:0.692667\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638627\tval-logloss:0.64835\n",
      "[200]\ttrain-logloss:0.591878\tval-logloss:0.612551\n",
      "[300]\ttrain-logloss:0.551247\tval-logloss:0.583208\n",
      "[400]\ttrain-logloss:0.515164\tval-logloss:0.558284\n",
      "[500]\ttrain-logloss:0.482971\tval-logloss:0.537717\n",
      "[600]\ttrain-logloss:0.454242\tval-logloss:0.521815\n",
      "[700]\ttrain-logloss:0.428389\tval-logloss:0.508806\n",
      "[800]\ttrain-logloss:0.404878\tval-logloss:0.497925\n",
      "[900]\ttrain-logloss:0.383502\tval-logloss:0.48956\n",
      "[1000]\ttrain-logloss:0.363977\tval-logloss:0.485393\n",
      "[1100]\ttrain-logloss:0.34624\tval-logloss:0.480037\n",
      "[1200]\ttrain-logloss:0.329977\tval-logloss:0.475776\n",
      "[1300]\ttrain-logloss:0.315028\tval-logloss:0.471956\n",
      "[1400]\ttrain-logloss:0.301148\tval-logloss:0.4693\n",
      "[1500]\ttrain-logloss:0.288333\tval-logloss:0.466667\n",
      "[1600]\ttrain-logloss:0.276425\tval-logloss:0.466085\n",
      "[1700]\ttrain-logloss:0.265423\tval-logloss:0.463295\n",
      "[1800]\ttrain-logloss:0.255053\tval-logloss:0.463254\n",
      "Stopping. Best iteration:\n",
      "[1759]\ttrain-logloss:0.259226\tval-logloss:0.462295\n",
      "\n",
      "Fold: 74\n",
      "[0]\ttrain-logloss:0.692554\tval-logloss:0.692528\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.6388\tval-logloss:0.641136\n",
      "[200]\ttrain-logloss:0.592337\tval-logloss:0.59717\n",
      "[300]\ttrain-logloss:0.551965\tval-logloss:0.562388\n",
      "[400]\ttrain-logloss:0.516093\tval-logloss:0.535052\n",
      "[500]\ttrain-logloss:0.483962\tval-logloss:0.508716\n",
      "[600]\ttrain-logloss:0.455095\tval-logloss:0.484254\n",
      "[700]\ttrain-logloss:0.42898\tval-logloss:0.461098\n",
      "[800]\ttrain-logloss:0.405293\tval-logloss:0.442984\n",
      "[900]\ttrain-logloss:0.38388\tval-logloss:0.427316\n",
      "[1000]\ttrain-logloss:0.364455\tval-logloss:0.413837\n",
      "[1100]\ttrain-logloss:0.346724\tval-logloss:0.402712\n",
      "[1200]\ttrain-logloss:0.330429\tval-logloss:0.393772\n",
      "[1300]\ttrain-logloss:0.31551\tval-logloss:0.386525\n",
      "[1400]\ttrain-logloss:0.30168\tval-logloss:0.381199\n",
      "[1500]\ttrain-logloss:0.288832\tval-logloss:0.375619\n",
      "[1600]\ttrain-logloss:0.276821\tval-logloss:0.372129\n",
      "[1700]\ttrain-logloss:0.26562\tval-logloss:0.369119\n",
      "[1800]\ttrain-logloss:0.255268\tval-logloss:0.365481\n",
      "[1900]\ttrain-logloss:0.245669\tval-logloss:0.363842\n",
      "[2000]\ttrain-logloss:0.236325\tval-logloss:0.357664\n",
      "[2100]\ttrain-logloss:0.227638\tval-logloss:0.351172\n",
      "[2200]\ttrain-logloss:0.219546\tval-logloss:0.346111\n",
      "[2300]\ttrain-logloss:0.211919\tval-logloss:0.342121\n",
      "[2400]\ttrain-logloss:0.204661\tval-logloss:0.338758\n",
      "[2500]\ttrain-logloss:0.197861\tval-logloss:0.33626\n",
      "[2600]\ttrain-logloss:0.191409\tval-logloss:0.334321\n",
      "[2700]\ttrain-logloss:0.185404\tval-logloss:0.331524\n",
      "[2800]\ttrain-logloss:0.179734\tval-logloss:0.328457\n",
      "[2900]\ttrain-logloss:0.174374\tval-logloss:0.325897\n",
      "[3000]\ttrain-logloss:0.169314\tval-logloss:0.324643\n",
      "[3100]\ttrain-logloss:0.164564\tval-logloss:0.323304\n",
      "[3200]\ttrain-logloss:0.160035\tval-logloss:0.321459\n",
      "[3300]\ttrain-logloss:0.155744\tval-logloss:0.319016\n",
      "[3400]\ttrain-logloss:0.15169\tval-logloss:0.31779\n",
      "[3500]\ttrain-logloss:0.147784\tval-logloss:0.316775\n",
      "[3600]\ttrain-logloss:0.1441\tval-logloss:0.31631\n",
      "[3700]\ttrain-logloss:0.140577\tval-logloss:0.314899\n",
      "[3800]\ttrain-logloss:0.137176\tval-logloss:0.313541\n",
      "[3900]\ttrain-logloss:0.133894\tval-logloss:0.313228\n",
      "Stopping. Best iteration:\n",
      "[3893]\ttrain-logloss:0.134125\tval-logloss:0.312925\n",
      "\n",
      "Fold: 75\n",
      "[0]\ttrain-logloss:0.692548\tval-logloss:0.692854\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638776\tval-logloss:0.66231\n",
      "[200]\ttrain-logloss:0.59216\tval-logloss:0.637839\n",
      "[300]\ttrain-logloss:0.551508\tval-logloss:0.619378\n",
      "[400]\ttrain-logloss:0.515347\tval-logloss:0.602731\n",
      "[500]\ttrain-logloss:0.483048\tval-logloss:0.587997\n",
      "[600]\ttrain-logloss:0.453932\tval-logloss:0.577341\n",
      "[700]\ttrain-logloss:0.427632\tval-logloss:0.567034\n",
      "[800]\ttrain-logloss:0.403829\tval-logloss:0.560657\n",
      "[900]\ttrain-logloss:0.38236\tval-logloss:0.55535\n",
      "[1000]\ttrain-logloss:0.362828\tval-logloss:0.552952\n",
      "[1100]\ttrain-logloss:0.345113\tval-logloss:0.550516\n",
      "[1200]\ttrain-logloss:0.328909\tval-logloss:0.548642\n",
      "[1300]\ttrain-logloss:0.313947\tval-logloss:0.546196\n",
      "[1400]\ttrain-logloss:0.30009\tval-logloss:0.542783\n",
      "[1500]\ttrain-logloss:0.28714\tval-logloss:0.540229\n",
      "[1600]\ttrain-logloss:0.27524\tval-logloss:0.536936\n",
      "[1700]\ttrain-logloss:0.264098\tval-logloss:0.535455\n",
      "[1800]\ttrain-logloss:0.253685\tval-logloss:0.536781\n",
      "Stopping. Best iteration:\n",
      "[1721]\ttrain-logloss:0.261855\tval-logloss:0.53485\n",
      "\n",
      "Fold: 76\n",
      "[0]\ttrain-logloss:0.692564\tval-logloss:0.692519\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638992\tval-logloss:0.639635\n",
      "[200]\ttrain-logloss:0.592496\tval-logloss:0.593419\n",
      "[300]\ttrain-logloss:0.551922\tval-logloss:0.556346\n",
      "[400]\ttrain-logloss:0.515828\tval-logloss:0.523346\n",
      "[500]\ttrain-logloss:0.483649\tval-logloss:0.495992\n",
      "[600]\ttrain-logloss:0.454837\tval-logloss:0.474834\n",
      "[700]\ttrain-logloss:0.428793\tval-logloss:0.457526\n",
      "[800]\ttrain-logloss:0.4052\tval-logloss:0.446982\n",
      "[900]\ttrain-logloss:0.383881\tval-logloss:0.435669\n",
      "[1000]\ttrain-logloss:0.364503\tval-logloss:0.426581\n",
      "[1100]\ttrain-logloss:0.346797\tval-logloss:0.420199\n",
      "[1200]\ttrain-logloss:0.33062\tval-logloss:0.413868\n",
      "[1300]\ttrain-logloss:0.315498\tval-logloss:0.409116\n",
      "[1400]\ttrain-logloss:0.301522\tval-logloss:0.405314\n",
      "[1500]\ttrain-logloss:0.28856\tval-logloss:0.401179\n",
      "[1600]\ttrain-logloss:0.276488\tval-logloss:0.397977\n",
      "[1700]\ttrain-logloss:0.265281\tval-logloss:0.395934\n",
      "[1800]\ttrain-logloss:0.254844\tval-logloss:0.392826\n",
      "[1900]\ttrain-logloss:0.244944\tval-logloss:0.383803\n",
      "[2000]\ttrain-logloss:0.235759\tval-logloss:0.375761\n",
      "[2100]\ttrain-logloss:0.227167\tval-logloss:0.371857\n",
      "[2200]\ttrain-logloss:0.218937\tval-logloss:0.36908\n",
      "[2300]\ttrain-logloss:0.211269\tval-logloss:0.36682\n",
      "[2400]\ttrain-logloss:0.204118\tval-logloss:0.362607\n",
      "[2500]\ttrain-logloss:0.197358\tval-logloss:0.35889\n",
      "[2600]\ttrain-logloss:0.191038\tval-logloss:0.357447\n",
      "[2700]\ttrain-logloss:0.185075\tval-logloss:0.355968\n",
      "[2800]\ttrain-logloss:0.179471\tval-logloss:0.354107\n",
      "[2900]\ttrain-logloss:0.174211\tval-logloss:0.351045\n",
      "[3000]\ttrain-logloss:0.169227\tval-logloss:0.346551\n",
      "[3100]\ttrain-logloss:0.164535\tval-logloss:0.343587\n",
      "[3200]\ttrain-logloss:0.160096\tval-logloss:0.341494\n",
      "[3300]\ttrain-logloss:0.155851\tval-logloss:0.338616\n",
      "[3400]\ttrain-logloss:0.151866\tval-logloss:0.335789\n",
      "[3500]\ttrain-logloss:0.148049\tval-logloss:0.334582\n",
      "[3600]\ttrain-logloss:0.144376\tval-logloss:0.33298\n",
      "[3700]\ttrain-logloss:0.140815\tval-logloss:0.332139\n",
      "[3800]\ttrain-logloss:0.137395\tval-logloss:0.331459\n",
      "[3900]\ttrain-logloss:0.134105\tval-logloss:0.330904\n",
      "Stopping. Best iteration:\n",
      "[3871]\ttrain-logloss:0.135049\tval-logloss:0.330426\n",
      "\n",
      "Fold: 77\n",
      "[0]\ttrain-logloss:0.692566\tval-logloss:0.692598\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638964\tval-logloss:0.646444\n",
      "[200]\ttrain-logloss:0.592367\tval-logloss:0.608996\n",
      "[300]\ttrain-logloss:0.551682\tval-logloss:0.576815\n",
      "[400]\ttrain-logloss:0.515471\tval-logloss:0.549024\n",
      "[500]\ttrain-logloss:0.483167\tval-logloss:0.524994\n",
      "[600]\ttrain-logloss:0.454307\tval-logloss:0.502985\n",
      "[700]\ttrain-logloss:0.428222\tval-logloss:0.480139\n",
      "[800]\ttrain-logloss:0.404598\tval-logloss:0.459508\n",
      "[900]\ttrain-logloss:0.383128\tval-logloss:0.44469\n",
      "[1000]\ttrain-logloss:0.363715\tval-logloss:0.430178\n",
      "[1100]\ttrain-logloss:0.34613\tval-logloss:0.417617\n",
      "[1200]\ttrain-logloss:0.329991\tval-logloss:0.406682\n",
      "[1300]\ttrain-logloss:0.315064\tval-logloss:0.396832\n",
      "[1400]\ttrain-logloss:0.30106\tval-logloss:0.388274\n",
      "[1500]\ttrain-logloss:0.288012\tval-logloss:0.381707\n",
      "[1600]\ttrain-logloss:0.276139\tval-logloss:0.376566\n",
      "[1700]\ttrain-logloss:0.264979\tval-logloss:0.371342\n",
      "[1800]\ttrain-logloss:0.254536\tval-logloss:0.367667\n",
      "[1900]\ttrain-logloss:0.244826\tval-logloss:0.364721\n",
      "[2000]\ttrain-logloss:0.235638\tval-logloss:0.361603\n",
      "[2100]\ttrain-logloss:0.226908\tval-logloss:0.357751\n",
      "[2200]\ttrain-logloss:0.218706\tval-logloss:0.354694\n",
      "[2300]\ttrain-logloss:0.211019\tval-logloss:0.349951\n",
      "[2400]\ttrain-logloss:0.203812\tval-logloss:0.34472\n",
      "[2500]\ttrain-logloss:0.196983\tval-logloss:0.341073\n",
      "[2600]\ttrain-logloss:0.190663\tval-logloss:0.337834\n",
      "[2700]\ttrain-logloss:0.184764\tval-logloss:0.334966\n",
      "[2800]\ttrain-logloss:0.179112\tval-logloss:0.332505\n",
      "[2900]\ttrain-logloss:0.173813\tval-logloss:0.329692\n",
      "[3000]\ttrain-logloss:0.168827\tval-logloss:0.327428\n",
      "[3100]\ttrain-logloss:0.164148\tval-logloss:0.324839\n",
      "[3200]\ttrain-logloss:0.15966\tval-logloss:0.322369\n",
      "[3300]\ttrain-logloss:0.155404\tval-logloss:0.319852\n",
      "[3400]\ttrain-logloss:0.151381\tval-logloss:0.318155\n",
      "[3500]\ttrain-logloss:0.147552\tval-logloss:0.316307\n",
      "[3600]\ttrain-logloss:0.143889\tval-logloss:0.314803\n",
      "[3700]\ttrain-logloss:0.140318\tval-logloss:0.312708\n",
      "[3800]\ttrain-logloss:0.13688\tval-logloss:0.310954\n",
      "[3900]\ttrain-logloss:0.13358\tval-logloss:0.310452\n",
      "[4000]\ttrain-logloss:0.130425\tval-logloss:0.309948\n",
      "Stopping. Best iteration:\n",
      "[3961]\ttrain-logloss:0.131628\tval-logloss:0.309643\n",
      "\n",
      "Fold: 78\n",
      "[0]\ttrain-logloss:0.692542\tval-logloss:0.692826\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638569\tval-logloss:0.658427\n",
      "[200]\ttrain-logloss:0.591922\tval-logloss:0.628204\n",
      "[300]\ttrain-logloss:0.551286\tval-logloss:0.604352\n",
      "[400]\ttrain-logloss:0.515169\tval-logloss:0.585785\n",
      "[500]\ttrain-logloss:0.48297\tval-logloss:0.566432\n",
      "[600]\ttrain-logloss:0.454051\tval-logloss:0.54798\n",
      "[700]\ttrain-logloss:0.427889\tval-logloss:0.534438\n",
      "[800]\ttrain-logloss:0.404179\tval-logloss:0.522182\n",
      "[900]\ttrain-logloss:0.382659\tval-logloss:0.514571\n",
      "[1000]\ttrain-logloss:0.363042\tval-logloss:0.509656\n",
      "[1100]\ttrain-logloss:0.34532\tval-logloss:0.505011\n",
      "[1200]\ttrain-logloss:0.329079\tval-logloss:0.501724\n",
      "[1300]\ttrain-logloss:0.314223\tval-logloss:0.499028\n",
      "[1400]\ttrain-logloss:0.300475\tval-logloss:0.495178\n",
      "[1500]\ttrain-logloss:0.287792\tval-logloss:0.491605\n",
      "[1600]\ttrain-logloss:0.275918\tval-logloss:0.488541\n",
      "[1700]\ttrain-logloss:0.264833\tval-logloss:0.485675\n",
      "[1800]\ttrain-logloss:0.254611\tval-logloss:0.482893\n",
      "[1900]\ttrain-logloss:0.245012\tval-logloss:0.480924\n",
      "Stopping. Best iteration:\n",
      "[1893]\ttrain-logloss:0.245665\tval-logloss:0.480792\n",
      "\n",
      "Fold: 79\n",
      "[0]\ttrain-logloss:0.692564\tval-logloss:0.692829\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638779\tval-logloss:0.662789\n",
      "[200]\ttrain-logloss:0.592057\tval-logloss:0.635418\n",
      "[300]\ttrain-logloss:0.551537\tval-logloss:0.607349\n",
      "[400]\ttrain-logloss:0.515375\tval-logloss:0.582508\n",
      "[500]\ttrain-logloss:0.483107\tval-logloss:0.556552\n",
      "[600]\ttrain-logloss:0.454281\tval-logloss:0.533923\n",
      "[700]\ttrain-logloss:0.428193\tval-logloss:0.513859\n",
      "[800]\ttrain-logloss:0.404654\tval-logloss:0.497541\n",
      "[900]\ttrain-logloss:0.383227\tval-logloss:0.482665\n",
      "[1000]\ttrain-logloss:0.363782\tval-logloss:0.47049\n",
      "[1100]\ttrain-logloss:0.34601\tval-logloss:0.459569\n",
      "[1200]\ttrain-logloss:0.329784\tval-logloss:0.446884\n",
      "[1300]\ttrain-logloss:0.31488\tval-logloss:0.436498\n",
      "[1400]\ttrain-logloss:0.301183\tval-logloss:0.424745\n",
      "[1500]\ttrain-logloss:0.288434\tval-logloss:0.41353\n",
      "[1600]\ttrain-logloss:0.27655\tval-logloss:0.401237\n",
      "[1700]\ttrain-logloss:0.265532\tval-logloss:0.390023\n",
      "[1800]\ttrain-logloss:0.255267\tval-logloss:0.379372\n",
      "[1900]\ttrain-logloss:0.245383\tval-logloss:0.372678\n",
      "[2000]\ttrain-logloss:0.23601\tval-logloss:0.369371\n",
      "[2100]\ttrain-logloss:0.227321\tval-logloss:0.364317\n",
      "[2200]\ttrain-logloss:0.219229\tval-logloss:0.359943\n",
      "[2300]\ttrain-logloss:0.211566\tval-logloss:0.356649\n",
      "[2400]\ttrain-logloss:0.204311\tval-logloss:0.352391\n",
      "[2500]\ttrain-logloss:0.19752\tval-logloss:0.347825\n",
      "[2600]\ttrain-logloss:0.191185\tval-logloss:0.343833\n",
      "[2700]\ttrain-logloss:0.185248\tval-logloss:0.339986\n",
      "[2800]\ttrain-logloss:0.179592\tval-logloss:0.336737\n",
      "[2900]\ttrain-logloss:0.174242\tval-logloss:0.333483\n",
      "[3000]\ttrain-logloss:0.169221\tval-logloss:0.330177\n",
      "[3100]\ttrain-logloss:0.1645\tval-logloss:0.32735\n",
      "[3200]\ttrain-logloss:0.159995\tval-logloss:0.32438\n",
      "[3300]\ttrain-logloss:0.15571\tval-logloss:0.322094\n",
      "[3400]\ttrain-logloss:0.151643\tval-logloss:0.321186\n",
      "[3500]\ttrain-logloss:0.147781\tval-logloss:0.319116\n",
      "[3600]\ttrain-logloss:0.144097\tval-logloss:0.316143\n",
      "[3700]\ttrain-logloss:0.140542\tval-logloss:0.312463\n",
      "[3800]\ttrain-logloss:0.13705\tval-logloss:0.31024\n",
      "[3900]\ttrain-logloss:0.133712\tval-logloss:0.30725\n",
      "[4000]\ttrain-logloss:0.130569\tval-logloss:0.305424\n",
      "[4100]\ttrain-logloss:0.12758\tval-logloss:0.303617\n",
      "[4200]\ttrain-logloss:0.124734\tval-logloss:0.302608\n",
      "[4300]\ttrain-logloss:0.122055\tval-logloss:0.30138\n",
      "[4400]\ttrain-logloss:0.119493\tval-logloss:0.300858\n",
      "[4500]\ttrain-logloss:0.116921\tval-logloss:0.298796\n",
      "[4600]\ttrain-logloss:0.114529\tval-logloss:0.294967\n",
      "[4700]\ttrain-logloss:0.112209\tval-logloss:0.291422\n",
      "[4800]\ttrain-logloss:0.109988\tval-logloss:0.289426\n",
      "[4900]\ttrain-logloss:0.107901\tval-logloss:0.288316\n",
      "[4999]\ttrain-logloss:0.105926\tval-logloss:0.286475\n",
      "Fold: 80\n",
      "[0]\ttrain-logloss:0.692553\tval-logloss:0.69251\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.6389\tval-logloss:0.639226\n",
      "[200]\ttrain-logloss:0.592487\tval-logloss:0.595122\n",
      "[300]\ttrain-logloss:0.552026\tval-logloss:0.559389\n",
      "[400]\ttrain-logloss:0.516163\tval-logloss:0.527563\n",
      "[500]\ttrain-logloss:0.484066\tval-logloss:0.497834\n",
      "[600]\ttrain-logloss:0.455265\tval-logloss:0.474555\n",
      "[700]\ttrain-logloss:0.42931\tval-logloss:0.453072\n",
      "[800]\ttrain-logloss:0.405668\tval-logloss:0.433592\n",
      "[900]\ttrain-logloss:0.384118\tval-logloss:0.416475\n",
      "[1000]\ttrain-logloss:0.364452\tval-logloss:0.400219\n",
      "[1100]\ttrain-logloss:0.34653\tval-logloss:0.386771\n",
      "[1200]\ttrain-logloss:0.330266\tval-logloss:0.376034\n",
      "[1300]\ttrain-logloss:0.315332\tval-logloss:0.367263\n",
      "[1400]\ttrain-logloss:0.30163\tval-logloss:0.359397\n",
      "[1500]\ttrain-logloss:0.288782\tval-logloss:0.352831\n",
      "[1600]\ttrain-logloss:0.276817\tval-logloss:0.346164\n",
      "[1700]\ttrain-logloss:0.265759\tval-logloss:0.340223\n",
      "[1800]\ttrain-logloss:0.255478\tval-logloss:0.334464\n",
      "[1900]\ttrain-logloss:0.24584\tval-logloss:0.328983\n",
      "[2000]\ttrain-logloss:0.236692\tval-logloss:0.324652\n",
      "[2100]\ttrain-logloss:0.228108\tval-logloss:0.320997\n",
      "[2200]\ttrain-logloss:0.219951\tval-logloss:0.320788\n",
      "[2300]\ttrain-logloss:0.212344\tval-logloss:0.318255\n",
      "[2400]\ttrain-logloss:0.205103\tval-logloss:0.312269\n",
      "[2500]\ttrain-logloss:0.198284\tval-logloss:0.304994\n",
      "[2600]\ttrain-logloss:0.191895\tval-logloss:0.299962\n",
      "[2700]\ttrain-logloss:0.185918\tval-logloss:0.296025\n",
      "[2800]\ttrain-logloss:0.180212\tval-logloss:0.291681\n",
      "[2900]\ttrain-logloss:0.174865\tval-logloss:0.288317\n",
      "[3000]\ttrain-logloss:0.16984\tval-logloss:0.285862\n",
      "[3100]\ttrain-logloss:0.165084\tval-logloss:0.282965\n",
      "[3200]\ttrain-logloss:0.160616\tval-logloss:0.279984\n",
      "[3300]\ttrain-logloss:0.156354\tval-logloss:0.277822\n",
      "[3400]\ttrain-logloss:0.152314\tval-logloss:0.275496\n",
      "[3500]\ttrain-logloss:0.148459\tval-logloss:0.272124\n",
      "[3600]\ttrain-logloss:0.144795\tval-logloss:0.269537\n",
      "[3700]\ttrain-logloss:0.141266\tval-logloss:0.266967\n",
      "[3800]\ttrain-logloss:0.137807\tval-logloss:0.264419\n",
      "[3900]\ttrain-logloss:0.13452\tval-logloss:0.260897\n",
      "[4000]\ttrain-logloss:0.13138\tval-logloss:0.258542\n",
      "[4100]\ttrain-logloss:0.128403\tval-logloss:0.256323\n",
      "[4200]\ttrain-logloss:0.125538\tval-logloss:0.25411\n",
      "[4300]\ttrain-logloss:0.122841\tval-logloss:0.252485\n",
      "[4400]\ttrain-logloss:0.120265\tval-logloss:0.250696\n",
      "[4500]\ttrain-logloss:0.117725\tval-logloss:0.247023\n",
      "[4600]\ttrain-logloss:0.11533\tval-logloss:0.243005\n",
      "[4700]\ttrain-logloss:0.11304\tval-logloss:0.239237\n",
      "[4800]\ttrain-logloss:0.110863\tval-logloss:0.235847\n",
      "[4900]\ttrain-logloss:0.108729\tval-logloss:0.232721\n",
      "[4999]\ttrain-logloss:0.106655\tval-logloss:0.228943\n",
      "Fold: 81\n",
      "[0]\ttrain-logloss:0.692564\tval-logloss:0.69252\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638851\tval-logloss:0.632479\n",
      "[200]\ttrain-logloss:0.592337\tval-logloss:0.582114\n",
      "[300]\ttrain-logloss:0.551909\tval-logloss:0.542903\n",
      "[400]\ttrain-logloss:0.515944\tval-logloss:0.509742\n",
      "[500]\ttrain-logloss:0.483754\tval-logloss:0.480748\n",
      "[600]\ttrain-logloss:0.45478\tval-logloss:0.453702\n",
      "[700]\ttrain-logloss:0.428746\tval-logloss:0.430049\n",
      "[800]\ttrain-logloss:0.40515\tval-logloss:0.409288\n",
      "[900]\ttrain-logloss:0.383753\tval-logloss:0.391734\n",
      "[1000]\ttrain-logloss:0.364307\tval-logloss:0.374223\n",
      "[1100]\ttrain-logloss:0.346597\tval-logloss:0.35635\n",
      "[1200]\ttrain-logloss:0.330302\tval-logloss:0.344438\n",
      "[1300]\ttrain-logloss:0.315357\tval-logloss:0.334111\n",
      "[1400]\ttrain-logloss:0.301518\tval-logloss:0.325466\n",
      "[1500]\ttrain-logloss:0.288683\tval-logloss:0.316962\n",
      "[1600]\ttrain-logloss:0.276748\tval-logloss:0.309797\n",
      "[1700]\ttrain-logloss:0.265655\tval-logloss:0.303729\n",
      "[1800]\ttrain-logloss:0.255305\tval-logloss:0.29775\n",
      "[1900]\ttrain-logloss:0.24564\tval-logloss:0.293259\n",
      "[2000]\ttrain-logloss:0.236511\tval-logloss:0.289079\n",
      "[2100]\ttrain-logloss:0.227787\tval-logloss:0.284292\n",
      "[2200]\ttrain-logloss:0.219556\tval-logloss:0.282605\n",
      "[2300]\ttrain-logloss:0.211915\tval-logloss:0.281963\n",
      "[2400]\ttrain-logloss:0.204715\tval-logloss:0.280215\n",
      "[2500]\ttrain-logloss:0.197869\tval-logloss:0.277969\n",
      "[2600]\ttrain-logloss:0.191451\tval-logloss:0.274956\n",
      "[2700]\ttrain-logloss:0.185491\tval-logloss:0.272065\n",
      "[2800]\ttrain-logloss:0.17986\tval-logloss:0.267936\n",
      "[2900]\ttrain-logloss:0.174555\tval-logloss:0.265764\n",
      "[3000]\ttrain-logloss:0.169538\tval-logloss:0.262776\n",
      "[3100]\ttrain-logloss:0.164844\tval-logloss:0.259763\n",
      "[3200]\ttrain-logloss:0.160385\tval-logloss:0.258068\n",
      "[3300]\ttrain-logloss:0.156133\tval-logloss:0.254936\n",
      "[3400]\ttrain-logloss:0.152109\tval-logloss:0.252196\n",
      "[3500]\ttrain-logloss:0.148266\tval-logloss:0.250324\n",
      "[3600]\ttrain-logloss:0.144586\tval-logloss:0.249221\n",
      "[3700]\ttrain-logloss:0.140988\tval-logloss:0.248521\n",
      "[3800]\ttrain-logloss:0.137574\tval-logloss:0.247061\n",
      "[3900]\ttrain-logloss:0.134281\tval-logloss:0.24605\n",
      "[4000]\ttrain-logloss:0.131139\tval-logloss:0.244949\n",
      "[4100]\ttrain-logloss:0.128136\tval-logloss:0.243981\n",
      "Stopping. Best iteration:\n",
      "[4080]\ttrain-logloss:0.128726\tval-logloss:0.243779\n",
      "\n",
      "Fold: 82\n",
      "[0]\ttrain-logloss:0.692551\tval-logloss:0.692619\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638875\tval-logloss:0.644074\n",
      "[200]\ttrain-logloss:0.592451\tval-logloss:0.602583\n",
      "[300]\ttrain-logloss:0.551944\tval-logloss:0.567132\n",
      "[400]\ttrain-logloss:0.515864\tval-logloss:0.535813\n",
      "[500]\ttrain-logloss:0.483614\tval-logloss:0.508591\n",
      "[600]\ttrain-logloss:0.454744\tval-logloss:0.484435\n",
      "[700]\ttrain-logloss:0.428624\tval-logloss:0.46463\n",
      "[800]\ttrain-logloss:0.405089\tval-logloss:0.448843\n",
      "[900]\ttrain-logloss:0.383685\tval-logloss:0.435362\n",
      "[1000]\ttrain-logloss:0.364319\tval-logloss:0.424226\n",
      "[1100]\ttrain-logloss:0.346701\tval-logloss:0.415703\n",
      "[1200]\ttrain-logloss:0.330499\tval-logloss:0.408353\n",
      "[1300]\ttrain-logloss:0.315549\tval-logloss:0.402229\n",
      "[1400]\ttrain-logloss:0.301681\tval-logloss:0.399783\n",
      "[1500]\ttrain-logloss:0.288874\tval-logloss:0.396267\n",
      "[1600]\ttrain-logloss:0.276984\tval-logloss:0.392867\n",
      "[1700]\ttrain-logloss:0.26588\tval-logloss:0.389376\n",
      "[1800]\ttrain-logloss:0.255532\tval-logloss:0.38472\n",
      "[1900]\ttrain-logloss:0.245718\tval-logloss:0.382875\n",
      "[2000]\ttrain-logloss:0.236577\tval-logloss:0.380936\n",
      "[2100]\ttrain-logloss:0.228058\tval-logloss:0.38098\n",
      "[2200]\ttrain-logloss:0.21983\tval-logloss:0.378874\n",
      "[2300]\ttrain-logloss:0.212195\tval-logloss:0.377761\n",
      "[2400]\ttrain-logloss:0.205053\tval-logloss:0.377622\n",
      "Stopping. Best iteration:\n",
      "[2320]\ttrain-logloss:0.210726\tval-logloss:0.37711\n",
      "\n",
      "Fold: 83\n",
      "[0]\ttrain-logloss:0.692557\tval-logloss:0.692488\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638812\tval-logloss:0.644268\n",
      "[200]\ttrain-logloss:0.592372\tval-logloss:0.60338\n",
      "[300]\ttrain-logloss:0.55183\tval-logloss:0.568585\n",
      "[400]\ttrain-logloss:0.515714\tval-logloss:0.537427\n",
      "[500]\ttrain-logloss:0.483513\tval-logloss:0.509985\n",
      "[600]\ttrain-logloss:0.45458\tval-logloss:0.485257\n",
      "[700]\ttrain-logloss:0.428527\tval-logloss:0.464105\n",
      "[800]\ttrain-logloss:0.404917\tval-logloss:0.44393\n",
      "[900]\ttrain-logloss:0.383358\tval-logloss:0.425583\n",
      "[1000]\ttrain-logloss:0.363908\tval-logloss:0.409641\n",
      "[1100]\ttrain-logloss:0.34633\tval-logloss:0.393857\n",
      "[1200]\ttrain-logloss:0.330186\tval-logloss:0.381696\n",
      "[1300]\ttrain-logloss:0.315399\tval-logloss:0.372436\n",
      "[1400]\ttrain-logloss:0.301663\tval-logloss:0.364411\n",
      "[1500]\ttrain-logloss:0.2889\tval-logloss:0.356474\n",
      "[1600]\ttrain-logloss:0.27695\tval-logloss:0.348199\n",
      "[1700]\ttrain-logloss:0.265929\tval-logloss:0.339852\n",
      "[1800]\ttrain-logloss:0.255658\tval-logloss:0.333442\n",
      "[1900]\ttrain-logloss:0.246042\tval-logloss:0.32866\n",
      "[2000]\ttrain-logloss:0.236837\tval-logloss:0.325204\n",
      "[2100]\ttrain-logloss:0.228262\tval-logloss:0.322336\n",
      "[2200]\ttrain-logloss:0.220241\tval-logloss:0.320642\n",
      "[2300]\ttrain-logloss:0.212569\tval-logloss:0.31783\n",
      "[2400]\ttrain-logloss:0.205209\tval-logloss:0.312246\n",
      "[2500]\ttrain-logloss:0.198385\tval-logloss:0.307029\n",
      "[2600]\ttrain-logloss:0.192039\tval-logloss:0.303626\n",
      "[2700]\ttrain-logloss:0.186048\tval-logloss:0.300719\n",
      "[2800]\ttrain-logloss:0.180365\tval-logloss:0.29958\n",
      "[2900]\ttrain-logloss:0.175022\tval-logloss:0.297105\n",
      "[3000]\ttrain-logloss:0.169965\tval-logloss:0.295974\n",
      "[3100]\ttrain-logloss:0.165225\tval-logloss:0.29546\n",
      "[3200]\ttrain-logloss:0.160713\tval-logloss:0.294235\n",
      "[3300]\ttrain-logloss:0.156442\tval-logloss:0.293487\n",
      "[3400]\ttrain-logloss:0.152375\tval-logloss:0.292892\n",
      "[3500]\ttrain-logloss:0.14849\tval-logloss:0.292512\n",
      "Stopping. Best iteration:\n",
      "[3429]\ttrain-logloss:0.151217\tval-logloss:0.292301\n",
      "\n",
      "Fold: 84\n",
      "[0]\ttrain-logloss:0.69256\tval-logloss:0.692693\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638947\tval-logloss:0.644639\n",
      "[200]\ttrain-logloss:0.592533\tval-logloss:0.604372\n",
      "[300]\ttrain-logloss:0.552073\tval-logloss:0.570398\n",
      "[400]\ttrain-logloss:0.516205\tval-logloss:0.542057\n",
      "[500]\ttrain-logloss:0.484101\tval-logloss:0.512778\n",
      "[600]\ttrain-logloss:0.455192\tval-logloss:0.4862\n",
      "[700]\ttrain-logloss:0.429037\tval-logloss:0.465893\n",
      "[800]\ttrain-logloss:0.40539\tval-logloss:0.445975\n",
      "[900]\ttrain-logloss:0.383969\tval-logloss:0.430865\n",
      "[1000]\ttrain-logloss:0.364478\tval-logloss:0.413738\n",
      "[1100]\ttrain-logloss:0.346702\tval-logloss:0.398225\n",
      "[1200]\ttrain-logloss:0.330563\tval-logloss:0.38469\n",
      "[1300]\ttrain-logloss:0.315656\tval-logloss:0.374551\n",
      "[1400]\ttrain-logloss:0.301866\tval-logloss:0.364372\n",
      "[1500]\ttrain-logloss:0.289078\tval-logloss:0.356321\n",
      "[1600]\ttrain-logloss:0.277181\tval-logloss:0.348636\n",
      "[1700]\ttrain-logloss:0.26611\tval-logloss:0.342389\n",
      "[1800]\ttrain-logloss:0.25578\tval-logloss:0.335641\n",
      "[1900]\ttrain-logloss:0.246131\tval-logloss:0.329389\n",
      "[2000]\ttrain-logloss:0.237049\tval-logloss:0.324218\n",
      "[2100]\ttrain-logloss:0.228287\tval-logloss:0.321084\n",
      "[2200]\ttrain-logloss:0.220115\tval-logloss:0.318517\n",
      "[2300]\ttrain-logloss:0.212491\tval-logloss:0.316354\n",
      "[2400]\ttrain-logloss:0.205281\tval-logloss:0.313194\n",
      "[2500]\ttrain-logloss:0.198499\tval-logloss:0.30846\n",
      "[2600]\ttrain-logloss:0.192141\tval-logloss:0.30376\n",
      "[2700]\ttrain-logloss:0.186161\tval-logloss:0.299238\n",
      "[2800]\ttrain-logloss:0.180465\tval-logloss:0.295951\n",
      "[2900]\ttrain-logloss:0.175121\tval-logloss:0.292131\n",
      "[3000]\ttrain-logloss:0.170088\tval-logloss:0.289222\n",
      "[3100]\ttrain-logloss:0.165298\tval-logloss:0.286158\n",
      "[3200]\ttrain-logloss:0.16076\tval-logloss:0.283066\n",
      "[3300]\ttrain-logloss:0.156473\tval-logloss:0.279667\n",
      "[3400]\ttrain-logloss:0.152401\tval-logloss:0.277913\n",
      "[3500]\ttrain-logloss:0.148512\tval-logloss:0.275634\n",
      "[3600]\ttrain-logloss:0.144817\tval-logloss:0.273291\n",
      "[3700]\ttrain-logloss:0.141255\tval-logloss:0.271138\n",
      "[3800]\ttrain-logloss:0.13782\tval-logloss:0.268921\n",
      "[3900]\ttrain-logloss:0.134515\tval-logloss:0.266639\n",
      "[4000]\ttrain-logloss:0.131354\tval-logloss:0.263763\n",
      "[4100]\ttrain-logloss:0.128333\tval-logloss:0.26053\n",
      "[4200]\ttrain-logloss:0.125482\tval-logloss:0.257442\n",
      "[4300]\ttrain-logloss:0.122782\tval-logloss:0.255312\n",
      "[4400]\ttrain-logloss:0.120188\tval-logloss:0.254162\n",
      "[4500]\ttrain-logloss:0.117664\tval-logloss:0.251953\n",
      "[4600]\ttrain-logloss:0.115288\tval-logloss:0.250288\n",
      "[4700]\ttrain-logloss:0.112972\tval-logloss:0.248692\n",
      "[4800]\ttrain-logloss:0.110732\tval-logloss:0.247628\n",
      "[4900]\ttrain-logloss:0.1086\tval-logloss:0.246794\n",
      "[4999]\ttrain-logloss:0.106529\tval-logloss:0.245672\n",
      "Fold: 85\n",
      "[0]\ttrain-logloss:0.692558\tval-logloss:0.692807\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638861\tval-logloss:0.652984\n",
      "[200]\ttrain-logloss:0.592323\tval-logloss:0.618538\n",
      "[300]\ttrain-logloss:0.55176\tval-logloss:0.590004\n",
      "[400]\ttrain-logloss:0.5157\tval-logloss:0.566881\n",
      "[500]\ttrain-logloss:0.483432\tval-logloss:0.549622\n",
      "[600]\ttrain-logloss:0.454456\tval-logloss:0.536446\n",
      "[700]\ttrain-logloss:0.428338\tval-logloss:0.523737\n",
      "[800]\ttrain-logloss:0.404678\tval-logloss:0.510151\n",
      "[900]\ttrain-logloss:0.383249\tval-logloss:0.496915\n",
      "[1000]\ttrain-logloss:0.363696\tval-logloss:0.483736\n",
      "[1100]\ttrain-logloss:0.345953\tval-logloss:0.472171\n",
      "[1200]\ttrain-logloss:0.329704\tval-logloss:0.463691\n",
      "[1300]\ttrain-logloss:0.31475\tval-logloss:0.456606\n",
      "[1400]\ttrain-logloss:0.300957\tval-logloss:0.451031\n",
      "[1500]\ttrain-logloss:0.288161\tval-logloss:0.445877\n",
      "[1600]\ttrain-logloss:0.276135\tval-logloss:0.441288\n",
      "[1700]\ttrain-logloss:0.265078\tval-logloss:0.437938\n",
      "[1800]\ttrain-logloss:0.254768\tval-logloss:0.434891\n",
      "[1900]\ttrain-logloss:0.245101\tval-logloss:0.431052\n",
      "[2000]\ttrain-logloss:0.235921\tval-logloss:0.428355\n",
      "[2100]\ttrain-logloss:0.227272\tval-logloss:0.426711\n",
      "[2200]\ttrain-logloss:0.219191\tval-logloss:0.425385\n",
      "[2300]\ttrain-logloss:0.211582\tval-logloss:0.423408\n",
      "[2400]\ttrain-logloss:0.204382\tval-logloss:0.421447\n",
      "[2500]\ttrain-logloss:0.197582\tval-logloss:0.420624\n",
      "[2600]\ttrain-logloss:0.191238\tval-logloss:0.419583\n",
      "[2700]\ttrain-logloss:0.185298\tval-logloss:0.418706\n",
      "[2800]\ttrain-logloss:0.179633\tval-logloss:0.417124\n",
      "[2900]\ttrain-logloss:0.174328\tval-logloss:0.416788\n",
      "Stopping. Best iteration:\n",
      "[2852]\ttrain-logloss:0.176804\tval-logloss:0.416322\n",
      "\n",
      "Fold: 86\n",
      "[0]\ttrain-logloss:0.692564\tval-logloss:0.692614\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638939\tval-logloss:0.654421\n",
      "[200]\ttrain-logloss:0.592425\tval-logloss:0.621262\n",
      "[300]\ttrain-logloss:0.55193\tval-logloss:0.596617\n",
      "[400]\ttrain-logloss:0.515998\tval-logloss:0.572373\n",
      "[500]\ttrain-logloss:0.483866\tval-logloss:0.552516\n",
      "[600]\ttrain-logloss:0.454943\tval-logloss:0.537254\n",
      "[700]\ttrain-logloss:0.428894\tval-logloss:0.520784\n",
      "[800]\ttrain-logloss:0.405199\tval-logloss:0.506206\n",
      "[900]\ttrain-logloss:0.383788\tval-logloss:0.489823\n",
      "[1000]\ttrain-logloss:0.3642\tval-logloss:0.476178\n",
      "[1100]\ttrain-logloss:0.346388\tval-logloss:0.4646\n",
      "[1200]\ttrain-logloss:0.330048\tval-logloss:0.454331\n",
      "[1300]\ttrain-logloss:0.315161\tval-logloss:0.447094\n",
      "[1400]\ttrain-logloss:0.301435\tval-logloss:0.442151\n",
      "[1500]\ttrain-logloss:0.288724\tval-logloss:0.437391\n",
      "[1600]\ttrain-logloss:0.276801\tval-logloss:0.431733\n",
      "[1700]\ttrain-logloss:0.265802\tval-logloss:0.426436\n",
      "[1800]\ttrain-logloss:0.255409\tval-logloss:0.424576\n",
      "[1900]\ttrain-logloss:0.24559\tval-logloss:0.42506\n",
      "Stopping. Best iteration:\n",
      "[1825]\ttrain-logloss:0.252902\tval-logloss:0.424003\n",
      "\n",
      "Fold: 87\n",
      "[0]\ttrain-logloss:0.69256\tval-logloss:0.692587\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638759\tval-logloss:0.653217\n",
      "[200]\ttrain-logloss:0.592008\tval-logloss:0.619992\n",
      "[300]\ttrain-logloss:0.551511\tval-logloss:0.591872\n",
      "[400]\ttrain-logloss:0.515498\tval-logloss:0.568658\n",
      "[500]\ttrain-logloss:0.483301\tval-logloss:0.550405\n",
      "[600]\ttrain-logloss:0.454315\tval-logloss:0.535114\n",
      "[700]\ttrain-logloss:0.42813\tval-logloss:0.523404\n",
      "[800]\ttrain-logloss:0.404497\tval-logloss:0.515378\n",
      "[900]\ttrain-logloss:0.383178\tval-logloss:0.508079\n",
      "[1000]\ttrain-logloss:0.363831\tval-logloss:0.500277\n",
      "[1100]\ttrain-logloss:0.34614\tval-logloss:0.496271\n",
      "[1200]\ttrain-logloss:0.329807\tval-logloss:0.492105\n",
      "[1300]\ttrain-logloss:0.314734\tval-logloss:0.488516\n",
      "[1400]\ttrain-logloss:0.300851\tval-logloss:0.485295\n",
      "[1500]\ttrain-logloss:0.288055\tval-logloss:0.484197\n",
      "[1600]\ttrain-logloss:0.276203\tval-logloss:0.480378\n",
      "[1700]\ttrain-logloss:0.265044\tval-logloss:0.478662\n",
      "Stopping. Best iteration:\n",
      "[1694]\ttrain-logloss:0.265699\tval-logloss:0.478404\n",
      "\n",
      "Fold: 88\n",
      "[0]\ttrain-logloss:0.692553\tval-logloss:0.692863\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638503\tval-logloss:0.675003\n",
      "[200]\ttrain-logloss:0.591649\tval-logloss:0.659766\n",
      "[300]\ttrain-logloss:0.550881\tval-logloss:0.645974\n",
      "[400]\ttrain-logloss:0.514702\tval-logloss:0.634021\n",
      "[500]\ttrain-logloss:0.482316\tval-logloss:0.626008\n",
      "[600]\ttrain-logloss:0.453202\tval-logloss:0.62129\n",
      "[700]\ttrain-logloss:0.426934\tval-logloss:0.618435\n",
      "[800]\ttrain-logloss:0.403145\tval-logloss:0.616661\n",
      "[900]\ttrain-logloss:0.38155\tval-logloss:0.617559\n",
      "Stopping. Best iteration:\n",
      "[816]\ttrain-logloss:0.399566\tval-logloss:0.616358\n",
      "\n",
      "Fold: 89\n",
      "[0]\ttrain-logloss:0.69255\tval-logloss:0.6931\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638385\tval-logloss:0.687833\n",
      "[200]\ttrain-logloss:0.591487\tval-logloss:0.686266\n",
      "[300]\ttrain-logloss:0.550647\tval-logloss:0.685172\n",
      "[400]\ttrain-logloss:0.514358\tval-logloss:0.682485\n",
      "[500]\ttrain-logloss:0.481951\tval-logloss:0.67873\n",
      "[600]\ttrain-logloss:0.45286\tval-logloss:0.674987\n",
      "[700]\ttrain-logloss:0.426373\tval-logloss:0.672667\n",
      "[800]\ttrain-logloss:0.402566\tval-logloss:0.670999\n",
      "[900]\ttrain-logloss:0.381086\tval-logloss:0.670177\n",
      "[1000]\ttrain-logloss:0.361728\tval-logloss:0.669788\n",
      "[1100]\ttrain-logloss:0.343936\tval-logloss:0.669793\n",
      "Stopping. Best iteration:\n",
      "[1054]\ttrain-logloss:0.351923\tval-logloss:0.669398\n",
      "\n",
      "Fold: 90\n",
      "[0]\ttrain-logloss:0.692567\tval-logloss:0.692585\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638781\tval-logloss:0.647636\n",
      "[200]\ttrain-logloss:0.592163\tval-logloss:0.60831\n",
      "[300]\ttrain-logloss:0.551398\tval-logloss:0.575653\n",
      "[400]\ttrain-logloss:0.515245\tval-logloss:0.547321\n",
      "[500]\ttrain-logloss:0.483059\tval-logloss:0.523328\n",
      "[600]\ttrain-logloss:0.45413\tval-logloss:0.502064\n",
      "[700]\ttrain-logloss:0.42804\tval-logloss:0.484459\n",
      "[800]\ttrain-logloss:0.404437\tval-logloss:0.470756\n",
      "[900]\ttrain-logloss:0.383116\tval-logloss:0.458834\n",
      "[1000]\ttrain-logloss:0.363613\tval-logloss:0.448933\n",
      "[1100]\ttrain-logloss:0.345905\tval-logloss:0.439264\n",
      "[1200]\ttrain-logloss:0.329663\tval-logloss:0.430959\n",
      "[1300]\ttrain-logloss:0.314637\tval-logloss:0.424315\n",
      "[1400]\ttrain-logloss:0.300741\tval-logloss:0.41788\n",
      "[1500]\ttrain-logloss:0.287802\tval-logloss:0.412416\n",
      "[1600]\ttrain-logloss:0.275881\tval-logloss:0.407426\n",
      "[1700]\ttrain-logloss:0.264788\tval-logloss:0.402076\n",
      "[1800]\ttrain-logloss:0.254417\tval-logloss:0.39791\n",
      "[1900]\ttrain-logloss:0.244742\tval-logloss:0.394886\n",
      "[2000]\ttrain-logloss:0.235716\tval-logloss:0.391841\n",
      "[2100]\ttrain-logloss:0.227115\tval-logloss:0.390165\n",
      "[2200]\ttrain-logloss:0.219077\tval-logloss:0.389066\n",
      "[2300]\ttrain-logloss:0.211525\tval-logloss:0.387545\n",
      "[2400]\ttrain-logloss:0.204349\tval-logloss:0.38418\n",
      "[2500]\ttrain-logloss:0.197496\tval-logloss:0.378718\n",
      "[2600]\ttrain-logloss:0.191134\tval-logloss:0.373179\n",
      "[2700]\ttrain-logloss:0.185181\tval-logloss:0.368463\n",
      "[2800]\ttrain-logloss:0.179563\tval-logloss:0.36462\n",
      "[2900]\ttrain-logloss:0.174327\tval-logloss:0.361232\n",
      "[3000]\ttrain-logloss:0.169351\tval-logloss:0.358491\n",
      "[3100]\ttrain-logloss:0.164654\tval-logloss:0.355879\n",
      "[3200]\ttrain-logloss:0.160141\tval-logloss:0.353556\n",
      "[3300]\ttrain-logloss:0.155877\tval-logloss:0.352144\n",
      "[3400]\ttrain-logloss:0.151828\tval-logloss:0.350721\n",
      "[3500]\ttrain-logloss:0.147945\tval-logloss:0.348509\n",
      "[3600]\ttrain-logloss:0.144212\tval-logloss:0.345744\n",
      "[3700]\ttrain-logloss:0.14063\tval-logloss:0.344579\n",
      "[3800]\ttrain-logloss:0.137214\tval-logloss:0.342901\n",
      "[3900]\ttrain-logloss:0.133929\tval-logloss:0.341712\n",
      "[4000]\ttrain-logloss:0.130818\tval-logloss:0.341139\n",
      "[4100]\ttrain-logloss:0.127787\tval-logloss:0.340502\n",
      "[4200]\ttrain-logloss:0.124902\tval-logloss:0.339967\n",
      "[4300]\ttrain-logloss:0.122178\tval-logloss:0.338921\n",
      "[4400]\ttrain-logloss:0.119556\tval-logloss:0.337286\n",
      "[4500]\ttrain-logloss:0.117092\tval-logloss:0.33602\n",
      "[4600]\ttrain-logloss:0.114807\tval-logloss:0.334763\n",
      "[4700]\ttrain-logloss:0.112558\tval-logloss:0.333432\n",
      "[4800]\ttrain-logloss:0.110342\tval-logloss:0.330816\n",
      "[4900]\ttrain-logloss:0.108271\tval-logloss:0.328806\n",
      "[4999]\ttrain-logloss:0.10625\tval-logloss:0.327683\n",
      "Fold: 91\n",
      "[0]\ttrain-logloss:0.692555\tval-logloss:0.692584\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639001\tval-logloss:0.640644\n",
      "[200]\ttrain-logloss:0.592658\tval-logloss:0.598694\n",
      "[300]\ttrain-logloss:0.552194\tval-logloss:0.564845\n",
      "[400]\ttrain-logloss:0.516324\tval-logloss:0.537008\n",
      "[500]\ttrain-logloss:0.484187\tval-logloss:0.511125\n",
      "[600]\ttrain-logloss:0.455331\tval-logloss:0.490221\n",
      "[700]\ttrain-logloss:0.429226\tval-logloss:0.473489\n",
      "[800]\ttrain-logloss:0.405649\tval-logloss:0.462001\n",
      "[900]\ttrain-logloss:0.384224\tval-logloss:0.453009\n",
      "[1000]\ttrain-logloss:0.364867\tval-logloss:0.444563\n",
      "[1100]\ttrain-logloss:0.347159\tval-logloss:0.437954\n",
      "[1200]\ttrain-logloss:0.330964\tval-logloss:0.433522\n",
      "[1300]\ttrain-logloss:0.315977\tval-logloss:0.430317\n",
      "[1400]\ttrain-logloss:0.301948\tval-logloss:0.428517\n",
      "[1500]\ttrain-logloss:0.28889\tval-logloss:0.426687\n",
      "[1600]\ttrain-logloss:0.276883\tval-logloss:0.42512\n",
      "[1700]\ttrain-logloss:0.265715\tval-logloss:0.424382\n",
      "Stopping. Best iteration:\n",
      "[1688]\ttrain-logloss:0.267017\tval-logloss:0.424227\n",
      "\n",
      "Fold: 92\n",
      "[0]\ttrain-logloss:0.692563\tval-logloss:0.692661\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638985\tval-logloss:0.645373\n",
      "[200]\ttrain-logloss:0.592565\tval-logloss:0.605501\n",
      "[300]\ttrain-logloss:0.552035\tval-logloss:0.575077\n",
      "[400]\ttrain-logloss:0.516098\tval-logloss:0.549284\n",
      "[500]\ttrain-logloss:0.483863\tval-logloss:0.526054\n",
      "[600]\ttrain-logloss:0.454912\tval-logloss:0.507536\n",
      "[700]\ttrain-logloss:0.428606\tval-logloss:0.492404\n",
      "[800]\ttrain-logloss:0.404903\tval-logloss:0.481156\n",
      "[900]\ttrain-logloss:0.383481\tval-logloss:0.473772\n",
      "[1000]\ttrain-logloss:0.364086\tval-logloss:0.468178\n",
      "[1100]\ttrain-logloss:0.346436\tval-logloss:0.463722\n",
      "[1200]\ttrain-logloss:0.330275\tval-logloss:0.460108\n",
      "[1300]\ttrain-logloss:0.315378\tval-logloss:0.458226\n",
      "[1400]\ttrain-logloss:0.301422\tval-logloss:0.455662\n",
      "[1500]\ttrain-logloss:0.288497\tval-logloss:0.455695\n",
      "Stopping. Best iteration:\n",
      "[1445]\ttrain-logloss:0.295482\tval-logloss:0.455088\n",
      "\n",
      "Fold: 93\n",
      "[0]\ttrain-logloss:0.692549\tval-logloss:0.692506\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638982\tval-logloss:0.634525\n",
      "[200]\ttrain-logloss:0.592565\tval-logloss:0.586317\n",
      "[300]\ttrain-logloss:0.55209\tval-logloss:0.546306\n",
      "[400]\ttrain-logloss:0.516038\tval-logloss:0.511749\n",
      "[500]\ttrain-logloss:0.483718\tval-logloss:0.482517\n",
      "[600]\ttrain-logloss:0.454727\tval-logloss:0.456916\n",
      "[700]\ttrain-logloss:0.428508\tval-logloss:0.4363\n",
      "[800]\ttrain-logloss:0.404766\tval-logloss:0.419198\n",
      "[900]\ttrain-logloss:0.383311\tval-logloss:0.403829\n",
      "[1000]\ttrain-logloss:0.363853\tval-logloss:0.392052\n",
      "[1100]\ttrain-logloss:0.346239\tval-logloss:0.382553\n",
      "[1200]\ttrain-logloss:0.330095\tval-logloss:0.376091\n",
      "[1300]\ttrain-logloss:0.315109\tval-logloss:0.368238\n",
      "[1400]\ttrain-logloss:0.301205\tval-logloss:0.363491\n",
      "[1500]\ttrain-logloss:0.288288\tval-logloss:0.358779\n",
      "[1600]\ttrain-logloss:0.276315\tval-logloss:0.354077\n",
      "[1700]\ttrain-logloss:0.26525\tval-logloss:0.349852\n",
      "[1800]\ttrain-logloss:0.254925\tval-logloss:0.345711\n",
      "[1900]\ttrain-logloss:0.245314\tval-logloss:0.340887\n",
      "[2000]\ttrain-logloss:0.23611\tval-logloss:0.333624\n",
      "[2100]\ttrain-logloss:0.227516\tval-logloss:0.326495\n",
      "[2200]\ttrain-logloss:0.219467\tval-logloss:0.320935\n",
      "[2300]\ttrain-logloss:0.211867\tval-logloss:0.315878\n",
      "[2400]\ttrain-logloss:0.204656\tval-logloss:0.312301\n",
      "[2500]\ttrain-logloss:0.19787\tval-logloss:0.308414\n",
      "[2600]\ttrain-logloss:0.191526\tval-logloss:0.305745\n",
      "[2700]\ttrain-logloss:0.185567\tval-logloss:0.302938\n",
      "[2800]\ttrain-logloss:0.179911\tval-logloss:0.300312\n",
      "[2900]\ttrain-logloss:0.174615\tval-logloss:0.298001\n",
      "[3000]\ttrain-logloss:0.169642\tval-logloss:0.296011\n",
      "[3100]\ttrain-logloss:0.164929\tval-logloss:0.294154\n",
      "[3200]\ttrain-logloss:0.160413\tval-logloss:0.291701\n",
      "[3300]\ttrain-logloss:0.15611\tval-logloss:0.289406\n",
      "[3400]\ttrain-logloss:0.152033\tval-logloss:0.287241\n",
      "[3500]\ttrain-logloss:0.148136\tval-logloss:0.285996\n",
      "[3600]\ttrain-logloss:0.144447\tval-logloss:0.284715\n",
      "[3700]\ttrain-logloss:0.140887\tval-logloss:0.282988\n",
      "[3800]\ttrain-logloss:0.137479\tval-logloss:0.281374\n",
      "[3900]\ttrain-logloss:0.134202\tval-logloss:0.280645\n",
      "[4000]\ttrain-logloss:0.131054\tval-logloss:0.280191\n",
      "[4100]\ttrain-logloss:0.128042\tval-logloss:0.280095\n",
      "Stopping. Best iteration:\n",
      "[4042]\ttrain-logloss:0.129775\tval-logloss:0.27949\n",
      "\n",
      "Fold: 94\n",
      "[0]\ttrain-logloss:0.692558\tval-logloss:0.692665\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.63907\tval-logloss:0.64978\n",
      "[200]\ttrain-logloss:0.592668\tval-logloss:0.615181\n",
      "[300]\ttrain-logloss:0.552139\tval-logloss:0.58869\n",
      "[400]\ttrain-logloss:0.516221\tval-logloss:0.564737\n",
      "[500]\ttrain-logloss:0.484033\tval-logloss:0.545874\n",
      "[600]\ttrain-logloss:0.455053\tval-logloss:0.528373\n",
      "[700]\ttrain-logloss:0.428911\tval-logloss:0.513974\n",
      "[800]\ttrain-logloss:0.405236\tval-logloss:0.502921\n",
      "[900]\ttrain-logloss:0.383766\tval-logloss:0.495055\n",
      "[1000]\ttrain-logloss:0.364283\tval-logloss:0.490103\n",
      "[1100]\ttrain-logloss:0.346477\tval-logloss:0.485065\n",
      "[1200]\ttrain-logloss:0.330282\tval-logloss:0.482771\n",
      "[1300]\ttrain-logloss:0.315284\tval-logloss:0.48081\n",
      "[1400]\ttrain-logloss:0.301378\tval-logloss:0.478631\n",
      "[1500]\ttrain-logloss:0.288436\tval-logloss:0.478542\n",
      "Stopping. Best iteration:\n",
      "[1426]\ttrain-logloss:0.297942\tval-logloss:0.478017\n",
      "\n",
      "Fold: 95\n",
      "[0]\ttrain-logloss:0.692553\tval-logloss:0.692753\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639033\tval-logloss:0.646611\n",
      "[200]\ttrain-logloss:0.592666\tval-logloss:0.607881\n",
      "[300]\ttrain-logloss:0.552106\tval-logloss:0.575141\n",
      "[400]\ttrain-logloss:0.516011\tval-logloss:0.5451\n",
      "[500]\ttrain-logloss:0.484006\tval-logloss:0.521201\n",
      "[600]\ttrain-logloss:0.455114\tval-logloss:0.497978\n",
      "[700]\ttrain-logloss:0.429137\tval-logloss:0.477733\n",
      "[800]\ttrain-logloss:0.405557\tval-logloss:0.457009\n",
      "[900]\ttrain-logloss:0.384111\tval-logloss:0.435064\n",
      "[1000]\ttrain-logloss:0.364635\tval-logloss:0.416169\n",
      "[1100]\ttrain-logloss:0.346832\tval-logloss:0.399421\n",
      "[1200]\ttrain-logloss:0.330588\tval-logloss:0.384531\n",
      "[1300]\ttrain-logloss:0.315623\tval-logloss:0.370156\n",
      "[1400]\ttrain-logloss:0.301751\tval-logloss:0.356581\n",
      "[1500]\ttrain-logloss:0.288906\tval-logloss:0.344253\n",
      "[1600]\ttrain-logloss:0.276829\tval-logloss:0.332376\n",
      "[1700]\ttrain-logloss:0.265672\tval-logloss:0.32326\n",
      "[1800]\ttrain-logloss:0.255354\tval-logloss:0.314237\n",
      "[1900]\ttrain-logloss:0.245712\tval-logloss:0.304532\n",
      "[2000]\ttrain-logloss:0.236351\tval-logloss:0.299381\n",
      "[2100]\ttrain-logloss:0.22773\tval-logloss:0.295578\n",
      "[2200]\ttrain-logloss:0.21956\tval-logloss:0.290775\n",
      "[2300]\ttrain-logloss:0.211876\tval-logloss:0.287045\n",
      "[2400]\ttrain-logloss:0.204683\tval-logloss:0.283903\n",
      "[2500]\ttrain-logloss:0.197922\tval-logloss:0.281265\n",
      "[2600]\ttrain-logloss:0.191572\tval-logloss:0.27891\n",
      "[2700]\ttrain-logloss:0.185602\tval-logloss:0.278123\n",
      "[2800]\ttrain-logloss:0.179943\tval-logloss:0.276459\n",
      "[2900]\ttrain-logloss:0.17463\tval-logloss:0.275012\n",
      "[3000]\ttrain-logloss:0.169608\tval-logloss:0.27281\n",
      "[3100]\ttrain-logloss:0.164849\tval-logloss:0.270173\n",
      "[3200]\ttrain-logloss:0.160357\tval-logloss:0.26751\n",
      "[3300]\ttrain-logloss:0.156109\tval-logloss:0.265298\n",
      "[3400]\ttrain-logloss:0.152058\tval-logloss:0.26322\n",
      "[3500]\ttrain-logloss:0.148193\tval-logloss:0.260782\n",
      "[3600]\ttrain-logloss:0.144491\tval-logloss:0.258154\n",
      "[3700]\ttrain-logloss:0.140944\tval-logloss:0.256991\n",
      "[3800]\ttrain-logloss:0.137507\tval-logloss:0.255731\n",
      "[3900]\ttrain-logloss:0.134176\tval-logloss:0.254335\n",
      "[4000]\ttrain-logloss:0.131008\tval-logloss:0.253648\n",
      "Stopping. Best iteration:\n",
      "[3996]\ttrain-logloss:0.131128\tval-logloss:0.253529\n",
      "\n",
      "Fold: 96\n",
      "[0]\ttrain-logloss:0.692559\tval-logloss:0.692672\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639073\tval-logloss:0.650592\n",
      "[200]\ttrain-logloss:0.592695\tval-logloss:0.61301\n",
      "[300]\ttrain-logloss:0.552154\tval-logloss:0.582805\n",
      "[400]\ttrain-logloss:0.515946\tval-logloss:0.554785\n",
      "[500]\ttrain-logloss:0.483602\tval-logloss:0.533585\n",
      "[600]\ttrain-logloss:0.454511\tval-logloss:0.517547\n",
      "[700]\ttrain-logloss:0.428281\tval-logloss:0.501556\n",
      "[800]\ttrain-logloss:0.404601\tval-logloss:0.488914\n",
      "[900]\ttrain-logloss:0.383138\tval-logloss:0.478114\n",
      "[1000]\ttrain-logloss:0.363598\tval-logloss:0.468164\n",
      "[1100]\ttrain-logloss:0.345702\tval-logloss:0.458707\n",
      "[1200]\ttrain-logloss:0.329198\tval-logloss:0.449042\n",
      "[1300]\ttrain-logloss:0.314017\tval-logloss:0.440371\n",
      "[1400]\ttrain-logloss:0.299975\tval-logloss:0.434564\n",
      "[1500]\ttrain-logloss:0.286985\tval-logloss:0.428656\n",
      "[1600]\ttrain-logloss:0.275031\tval-logloss:0.421765\n",
      "[1700]\ttrain-logloss:0.263989\tval-logloss:0.415023\n",
      "[1800]\ttrain-logloss:0.253697\tval-logloss:0.410175\n",
      "[1900]\ttrain-logloss:0.244026\tval-logloss:0.406879\n",
      "[2000]\ttrain-logloss:0.2351\tval-logloss:0.402974\n",
      "[2100]\ttrain-logloss:0.226574\tval-logloss:0.396171\n",
      "[2200]\ttrain-logloss:0.218497\tval-logloss:0.388652\n",
      "[2300]\ttrain-logloss:0.210866\tval-logloss:0.382186\n",
      "[2400]\ttrain-logloss:0.203659\tval-logloss:0.377426\n",
      "[2500]\ttrain-logloss:0.196875\tval-logloss:0.373245\n",
      "[2600]\ttrain-logloss:0.190438\tval-logloss:0.369168\n",
      "[2700]\ttrain-logloss:0.184435\tval-logloss:0.366028\n",
      "[2800]\ttrain-logloss:0.17885\tval-logloss:0.362271\n",
      "[2900]\ttrain-logloss:0.173622\tval-logloss:0.357454\n",
      "[3000]\ttrain-logloss:0.168706\tval-logloss:0.351104\n",
      "[3100]\ttrain-logloss:0.164081\tval-logloss:0.346337\n",
      "[3200]\ttrain-logloss:0.159681\tval-logloss:0.341669\n",
      "[3300]\ttrain-logloss:0.155471\tval-logloss:0.337551\n",
      "[3400]\ttrain-logloss:0.151449\tval-logloss:0.333784\n",
      "[3500]\ttrain-logloss:0.147642\tval-logloss:0.329771\n",
      "[3600]\ttrain-logloss:0.144042\tval-logloss:0.325984\n",
      "[3700]\ttrain-logloss:0.140552\tval-logloss:0.324118\n",
      "[3800]\ttrain-logloss:0.137132\tval-logloss:0.323751\n",
      "Stopping. Best iteration:\n",
      "[3758]\ttrain-logloss:0.138541\tval-logloss:0.323225\n",
      "\n",
      "Fold: 97\n",
      "[0]\ttrain-logloss:0.692546\tval-logloss:0.693168\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638616\tval-logloss:0.689188\n",
      "[200]\ttrain-logloss:0.59198\tval-logloss:0.684835\n",
      "[300]\ttrain-logloss:0.551279\tval-logloss:0.680202\n",
      "[400]\ttrain-logloss:0.515157\tval-logloss:0.674088\n",
      "[500]\ttrain-logloss:0.482734\tval-logloss:0.669747\n",
      "[600]\ttrain-logloss:0.45372\tval-logloss:0.668419\n",
      "[700]\ttrain-logloss:0.427506\tval-logloss:0.668737\n",
      "Stopping. Best iteration:\n",
      "[609]\ttrain-logloss:0.451228\tval-logloss:0.667874\n",
      "\n",
      "Fold: 98\n",
      "[0]\ttrain-logloss:0.692551\tval-logloss:0.692836\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638766\tval-logloss:0.667269\n",
      "[200]\ttrain-logloss:0.592176\tval-logloss:0.646855\n",
      "[300]\ttrain-logloss:0.551675\tval-logloss:0.628629\n",
      "[400]\ttrain-logloss:0.515401\tval-logloss:0.616941\n",
      "[500]\ttrain-logloss:0.482952\tval-logloss:0.606985\n",
      "[600]\ttrain-logloss:0.453809\tval-logloss:0.598455\n",
      "[700]\ttrain-logloss:0.427475\tval-logloss:0.589614\n",
      "[800]\ttrain-logloss:0.403757\tval-logloss:0.583846\n",
      "[900]\ttrain-logloss:0.382149\tval-logloss:0.579364\n",
      "[1000]\ttrain-logloss:0.362498\tval-logloss:0.571136\n",
      "[1100]\ttrain-logloss:0.344512\tval-logloss:0.567106\n",
      "[1200]\ttrain-logloss:0.328145\tval-logloss:0.564192\n",
      "[1300]\ttrain-logloss:0.313053\tval-logloss:0.562551\n",
      "Stopping. Best iteration:\n",
      "[1270]\ttrain-logloss:0.317503\tval-logloss:0.561877\n",
      "\n",
      "Fold: 99\n",
      "[0]\ttrain-logloss:0.692545\tval-logloss:0.692883\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.638718\tval-logloss:0.6634\n",
      "[200]\ttrain-logloss:0.591939\tval-logloss:0.638036\n",
      "[300]\ttrain-logloss:0.551071\tval-logloss:0.61449\n",
      "[400]\ttrain-logloss:0.514805\tval-logloss:0.596835\n",
      "[500]\ttrain-logloss:0.482487\tval-logloss:0.582337\n",
      "[600]\ttrain-logloss:0.4533\tval-logloss:0.570673\n",
      "[700]\ttrain-logloss:0.427261\tval-logloss:0.556104\n",
      "[800]\ttrain-logloss:0.403752\tval-logloss:0.541062\n",
      "[900]\ttrain-logloss:0.382195\tval-logloss:0.525922\n",
      "[1000]\ttrain-logloss:0.362751\tval-logloss:0.513118\n",
      "[1100]\ttrain-logloss:0.344875\tval-logloss:0.504055\n",
      "[1200]\ttrain-logloss:0.328536\tval-logloss:0.493285\n",
      "[1300]\ttrain-logloss:0.313598\tval-logloss:0.484103\n",
      "[1400]\ttrain-logloss:0.299811\tval-logloss:0.47539\n",
      "[1500]\ttrain-logloss:0.287131\tval-logloss:0.467466\n",
      "[1600]\ttrain-logloss:0.275289\tval-logloss:0.460504\n",
      "[1700]\ttrain-logloss:0.264319\tval-logloss:0.454422\n",
      "[1800]\ttrain-logloss:0.254046\tval-logloss:0.446738\n",
      "[1900]\ttrain-logloss:0.244235\tval-logloss:0.441111\n",
      "[2000]\ttrain-logloss:0.234954\tval-logloss:0.4364\n",
      "[2100]\ttrain-logloss:0.226332\tval-logloss:0.434361\n",
      "[2200]\ttrain-logloss:0.218285\tval-logloss:0.43239\n",
      "[2300]\ttrain-logloss:0.210687\tval-logloss:0.428642\n",
      "[2400]\ttrain-logloss:0.203606\tval-logloss:0.426325\n",
      "[2500]\ttrain-logloss:0.196973\tval-logloss:0.425018\n",
      "[2600]\ttrain-logloss:0.190625\tval-logloss:0.424738\n",
      "Stopping. Best iteration:\n",
      "[2556]\ttrain-logloss:0.193371\tval-logloss:0.424466\n",
      "\n",
      "Fold: 100\n",
      "[0]\ttrain-logloss:0.692563\tval-logloss:0.693046\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[100]\ttrain-logloss:0.639214\tval-logloss:0.682927\n",
      "[200]\ttrain-logloss:0.592719\tval-logloss:0.674127\n",
      "[300]\ttrain-logloss:0.552104\tval-logloss:0.666835\n",
      "[400]\ttrain-logloss:0.515946\tval-logloss:0.658576\n",
      "[500]\ttrain-logloss:0.483547\tval-logloss:0.653889\n",
      "[600]\ttrain-logloss:0.454551\tval-logloss:0.648769\n",
      "[700]\ttrain-logloss:0.42834\tval-logloss:0.644105\n",
      "[800]\ttrain-logloss:0.404633\tval-logloss:0.640787\n",
      "[900]\ttrain-logloss:0.383107\tval-logloss:0.63649\n",
      "[1000]\ttrain-logloss:0.363487\tval-logloss:0.631442\n",
      "[1100]\ttrain-logloss:0.345683\tval-logloss:0.625149\n",
      "[1200]\ttrain-logloss:0.329377\tval-logloss:0.618872\n",
      "[1300]\ttrain-logloss:0.314232\tval-logloss:0.621171\n",
      "Stopping. Best iteration:\n",
      "[1234]\ttrain-logloss:0.32408\tval-logloss:0.618578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NFOLDS = 100\n",
    "folds = KFold(n_splits=NFOLDS)\n",
    "\n",
    "columns = X_train.columns\n",
    "splits = folds.split(X_train, y_train)\n",
    "\n",
    "y_preds_xgb = np.zeros(test_df.shape[0])\n",
    "y_oof_xgb = np.zeros(X_train.shape[0])\n",
    "  \n",
    "for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "    print('Fold:',fold_n+1)\n",
    "    X_train2, X_valid2 = X_train[columns].iloc[train_index], X_train[columns].iloc[valid_index]\n",
    "    y_train2, y_valid2 = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "    \n",
    "    train_set = xgb.DMatrix(X_train2, y_train2)\n",
    "    val_set = xgb.DMatrix(X_valid2, y_valid2)\n",
    "    test_set = xgb.DMatrix(test_df)\n",
    "    \n",
    "    clf = xgb.train(params_xgb, train_set,num_boost_round=5000, evals=[(train_set, 'train'), (val_set, 'val')], early_stopping_rounds=100, verbose_eval=100)\n",
    "    \n",
    "    y_preds_xgb += clf.predict(test_set) / NFOLDS\n",
    "    \n",
    "    del X_train2, X_valid2, y_train2, y_valid2\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>0.467229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>0.530143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>0.096529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>0.364995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>0.367708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10075</th>\n",
       "      <td>2019_3413_3417</td>\n",
       "      <td>0.096838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10076</th>\n",
       "      <td>2019_3413_3460</td>\n",
       "      <td>0.322795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10077</th>\n",
       "      <td>2019_3416_3417</td>\n",
       "      <td>0.210465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>2019_3416_3460</td>\n",
       "      <td>0.487034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10079</th>\n",
       "      <td>2019_3417_3460</td>\n",
       "      <td>0.838904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10080 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID      Pred\n",
       "0      2015_3106_3107  0.467229\n",
       "1      2015_3106_3110  0.530143\n",
       "2      2015_3106_3113  0.096529\n",
       "3      2015_3106_3114  0.364995\n",
       "4      2015_3106_3116  0.367708\n",
       "...               ...       ...\n",
       "10075  2019_3413_3417  0.096838\n",
       "10076  2019_3413_3460  0.322795\n",
       "10077  2019_3416_3417  0.210465\n",
       "10078  2019_3416_3460  0.487034\n",
       "10079  2019_3417_3460  0.838904\n",
       "\n",
       "[10080 rows x 2 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(os.path.join(path, 'WSampleSubmissionStage1_2020.csv'))\n",
    "submission['Pred'] = y_preds_xgb\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('NCAAW_Ensemble.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
