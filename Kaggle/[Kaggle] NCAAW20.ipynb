{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "%matplotlib inline\n",
    "import copy\n",
    "import datetime\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "#import plotly.offline as py\n",
    "#py.init_notebook_mode(connected=True)\n",
    "#import plotly.graph_objs as go\n",
    "#import plotly.tools as tls\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "#from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, roc_auc_score, log_loss, classification_report, confusion_matrix\n",
    "import json\n",
    "import ast\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# keras\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, LambdaCallback\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Layer, Dense, Concatenate, Reshape, Dropout, merge, Add, BatchNormalization, GaussianNoise\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras.callbacks import *\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\bokhy\\\\Desktop\\\\Python\\\\Python-Projects\\\\Kaggle\\\\google-cloud-ncaa-march-madness-2020-division-1-womens-tournament\\\\'\n",
    "SeasonCompactResults = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WRegularSeasonCompactResults.csv'))\n",
    "SeasonDetailedResults = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WRegularSeasonDetailedResults.csv'))\n",
    "TourneyCompactResults = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WNCAATourneyCompactResults.csv'))\n",
    "TourneyDetailedResults = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WNCAATourneyDetailedResults.csv'))\n",
    "TourneySeeds = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WNCAATourneySeeds.csv'))\n",
    "GameCities = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WGameCities.csv'))\n",
    "Cities = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\Cities.csv'))\n",
    "Teams = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WTeams.csv'))\n",
    "Conferences = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WTeamConferences.csv'))\n",
    "Seasons = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WSeasons.csv'))\n",
    "TourneySlots = pd.read_csv(os.path.join(path, 'WDataFiles_Stage1\\\\WNCAATourneySlots.csv'))\n",
    "\n",
    "test = pd.read_csv(os.path.join(path, 'WSampleSubmissionStage1_2020.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format ID\n",
    "test = test.drop(['Pred'], axis=1)\n",
    "test['Season'] = test['ID'].apply(lambda x: int(x.split('_')[0]))\n",
    "test['WTeamID'] = test['ID'].apply(lambda x: int(x.split('_')[1]))\n",
    "test['LTeamID'] = test['ID'].apply(lambda x: int(x.split('_')[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>LTeamID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Season  WTeamID  LTeamID\n",
       "0  2015_3106_3107    2015     3106     3107\n",
       "1  2015_3106_3110    2015     3106     3110\n",
       "2  2015_3106_3113    2015     3106     3113\n",
       "3  2015_3106_3114    2015     3106     3114\n",
       "4  2015_3106_3116    2015     3106     3116"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>WFGA3</th>\n",
       "      <th>WFTM</th>\n",
       "      <th>WFTA</th>\n",
       "      <th>WOR</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WAst</th>\n",
       "      <th>WTO</th>\n",
       "      <th>WStl</th>\n",
       "      <th>WBlk</th>\n",
       "      <th>WPF</th>\n",
       "      <th>LFGM</th>\n",
       "      <th>LFGA</th>\n",
       "      <th>LFGM3</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>138</td>\n",
       "      <td>3124</td>\n",
       "      <td>69</td>\n",
       "      <td>3201</td>\n",
       "      <td>55</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>138</td>\n",
       "      <td>3173</td>\n",
       "      <td>67</td>\n",
       "      <td>3395</td>\n",
       "      <td>66</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>138</td>\n",
       "      <td>3181</td>\n",
       "      <td>72</td>\n",
       "      <td>3214</td>\n",
       "      <td>37</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>138</td>\n",
       "      <td>3199</td>\n",
       "      <td>75</td>\n",
       "      <td>3256</td>\n",
       "      <td>61</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>138</td>\n",
       "      <td>3207</td>\n",
       "      <td>62</td>\n",
       "      <td>3265</td>\n",
       "      <td>42</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
       "0    2010     138     3124      69     3201      55    N      0    28    57   \n",
       "1    2010     138     3173      67     3395      66    N      0    23    59   \n",
       "2    2010     138     3181      72     3214      37    H      0    26    57   \n",
       "3    2010     138     3199      75     3256      61    H      0    25    63   \n",
       "4    2010     138     3207      62     3265      42    N      0    24    68   \n",
       "\n",
       "   WFGM3  WFGA3  WFTM  WFTA  WOR  WDR  WAst  WTO  WStl  WBlk  WPF  LFGM  LFGA  \\\n",
       "0      1      5    12    19   13   24    22   12     6     2   12    21    61   \n",
       "1      9     26    12    19   13   34    13   16     3    10   14    22    73   \n",
       "2      4     13    16    22   13   34    15   11    10     7   11    15    56   \n",
       "3      3     15    22    26   20   27    13   17     8     3   21    21    62   \n",
       "4      8     25     6     8   20   29    16    8     5     5   18    13    60   \n",
       "\n",
       "   LFGM3  LFGA3  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF  \n",
       "0     10     34     3     5   17   19    12   18     4     1   18  \n",
       "1      8     27    14    15   18   26     8    8     8     6   22  \n",
       "2      4     15     3     8   10   21     4   16     6     4   20  \n",
       "3      2     20    17    22   16   21    13   16     5     4   24  \n",
       "4      5     26    11    17   16   22     9   10     3     4   12  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TourneyDetailedResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(630, 34)\n"
     ]
    }
   ],
   "source": [
    "print(TourneyDetailedResults.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3104</td>\n",
       "      <td>94</td>\n",
       "      <td>3422</td>\n",
       "      <td>46</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3112</td>\n",
       "      <td>75</td>\n",
       "      <td>3365</td>\n",
       "      <td>63</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3163</td>\n",
       "      <td>93</td>\n",
       "      <td>3193</td>\n",
       "      <td>52</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3198</td>\n",
       "      <td>59</td>\n",
       "      <td>3266</td>\n",
       "      <td>45</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3203</td>\n",
       "      <td>74</td>\n",
       "      <td>3208</td>\n",
       "      <td>72</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT\n",
       "0    1998     137     3104      94     3422      46    H      0\n",
       "1    1998     137     3112      75     3365      63    H      0\n",
       "2    1998     137     3163      93     3193      52    H      0\n",
       "3    1998     137     3198      59     3266      45    H      0\n",
       "4    1998     137     3203      74     3208      72    A      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TourneyCompactResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1386, 8)\n"
     ]
    }
   ],
   "source": [
    "print(TourneyCompactResults.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tournament CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>WFGA3</th>\n",
       "      <th>WFTM</th>\n",
       "      <th>WFTA</th>\n",
       "      <th>WOR</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WAst</th>\n",
       "      <th>WTO</th>\n",
       "      <th>WStl</th>\n",
       "      <th>WBlk</th>\n",
       "      <th>WPF</th>\n",
       "      <th>LFGM</th>\n",
       "      <th>LFGA</th>\n",
       "      <th>LFGM3</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3104</td>\n",
       "      <td>94</td>\n",
       "      <td>3422</td>\n",
       "      <td>46</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3112</td>\n",
       "      <td>75</td>\n",
       "      <td>3365</td>\n",
       "      <td>63</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3163</td>\n",
       "      <td>93</td>\n",
       "      <td>3193</td>\n",
       "      <td>52</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3198</td>\n",
       "      <td>59</td>\n",
       "      <td>3266</td>\n",
       "      <td>45</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3203</td>\n",
       "      <td>74</td>\n",
       "      <td>3208</td>\n",
       "      <td>72</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
       "0    1998     137     3104      94     3422      46    H      0   NaN   NaN   \n",
       "1    1998     137     3112      75     3365      63    H      0   NaN   NaN   \n",
       "2    1998     137     3163      93     3193      52    H      0   NaN   NaN   \n",
       "3    1998     137     3198      59     3266      45    H      0   NaN   NaN   \n",
       "4    1998     137     3203      74     3208      72    A      0   NaN   NaN   \n",
       "\n",
       "   WFGM3  WFGA3  WFTM  WFTA  WOR  WDR  WAst  WTO  WStl  WBlk  WPF  LFGM  LFGA  \\\n",
       "0    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "1    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "2    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "3    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "4    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "\n",
       "   LFGM3  LFGA3  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF  \n",
       "0    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN  \n",
       "1    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN  \n",
       "2    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN  \n",
       "3    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN  \n",
       "4    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.merge(TourneyCompactResults,TourneyDetailedResults, how='left', on=['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc', 'NumOT'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1386, 34)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with Game Cities\n",
    "GameCities = pd.merge(GameCities, Cities, how = 'left', on = 'CityID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>CRType</th>\n",
       "      <th>CityID</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3103</td>\n",
       "      <td>3237</td>\n",
       "      <td>Regular</td>\n",
       "      <td>4002</td>\n",
       "      <td>Akron</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3104</td>\n",
       "      <td>3399</td>\n",
       "      <td>Regular</td>\n",
       "      <td>4085</td>\n",
       "      <td>Corpus Christi</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3110</td>\n",
       "      <td>3224</td>\n",
       "      <td>Regular</td>\n",
       "      <td>4363</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3111</td>\n",
       "      <td>3267</td>\n",
       "      <td>Regular</td>\n",
       "      <td>4158</td>\n",
       "      <td>Huntington</td>\n",
       "      <td>WV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3119</td>\n",
       "      <td>3447</td>\n",
       "      <td>Regular</td>\n",
       "      <td>4367</td>\n",
       "      <td>West Point</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  LTeamID   CRType  CityID            City State\n",
       "0    2010      11     3103     3237  Regular    4002           Akron    OH\n",
       "1    2010      11     3104     3399  Regular    4085  Corpus Christi    TX\n",
       "2    2010      11     3110     3224  Regular    4363      Washington    DC\n",
       "3    2010      11     3111     3267  Regular    4158      Huntington    WV\n",
       "4    2010      11     3119     3447  Regular    4367      West Point    NY"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GameCities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns1 = GameCities.columns.difference(train.columns).tolist() + [\"Season\", \"WTeamID\", \"LTeamID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(GameCities[columns1], how=\"left\", on=[\"Season\", \"WTeamID\", \"LTeamID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>WFGA3</th>\n",
       "      <th>WFTM</th>\n",
       "      <th>WFTA</th>\n",
       "      <th>WOR</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WAst</th>\n",
       "      <th>WTO</th>\n",
       "      <th>WStl</th>\n",
       "      <th>WBlk</th>\n",
       "      <th>WPF</th>\n",
       "      <th>LFGM</th>\n",
       "      <th>LFGA</th>\n",
       "      <th>LFGM3</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3104</td>\n",
       "      <td>94</td>\n",
       "      <td>3422</td>\n",
       "      <td>46</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3112</td>\n",
       "      <td>75</td>\n",
       "      <td>3365</td>\n",
       "      <td>63</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3163</td>\n",
       "      <td>93</td>\n",
       "      <td>3193</td>\n",
       "      <td>52</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3198</td>\n",
       "      <td>59</td>\n",
       "      <td>3266</td>\n",
       "      <td>45</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3203</td>\n",
       "      <td>74</td>\n",
       "      <td>3208</td>\n",
       "      <td>72</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
       "0    1998     137     3104      94     3422      46    H      0   NaN   NaN   \n",
       "1    1998     137     3112      75     3365      63    H      0   NaN   NaN   \n",
       "2    1998     137     3163      93     3193      52    H      0   NaN   NaN   \n",
       "3    1998     137     3198      59     3266      45    H      0   NaN   NaN   \n",
       "4    1998     137     3203      74     3208      72    A      0   NaN   NaN   \n",
       "\n",
       "   WFGM3  WFGA3  WFTM  WFTA  WOR  WDR  WAst  WTO  WStl  WBlk  WPF  LFGM  LFGA  \\\n",
       "0    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "1    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "2    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "3    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "4    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "\n",
       "   LFGM3  LFGA3  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF CRType City  \\\n",
       "0    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "1    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "2    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "3    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "4    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "\n",
       "   CityID State  \n",
       "0     NaN   NaN  \n",
       "1     NaN   NaN  \n",
       "2     NaN   NaN  \n",
       "3     NaN   NaN  \n",
       "4     NaN   NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429, 38)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>WFGA3</th>\n",
       "      <th>WFTM</th>\n",
       "      <th>WFTA</th>\n",
       "      <th>WOR</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WAst</th>\n",
       "      <th>WTO</th>\n",
       "      <th>WStl</th>\n",
       "      <th>WBlk</th>\n",
       "      <th>WPF</th>\n",
       "      <th>LFGM</th>\n",
       "      <th>LFGA</th>\n",
       "      <th>LFGM3</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>State</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>RegionW</th>\n",
       "      <th>RegionX</th>\n",
       "      <th>RegionY</th>\n",
       "      <th>RegionZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3104</td>\n",
       "      <td>94</td>\n",
       "      <td>3422</td>\n",
       "      <td>46</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3112</td>\n",
       "      <td>75</td>\n",
       "      <td>3365</td>\n",
       "      <td>63</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3163</td>\n",
       "      <td>93</td>\n",
       "      <td>3193</td>\n",
       "      <td>52</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3198</td>\n",
       "      <td>59</td>\n",
       "      <td>3266</td>\n",
       "      <td>45</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3203</td>\n",
       "      <td>74</td>\n",
       "      <td>3208</td>\n",
       "      <td>72</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
       "0    1998     137     3104      94     3422      46    H      0   NaN   NaN   \n",
       "1    1998     137     3112      75     3365      63    H      0   NaN   NaN   \n",
       "2    1998     137     3163      93     3193      52    H      0   NaN   NaN   \n",
       "3    1998     137     3198      59     3266      45    H      0   NaN   NaN   \n",
       "4    1998     137     3203      74     3208      72    A      0   NaN   NaN   \n",
       "\n",
       "   WFGM3  WFGA3  WFTM  WFTA  WOR  WDR  WAst  WTO  WStl  WBlk  WPF  LFGM  LFGA  \\\n",
       "0    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "1    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "2    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "3    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "4    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "\n",
       "   LFGM3  LFGA3  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF CRType City  \\\n",
       "0    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "1    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "2    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "3    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "4    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "\n",
       "   CityID State     DayZero RegionW  RegionX  RegionY RegionZ  \n",
       "0     NaN   NaN  10/27/1997    East  Midwest  Mideast    West  \n",
       "1     NaN   NaN  10/27/1997    East  Midwest  Mideast    West  \n",
       "2     NaN   NaN  10/27/1997    East  Midwest  Mideast    West  \n",
       "3     NaN   NaN  10/27/1997    East  Midwest  Mideast    West  \n",
       "4     NaN   NaN  10/27/1997    East  Midwest  Mideast    West  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge with WSeasons\n",
    "columns2 = Seasons.columns.difference(train.columns).tolist() + [\"Season\"]\n",
    "train = train.merge(Seasons[columns2], how=\"left\", on=\"Season\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429, 43)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>WFGA3</th>\n",
       "      <th>WFTM</th>\n",
       "      <th>WFTA</th>\n",
       "      <th>WOR</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WAst</th>\n",
       "      <th>WTO</th>\n",
       "      <th>WStl</th>\n",
       "      <th>WBlk</th>\n",
       "      <th>WPF</th>\n",
       "      <th>LFGM</th>\n",
       "      <th>LFGA</th>\n",
       "      <th>LFGM3</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>State</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>RegionW</th>\n",
       "      <th>RegionX</th>\n",
       "      <th>RegionY</th>\n",
       "      <th>RegionZ</th>\n",
       "      <th>TeamID</th>\n",
       "      <th>TeamName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3104</td>\n",
       "      <td>94</td>\n",
       "      <td>3422</td>\n",
       "      <td>46</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>3104</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3112</td>\n",
       "      <td>75</td>\n",
       "      <td>3365</td>\n",
       "      <td>63</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>3112</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3163</td>\n",
       "      <td>93</td>\n",
       "      <td>3193</td>\n",
       "      <td>52</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>3163</td>\n",
       "      <td>Connecticut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3198</td>\n",
       "      <td>59</td>\n",
       "      <td>3266</td>\n",
       "      <td>45</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>3198</td>\n",
       "      <td>Florida Intl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3203</td>\n",
       "      <td>74</td>\n",
       "      <td>3208</td>\n",
       "      <td>72</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>3203</td>\n",
       "      <td>G Washington</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
       "0    1998     137     3104      94     3422      46    H      0   NaN   NaN   \n",
       "1    1998     137     3112      75     3365      63    H      0   NaN   NaN   \n",
       "2    1998     137     3163      93     3193      52    H      0   NaN   NaN   \n",
       "3    1998     137     3198      59     3266      45    H      0   NaN   NaN   \n",
       "4    1998     137     3203      74     3208      72    A      0   NaN   NaN   \n",
       "\n",
       "   WFGM3  WFGA3  WFTM  WFTA  WOR  WDR  WAst  WTO  WStl  WBlk  WPF  LFGM  LFGA  \\\n",
       "0    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "1    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "2    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "3    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "4    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "\n",
       "   LFGM3  LFGA3  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF CRType City  \\\n",
       "0    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "1    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "2    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "3    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "4    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "\n",
       "   CityID State     DayZero RegionW  RegionX  RegionY RegionZ  TeamID  \\\n",
       "0     NaN   NaN  10/27/1997    East  Midwest  Mideast    West    3104   \n",
       "1     NaN   NaN  10/27/1997    East  Midwest  Mideast    West    3112   \n",
       "2     NaN   NaN  10/27/1997    East  Midwest  Mideast    West    3163   \n",
       "3     NaN   NaN  10/27/1997    East  Midwest  Mideast    West    3198   \n",
       "4     NaN   NaN  10/27/1997    East  Midwest  Mideast    West    3203   \n",
       "\n",
       "       TeamName  \n",
       "0       Alabama  \n",
       "1       Arizona  \n",
       "2   Connecticut  \n",
       "3  Florida Intl  \n",
       "4  G Washington  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge with WTeams\n",
    "columns3 = Teams.columns.difference(train.columns).tolist()\n",
    "train = train.merge(Teams[columns3], how=\"left\", left_on=[\"WTeamID\"], right_on=[\"TeamID\"])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['TeamID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>WFGA3</th>\n",
       "      <th>WFTM</th>\n",
       "      <th>WFTA</th>\n",
       "      <th>WOR</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WAst</th>\n",
       "      <th>WTO</th>\n",
       "      <th>WStl</th>\n",
       "      <th>WBlk</th>\n",
       "      <th>WPF</th>\n",
       "      <th>LFGM</th>\n",
       "      <th>LFGA</th>\n",
       "      <th>LFGM3</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>State</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>RegionW</th>\n",
       "      <th>RegionX</th>\n",
       "      <th>RegionY</th>\n",
       "      <th>RegionZ</th>\n",
       "      <th>TeamName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3104</td>\n",
       "      <td>94</td>\n",
       "      <td>3422</td>\n",
       "      <td>46</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3112</td>\n",
       "      <td>75</td>\n",
       "      <td>3365</td>\n",
       "      <td>63</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3163</td>\n",
       "      <td>93</td>\n",
       "      <td>3193</td>\n",
       "      <td>52</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Connecticut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3198</td>\n",
       "      <td>59</td>\n",
       "      <td>3266</td>\n",
       "      <td>45</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Florida Intl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3203</td>\n",
       "      <td>74</td>\n",
       "      <td>3208</td>\n",
       "      <td>72</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>G Washington</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
       "0    1998     137     3104      94     3422      46    H      0   NaN   NaN   \n",
       "1    1998     137     3112      75     3365      63    H      0   NaN   NaN   \n",
       "2    1998     137     3163      93     3193      52    H      0   NaN   NaN   \n",
       "3    1998     137     3198      59     3266      45    H      0   NaN   NaN   \n",
       "4    1998     137     3203      74     3208      72    A      0   NaN   NaN   \n",
       "\n",
       "   WFGM3  WFGA3  WFTM  WFTA  WOR  WDR  WAst  WTO  WStl  WBlk  WPF  LFGM  LFGA  \\\n",
       "0    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "1    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "2    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "3    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "4    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "\n",
       "   LFGM3  LFGA3  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF CRType City  \\\n",
       "0    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "1    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "2    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "3    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "4    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "\n",
       "   CityID State     DayZero RegionW  RegionX  RegionY RegionZ      TeamName  \n",
       "0     NaN   NaN  10/27/1997    East  Midwest  Mideast    West       Alabama  \n",
       "1     NaN   NaN  10/27/1997    East  Midwest  Mideast    West       Arizona  \n",
       "2     NaN   NaN  10/27/1997    East  Midwest  Mideast    West   Connecticut  \n",
       "3     NaN   NaN  10/27/1997    East  Midwest  Mideast    West  Florida Intl  \n",
       "4     NaN   NaN  10/27/1997    East  Midwest  Mideast    West  G Washington  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>WFGA3</th>\n",
       "      <th>WFTM</th>\n",
       "      <th>WFTA</th>\n",
       "      <th>WOR</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WAst</th>\n",
       "      <th>WTO</th>\n",
       "      <th>WStl</th>\n",
       "      <th>WBlk</th>\n",
       "      <th>WPF</th>\n",
       "      <th>LFGM</th>\n",
       "      <th>LFGA</th>\n",
       "      <th>LFGM3</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>State</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>RegionW</th>\n",
       "      <th>RegionX</th>\n",
       "      <th>RegionY</th>\n",
       "      <th>RegionZ</th>\n",
       "      <th>TeamName_W</th>\n",
       "      <th>TeamName_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3104</td>\n",
       "      <td>94</td>\n",
       "      <td>3422</td>\n",
       "      <td>46</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>UNC Greensboro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3112</td>\n",
       "      <td>75</td>\n",
       "      <td>3365</td>\n",
       "      <td>63</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Santa Clara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3163</td>\n",
       "      <td>93</td>\n",
       "      <td>3193</td>\n",
       "      <td>52</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Fairfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3198</td>\n",
       "      <td>59</td>\n",
       "      <td>3266</td>\n",
       "      <td>45</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Florida Intl</td>\n",
       "      <td>Marquette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3203</td>\n",
       "      <td>74</td>\n",
       "      <td>3208</td>\n",
       "      <td>72</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>G Washington</td>\n",
       "      <td>Georgia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
       "0    1998     137     3104      94     3422      46    H      0   NaN   NaN   \n",
       "1    1998     137     3112      75     3365      63    H      0   NaN   NaN   \n",
       "2    1998     137     3163      93     3193      52    H      0   NaN   NaN   \n",
       "3    1998     137     3198      59     3266      45    H      0   NaN   NaN   \n",
       "4    1998     137     3203      74     3208      72    A      0   NaN   NaN   \n",
       "\n",
       "   WFGM3  WFGA3  WFTM  WFTA  WOR  WDR  WAst  WTO  WStl  WBlk  WPF  LFGM  LFGA  \\\n",
       "0    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "1    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "2    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "3    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "4    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "\n",
       "   LFGM3  LFGA3  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF CRType City  \\\n",
       "0    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "1    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "2    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "3    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "4    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "\n",
       "   CityID State     DayZero RegionW  RegionX  RegionY RegionZ    TeamName_W  \\\n",
       "0     NaN   NaN  10/27/1997    East  Midwest  Mideast    West       Alabama   \n",
       "1     NaN   NaN  10/27/1997    East  Midwest  Mideast    West       Arizona   \n",
       "2     NaN   NaN  10/27/1997    East  Midwest  Mideast    West   Connecticut   \n",
       "3     NaN   NaN  10/27/1997    East  Midwest  Mideast    West  Florida Intl   \n",
       "4     NaN   NaN  10/27/1997    East  Midwest  Mideast    West  G Washington   \n",
       "\n",
       "       TeamName_L  \n",
       "0  UNC Greensboro  \n",
       "1     Santa Clara  \n",
       "2       Fairfield  \n",
       "3       Marquette  \n",
       "4         Georgia  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(Teams[columns3], how=\"left\", left_on=[\"LTeamID\"], right_on=[\"TeamID\"], suffixes=('_W', '_L'))\n",
    "train.drop(['TeamID'], axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429, 45)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with WNCAATourneySeeds\n",
    "columns4 = TourneySeeds.columns.difference(train.columns).tolist() + ['Season']\n",
    "train = train.merge(TourneySeeds[columns4].drop_duplicates(subset=[\"Season\",\"TeamID\"]),\n",
    "                    how='left', left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'])\n",
    "train.drop(['TeamID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>WFGA3</th>\n",
       "      <th>WFTM</th>\n",
       "      <th>WFTA</th>\n",
       "      <th>WOR</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WAst</th>\n",
       "      <th>WTO</th>\n",
       "      <th>WStl</th>\n",
       "      <th>WBlk</th>\n",
       "      <th>WPF</th>\n",
       "      <th>LFGM</th>\n",
       "      <th>LFGA</th>\n",
       "      <th>LFGM3</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>State</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>RegionW</th>\n",
       "      <th>RegionX</th>\n",
       "      <th>RegionY</th>\n",
       "      <th>RegionZ</th>\n",
       "      <th>TeamName_W</th>\n",
       "      <th>TeamName_L</th>\n",
       "      <th>Seed_W</th>\n",
       "      <th>Seed_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3104</td>\n",
       "      <td>94</td>\n",
       "      <td>3422</td>\n",
       "      <td>46</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>UNC Greensboro</td>\n",
       "      <td>X02</td>\n",
       "      <td>X15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3112</td>\n",
       "      <td>75</td>\n",
       "      <td>3365</td>\n",
       "      <td>63</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>W03</td>\n",
       "      <td>W14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3163</td>\n",
       "      <td>93</td>\n",
       "      <td>3193</td>\n",
       "      <td>52</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>W02</td>\n",
       "      <td>W15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3198</td>\n",
       "      <td>59</td>\n",
       "      <td>3266</td>\n",
       "      <td>45</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Florida Intl</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>Y07</td>\n",
       "      <td>Y10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3203</td>\n",
       "      <td>74</td>\n",
       "      <td>3208</td>\n",
       "      <td>72</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>G Washington</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>W10</td>\n",
       "      <td>W07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
       "0    1998     137     3104      94     3422      46    H      0   NaN   NaN   \n",
       "1    1998     137     3112      75     3365      63    H      0   NaN   NaN   \n",
       "2    1998     137     3163      93     3193      52    H      0   NaN   NaN   \n",
       "3    1998     137     3198      59     3266      45    H      0   NaN   NaN   \n",
       "4    1998     137     3203      74     3208      72    A      0   NaN   NaN   \n",
       "\n",
       "   WFGM3  WFGA3  WFTM  WFTA  WOR  WDR  WAst  WTO  WStl  WBlk  WPF  LFGM  LFGA  \\\n",
       "0    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "1    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "2    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "3    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "4    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "\n",
       "   LFGM3  LFGA3  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF CRType City  \\\n",
       "0    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "1    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "2    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "3    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "4    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN    NaN  NaN   \n",
       "\n",
       "   CityID State     DayZero RegionW  RegionX  RegionY RegionZ    TeamName_W  \\\n",
       "0     NaN   NaN  10/27/1997    East  Midwest  Mideast    West       Alabama   \n",
       "1     NaN   NaN  10/27/1997    East  Midwest  Mideast    West       Arizona   \n",
       "2     NaN   NaN  10/27/1997    East  Midwest  Mideast    West   Connecticut   \n",
       "3     NaN   NaN  10/27/1997    East  Midwest  Mideast    West  Florida Intl   \n",
       "4     NaN   NaN  10/27/1997    East  Midwest  Mideast    West  G Washington   \n",
       "\n",
       "       TeamName_L Seed_W Seed_L  \n",
       "0  UNC Greensboro    X02    X15  \n",
       "1     Santa Clara    W03    W14  \n",
       "2       Fairfield    W02    W15  \n",
       "3       Marquette    Y07    Y10  \n",
       "4         Georgia    W10    W07  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(TourneySeeds[columns4].drop_duplicates(subset=[\"Season\",\"TeamID\"]),\n",
    "                    how='left', left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'], suffixes=('_W', '_L'))\n",
    "train.drop(['TeamID'], axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429, 47)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Season  WTeamID  LTeamID CRType City  CityID  DayNum State\n",
       "0  2015_3106_3107    2015     3106     3107    NaN  NaN     NaN     NaN   NaN\n",
       "1  2015_3106_3110    2015     3106     3110    NaN  NaN     NaN     NaN   NaN\n",
       "2  2015_3106_3113    2015     3106     3113    NaN  NaN     NaN     NaN   NaN\n",
       "3  2015_3106_3114    2015     3106     3114    NaN  NaN     NaN     NaN   NaN\n",
       "4  2015_3106_3116    2015     3106     3116    NaN  NaN     NaN     NaN   NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do same with Test set\n",
    "# merge with Game Cities\n",
    "columns5 = GameCities.columns.difference(test.columns).tolist() + [\"Season\", \"WTeamID\", \"LTeamID\"]\n",
    "test = test.merge(GameCities[columns5].drop_duplicates(subset=[\"Season\", \"WTeamID\", \"LTeamID\"]),\n",
    "                  how=\"left\", on=[\"Season\", \"WTeamID\", \"LTeamID\"])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>State</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>RegionW</th>\n",
       "      <th>RegionX</th>\n",
       "      <th>RegionY</th>\n",
       "      <th>RegionZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Season  WTeamID  LTeamID CRType City  CityID  DayNum State  \\\n",
       "0  2015_3106_3107    2015     3106     3107    NaN  NaN     NaN     NaN   NaN   \n",
       "1  2015_3106_3110    2015     3106     3110    NaN  NaN     NaN     NaN   NaN   \n",
       "2  2015_3106_3113    2015     3106     3113    NaN  NaN     NaN     NaN   NaN   \n",
       "3  2015_3106_3114    2015     3106     3114    NaN  NaN     NaN     NaN   NaN   \n",
       "4  2015_3106_3116    2015     3106     3116    NaN  NaN     NaN     NaN   NaN   \n",
       "\n",
       "     DayZero RegionW  RegionX     RegionY       RegionZ  \n",
       "0  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  \n",
       "1  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  \n",
       "2  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  \n",
       "3  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  \n",
       "4  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge with WSeasons\n",
    "columns6 = Seasons.columns.difference(test.columns).tolist() + [\"Season\"]\n",
    "test = test.merge(Seasons[columns6].drop_duplicates(subset=[\"Season\"]),\n",
    "                  how=\"left\", on= \"Season\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>State</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>RegionW</th>\n",
       "      <th>RegionX</th>\n",
       "      <th>RegionY</th>\n",
       "      <th>RegionZ</th>\n",
       "      <th>TeamName_W</th>\n",
       "      <th>TeamName_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>SUNY Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>American Univ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>Arizona St</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>Ark Little Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Season  WTeamID  LTeamID CRType City  CityID  DayNum State  \\\n",
       "0  2015_3106_3107    2015     3106     3107    NaN  NaN     NaN     NaN   NaN   \n",
       "1  2015_3106_3110    2015     3106     3110    NaN  NaN     NaN     NaN   NaN   \n",
       "2  2015_3106_3113    2015     3106     3113    NaN  NaN     NaN     NaN   NaN   \n",
       "3  2015_3106_3114    2015     3106     3114    NaN  NaN     NaN     NaN   NaN   \n",
       "4  2015_3106_3116    2015     3106     3116    NaN  NaN     NaN     NaN   NaN   \n",
       "\n",
       "     DayZero RegionW  RegionX     RegionY       RegionZ  TeamName_W  \\\n",
       "0  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "1  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "2  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "3  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "4  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "\n",
       "        TeamName_L  \n",
       "0      SUNY Albany  \n",
       "1    American Univ  \n",
       "2       Arizona St  \n",
       "3  Ark Little Rock  \n",
       "4         Arkansas  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge with WTeams\n",
    "columns7 = Teams.columns.difference(test.columns).tolist()\n",
    "test = test.merge(Teams[columns7].drop_duplicates(subset=[\"TeamID\"]),\n",
    "                  how=\"left\", left_on=[\"WTeamID\"], right_on=[\"TeamID\"])\n",
    "test.drop(['TeamID'], axis=1, inplace=True)\n",
    "test = test.merge(Teams[columns7].drop_duplicates(subset=[\"TeamID\"]),\n",
    "                  how=\"left\", left_on=[\"LTeamID\"], right_on=[\"TeamID\"], suffixes=('_W', '_L'))\n",
    "test.drop(['TeamID'], axis=1, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>State</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>RegionW</th>\n",
       "      <th>RegionX</th>\n",
       "      <th>RegionY</th>\n",
       "      <th>RegionZ</th>\n",
       "      <th>TeamName_W</th>\n",
       "      <th>TeamName_L</th>\n",
       "      <th>Seed_W</th>\n",
       "      <th>Seed_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>SUNY Albany</td>\n",
       "      <td>Y15</td>\n",
       "      <td>X13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>American Univ</td>\n",
       "      <td>Y15</td>\n",
       "      <td>Z14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>Arizona St</td>\n",
       "      <td>Y15</td>\n",
       "      <td>Y03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>Ark Little Rock</td>\n",
       "      <td>Y15</td>\n",
       "      <td>Y11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Y15</td>\n",
       "      <td>Z10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Season  WTeamID  LTeamID CRType City  CityID  DayNum State  \\\n",
       "0  2015_3106_3107    2015     3106     3107    NaN  NaN     NaN     NaN   NaN   \n",
       "1  2015_3106_3110    2015     3106     3110    NaN  NaN     NaN     NaN   NaN   \n",
       "2  2015_3106_3113    2015     3106     3113    NaN  NaN     NaN     NaN   NaN   \n",
       "3  2015_3106_3114    2015     3106     3114    NaN  NaN     NaN     NaN   NaN   \n",
       "4  2015_3106_3116    2015     3106     3116    NaN  NaN     NaN     NaN   NaN   \n",
       "\n",
       "     DayZero RegionW  RegionX     RegionY       RegionZ  TeamName_W  \\\n",
       "0  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "1  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "2  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "3  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "4  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "\n",
       "        TeamName_L Seed_W Seed_L  \n",
       "0      SUNY Albany    Y15    X13  \n",
       "1    American Univ    Y15    Z14  \n",
       "2       Arizona St    Y15    Y03  \n",
       "3  Ark Little Rock    Y15    Y11  \n",
       "4         Arkansas    Y15    Z10  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge with WNCAATourneySeeds\n",
    "columns8 = TourneySeeds.columns.difference(test.columns).tolist() + ['Season']\n",
    "test = test.merge(TourneySeeds[columns8].drop_duplicates(subset=[\"Season\",\"TeamID\"]),\n",
    "                  how='left', left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'])\n",
    "test.drop(['TeamID'], axis=1, inplace=True)\n",
    "test = test.merge(TourneySeeds[columns8].drop_duplicates(subset=[\"Season\",\"TeamID\"]),\n",
    "                  how='left', left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'], suffixes=('_W', '_L'))\n",
    "test.drop(['TeamID'], axis=1, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10080, 18)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WScore', 'LScore', 'WLoc', 'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']\n"
     ]
    }
   ],
   "source": [
    "# Exclude variables that are in Train-set, but does not in Test-set\n",
    "columns9 = [c for c in train.columns.values.tolist() if c not in test.columns.values.tolist()]\n",
    "print(columns9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>State</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>RegionW</th>\n",
       "      <th>RegionX</th>\n",
       "      <th>RegionY</th>\n",
       "      <th>RegionZ</th>\n",
       "      <th>TeamName_W</th>\n",
       "      <th>TeamName_L</th>\n",
       "      <th>Seed_W</th>\n",
       "      <th>Seed_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3104</td>\n",
       "      <td>3422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>UNC Greensboro</td>\n",
       "      <td>X02</td>\n",
       "      <td>X15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3112</td>\n",
       "      <td>3365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>W03</td>\n",
       "      <td>W14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3163</td>\n",
       "      <td>3193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>W02</td>\n",
       "      <td>W15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3198</td>\n",
       "      <td>3266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Florida Intl</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>Y07</td>\n",
       "      <td>Y10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3203</td>\n",
       "      <td>3208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>G Washington</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>W10</td>\n",
       "      <td>W07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  LTeamID CRType City  CityID State     DayZero  \\\n",
       "0    1998     137     3104     3422    NaN  NaN     NaN   NaN  10/27/1997   \n",
       "1    1998     137     3112     3365    NaN  NaN     NaN   NaN  10/27/1997   \n",
       "2    1998     137     3163     3193    NaN  NaN     NaN   NaN  10/27/1997   \n",
       "3    1998     137     3198     3266    NaN  NaN     NaN   NaN  10/27/1997   \n",
       "4    1998     137     3203     3208    NaN  NaN     NaN   NaN  10/27/1997   \n",
       "\n",
       "  RegionW  RegionX  RegionY RegionZ    TeamName_W      TeamName_L Seed_W  \\\n",
       "0    East  Midwest  Mideast    West       Alabama  UNC Greensboro    X02   \n",
       "1    East  Midwest  Mideast    West       Arizona     Santa Clara    W03   \n",
       "2    East  Midwest  Mideast    West   Connecticut       Fairfield    W02   \n",
       "3    East  Midwest  Mideast    West  Florida Intl       Marquette    Y07   \n",
       "4    East  Midwest  Mideast    West  G Washington         Georgia    W10   \n",
       "\n",
       "  Seed_L  \n",
       "0    X15  \n",
       "1    W14  \n",
       "2    W15  \n",
       "3    Y10  \n",
       "4    W07  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(columns9, axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to datetime format\n",
    "train[\"DayZero\"] = pd.to_datetime(train[\"DayZero\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by date\n",
    "train = train.sort_values(by=[\"DayZero\", \"Season\", \"DayNum\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>State</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>RegionW</th>\n",
       "      <th>RegionX</th>\n",
       "      <th>RegionY</th>\n",
       "      <th>RegionZ</th>\n",
       "      <th>TeamName_W</th>\n",
       "      <th>TeamName_L</th>\n",
       "      <th>Seed_W</th>\n",
       "      <th>Seed_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3104</td>\n",
       "      <td>3422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-10-27</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>UNC Greensboro</td>\n",
       "      <td>X02</td>\n",
       "      <td>X15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3112</td>\n",
       "      <td>3365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-10-27</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>W03</td>\n",
       "      <td>W14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3163</td>\n",
       "      <td>3193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-10-27</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>W02</td>\n",
       "      <td>W15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3198</td>\n",
       "      <td>3266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-10-27</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Florida Intl</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>Y07</td>\n",
       "      <td>Y10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3203</td>\n",
       "      <td>3208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-10-27</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>G Washington</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>W10</td>\n",
       "      <td>W07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  LTeamID CRType City  CityID State    DayZero  \\\n",
       "0    1998     137     3104     3422    NaN  NaN     NaN   NaN 1997-10-27   \n",
       "1    1998     137     3112     3365    NaN  NaN     NaN   NaN 1997-10-27   \n",
       "2    1998     137     3163     3193    NaN  NaN     NaN   NaN 1997-10-27   \n",
       "3    1998     137     3198     3266    NaN  NaN     NaN   NaN 1997-10-27   \n",
       "4    1998     137     3203     3208    NaN  NaN     NaN   NaN 1997-10-27   \n",
       "\n",
       "  RegionW  RegionX  RegionY RegionZ    TeamName_W      TeamName_L Seed_W  \\\n",
       "0    East  Midwest  Mideast    West       Alabama  UNC Greensboro    X02   \n",
       "1    East  Midwest  Mideast    West       Arizona     Santa Clara    W03   \n",
       "2    East  Midwest  Mideast    West   Connecticut       Fairfield    W02   \n",
       "3    East  Midwest  Mideast    West  Florida Intl       Marquette    Y07   \n",
       "4    East  Midwest  Mideast    West  G Washington         Georgia    W10   \n",
       "\n",
       "  Seed_L  \n",
       "0    X15  \n",
       "1    W14  \n",
       "2    W15  \n",
       "3    Y10  \n",
       "4    W07  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>State</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>RegionW</th>\n",
       "      <th>RegionX</th>\n",
       "      <th>RegionY</th>\n",
       "      <th>RegionZ</th>\n",
       "      <th>TeamName_W</th>\n",
       "      <th>TeamName_L</th>\n",
       "      <th>Seed_W</th>\n",
       "      <th>Seed_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>SUNY Albany</td>\n",
       "      <td>Y15</td>\n",
       "      <td>X13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>American Univ</td>\n",
       "      <td>Y15</td>\n",
       "      <td>Z14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>Arizona St</td>\n",
       "      <td>Y15</td>\n",
       "      <td>Y03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>Ark Little Rock</td>\n",
       "      <td>Y15</td>\n",
       "      <td>Y11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Y15</td>\n",
       "      <td>Z10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Season  WTeamID  LTeamID CRType City  CityID  DayNum State  \\\n",
       "0  2015_3106_3107    2015     3106     3107    NaN  NaN     NaN     NaN   NaN   \n",
       "1  2015_3106_3110    2015     3106     3110    NaN  NaN     NaN     NaN   NaN   \n",
       "2  2015_3106_3113    2015     3106     3113    NaN  NaN     NaN     NaN   NaN   \n",
       "3  2015_3106_3114    2015     3106     3114    NaN  NaN     NaN     NaN   NaN   \n",
       "4  2015_3106_3116    2015     3106     3116    NaN  NaN     NaN     NaN   NaN   \n",
       "\n",
       "     DayZero RegionW  RegionX     RegionY       RegionZ  TeamName_W  \\\n",
       "0  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "1  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "2  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "3  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "4  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "\n",
       "        TeamName_L Seed_W Seed_L  \n",
       "0      SUNY Albany    Y15    X13  \n",
       "1    American Univ    Y15    Z14  \n",
       "2       Arizona St    Y15    Y03  \n",
       "3  Ark Little Rock    Y15    Y11  \n",
       "4         Arkansas    Y15    Z10  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Season CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_regularSeason(df, regularSeason):\n",
    "    df_new = pd.DataFrame()\n",
    "    for i, season in enumerate(df[\"Season\"].unique()):\n",
    "        print(season)\n",
    "        if season <= 1998:\n",
    "            continue\n",
    "            \n",
    "        # split winners and losers (make sure not to use the future data!)\n",
    "        team_win_score = regularSeason.loc[regularSeason[\"Season\"] <= season, :].groupby(['WTeamID']).agg({'WScore':['sum', 'count', 'var']}).reset_index()\n",
    "        team_win_score.columns = [' '.join(col).strip() for col in team_win_score.columns.values]\n",
    "        team_loss_score = regularSeason.loc[regularSeason[\"Season\"] <= season, :].groupby(['LTeamID']).agg({'LScore':['sum', 'count', 'var']}).reset_index()\n",
    "        team_loss_score.columns = [' '.join(col).strip() for col in team_loss_score.columns.values]\n",
    "        \n",
    "        # merge with train \n",
    "        team_win_score[\"Season\"] = season\n",
    "        team_loss_score[\"Season\"] = season\n",
    "        df_fold = df.loc[df[\"Season\"] == season, :].reset_index(drop=True)\n",
    "        df_fold = df_fold.merge(team_win_score, how='left', left_on=['Season', 'WTeamID'], right_on=['Season', 'WTeamID'])\n",
    "        df_fold = df_fold.merge(team_loss_score, how='left', left_on=['Season', 'LTeamID'], right_on=['Season', 'LTeamID'])\n",
    "        df_fold = df_fold.merge(team_loss_score, how='left', left_on=['Season', 'WTeamID'], right_on=['Season', 'LTeamID'])\n",
    "        df_fold = df_fold.merge(team_win_score, how='left', left_on=['Season', 'LTeamID_x'], right_on=['Season', 'WTeamID'])\n",
    "        df_fold.drop(['LTeamID_y', 'WTeamID_y'], axis=1, inplace=True)\n",
    "        \n",
    "        # restore\n",
    "        df_new = pd.concat([df_new, df_fold], ignore_index=True)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "train = merge_regularSeason(train, SeasonCompactResults)\n",
    "test = merge_regularSeason(test, SeasonCompactResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition(table):\n",
    "    table['x_score'] = table['WScore sum_x'] + table['LScore sum_y']\n",
    "    table['y_score'] = table['WScore sum_y'] + table['LScore sum_x']\n",
    "    table['x_count'] = table['WScore count_x'] + table['LScore count_y']\n",
    "    table['y_count'] = table['WScore count_y'] + table['WScore count_x']\n",
    "    table['x_var'] = table['WScore var_x'] + table['LScore var_y']\n",
    "    table['y_var'] = table['WScore var_y'] + table['WScore var_x']\n",
    "    return table\n",
    "train = addition(train)\n",
    "test = addition(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID_x</th>\n",
       "      <th>LTeamID_x</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>State</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>RegionW</th>\n",
       "      <th>RegionX</th>\n",
       "      <th>RegionY</th>\n",
       "      <th>RegionZ</th>\n",
       "      <th>TeamName_W</th>\n",
       "      <th>TeamName_L</th>\n",
       "      <th>Seed_W</th>\n",
       "      <th>Seed_L</th>\n",
       "      <th>WScore sum_x</th>\n",
       "      <th>WScore count_x</th>\n",
       "      <th>WScore var_x</th>\n",
       "      <th>LScore sum_x</th>\n",
       "      <th>LScore count_x</th>\n",
       "      <th>LScore var_x</th>\n",
       "      <th>LScore sum_y</th>\n",
       "      <th>LScore count_y</th>\n",
       "      <th>LScore var_y</th>\n",
       "      <th>WScore sum_y</th>\n",
       "      <th>WScore count_y</th>\n",
       "      <th>WScore var_y</th>\n",
       "      <th>x_score</th>\n",
       "      <th>y_score</th>\n",
       "      <th>x_count</th>\n",
       "      <th>y_count</th>\n",
       "      <th>x_var</th>\n",
       "      <th>y_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>3104</td>\n",
       "      <td>3212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>East</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>West</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Grambling</td>\n",
       "      <td>Y05</td>\n",
       "      <td>Y12</td>\n",
       "      <td>3229</td>\n",
       "      <td>40</td>\n",
       "      <td>131.845513</td>\n",
       "      <td>664</td>\n",
       "      <td>10</td>\n",
       "      <td>149.822222</td>\n",
       "      <td>1335</td>\n",
       "      <td>19</td>\n",
       "      <td>84.315789</td>\n",
       "      <td>3389</td>\n",
       "      <td>39</td>\n",
       "      <td>132.041835</td>\n",
       "      <td>4564</td>\n",
       "      <td>4053</td>\n",
       "      <td>59</td>\n",
       "      <td>79</td>\n",
       "      <td>216.161302</td>\n",
       "      <td>263.887348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>3112</td>\n",
       "      <td>3196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>East</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>West</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Y06</td>\n",
       "      <td>Y11</td>\n",
       "      <td>3044</td>\n",
       "      <td>38</td>\n",
       "      <td>90.907539</td>\n",
       "      <td>1391</td>\n",
       "      <td>21</td>\n",
       "      <td>86.490476</td>\n",
       "      <td>1090</td>\n",
       "      <td>16</td>\n",
       "      <td>109.450000</td>\n",
       "      <td>3160</td>\n",
       "      <td>40</td>\n",
       "      <td>166.256410</td>\n",
       "      <td>4134</td>\n",
       "      <td>4551</td>\n",
       "      <td>54</td>\n",
       "      <td>78</td>\n",
       "      <td>200.357539</td>\n",
       "      <td>257.163949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>3155</td>\n",
       "      <td>3197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>East</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>West</td>\n",
       "      <td>Clemson</td>\n",
       "      <td>Florida A&amp;M</td>\n",
       "      <td>X02</td>\n",
       "      <td>X15</td>\n",
       "      <td>3520</td>\n",
       "      <td>46</td>\n",
       "      <td>152.255072</td>\n",
       "      <td>1148</td>\n",
       "      <td>18</td>\n",
       "      <td>76.418301</td>\n",
       "      <td>792</td>\n",
       "      <td>13</td>\n",
       "      <td>122.743590</td>\n",
       "      <td>2331</td>\n",
       "      <td>33</td>\n",
       "      <td>76.363636</td>\n",
       "      <td>4312</td>\n",
       "      <td>3479</td>\n",
       "      <td>59</td>\n",
       "      <td>79</td>\n",
       "      <td>274.998662</td>\n",
       "      <td>228.618709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>3161</td>\n",
       "      <td>3169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>East</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>West</td>\n",
       "      <td>Colorado St</td>\n",
       "      <td>CS Northridge</td>\n",
       "      <td>Z02</td>\n",
       "      <td>Z15</td>\n",
       "      <td>4279</td>\n",
       "      <td>52</td>\n",
       "      <td>142.091629</td>\n",
       "      <td>1226</td>\n",
       "      <td>20</td>\n",
       "      <td>110.115789</td>\n",
       "      <td>465</td>\n",
       "      <td>7</td>\n",
       "      <td>269.619048</td>\n",
       "      <td>2401</td>\n",
       "      <td>33</td>\n",
       "      <td>75.126894</td>\n",
       "      <td>4744</td>\n",
       "      <td>3627</td>\n",
       "      <td>59</td>\n",
       "      <td>85</td>\n",
       "      <td>411.710677</td>\n",
       "      <td>217.218523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>3163</td>\n",
       "      <td>3384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>East</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>West</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>St Francis PA</td>\n",
       "      <td>X01</td>\n",
       "      <td>X16</td>\n",
       "      <td>5116</td>\n",
       "      <td>57</td>\n",
       "      <td>221.224311</td>\n",
       "      <td>1048</td>\n",
       "      <td>18</td>\n",
       "      <td>117.124183</td>\n",
       "      <td>439</td>\n",
       "      <td>6</td>\n",
       "      <td>32.566667</td>\n",
       "      <td>2812</td>\n",
       "      <td>38</td>\n",
       "      <td>119.135135</td>\n",
       "      <td>5555</td>\n",
       "      <td>3860</td>\n",
       "      <td>63</td>\n",
       "      <td>95</td>\n",
       "      <td>253.790977</td>\n",
       "      <td>340.359446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID_x  LTeamID_x CRType City  CityID State    DayZero  \\\n",
       "0    1999     137       3104       3212    NaN  NaN     NaN   NaN 1998-10-26   \n",
       "1    1999     137       3112       3196    NaN  NaN     NaN   NaN 1998-10-26   \n",
       "2    1999     137       3155       3197    NaN  NaN     NaN   NaN 1998-10-26   \n",
       "3    1999     137       3161       3169    NaN  NaN     NaN   NaN 1998-10-26   \n",
       "4    1999     137       3163       3384    NaN  NaN     NaN   NaN 1998-10-26   \n",
       "\n",
       "  RegionW  RegionX  RegionY RegionZ   TeamName_W     TeamName_L Seed_W Seed_L  \\\n",
       "0    East  Mideast  Midwest    West      Alabama      Grambling    Y05    Y12   \n",
       "1    East  Mideast  Midwest    West      Arizona        Florida    Y06    Y11   \n",
       "2    East  Mideast  Midwest    West      Clemson    Florida A&M    X02    X15   \n",
       "3    East  Mideast  Midwest    West  Colorado St  CS Northridge    Z02    Z15   \n",
       "4    East  Mideast  Midwest    West  Connecticut  St Francis PA    X01    X16   \n",
       "\n",
       "   WScore sum_x  WScore count_x  WScore var_x  LScore sum_x  LScore count_x  \\\n",
       "0          3229              40    131.845513           664              10   \n",
       "1          3044              38     90.907539          1391              21   \n",
       "2          3520              46    152.255072          1148              18   \n",
       "3          4279              52    142.091629          1226              20   \n",
       "4          5116              57    221.224311          1048              18   \n",
       "\n",
       "   LScore var_x  LScore sum_y  LScore count_y  LScore var_y  WScore sum_y  \\\n",
       "0    149.822222          1335              19     84.315789          3389   \n",
       "1     86.490476          1090              16    109.450000          3160   \n",
       "2     76.418301           792              13    122.743590          2331   \n",
       "3    110.115789           465               7    269.619048          2401   \n",
       "4    117.124183           439               6     32.566667          2812   \n",
       "\n",
       "   WScore count_y  WScore var_y  x_score  y_score  x_count  y_count  \\\n",
       "0              39    132.041835     4564     4053       59       79   \n",
       "1              40    166.256410     4134     4551       54       78   \n",
       "2              33     76.363636     4312     3479       59       79   \n",
       "3              33     75.126894     4744     3627       59       85   \n",
       "4              38    119.135135     5555     3860       63       95   \n",
       "\n",
       "        x_var       y_var  \n",
       "0  216.161302  263.887348  \n",
       "1  200.357539  257.163949  \n",
       "2  274.998662  228.618709  \n",
       "3  411.710677  217.218523  \n",
       "4  253.790977  340.359446  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>WTeamID_x</th>\n",
       "      <th>LTeamID_x</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>State</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>RegionW</th>\n",
       "      <th>RegionX</th>\n",
       "      <th>RegionY</th>\n",
       "      <th>RegionZ</th>\n",
       "      <th>TeamName_W</th>\n",
       "      <th>TeamName_L</th>\n",
       "      <th>Seed_W</th>\n",
       "      <th>Seed_L</th>\n",
       "      <th>WScore sum_x</th>\n",
       "      <th>WScore count_x</th>\n",
       "      <th>WScore var_x</th>\n",
       "      <th>LScore sum_x</th>\n",
       "      <th>LScore count_x</th>\n",
       "      <th>LScore var_x</th>\n",
       "      <th>LScore sum_y</th>\n",
       "      <th>LScore count_y</th>\n",
       "      <th>LScore var_y</th>\n",
       "      <th>WScore sum_y</th>\n",
       "      <th>WScore count_y</th>\n",
       "      <th>WScore var_y</th>\n",
       "      <th>x_score</th>\n",
       "      <th>y_score</th>\n",
       "      <th>x_count</th>\n",
       "      <th>y_count</th>\n",
       "      <th>x_var</th>\n",
       "      <th>y_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>SUNY Albany</td>\n",
       "      <td>Y15</td>\n",
       "      <td>X13</td>\n",
       "      <td>15765</td>\n",
       "      <td>236</td>\n",
       "      <td>114.03251</td>\n",
       "      <td>13414</td>\n",
       "      <td>248</td>\n",
       "      <td>86.607483</td>\n",
       "      <td>13799</td>\n",
       "      <td>257</td>\n",
       "      <td>129.346547</td>\n",
       "      <td>14676</td>\n",
       "      <td>216</td>\n",
       "      <td>112.759690</td>\n",
       "      <td>29564</td>\n",
       "      <td>28090</td>\n",
       "      <td>493</td>\n",
       "      <td>452</td>\n",
       "      <td>243.379057</td>\n",
       "      <td>226.792200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>American Univ</td>\n",
       "      <td>Y15</td>\n",
       "      <td>Z14</td>\n",
       "      <td>15765</td>\n",
       "      <td>236</td>\n",
       "      <td>114.03251</td>\n",
       "      <td>13399</td>\n",
       "      <td>236</td>\n",
       "      <td>100.089776</td>\n",
       "      <td>13799</td>\n",
       "      <td>257</td>\n",
       "      <td>129.346547</td>\n",
       "      <td>19628</td>\n",
       "      <td>291</td>\n",
       "      <td>105.372509</td>\n",
       "      <td>29564</td>\n",
       "      <td>33027</td>\n",
       "      <td>493</td>\n",
       "      <td>527</td>\n",
       "      <td>243.379057</td>\n",
       "      <td>219.405019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>Arizona St</td>\n",
       "      <td>Y15</td>\n",
       "      <td>Y03</td>\n",
       "      <td>15765</td>\n",
       "      <td>236</td>\n",
       "      <td>114.03251</td>\n",
       "      <td>10932</td>\n",
       "      <td>191</td>\n",
       "      <td>91.338936</td>\n",
       "      <td>13799</td>\n",
       "      <td>257</td>\n",
       "      <td>129.346547</td>\n",
       "      <td>24404</td>\n",
       "      <td>347</td>\n",
       "      <td>112.868635</td>\n",
       "      <td>29564</td>\n",
       "      <td>35336</td>\n",
       "      <td>493</td>\n",
       "      <td>583</td>\n",
       "      <td>243.379057</td>\n",
       "      <td>226.901144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>Ark Little Rock</td>\n",
       "      <td>Y15</td>\n",
       "      <td>Y11</td>\n",
       "      <td>15765</td>\n",
       "      <td>236</td>\n",
       "      <td>114.03251</td>\n",
       "      <td>11356</td>\n",
       "      <td>208</td>\n",
       "      <td>91.169454</td>\n",
       "      <td>13799</td>\n",
       "      <td>257</td>\n",
       "      <td>129.346547</td>\n",
       "      <td>16853</td>\n",
       "      <td>260</td>\n",
       "      <td>97.723953</td>\n",
       "      <td>29564</td>\n",
       "      <td>28209</td>\n",
       "      <td>493</td>\n",
       "      <td>496</td>\n",
       "      <td>243.379057</td>\n",
       "      <td>211.756463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Y15</td>\n",
       "      <td>Z10</td>\n",
       "      <td>15765</td>\n",
       "      <td>236</td>\n",
       "      <td>114.03251</td>\n",
       "      <td>13268</td>\n",
       "      <td>224</td>\n",
       "      <td>113.667841</td>\n",
       "      <td>13799</td>\n",
       "      <td>257</td>\n",
       "      <td>129.346547</td>\n",
       "      <td>22905</td>\n",
       "      <td>310</td>\n",
       "      <td>136.352907</td>\n",
       "      <td>29564</td>\n",
       "      <td>36173</td>\n",
       "      <td>493</td>\n",
       "      <td>546</td>\n",
       "      <td>243.379057</td>\n",
       "      <td>250.385417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Season  WTeamID_x  LTeamID_x CRType City  CityID  DayNum  \\\n",
       "0  2015_3106_3107    2015       3106       3107    NaN  NaN     NaN     NaN   \n",
       "1  2015_3106_3110    2015       3106       3110    NaN  NaN     NaN     NaN   \n",
       "2  2015_3106_3113    2015       3106       3113    NaN  NaN     NaN     NaN   \n",
       "3  2015_3106_3114    2015       3106       3114    NaN  NaN     NaN     NaN   \n",
       "4  2015_3106_3116    2015       3106       3116    NaN  NaN     NaN     NaN   \n",
       "\n",
       "  State    DayZero RegionW  RegionX     RegionY       RegionZ  TeamName_W  \\\n",
       "0   NaN  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "1   NaN  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "2   NaN  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "3   NaN  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "4   NaN  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "\n",
       "        TeamName_L Seed_W Seed_L  WScore sum_x  WScore count_x  WScore var_x  \\\n",
       "0      SUNY Albany    Y15    X13         15765             236     114.03251   \n",
       "1    American Univ    Y15    Z14         15765             236     114.03251   \n",
       "2       Arizona St    Y15    Y03         15765             236     114.03251   \n",
       "3  Ark Little Rock    Y15    Y11         15765             236     114.03251   \n",
       "4         Arkansas    Y15    Z10         15765             236     114.03251   \n",
       "\n",
       "   LScore sum_x  LScore count_x  LScore var_x  LScore sum_y  LScore count_y  \\\n",
       "0         13414             248     86.607483         13799             257   \n",
       "1         13399             236    100.089776         13799             257   \n",
       "2         10932             191     91.338936         13799             257   \n",
       "3         11356             208     91.169454         13799             257   \n",
       "4         13268             224    113.667841         13799             257   \n",
       "\n",
       "   LScore var_y  WScore sum_y  WScore count_y  WScore var_y  x_score  y_score  \\\n",
       "0    129.346547         14676             216    112.759690    29564    28090   \n",
       "1    129.346547         19628             291    105.372509    29564    33027   \n",
       "2    129.346547         24404             347    112.868635    29564    35336   \n",
       "3    129.346547         16853             260     97.723953    29564    28209   \n",
       "4    129.346547         22905             310    136.352907    29564    36173   \n",
       "\n",
       "   x_count  y_count       x_var       y_var  \n",
       "0      493      452  243.379057  226.792200  \n",
       "1      493      527  243.379057  219.405019  \n",
       "2      493      583  243.379057  226.901144  \n",
       "3      493      496  243.379057  211.756463  \n",
       "4      493      546  243.379057  250.385417  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make winner and loser train\n",
    "train_win = train.copy()\n",
    "train_los = train.copy()\n",
    "train_win = train_win[['WTeamID_x','LTeamID_x','Season','DayNum', 'DayZero', 'Seed_W', 'Seed_L', 'x_score', 'y_score', 'x_count', 'y_count', 'x_var', 'y_var']]\n",
    "train_los = train_los[['WTeamID_x','LTeamID_x','Season','DayNum', 'DayZero','Seed_L', 'Seed_W', 'y_score', 'x_score', 'x_count', 'y_count', 'x_var', 'y_var']]\n",
    "train_win.columns = ['TeamName_1','TeamName_2','Season','DayNum', 'DayZero','Seed_1', 'Seed_2', 'Score_1', 'Score_2', 'Count_1', 'Count_2', 'Var_1', 'Var_2']\n",
    "train_los.columns = ['TeamName_1','TeamName_2','Season','DayNum', 'DayZero','Seed_1', 'Seed_2', 'Score_1', 'Score_2', 'Count_1', 'Count_2', 'Var_1', 'Var_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same processing for test\n",
    "test = test[['ID','WTeamID_x','LTeamID_x','Season','DayNum', 'Seed_W', 'Seed_L', 'x_score', 'y_score', 'x_count', 'y_count', 'x_var', 'y_var']]\n",
    "test.columns = ['ID','TeamName_1','TeamName_2','Season', 'DayNum', 'Seed_1', 'Seed_2', 'Score_1', 'Score_2', 'Count_1', 'Count_2', 'Var_1', 'Var_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seed(x):\n",
    "    return int(x[1:3])\n",
    "train_win['Seed_1'] = train_win['Seed_1'].map(lambda x: get_seed(x))\n",
    "train_win['Seed_2'] = train_win['Seed_2'].map(lambda x: get_seed(x))\n",
    "\n",
    "train_los['Seed_1'] = train_los['Seed_1'].map(lambda x: get_seed(x))\n",
    "train_los['Seed_2']= train_los['Seed_2'].map(lambda x: get_seed(x))\n",
    "\n",
    "test['Seed_1'] = test['Seed_1'].map(lambda x: get_seed(x))\n",
    "test['Seed_2']= test['Seed_2'].map(lambda x: get_seed(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_win[\"result\"] = 1\n",
    "train_los[\"result\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamName_1</th>\n",
       "      <th>TeamName_2</th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>Seed_1</th>\n",
       "      <th>Seed_2</th>\n",
       "      <th>Score_1</th>\n",
       "      <th>Score_2</th>\n",
       "      <th>Count_1</th>\n",
       "      <th>Count_2</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Var_2</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3104</td>\n",
       "      <td>3212</td>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>4564</td>\n",
       "      <td>4053</td>\n",
       "      <td>59</td>\n",
       "      <td>79</td>\n",
       "      <td>216.161302</td>\n",
       "      <td>263.887348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3112</td>\n",
       "      <td>3196</td>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>4134</td>\n",
       "      <td>4551</td>\n",
       "      <td>54</td>\n",
       "      <td>78</td>\n",
       "      <td>200.357539</td>\n",
       "      <td>257.163949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3155</td>\n",
       "      <td>3197</td>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4312</td>\n",
       "      <td>3479</td>\n",
       "      <td>59</td>\n",
       "      <td>79</td>\n",
       "      <td>274.998662</td>\n",
       "      <td>228.618709</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3161</td>\n",
       "      <td>3169</td>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4744</td>\n",
       "      <td>3627</td>\n",
       "      <td>59</td>\n",
       "      <td>85</td>\n",
       "      <td>411.710677</td>\n",
       "      <td>217.218523</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3163</td>\n",
       "      <td>3384</td>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5555</td>\n",
       "      <td>3860</td>\n",
       "      <td>63</td>\n",
       "      <td>95</td>\n",
       "      <td>253.790977</td>\n",
       "      <td>340.359446</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TeamName_1  TeamName_2  Season  DayNum    DayZero  Seed_1  Seed_2  Score_1  \\\n",
       "0        3104        3212    1999     137 1998-10-26       5      12     4564   \n",
       "1        3112        3196    1999     137 1998-10-26       6      11     4134   \n",
       "2        3155        3197    1999     137 1998-10-26       2      15     4312   \n",
       "3        3161        3169    1999     137 1998-10-26       2      15     4744   \n",
       "4        3163        3384    1999     137 1998-10-26       1      16     5555   \n",
       "\n",
       "   Score_2  Count_1  Count_2       Var_1       Var_2  result  \n",
       "0     4053       59       79  216.161302  263.887348       1  \n",
       "1     4551       54       78  200.357539  257.163949       1  \n",
       "2     3479       59       79  274.998662  228.618709       1  \n",
       "3     3627       59       85  411.710677  217.218523       1  \n",
       "4     3860       63       95  253.790977  340.359446       1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat((train_win, train_los)).reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamName_1</th>\n",
       "      <th>TeamName_2</th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>Seed_1</th>\n",
       "      <th>Seed_2</th>\n",
       "      <th>Score_1</th>\n",
       "      <th>Score_2</th>\n",
       "      <th>Count_1</th>\n",
       "      <th>Count_2</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Var_2</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3104</td>\n",
       "      <td>3212</td>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>4564</td>\n",
       "      <td>4053</td>\n",
       "      <td>59</td>\n",
       "      <td>79</td>\n",
       "      <td>216.161302</td>\n",
       "      <td>263.887348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3112</td>\n",
       "      <td>3196</td>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>4134</td>\n",
       "      <td>4551</td>\n",
       "      <td>54</td>\n",
       "      <td>78</td>\n",
       "      <td>200.357539</td>\n",
       "      <td>257.163949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3155</td>\n",
       "      <td>3197</td>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4312</td>\n",
       "      <td>3479</td>\n",
       "      <td>59</td>\n",
       "      <td>79</td>\n",
       "      <td>274.998662</td>\n",
       "      <td>228.618709</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3161</td>\n",
       "      <td>3169</td>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4744</td>\n",
       "      <td>3627</td>\n",
       "      <td>59</td>\n",
       "      <td>85</td>\n",
       "      <td>411.710677</td>\n",
       "      <td>217.218523</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3163</td>\n",
       "      <td>3384</td>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5555</td>\n",
       "      <td>3860</td>\n",
       "      <td>63</td>\n",
       "      <td>95</td>\n",
       "      <td>253.790977</td>\n",
       "      <td>340.359446</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TeamName_1  TeamName_2  Season  DayNum    DayZero  Seed_1  Seed_2  Score_1  \\\n",
       "0        3104        3212    1999     137 1998-10-26       5      12     4564   \n",
       "1        3112        3196    1999     137 1998-10-26       6      11     4134   \n",
       "2        3155        3197    1999     137 1998-10-26       2      15     4312   \n",
       "3        3161        3169    1999     137 1998-10-26       2      15     4744   \n",
       "4        3163        3384    1999     137 1998-10-26       1      16     5555   \n",
       "\n",
       "   Score_2  Count_1  Count_2       Var_1       Var_2  result  \n",
       "0     4053       59       79  216.161302  263.887348       1  \n",
       "1     4551       54       78  200.357539  257.163949       1  \n",
       "2     3479       59       79  274.998662  228.618709       1  \n",
       "3     3627       59       85  411.710677  217.218523       1  \n",
       "4     3860       63       95  253.790977  340.359446       1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.sort_values(by=['DayZero', 'DayNum']).reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TeamName_1</th>\n",
       "      <th>TeamName_2</th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>Seed_1</th>\n",
       "      <th>Seed_2</th>\n",
       "      <th>Score_1</th>\n",
       "      <th>Score_2</th>\n",
       "      <th>Count_1</th>\n",
       "      <th>Count_2</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Var_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>3106</td>\n",
       "      <td>3107</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>29564</td>\n",
       "      <td>28090</td>\n",
       "      <td>493</td>\n",
       "      <td>452</td>\n",
       "      <td>243.379057</td>\n",
       "      <td>226.792200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>3106</td>\n",
       "      <td>3110</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>29564</td>\n",
       "      <td>33027</td>\n",
       "      <td>493</td>\n",
       "      <td>527</td>\n",
       "      <td>243.379057</td>\n",
       "      <td>219.405019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>3106</td>\n",
       "      <td>3113</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>29564</td>\n",
       "      <td>35336</td>\n",
       "      <td>493</td>\n",
       "      <td>583</td>\n",
       "      <td>243.379057</td>\n",
       "      <td>226.901144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>3106</td>\n",
       "      <td>3114</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>29564</td>\n",
       "      <td>28209</td>\n",
       "      <td>493</td>\n",
       "      <td>496</td>\n",
       "      <td>243.379057</td>\n",
       "      <td>211.756463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>3106</td>\n",
       "      <td>3116</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>29564</td>\n",
       "      <td>36173</td>\n",
       "      <td>493</td>\n",
       "      <td>546</td>\n",
       "      <td>243.379057</td>\n",
       "      <td>250.385417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  TeamName_1  TeamName_2  Season  DayNum  Seed_1  Seed_2  \\\n",
       "0  2015_3106_3107        3106        3107    2015     NaN      15      13   \n",
       "1  2015_3106_3110        3106        3110    2015     NaN      15      14   \n",
       "2  2015_3106_3113        3106        3113    2015     NaN      15       3   \n",
       "3  2015_3106_3114        3106        3114    2015     NaN      15      11   \n",
       "4  2015_3106_3116        3106        3116    2015     NaN      15      10   \n",
       "\n",
       "   Score_1  Score_2  Count_1  Count_2       Var_1       Var_2  \n",
       "0    29564    28090      493      452  243.379057  226.792200  \n",
       "1    29564    33027      493      527  243.379057  219.405019  \n",
       "2    29564    35336      493      583  243.379057  226.901144  \n",
       "3    29564    28209      493      496  243.379057  211.756463  \n",
       "4    29564    36173      493      546  243.379057  250.385417  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition2(table):\n",
    "    # Seed\n",
    "    table['Seed_diff'] = table['Seed_1'] - table['Seed_2']\n",
    "    table['Seed_div'] = table['Seed_1'] / table['Seed_2']\n",
    "    \n",
    "    # Score\n",
    "    table['Score_diff'] = table['Score_1'] - table['Score_2'] \n",
    "    table['Score_div'] = table['Score_1'] / table['Score_2'] \n",
    "    \n",
    "    # Count\n",
    "    table['Count_diff'] = table['Count_1'] - table['Count_2']\n",
    "    table['Count_div'] = table['Count_1'] / table['Count_2']   \n",
    "\n",
    "    # Var\n",
    "    table['Var_diff'] = table['Var_1'] - table['Var_2']\n",
    "    table['Var_div'] = table['Var_1'] / table['Var_2']  \n",
    "    \n",
    "    # Mean\n",
    "    table['Mean_score1'] = table['Score_1'] / table['Count_1']\n",
    "    table['Mean_score2'] = table['Score_2'] / table['Count_2']\n",
    "    table['Mean_score_diff'] = table['Mean_score1'] - table['Mean_score2']\n",
    "    table['Mean_score_div'] = table['Mean_score1'] / table['Mean_score2']\n",
    "    \n",
    "    # FanoFactor\n",
    "    table['FanoFactor_1'] = table['Var_1'] / table['Mean_score1']\n",
    "    table['FanoFactor_2'] = table['Var_2'] / table['Mean_score2']    \n",
    "    table['FanoFactor_diff'] = table['FanoFactor_1'] - table['FanoFactor_2'] \n",
    "    table['FanoFactor_div'] = table['FanoFactor_1'] / table['FanoFactor_2']    \n",
    "    # Drop\n",
    "    table = table.drop(['Count_1', 'Count_2', 'Var_1', 'Var_2'], axis=1)\n",
    "    \n",
    "    table['win14days'] = np.where((table['DayNum']> 118) & (table['Score_1'] > table['Score_2']), 1, 0)\n",
    "    table['last14days'] = np.where(table['DayNum']> 118,  1, 0)\n",
    "    \n",
    "    table = table.drop(['Score_1', 'Score_2'], axis=1)\n",
    "    \n",
    "    return table\n",
    "train = addition2(train)\n",
    "test = addition2(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(['DayNum'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamName_1</th>\n",
       "      <th>TeamName_2</th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>Seed_1</th>\n",
       "      <th>Seed_2</th>\n",
       "      <th>result</th>\n",
       "      <th>Seed_diff</th>\n",
       "      <th>Seed_div</th>\n",
       "      <th>Score_diff</th>\n",
       "      <th>Score_div</th>\n",
       "      <th>Count_diff</th>\n",
       "      <th>Count_div</th>\n",
       "      <th>Var_diff</th>\n",
       "      <th>Var_div</th>\n",
       "      <th>Mean_score1</th>\n",
       "      <th>Mean_score2</th>\n",
       "      <th>Mean_score_diff</th>\n",
       "      <th>Mean_score_div</th>\n",
       "      <th>FanoFactor_1</th>\n",
       "      <th>FanoFactor_2</th>\n",
       "      <th>FanoFactor_diff</th>\n",
       "      <th>FanoFactor_div</th>\n",
       "      <th>win14days</th>\n",
       "      <th>last14days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3104</td>\n",
       "      <td>3212</td>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>-7</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>511</td>\n",
       "      <td>1.126079</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>-47.726046</td>\n",
       "      <td>0.819142</td>\n",
       "      <td>77.355932</td>\n",
       "      <td>51.303797</td>\n",
       "      <td>26.052135</td>\n",
       "      <td>1.507801</td>\n",
       "      <td>2.794373</td>\n",
       "      <td>5.143622</td>\n",
       "      <td>-2.349249</td>\n",
       "      <td>0.543269</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3112</td>\n",
       "      <td>3196</td>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>-417</td>\n",
       "      <td>0.908372</td>\n",
       "      <td>-24</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>-56.806410</td>\n",
       "      <td>0.779104</td>\n",
       "      <td>76.555556</td>\n",
       "      <td>58.346154</td>\n",
       "      <td>18.209402</td>\n",
       "      <td>1.312093</td>\n",
       "      <td>2.617152</td>\n",
       "      <td>4.407556</td>\n",
       "      <td>-1.790404</td>\n",
       "      <td>0.593788</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3155</td>\n",
       "      <td>3197</td>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>-13</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>833</td>\n",
       "      <td>1.239437</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>46.379953</td>\n",
       "      <td>1.202870</td>\n",
       "      <td>73.084746</td>\n",
       "      <td>44.037975</td>\n",
       "      <td>29.046771</td>\n",
       "      <td>1.659585</td>\n",
       "      <td>3.762737</td>\n",
       "      <td>5.191399</td>\n",
       "      <td>-1.428662</td>\n",
       "      <td>0.724802</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3161</td>\n",
       "      <td>3169</td>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>-13</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1117</td>\n",
       "      <td>1.307968</td>\n",
       "      <td>-26</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>194.492154</td>\n",
       "      <td>1.895376</td>\n",
       "      <td>80.406780</td>\n",
       "      <td>42.670588</td>\n",
       "      <td>37.736191</td>\n",
       "      <td>1.884361</td>\n",
       "      <td>5.120348</td>\n",
       "      <td>5.090591</td>\n",
       "      <td>0.029757</td>\n",
       "      <td>1.005845</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3163</td>\n",
       "      <td>3384</td>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>-15</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>1695</td>\n",
       "      <td>1.439119</td>\n",
       "      <td>-32</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>-86.568468</td>\n",
       "      <td>0.745656</td>\n",
       "      <td>88.174603</td>\n",
       "      <td>40.631579</td>\n",
       "      <td>47.543024</td>\n",
       "      <td>2.170100</td>\n",
       "      <td>2.878278</td>\n",
       "      <td>8.376722</td>\n",
       "      <td>-5.498445</td>\n",
       "      <td>0.343604</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TeamName_1  TeamName_2  Season  DayNum    DayZero  Seed_1  Seed_2  result  \\\n",
       "0        3104        3212    1999     137 1998-10-26       5      12       1   \n",
       "1        3112        3196    1999     137 1998-10-26       6      11       1   \n",
       "2        3155        3197    1999     137 1998-10-26       2      15       1   \n",
       "3        3161        3169    1999     137 1998-10-26       2      15       1   \n",
       "4        3163        3384    1999     137 1998-10-26       1      16       1   \n",
       "\n",
       "   Seed_diff  Seed_div  Score_diff  Score_div  Count_diff  Count_div  \\\n",
       "0         -7  0.416667         511   1.126079         -20   0.746835   \n",
       "1         -5  0.545455        -417   0.908372         -24   0.692308   \n",
       "2        -13  0.133333         833   1.239437         -20   0.746835   \n",
       "3        -13  0.133333        1117   1.307968         -26   0.694118   \n",
       "4        -15  0.062500        1695   1.439119         -32   0.663158   \n",
       "\n",
       "     Var_diff   Var_div  Mean_score1  Mean_score2  Mean_score_diff  \\\n",
       "0  -47.726046  0.819142    77.355932    51.303797        26.052135   \n",
       "1  -56.806410  0.779104    76.555556    58.346154        18.209402   \n",
       "2   46.379953  1.202870    73.084746    44.037975        29.046771   \n",
       "3  194.492154  1.895376    80.406780    42.670588        37.736191   \n",
       "4  -86.568468  0.745656    88.174603    40.631579        47.543024   \n",
       "\n",
       "   Mean_score_div  FanoFactor_1  FanoFactor_2  FanoFactor_diff  \\\n",
       "0        1.507801      2.794373      5.143622        -2.349249   \n",
       "1        1.312093      2.617152      4.407556        -1.790404   \n",
       "2        1.659585      3.762737      5.191399        -1.428662   \n",
       "3        1.884361      5.120348      5.090591         0.029757   \n",
       "4        2.170100      2.878278      8.376722        -5.498445   \n",
       "\n",
       "   FanoFactor_div  win14days  last14days  \n",
       "0        0.543269          1           1  \n",
       "1        0.593788          0           1  \n",
       "2        0.724802          1           1  \n",
       "3        1.005845          1           1  \n",
       "4        0.343604          1           1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TeamName_1</th>\n",
       "      <th>TeamName_2</th>\n",
       "      <th>Season</th>\n",
       "      <th>Seed_1</th>\n",
       "      <th>Seed_2</th>\n",
       "      <th>Seed_diff</th>\n",
       "      <th>Seed_div</th>\n",
       "      <th>Score_diff</th>\n",
       "      <th>Score_div</th>\n",
       "      <th>Count_diff</th>\n",
       "      <th>Count_div</th>\n",
       "      <th>Var_diff</th>\n",
       "      <th>Var_div</th>\n",
       "      <th>Mean_score1</th>\n",
       "      <th>Mean_score2</th>\n",
       "      <th>Mean_score_diff</th>\n",
       "      <th>Mean_score_div</th>\n",
       "      <th>FanoFactor_1</th>\n",
       "      <th>FanoFactor_2</th>\n",
       "      <th>FanoFactor_diff</th>\n",
       "      <th>FanoFactor_div</th>\n",
       "      <th>win14days</th>\n",
       "      <th>last14days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>3106</td>\n",
       "      <td>3107</td>\n",
       "      <td>2015</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>1474</td>\n",
       "      <td>1.052474</td>\n",
       "      <td>41</td>\n",
       "      <td>1.090708</td>\n",
       "      <td>16.586857</td>\n",
       "      <td>1.073137</td>\n",
       "      <td>59.967546</td>\n",
       "      <td>62.146018</td>\n",
       "      <td>-2.178472</td>\n",
       "      <td>0.964946</td>\n",
       "      <td>4.058513</td>\n",
       "      <td>3.649344</td>\n",
       "      <td>0.409169</td>\n",
       "      <td>1.112121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>3106</td>\n",
       "      <td>3110</td>\n",
       "      <td>2015</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>-3463</td>\n",
       "      <td>0.895146</td>\n",
       "      <td>-34</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>23.974038</td>\n",
       "      <td>1.109268</td>\n",
       "      <td>59.967546</td>\n",
       "      <td>62.669829</td>\n",
       "      <td>-2.702284</td>\n",
       "      <td>0.956881</td>\n",
       "      <td>4.058513</td>\n",
       "      <td>3.500967</td>\n",
       "      <td>0.557546</td>\n",
       "      <td>1.159255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>3106</td>\n",
       "      <td>3113</td>\n",
       "      <td>2015</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-5772</td>\n",
       "      <td>0.836654</td>\n",
       "      <td>-90</td>\n",
       "      <td>0.845626</td>\n",
       "      <td>16.477912</td>\n",
       "      <td>1.072622</td>\n",
       "      <td>59.967546</td>\n",
       "      <td>60.610635</td>\n",
       "      <td>-0.643089</td>\n",
       "      <td>0.989390</td>\n",
       "      <td>4.058513</td>\n",
       "      <td>3.743586</td>\n",
       "      <td>0.314927</td>\n",
       "      <td>1.084124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>3106</td>\n",
       "      <td>3114</td>\n",
       "      <td>2015</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>1355</td>\n",
       "      <td>1.048034</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.993952</td>\n",
       "      <td>31.622594</td>\n",
       "      <td>1.149335</td>\n",
       "      <td>59.967546</td>\n",
       "      <td>56.872984</td>\n",
       "      <td>3.094562</td>\n",
       "      <td>1.054412</td>\n",
       "      <td>4.058513</td>\n",
       "      <td>3.723323</td>\n",
       "      <td>0.335190</td>\n",
       "      <td>1.090025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>3106</td>\n",
       "      <td>3116</td>\n",
       "      <td>2015</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-6609</td>\n",
       "      <td>0.817295</td>\n",
       "      <td>-53</td>\n",
       "      <td>0.902930</td>\n",
       "      <td>-7.006361</td>\n",
       "      <td>0.972018</td>\n",
       "      <td>59.967546</td>\n",
       "      <td>66.250916</td>\n",
       "      <td>-6.283370</td>\n",
       "      <td>0.905158</td>\n",
       "      <td>4.058513</td>\n",
       "      <td>3.779350</td>\n",
       "      <td>0.279163</td>\n",
       "      <td>1.073865</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  TeamName_1  TeamName_2  Season  Seed_1  Seed_2  Seed_diff  \\\n",
       "0  2015_3106_3107        3106        3107    2015      15      13          2   \n",
       "1  2015_3106_3110        3106        3110    2015      15      14          1   \n",
       "2  2015_3106_3113        3106        3113    2015      15       3         12   \n",
       "3  2015_3106_3114        3106        3114    2015      15      11          4   \n",
       "4  2015_3106_3116        3106        3116    2015      15      10          5   \n",
       "\n",
       "   Seed_div  Score_diff  Score_div  Count_diff  Count_div   Var_diff  \\\n",
       "0  1.153846        1474   1.052474          41   1.090708  16.586857   \n",
       "1  1.071429       -3463   0.895146         -34   0.935484  23.974038   \n",
       "2  5.000000       -5772   0.836654         -90   0.845626  16.477912   \n",
       "3  1.363636        1355   1.048034          -3   0.993952  31.622594   \n",
       "4  1.500000       -6609   0.817295         -53   0.902930  -7.006361   \n",
       "\n",
       "    Var_div  Mean_score1  Mean_score2  Mean_score_diff  Mean_score_div  \\\n",
       "0  1.073137    59.967546    62.146018        -2.178472        0.964946   \n",
       "1  1.109268    59.967546    62.669829        -2.702284        0.956881   \n",
       "2  1.072622    59.967546    60.610635        -0.643089        0.989390   \n",
       "3  1.149335    59.967546    56.872984         3.094562        1.054412   \n",
       "4  0.972018    59.967546    66.250916        -6.283370        0.905158   \n",
       "\n",
       "   FanoFactor_1  FanoFactor_2  FanoFactor_diff  FanoFactor_div  win14days  \\\n",
       "0      4.058513      3.649344         0.409169        1.112121          0   \n",
       "1      4.058513      3.500967         0.557546        1.159255          0   \n",
       "2      4.058513      3.743586         0.314927        1.084124          0   \n",
       "3      4.058513      3.723323         0.335190        1.090025          0   \n",
       "4      4.058513      3.779350         0.279163        1.073865          0   \n",
       "\n",
       "   last14days  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2732"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10080"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_row(r):\n",
    "    if r['TeamName_1'] < r['TeamName_2']:\n",
    "        res = str(r['Season'])+\"_\"+str(r['TeamName_1'])+\"_\"+str(r['TeamName_2'])\n",
    "    else:\n",
    "        res = str(r['Season'])+\"_\"+str(r['TeamName_2'])+\"_\"+str(r['TeamName_1'])\n",
    "    return res\n",
    "\n",
    "# Delete leaked from train\n",
    "def delete_leaked_from_df_train(df_train, df_test):\n",
    "    df_train['Concats'] = df_train.apply(concat_row, axis=1)\n",
    "    df_train_duplicates = df_train[df_train['Concats'].isin(df_test['ID'].unique())]\n",
    "    df_train_idx = df_train_duplicates.index.values\n",
    "    df_train = df_train.drop(df_train_idx)\n",
    "    df_train = df_train.drop('Concats', axis=1)\n",
    "    \n",
    "    return df_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = delete_leaked_from_df_train(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2058"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10080"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['TeamName_1', 'TeamName_2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(['TeamName_1', 'TeamName_2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'result'\n",
    "features = train.columns.values.tolist()\n",
    "dropcols = [target,'DayNum', 'Season','DayZero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Seed_1', 'Seed_2', 'Seed_diff', 'Seed_div', 'Score_diff', 'Score_div', 'Count_diff', 'Count_div', 'Var_diff', 'Var_div', 'Mean_score1', 'Mean_score2', 'Mean_score_diff', 'Mean_score_div', 'FanoFactor_1', 'FanoFactor_2', 'FanoFactor_diff', 'FanoFactor_div', 'win14days', 'last14days']\n"
     ]
    }
   ],
   "source": [
    "features = [f for f in features if f not in dropcols]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>Seed_1</th>\n",
       "      <th>Seed_2</th>\n",
       "      <th>result</th>\n",
       "      <th>Seed_diff</th>\n",
       "      <th>Seed_div</th>\n",
       "      <th>Score_diff</th>\n",
       "      <th>Score_div</th>\n",
       "      <th>Count_diff</th>\n",
       "      <th>Count_div</th>\n",
       "      <th>Var_diff</th>\n",
       "      <th>Var_div</th>\n",
       "      <th>Mean_score1</th>\n",
       "      <th>Mean_score2</th>\n",
       "      <th>Mean_score_diff</th>\n",
       "      <th>Mean_score_div</th>\n",
       "      <th>FanoFactor_1</th>\n",
       "      <th>FanoFactor_2</th>\n",
       "      <th>FanoFactor_diff</th>\n",
       "      <th>FanoFactor_div</th>\n",
       "      <th>win14days</th>\n",
       "      <th>last14days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>-7</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>511</td>\n",
       "      <td>1.126079</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>-47.726046</td>\n",
       "      <td>0.819142</td>\n",
       "      <td>77.355932</td>\n",
       "      <td>51.303797</td>\n",
       "      <td>26.052135</td>\n",
       "      <td>1.507801</td>\n",
       "      <td>2.794373</td>\n",
       "      <td>5.143622</td>\n",
       "      <td>-2.349249</td>\n",
       "      <td>0.543269</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>-417</td>\n",
       "      <td>0.908372</td>\n",
       "      <td>-24</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>-56.806410</td>\n",
       "      <td>0.779104</td>\n",
       "      <td>76.555556</td>\n",
       "      <td>58.346154</td>\n",
       "      <td>18.209402</td>\n",
       "      <td>1.312093</td>\n",
       "      <td>2.617152</td>\n",
       "      <td>4.407556</td>\n",
       "      <td>-1.790404</td>\n",
       "      <td>0.593788</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>-13</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>833</td>\n",
       "      <td>1.239437</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>46.379953</td>\n",
       "      <td>1.202870</td>\n",
       "      <td>73.084746</td>\n",
       "      <td>44.037975</td>\n",
       "      <td>29.046771</td>\n",
       "      <td>1.659585</td>\n",
       "      <td>3.762737</td>\n",
       "      <td>5.191399</td>\n",
       "      <td>-1.428662</td>\n",
       "      <td>0.724802</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>-13</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1117</td>\n",
       "      <td>1.307968</td>\n",
       "      <td>-26</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>194.492154</td>\n",
       "      <td>1.895376</td>\n",
       "      <td>80.406780</td>\n",
       "      <td>42.670588</td>\n",
       "      <td>37.736191</td>\n",
       "      <td>1.884361</td>\n",
       "      <td>5.120348</td>\n",
       "      <td>5.090591</td>\n",
       "      <td>0.029757</td>\n",
       "      <td>1.005845</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>137</td>\n",
       "      <td>1998-10-26</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>-15</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>1695</td>\n",
       "      <td>1.439119</td>\n",
       "      <td>-32</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>-86.568468</td>\n",
       "      <td>0.745656</td>\n",
       "      <td>88.174603</td>\n",
       "      <td>40.631579</td>\n",
       "      <td>47.543024</td>\n",
       "      <td>2.170100</td>\n",
       "      <td>2.878278</td>\n",
       "      <td>8.376722</td>\n",
       "      <td>-5.498445</td>\n",
       "      <td>0.343604</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum    DayZero  Seed_1  Seed_2  result  Seed_diff  Seed_div  \\\n",
       "0    1999     137 1998-10-26       5      12       1         -7  0.416667   \n",
       "1    1999     137 1998-10-26       6      11       1         -5  0.545455   \n",
       "2    1999     137 1998-10-26       2      15       1        -13  0.133333   \n",
       "3    1999     137 1998-10-26       2      15       1        -13  0.133333   \n",
       "4    1999     137 1998-10-26       1      16       1        -15  0.062500   \n",
       "\n",
       "   Score_diff  Score_div  Count_diff  Count_div    Var_diff   Var_div  \\\n",
       "0         511   1.126079         -20   0.746835  -47.726046  0.819142   \n",
       "1        -417   0.908372         -24   0.692308  -56.806410  0.779104   \n",
       "2         833   1.239437         -20   0.746835   46.379953  1.202870   \n",
       "3        1117   1.307968         -26   0.694118  194.492154  1.895376   \n",
       "4        1695   1.439119         -32   0.663158  -86.568468  0.745656   \n",
       "\n",
       "   Mean_score1  Mean_score2  Mean_score_diff  Mean_score_div  FanoFactor_1  \\\n",
       "0    77.355932    51.303797        26.052135        1.507801      2.794373   \n",
       "1    76.555556    58.346154        18.209402        1.312093      2.617152   \n",
       "2    73.084746    44.037975        29.046771        1.659585      3.762737   \n",
       "3    80.406780    42.670588        37.736191        1.884361      5.120348   \n",
       "4    88.174603    40.631579        47.543024        2.170100      2.878278   \n",
       "\n",
       "   FanoFactor_2  FanoFactor_diff  FanoFactor_div  win14days  last14days  \n",
       "0      5.143622        -2.349249        0.543269          1           1  \n",
       "1      4.407556        -1.790404        0.593788          0           1  \n",
       "2      5.191399        -1.428662        0.724802          1           1  \n",
       "3      5.090591         0.029757        1.005845          1           1  \n",
       "4      8.376722        -5.498445        0.343604          1           1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Seed_1</th>\n",
       "      <th>Seed_2</th>\n",
       "      <th>Seed_diff</th>\n",
       "      <th>Seed_div</th>\n",
       "      <th>Score_diff</th>\n",
       "      <th>Score_div</th>\n",
       "      <th>Count_diff</th>\n",
       "      <th>Count_div</th>\n",
       "      <th>Var_diff</th>\n",
       "      <th>Var_div</th>\n",
       "      <th>Mean_score1</th>\n",
       "      <th>Mean_score2</th>\n",
       "      <th>Mean_score_diff</th>\n",
       "      <th>Mean_score_div</th>\n",
       "      <th>FanoFactor_1</th>\n",
       "      <th>FanoFactor_2</th>\n",
       "      <th>FanoFactor_diff</th>\n",
       "      <th>FanoFactor_div</th>\n",
       "      <th>win14days</th>\n",
       "      <th>last14days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>2015</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>1474</td>\n",
       "      <td>1.052474</td>\n",
       "      <td>41</td>\n",
       "      <td>1.090708</td>\n",
       "      <td>16.586857</td>\n",
       "      <td>1.073137</td>\n",
       "      <td>59.967546</td>\n",
       "      <td>62.146018</td>\n",
       "      <td>-2.178472</td>\n",
       "      <td>0.964946</td>\n",
       "      <td>4.058513</td>\n",
       "      <td>3.649344</td>\n",
       "      <td>0.409169</td>\n",
       "      <td>1.112121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>2015</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>-3463</td>\n",
       "      <td>0.895146</td>\n",
       "      <td>-34</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>23.974038</td>\n",
       "      <td>1.109268</td>\n",
       "      <td>59.967546</td>\n",
       "      <td>62.669829</td>\n",
       "      <td>-2.702284</td>\n",
       "      <td>0.956881</td>\n",
       "      <td>4.058513</td>\n",
       "      <td>3.500967</td>\n",
       "      <td>0.557546</td>\n",
       "      <td>1.159255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>2015</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-5772</td>\n",
       "      <td>0.836654</td>\n",
       "      <td>-90</td>\n",
       "      <td>0.845626</td>\n",
       "      <td>16.477912</td>\n",
       "      <td>1.072622</td>\n",
       "      <td>59.967546</td>\n",
       "      <td>60.610635</td>\n",
       "      <td>-0.643089</td>\n",
       "      <td>0.989390</td>\n",
       "      <td>4.058513</td>\n",
       "      <td>3.743586</td>\n",
       "      <td>0.314927</td>\n",
       "      <td>1.084124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>2015</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>1355</td>\n",
       "      <td>1.048034</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.993952</td>\n",
       "      <td>31.622594</td>\n",
       "      <td>1.149335</td>\n",
       "      <td>59.967546</td>\n",
       "      <td>56.872984</td>\n",
       "      <td>3.094562</td>\n",
       "      <td>1.054412</td>\n",
       "      <td>4.058513</td>\n",
       "      <td>3.723323</td>\n",
       "      <td>0.335190</td>\n",
       "      <td>1.090025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>2015</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-6609</td>\n",
       "      <td>0.817295</td>\n",
       "      <td>-53</td>\n",
       "      <td>0.902930</td>\n",
       "      <td>-7.006361</td>\n",
       "      <td>0.972018</td>\n",
       "      <td>59.967546</td>\n",
       "      <td>66.250916</td>\n",
       "      <td>-6.283370</td>\n",
       "      <td>0.905158</td>\n",
       "      <td>4.058513</td>\n",
       "      <td>3.779350</td>\n",
       "      <td>0.279163</td>\n",
       "      <td>1.073865</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Season  Seed_1  Seed_2  Seed_diff  Seed_div  Score_diff  \\\n",
       "0  2015_3106_3107    2015      15      13          2  1.153846        1474   \n",
       "1  2015_3106_3110    2015      15      14          1  1.071429       -3463   \n",
       "2  2015_3106_3113    2015      15       3         12  5.000000       -5772   \n",
       "3  2015_3106_3114    2015      15      11          4  1.363636        1355   \n",
       "4  2015_3106_3116    2015      15      10          5  1.500000       -6609   \n",
       "\n",
       "   Score_div  Count_diff  Count_div   Var_diff   Var_div  Mean_score1  \\\n",
       "0   1.052474          41   1.090708  16.586857  1.073137    59.967546   \n",
       "1   0.895146         -34   0.935484  23.974038  1.109268    59.967546   \n",
       "2   0.836654         -90   0.845626  16.477912  1.072622    59.967546   \n",
       "3   1.048034          -3   0.993952  31.622594  1.149335    59.967546   \n",
       "4   0.817295         -53   0.902930  -7.006361  0.972018    59.967546   \n",
       "\n",
       "   Mean_score2  Mean_score_diff  Mean_score_div  FanoFactor_1  FanoFactor_2  \\\n",
       "0    62.146018        -2.178472        0.964946      4.058513      3.649344   \n",
       "1    62.669829        -2.702284        0.956881      4.058513      3.500967   \n",
       "2    60.610635        -0.643089        0.989390      4.058513      3.743586   \n",
       "3    56.872984         3.094562        1.054412      4.058513      3.723323   \n",
       "4    66.250916        -6.283370        0.905158      4.058513      3.779350   \n",
       "\n",
       "   FanoFactor_diff  FanoFactor_div  win14days  last14days  \n",
       "0         0.409169        1.112121          0           0  \n",
       "1         0.557546        1.159255          0           0  \n",
       "2         0.314927        1.084124          0           0  \n",
       "3         0.335190        1.090025          0           0  \n",
       "4         0.279163        1.073865          0           0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "\n",
    "    def __init__(self, train_df, test_df, target, features, categoricals=[], \n",
    "                n_splits=3, cv_method=\"KFold\", group=None, task=\"regression\", \n",
    "                parameter_tuning=False, seed=42, scaler=None, verbose=True):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.target = target\n",
    "        self.features = features\n",
    "        self.n_splits = n_splits\n",
    "        self.categoricals = categoricals\n",
    "        self.cv_method = cv_method\n",
    "        self.group = group\n",
    "        self.task = task\n",
    "        self.parameter_tuning = parameter_tuning\n",
    "        self.seed = seed\n",
    "        self.scaler = scaler\n",
    "        self.cv = self.get_cv()\n",
    "        self.verbose = verbose\n",
    "        self.params = self.get_params()\n",
    "        self.y_pred, self.score, self.model, self.oof, self.y_val, self.fi_df = self.fit()\n",
    "\n",
    "    def train_model(self, train_set, val_set):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_params(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def convert_x(self, x):\n",
    "        return x\n",
    "\n",
    "    def calc_metric(self, y_true, y_pred): # this may need to be changed based on the metric of interest\n",
    "        if self.task == \"multiclass\":\n",
    "            return log_loss(y_true, y_pred)\n",
    "        elif self.task == \"binary\":\n",
    "            return log_loss(y_true, y_pred)\n",
    "#             return roc_auc_score(y_true, y_pred)\n",
    "        elif self.task == \"regression\":\n",
    "            return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    def get_cv(self):\n",
    "        if self.cv_method == \"KFold\":\n",
    "            cv = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.seed)\n",
    "            return cv.split(self.train_df)\n",
    "        elif self.cv_method == \"StratifiedKFold\":\n",
    "            cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.seed)\n",
    "            return cv.split(self.train_df, self.train_df[self.target])\n",
    "        elif self.cv_method == \"TimeSeriesSplit\":\n",
    "            cv = TimeSeriesSplit(max_train_size=None, n_splits=self.n_splits)\n",
    "            return cv.split(self.train_df)\n",
    "\n",
    "    def fit(self):\n",
    "        # initialize\n",
    "        oof_pred = np.zeros((self.train_df.shape[0], ))\n",
    "        y_vals = np.zeros((self.train_df.shape[0], ))\n",
    "        y_pred = np.zeros((self.test_df.shape[0], ))\n",
    "        if self.group is not None:\n",
    "            if self.group in self.features:\n",
    "                self.features.remove(self.group)\n",
    "            if self.group in self.categoricals:\n",
    "                self.categoricals.remove(self.group)\n",
    "        fi = np.zeros((self.n_splits, len(self.features)))\n",
    "\n",
    "        # scaling, if necessary\n",
    "        if self.scaler is not None:\n",
    "            # fill NaN\n",
    "            numerical_features = [f for f in self.features if f not in self.categoricals]\n",
    "            self.train_df[numerical_features] = self.train_df[numerical_features].fillna(self.train_df[numerical_features].median())\n",
    "            self.test_df[numerical_features] = self.test_df[numerical_features].fillna(self.test_df[numerical_features].median())\n",
    "            self.train_df[self.categoricals] = self.train_df[self.categoricals].fillna(self.train_df[self.categoricals].mode().iloc[0])\n",
    "            self.test_df[self.categoricals] = self.test_df[self.categoricals].fillna(self.test_df[self.categoricals].mode().iloc[0])\n",
    "\n",
    "            # scaling\n",
    "            if self.scaler == \"MinMax\":\n",
    "                scaler = MinMaxScaler()\n",
    "            elif self.scaler == \"Standard\":\n",
    "                scaler = StandardScaler()\n",
    "            df = pd.concat([self.train_df[numerical_features], self.test_df[numerical_features]], ignore_index=True)\n",
    "            scaler.fit(df[numerical_features])\n",
    "            x_test = self.test_df.copy()\n",
    "            x_test[numerical_features] = scaler.transform(x_test[numerical_features])\n",
    "            x_test = [np.absolute(x_test[i]) for i in self.categoricals] + [x_test[numerical_features]]\n",
    "        else:\n",
    "            x_test = self.test_df[self.features]\n",
    "\n",
    "        # fitting with out of fold\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv):\n",
    "            # train test split\n",
    "            x_train, x_val = self.train_df.loc[train_idx, self.features], self.train_df.loc[val_idx, self.features]\n",
    "            y_train, y_val = self.train_df.loc[train_idx, self.target], self.train_df.loc[val_idx, self.target]\n",
    "\n",
    "            # fitting & get feature importance\n",
    "            if self.scaler is not None:\n",
    "                x_train[numerical_features] = scaler.transform(x_train[numerical_features])\n",
    "                x_val[numerical_features] = scaler.transform(x_val[numerical_features])\n",
    "                x_train = [np.absolute(x_train[i]) for i in self.categoricals] + [x_train[numerical_features]]\n",
    "                x_val = [np.absolute(x_val[i]) for i in self.categoricals] + [x_val[numerical_features]]\n",
    "            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n",
    "            model, importance = self.train_model(train_set, val_set)\n",
    "            fi[fold, :] = importance\n",
    "            conv_x_val = self.convert_x(x_val)\n",
    "            y_vals[val_idx] = y_val\n",
    "            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n",
    "            x_test = self.convert_x(x_test)\n",
    "            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n",
    "            print('Partial score of fold {} is: {}'.format(fold, self.calc_metric(y_val, oof_pred[val_idx])))\n",
    "        \n",
    "        # feature importance data frame\n",
    "        fi_df = pd.DataFrame()\n",
    "        for n in np.arange(self.n_splits):\n",
    "            tmp = pd.DataFrame()\n",
    "            tmp[\"features\"] = self.features\n",
    "            tmp[\"importance\"] = fi[n, :]\n",
    "            tmp[\"fold\"] = n\n",
    "            fi_df = pd.concat([fi_df, tmp], ignore_index=True)\n",
    "        gfi = fi_df[[\"features\", \"importance\"]].groupby([\"features\"]).mean().reset_index()\n",
    "        fi_df = fi_df.merge(gfi, on=\"features\", how=\"left\", suffixes=('', '_mean'))\n",
    "\n",
    "        # outputs\n",
    "        loss_score = self.calc_metric(y_vals, oof_pred)\n",
    "        if self.verbose:\n",
    "            print('Our oof loss score is: ', loss_score)\n",
    "        return y_pred, loss_score, model, oof_pred, y_vals, fi_df\n",
    "\n",
    "    def plot_feature_importance(self, rank_range=[1, 50]):\n",
    "        # plot\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 20))\n",
    "        sorted_df = self.fi_df.sort_values(by = \"importance_mean\", ascending=False).reset_index().iloc[self.n_splits * (rank_range[0]-1) : self.n_splits * rank_range[1]]\n",
    "        sns.barplot(data=sorted_df, x =\"importance\", y =\"features\", orient='h')\n",
    "        ax.set_xlabel(\"feature importance\")\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LgbModel(BaseModel):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        model = lgb.train(self.params, train_set, num_boost_round = 5000, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n",
    "        fi = model.feature_importance(importance_type=\"gain\")\n",
    "        return model, fi\n",
    "\n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val, categorical_feature=self.categoricals)\n",
    "        return train_set, val_set\n",
    "\n",
    "    def get_params(self):\n",
    "        # fast fit parameters\n",
    "        params = {\n",
    "          'num_leaves': 127,\n",
    "          'objective': self.task,\n",
    "          'min_data_in_leaf': 70,\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.005,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"verbosity\": -1,\n",
    "          'random_state': 42,\n",
    "         }\n",
    "\n",
    "        # list is here: https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "        if self.task == \"regression\":\n",
    "            params[\"metric\"] = \"rmse\"\n",
    "        elif self.task == \"binary\":\n",
    "            params[\"metric\"] = \"binary_logloss\" # auc\n",
    "        elif self.task == \"multiclass\":\n",
    "            params[\"metric\"] = \"multi_logloss\" # cross_entropy, auc_mu\n",
    "        \n",
    "        # Bayesian Optimization by Optuna\n",
    "        if self.parameter_tuning == True:\n",
    "            # define objective function\n",
    "            def objective(trial):\n",
    "                # train, test split\n",
    "                train_x, test_x, train_y, test_y = train_test_split(self.train_df[self.features], \n",
    "                                                                    self.train_df[self.target],\n",
    "                                                                    test_size=0.3, random_state=self.seed)\n",
    "                dtrain = lgb.Dataset(train_x, train_y, categorical_feature=self.categoricals)\n",
    "                dtest = lgb.Dataset(test_x, test_y, categorical_feature=self.categoricals)\n",
    "\n",
    "                # parameters to be explored\n",
    "                hyperparams = {'num_leaves': trial.suggest_int('num_leaves', 24, 1024),\n",
    "                        'boosting_type': 'gbdt',\n",
    "                        'objective': params[\"objective\"],\n",
    "                        'metric': params[\"metric\"],\n",
    "                        'max_depth': trial.suggest_int('max_depth', 4, 30),\n",
    "                        'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "                        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "                        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "                        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "                        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "                        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "                        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "                        'early_stopping_rounds': 100\n",
    "                        }\n",
    "\n",
    "                # LGB\n",
    "                model = lgb.train(hyperparams, dtrain, valid_sets=dtest, verbose_eval=500)\n",
    "                pred = model.predict(test_x)\n",
    "                if (self.task == \"binary\") | (self.task == \"multiclass\"):\n",
    "                    return log_loss(test_y, pred)\n",
    "                elif self.task == \"regression\":\n",
    "                    return np.sqrt(mean_squared_error(test_y, pred))\n",
    "\n",
    "            # run optimization\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            study.optimize(objective, n_trials=100)\n",
    "\n",
    "            print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "            print('Best trial:')\n",
    "            trial = study.best_trial\n",
    "            print('  Value: {}'.format(trial.value))\n",
    "            print('  Params: ')\n",
    "            for key, value in trial.params.items():\n",
    "                print('    {}: {}'.format(key, value))\n",
    "\n",
    "            params = trial.params\n",
    "\n",
    "            # lower learning rate for better accuracy\n",
    "            params[\"learning_rate\"] = 0.001\n",
    "\n",
    "            # plot history\n",
    "            plot_optimization_history(study)\n",
    "\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2015, 2016, 2017, 2018, 2019], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"Season\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "categoricals = [\"win14days\", \"last14days\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 2015...\n",
      "[100]\ttraining's binary_logloss: 0.533879\tvalid_1's binary_logloss: 0.534065\n",
      "[200]\ttraining's binary_logloss: 0.452487\tvalid_1's binary_logloss: 0.46114\n",
      "[300]\ttraining's binary_logloss: 0.403154\tvalid_1's binary_logloss: 0.421739\n",
      "[400]\ttraining's binary_logloss: 0.36762\tvalid_1's binary_logloss: 0.397692\n",
      "[500]\ttraining's binary_logloss: 0.341535\tvalid_1's binary_logloss: 0.385279\n",
      "[600]\ttraining's binary_logloss: 0.318978\tvalid_1's binary_logloss: 0.376851\n",
      "[700]\ttraining's binary_logloss: 0.30085\tvalid_1's binary_logloss: 0.369637\n",
      "[800]\ttraining's binary_logloss: 0.284574\tvalid_1's binary_logloss: 0.367872\n",
      "[900]\ttraining's binary_logloss: 0.269425\tvalid_1's binary_logloss: 0.366573\n",
      "[1000]\ttraining's binary_logloss: 0.255449\tvalid_1's binary_logloss: 0.368907\n",
      "[1100]\ttraining's binary_logloss: 0.242711\tvalid_1's binary_logloss: 0.369007\n",
      "[1200]\ttraining's binary_logloss: 0.231964\tvalid_1's binary_logloss: 0.368506\n",
      "[1300]\ttraining's binary_logloss: 0.221943\tvalid_1's binary_logloss: 0.37021\n",
      "[1400]\ttraining's binary_logloss: 0.211687\tvalid_1's binary_logloss: 0.369412\n",
      "[1500]\ttraining's binary_logloss: 0.202533\tvalid_1's binary_logloss: 0.370966\n",
      "[1600]\ttraining's binary_logloss: 0.193914\tvalid_1's binary_logloss: 0.371372\n",
      "[1700]\ttraining's binary_logloss: 0.185807\tvalid_1's binary_logloss: 0.372936\n",
      "[1800]\ttraining's binary_logloss: 0.178325\tvalid_1's binary_logloss: 0.374704\n",
      "[1900]\ttraining's binary_logloss: 0.171353\tvalid_1's binary_logloss: 0.376542\n",
      "[2000]\ttraining's binary_logloss: 0.164523\tvalid_1's binary_logloss: 0.376931\n",
      "[2100]\ttraining's binary_logloss: 0.157939\tvalid_1's binary_logloss: 0.378364\n",
      "[2200]\ttraining's binary_logloss: 0.151368\tvalid_1's binary_logloss: 0.379831\n",
      "[2300]\ttraining's binary_logloss: 0.145395\tvalid_1's binary_logloss: 0.380688\n",
      "[2400]\ttraining's binary_logloss: 0.139983\tvalid_1's binary_logloss: 0.380542\n",
      "[2500]\ttraining's binary_logloss: 0.134606\tvalid_1's binary_logloss: 0.380424\n",
      "[2600]\ttraining's binary_logloss: 0.129612\tvalid_1's binary_logloss: 0.382421\n",
      "[2700]\ttraining's binary_logloss: 0.124962\tvalid_1's binary_logloss: 0.38418\n",
      "[2800]\ttraining's binary_logloss: 0.12038\tvalid_1's binary_logloss: 0.3852\n",
      "[2900]\ttraining's binary_logloss: 0.116159\tvalid_1's binary_logloss: 0.386413\n",
      "[3000]\ttraining's binary_logloss: 0.111946\tvalid_1's binary_logloss: 0.388673\n",
      "[3100]\ttraining's binary_logloss: 0.108017\tvalid_1's binary_logloss: 0.389113\n",
      "[3200]\ttraining's binary_logloss: 0.10444\tvalid_1's binary_logloss: 0.390926\n",
      "[3300]\ttraining's binary_logloss: 0.100677\tvalid_1's binary_logloss: 0.392834\n",
      "[3400]\ttraining's binary_logloss: 0.0970393\tvalid_1's binary_logloss: 0.394797\n",
      "[3500]\ttraining's binary_logloss: 0.0935917\tvalid_1's binary_logloss: 0.397031\n",
      "[3600]\ttraining's binary_logloss: 0.0904213\tvalid_1's binary_logloss: 0.397639\n",
      "[3700]\ttraining's binary_logloss: 0.0873464\tvalid_1's binary_logloss: 0.397845\n",
      "[3800]\ttraining's binary_logloss: 0.0843028\tvalid_1's binary_logloss: 0.399672\n",
      "[3900]\ttraining's binary_logloss: 0.0812572\tvalid_1's binary_logloss: 0.400708\n",
      "[4000]\ttraining's binary_logloss: 0.0781527\tvalid_1's binary_logloss: 0.40245\n",
      "[4100]\ttraining's binary_logloss: 0.0754306\tvalid_1's binary_logloss: 0.403645\n",
      "[4200]\ttraining's binary_logloss: 0.0727553\tvalid_1's binary_logloss: 0.405596\n",
      "[4300]\ttraining's binary_logloss: 0.0699965\tvalid_1's binary_logloss: 0.407887\n",
      "[4400]\ttraining's binary_logloss: 0.0675656\tvalid_1's binary_logloss: 0.409225\n",
      "[4500]\ttraining's binary_logloss: 0.0652473\tvalid_1's binary_logloss: 0.411902\n",
      "[4600]\ttraining's binary_logloss: 0.0629514\tvalid_1's binary_logloss: 0.413904\n",
      "[4700]\ttraining's binary_logloss: 0.0606707\tvalid_1's binary_logloss: 0.417078\n",
      "[4800]\ttraining's binary_logloss: 0.0584421\tvalid_1's binary_logloss: 0.421263\n",
      "[4900]\ttraining's binary_logloss: 0.0564469\tvalid_1's binary_logloss: 0.424689\n",
      "[5000]\ttraining's binary_logloss: 0.0544951\tvalid_1's binary_logloss: 0.426622\n",
      "Partial score of fold 0 is: 0.42662156595615264\n",
      "[100]\ttraining's binary_logloss: 0.530438\tvalid_1's binary_logloss: 0.558449\n",
      "[200]\ttraining's binary_logloss: 0.447642\tvalid_1's binary_logloss: 0.494672\n",
      "[300]\ttraining's binary_logloss: 0.39838\tvalid_1's binary_logloss: 0.462501\n",
      "[400]\ttraining's binary_logloss: 0.364537\tvalid_1's binary_logloss: 0.441584\n",
      "[500]\ttraining's binary_logloss: 0.338264\tvalid_1's binary_logloss: 0.425405\n",
      "[600]\ttraining's binary_logloss: 0.316262\tvalid_1's binary_logloss: 0.413279\n",
      "[700]\ttraining's binary_logloss: 0.297503\tvalid_1's binary_logloss: 0.401126\n",
      "[800]\ttraining's binary_logloss: 0.281868\tvalid_1's binary_logloss: 0.395245\n",
      "[900]\ttraining's binary_logloss: 0.266963\tvalid_1's binary_logloss: 0.392217\n",
      "[1000]\ttraining's binary_logloss: 0.253438\tvalid_1's binary_logloss: 0.388792\n",
      "[1100]\ttraining's binary_logloss: 0.241799\tvalid_1's binary_logloss: 0.387876\n",
      "[1200]\ttraining's binary_logloss: 0.230304\tvalid_1's binary_logloss: 0.388533\n",
      "[1300]\ttraining's binary_logloss: 0.219818\tvalid_1's binary_logloss: 0.388828\n",
      "[1400]\ttraining's binary_logloss: 0.210796\tvalid_1's binary_logloss: 0.387442\n",
      "[1500]\ttraining's binary_logloss: 0.201804\tvalid_1's binary_logloss: 0.38349\n",
      "[1600]\ttraining's binary_logloss: 0.192676\tvalid_1's binary_logloss: 0.382124\n",
      "[1700]\ttraining's binary_logloss: 0.18439\tvalid_1's binary_logloss: 0.381894\n",
      "[1800]\ttraining's binary_logloss: 0.17671\tvalid_1's binary_logloss: 0.382925\n",
      "[1900]\ttraining's binary_logloss: 0.169522\tvalid_1's binary_logloss: 0.384151\n",
      "[2000]\ttraining's binary_logloss: 0.162754\tvalid_1's binary_logloss: 0.387153\n",
      "[2100]\ttraining's binary_logloss: 0.156364\tvalid_1's binary_logloss: 0.388848\n",
      "[2200]\ttraining's binary_logloss: 0.150222\tvalid_1's binary_logloss: 0.389225\n",
      "[2300]\ttraining's binary_logloss: 0.144416\tvalid_1's binary_logloss: 0.39068\n",
      "[2400]\ttraining's binary_logloss: 0.138904\tvalid_1's binary_logloss: 0.391381\n",
      "[2500]\ttraining's binary_logloss: 0.133795\tvalid_1's binary_logloss: 0.392873\n",
      "[2600]\ttraining's binary_logloss: 0.128855\tvalid_1's binary_logloss: 0.393753\n",
      "[2700]\ttraining's binary_logloss: 0.123958\tvalid_1's binary_logloss: 0.395305\n",
      "[2800]\ttraining's binary_logloss: 0.119385\tvalid_1's binary_logloss: 0.3972\n",
      "[2900]\ttraining's binary_logloss: 0.115016\tvalid_1's binary_logloss: 0.397092\n",
      "[3000]\ttraining's binary_logloss: 0.110934\tvalid_1's binary_logloss: 0.398833\n",
      "[3100]\ttraining's binary_logloss: 0.106994\tvalid_1's binary_logloss: 0.399147\n",
      "[3200]\ttraining's binary_logloss: 0.103212\tvalid_1's binary_logloss: 0.397454\n",
      "[3300]\ttraining's binary_logloss: 0.0995624\tvalid_1's binary_logloss: 0.397103\n",
      "[3400]\ttraining's binary_logloss: 0.0962272\tvalid_1's binary_logloss: 0.398199\n",
      "[3500]\ttraining's binary_logloss: 0.0929324\tvalid_1's binary_logloss: 0.399208\n",
      "[3600]\ttraining's binary_logloss: 0.0895938\tvalid_1's binary_logloss: 0.400215\n",
      "[3700]\ttraining's binary_logloss: 0.0864706\tvalid_1's binary_logloss: 0.401542\n",
      "[3800]\ttraining's binary_logloss: 0.083555\tvalid_1's binary_logloss: 0.403102\n",
      "[3900]\ttraining's binary_logloss: 0.0805301\tvalid_1's binary_logloss: 0.404623\n",
      "[4000]\ttraining's binary_logloss: 0.0776831\tvalid_1's binary_logloss: 0.405612\n",
      "[4100]\ttraining's binary_logloss: 0.075055\tvalid_1's binary_logloss: 0.407654\n",
      "[4200]\ttraining's binary_logloss: 0.0724351\tvalid_1's binary_logloss: 0.409381\n",
      "[4300]\ttraining's binary_logloss: 0.0700671\tvalid_1's binary_logloss: 0.411627\n",
      "[4400]\ttraining's binary_logloss: 0.0677596\tvalid_1's binary_logloss: 0.412996\n",
      "[4500]\ttraining's binary_logloss: 0.0655712\tvalid_1's binary_logloss: 0.414448\n",
      "[4600]\ttraining's binary_logloss: 0.0633367\tvalid_1's binary_logloss: 0.41432\n",
      "[4700]\ttraining's binary_logloss: 0.0611838\tvalid_1's binary_logloss: 0.416275\n",
      "[4800]\ttraining's binary_logloss: 0.0590429\tvalid_1's binary_logloss: 0.4188\n",
      "[4900]\ttraining's binary_logloss: 0.0569747\tvalid_1's binary_logloss: 0.420533\n",
      "[5000]\ttraining's binary_logloss: 0.0550032\tvalid_1's binary_logloss: 0.422815\n",
      "Partial score of fold 1 is: 0.42281512322351805\n",
      "[100]\ttraining's binary_logloss: 0.531659\tvalid_1's binary_logloss: 0.551978\n",
      "[200]\ttraining's binary_logloss: 0.450432\tvalid_1's binary_logloss: 0.481607\n",
      "[300]\ttraining's binary_logloss: 0.401965\tvalid_1's binary_logloss: 0.440426\n",
      "[400]\ttraining's binary_logloss: 0.368132\tvalid_1's binary_logloss: 0.41241\n",
      "[500]\ttraining's binary_logloss: 0.341827\tvalid_1's binary_logloss: 0.396649\n",
      "[600]\ttraining's binary_logloss: 0.319436\tvalid_1's binary_logloss: 0.386696\n",
      "[700]\ttraining's binary_logloss: 0.299313\tvalid_1's binary_logloss: 0.379062\n",
      "[800]\ttraining's binary_logloss: 0.281861\tvalid_1's binary_logloss: 0.375632\n",
      "[900]\ttraining's binary_logloss: 0.267045\tvalid_1's binary_logloss: 0.374904\n",
      "[1000]\ttraining's binary_logloss: 0.254546\tvalid_1's binary_logloss: 0.37277\n",
      "[1100]\ttraining's binary_logloss: 0.242942\tvalid_1's binary_logloss: 0.372153\n",
      "[1200]\ttraining's binary_logloss: 0.231424\tvalid_1's binary_logloss: 0.374227\n",
      "[1300]\ttraining's binary_logloss: 0.220939\tvalid_1's binary_logloss: 0.375613\n",
      "[1400]\ttraining's binary_logloss: 0.211329\tvalid_1's binary_logloss: 0.377424\n",
      "[1500]\ttraining's binary_logloss: 0.202066\tvalid_1's binary_logloss: 0.378829\n",
      "[1600]\ttraining's binary_logloss: 0.193317\tvalid_1's binary_logloss: 0.379931\n",
      "[1700]\ttraining's binary_logloss: 0.185\tvalid_1's binary_logloss: 0.381917\n",
      "[1800]\ttraining's binary_logloss: 0.177432\tvalid_1's binary_logloss: 0.383454\n",
      "[1900]\ttraining's binary_logloss: 0.170168\tvalid_1's binary_logloss: 0.38613\n",
      "[2000]\ttraining's binary_logloss: 0.163186\tvalid_1's binary_logloss: 0.387726\n",
      "[2100]\ttraining's binary_logloss: 0.156751\tvalid_1's binary_logloss: 0.39108\n",
      "[2200]\ttraining's binary_logloss: 0.150822\tvalid_1's binary_logloss: 0.394201\n",
      "[2300]\ttraining's binary_logloss: 0.145051\tvalid_1's binary_logloss: 0.397381\n",
      "[2400]\ttraining's binary_logloss: 0.139212\tvalid_1's binary_logloss: 0.400304\n",
      "[2500]\ttraining's binary_logloss: 0.133871\tvalid_1's binary_logloss: 0.404038\n",
      "[2600]\ttraining's binary_logloss: 0.128806\tvalid_1's binary_logloss: 0.408005\n",
      "[2700]\ttraining's binary_logloss: 0.123777\tvalid_1's binary_logloss: 0.409688\n",
      "[2800]\ttraining's binary_logloss: 0.118944\tvalid_1's binary_logloss: 0.410787\n",
      "[2900]\ttraining's binary_logloss: 0.114424\tvalid_1's binary_logloss: 0.411524\n",
      "[3000]\ttraining's binary_logloss: 0.110064\tvalid_1's binary_logloss: 0.412231\n",
      "[3100]\ttraining's binary_logloss: 0.106018\tvalid_1's binary_logloss: 0.413983\n",
      "[3200]\ttraining's binary_logloss: 0.102122\tvalid_1's binary_logloss: 0.416922\n",
      "[3300]\ttraining's binary_logloss: 0.098301\tvalid_1's binary_logloss: 0.419291\n",
      "[3400]\ttraining's binary_logloss: 0.0946849\tvalid_1's binary_logloss: 0.423835\n",
      "[3500]\ttraining's binary_logloss: 0.0911475\tvalid_1's binary_logloss: 0.427682\n",
      "[3600]\ttraining's binary_logloss: 0.0878085\tvalid_1's binary_logloss: 0.430953\n",
      "[3700]\ttraining's binary_logloss: 0.0846108\tvalid_1's binary_logloss: 0.433879\n",
      "[3800]\ttraining's binary_logloss: 0.0815005\tvalid_1's binary_logloss: 0.43633\n",
      "[3900]\ttraining's binary_logloss: 0.0785155\tvalid_1's binary_logloss: 0.439659\n",
      "[4000]\ttraining's binary_logloss: 0.0756991\tvalid_1's binary_logloss: 0.441381\n",
      "[4100]\ttraining's binary_logloss: 0.0730795\tvalid_1's binary_logloss: 0.44361\n",
      "[4200]\ttraining's binary_logloss: 0.0705581\tvalid_1's binary_logloss: 0.445482\n",
      "[4300]\ttraining's binary_logloss: 0.0680622\tvalid_1's binary_logloss: 0.446788\n",
      "[4400]\ttraining's binary_logloss: 0.0656703\tvalid_1's binary_logloss: 0.448533\n",
      "[4500]\ttraining's binary_logloss: 0.0633806\tvalid_1's binary_logloss: 0.451458\n",
      "[4600]\ttraining's binary_logloss: 0.0611404\tvalid_1's binary_logloss: 0.454736\n",
      "[4700]\ttraining's binary_logloss: 0.0589495\tvalid_1's binary_logloss: 0.457747\n",
      "[4800]\ttraining's binary_logloss: 0.0568939\tvalid_1's binary_logloss: 0.461163\n",
      "[4900]\ttraining's binary_logloss: 0.0549723\tvalid_1's binary_logloss: 0.464822\n",
      "[5000]\ttraining's binary_logloss: 0.0530444\tvalid_1's binary_logloss: 0.466911\n",
      "Partial score of fold 2 is: 0.4669114262800087\n",
      "[100]\ttraining's binary_logloss: 0.530339\tvalid_1's binary_logloss: 0.553748\n",
      "[200]\ttraining's binary_logloss: 0.448659\tvalid_1's binary_logloss: 0.49148\n",
      "[300]\ttraining's binary_logloss: 0.400933\tvalid_1's binary_logloss: 0.458645\n",
      "[400]\ttraining's binary_logloss: 0.366942\tvalid_1's binary_logloss: 0.434217\n",
      "[500]\ttraining's binary_logloss: 0.341418\tvalid_1's binary_logloss: 0.41699\n",
      "[600]\ttraining's binary_logloss: 0.319602\tvalid_1's binary_logloss: 0.405681\n",
      "[700]\ttraining's binary_logloss: 0.302145\tvalid_1's binary_logloss: 0.396424\n",
      "[800]\ttraining's binary_logloss: 0.285723\tvalid_1's binary_logloss: 0.38785\n",
      "[900]\ttraining's binary_logloss: 0.270712\tvalid_1's binary_logloss: 0.378617\n",
      "[1000]\ttraining's binary_logloss: 0.256994\tvalid_1's binary_logloss: 0.371381\n",
      "[1100]\ttraining's binary_logloss: 0.244546\tvalid_1's binary_logloss: 0.367102\n",
      "[1200]\ttraining's binary_logloss: 0.232735\tvalid_1's binary_logloss: 0.364709\n",
      "[1300]\ttraining's binary_logloss: 0.221547\tvalid_1's binary_logloss: 0.364609\n",
      "[1400]\ttraining's binary_logloss: 0.211528\tvalid_1's binary_logloss: 0.361082\n",
      "[1500]\ttraining's binary_logloss: 0.202474\tvalid_1's binary_logloss: 0.359661\n",
      "[1600]\ttraining's binary_logloss: 0.193828\tvalid_1's binary_logloss: 0.358836\n",
      "[1700]\ttraining's binary_logloss: 0.18594\tvalid_1's binary_logloss: 0.357816\n",
      "[1800]\ttraining's binary_logloss: 0.178084\tvalid_1's binary_logloss: 0.357598\n",
      "[1900]\ttraining's binary_logloss: 0.170703\tvalid_1's binary_logloss: 0.356676\n",
      "[2000]\ttraining's binary_logloss: 0.163761\tvalid_1's binary_logloss: 0.355811\n",
      "[2100]\ttraining's binary_logloss: 0.15727\tvalid_1's binary_logloss: 0.354328\n",
      "[2200]\ttraining's binary_logloss: 0.151053\tvalid_1's binary_logloss: 0.35311\n",
      "[2300]\ttraining's binary_logloss: 0.145158\tvalid_1's binary_logloss: 0.351953\n",
      "[2400]\ttraining's binary_logloss: 0.139519\tvalid_1's binary_logloss: 0.351956\n",
      "[2500]\ttraining's binary_logloss: 0.133985\tvalid_1's binary_logloss: 0.351625\n",
      "[2600]\ttraining's binary_logloss: 0.128939\tvalid_1's binary_logloss: 0.352851\n",
      "[2700]\ttraining's binary_logloss: 0.124421\tvalid_1's binary_logloss: 0.353913\n",
      "[2800]\ttraining's binary_logloss: 0.119941\tvalid_1's binary_logloss: 0.3543\n",
      "[2900]\ttraining's binary_logloss: 0.115704\tvalid_1's binary_logloss: 0.355869\n",
      "[3000]\ttraining's binary_logloss: 0.111641\tvalid_1's binary_logloss: 0.356307\n",
      "[3100]\ttraining's binary_logloss: 0.107663\tvalid_1's binary_logloss: 0.357082\n",
      "[3200]\ttraining's binary_logloss: 0.103931\tvalid_1's binary_logloss: 0.356326\n",
      "[3300]\ttraining's binary_logloss: 0.100212\tvalid_1's binary_logloss: 0.356747\n",
      "[3400]\ttraining's binary_logloss: 0.0966412\tvalid_1's binary_logloss: 0.357642\n",
      "[3500]\ttraining's binary_logloss: 0.0931266\tvalid_1's binary_logloss: 0.358141\n",
      "[3600]\ttraining's binary_logloss: 0.0898515\tvalid_1's binary_logloss: 0.360204\n",
      "[3700]\ttraining's binary_logloss: 0.0866503\tvalid_1's binary_logloss: 0.361612\n",
      "[3800]\ttraining's binary_logloss: 0.0835909\tvalid_1's binary_logloss: 0.363981\n",
      "[3900]\ttraining's binary_logloss: 0.0805405\tvalid_1's binary_logloss: 0.36614\n",
      "[4000]\ttraining's binary_logloss: 0.0777963\tvalid_1's binary_logloss: 0.367623\n",
      "[4100]\ttraining's binary_logloss: 0.0751431\tvalid_1's binary_logloss: 0.367707\n",
      "[4200]\ttraining's binary_logloss: 0.0726022\tvalid_1's binary_logloss: 0.368909\n",
      "[4300]\ttraining's binary_logloss: 0.0700562\tvalid_1's binary_logloss: 0.369212\n",
      "[4400]\ttraining's binary_logloss: 0.0676707\tvalid_1's binary_logloss: 0.369494\n",
      "[4500]\ttraining's binary_logloss: 0.065345\tvalid_1's binary_logloss: 0.370199\n",
      "[4600]\ttraining's binary_logloss: 0.0630438\tvalid_1's binary_logloss: 0.371331\n",
      "[4700]\ttraining's binary_logloss: 0.061033\tvalid_1's binary_logloss: 0.372265\n",
      "[4800]\ttraining's binary_logloss: 0.0590266\tvalid_1's binary_logloss: 0.373438\n",
      "[4900]\ttraining's binary_logloss: 0.0571166\tvalid_1's binary_logloss: 0.374169\n",
      "[5000]\ttraining's binary_logloss: 0.0552094\tvalid_1's binary_logloss: 0.374913\n",
      "Partial score of fold 3 is: 0.3749130315526168\n",
      "[100]\ttraining's binary_logloss: 0.531849\tvalid_1's binary_logloss: 0.550082\n",
      "[200]\ttraining's binary_logloss: 0.449828\tvalid_1's binary_logloss: 0.482729\n",
      "[300]\ttraining's binary_logloss: 0.399152\tvalid_1's binary_logloss: 0.4479\n",
      "[400]\ttraining's binary_logloss: 0.365826\tvalid_1's binary_logloss: 0.429751\n",
      "[500]\ttraining's binary_logloss: 0.339025\tvalid_1's binary_logloss: 0.417744\n",
      "[600]\ttraining's binary_logloss: 0.317371\tvalid_1's binary_logloss: 0.407631\n",
      "[700]\ttraining's binary_logloss: 0.299591\tvalid_1's binary_logloss: 0.401681\n",
      "[800]\ttraining's binary_logloss: 0.284032\tvalid_1's binary_logloss: 0.397361\n",
      "[900]\ttraining's binary_logloss: 0.26989\tvalid_1's binary_logloss: 0.393892\n",
      "[1000]\ttraining's binary_logloss: 0.255998\tvalid_1's binary_logloss: 0.392542\n",
      "[1100]\ttraining's binary_logloss: 0.243475\tvalid_1's binary_logloss: 0.390296\n",
      "[1200]\ttraining's binary_logloss: 0.231923\tvalid_1's binary_logloss: 0.38798\n",
      "[1300]\ttraining's binary_logloss: 0.221225\tvalid_1's binary_logloss: 0.38668\n",
      "[1400]\ttraining's binary_logloss: 0.211457\tvalid_1's binary_logloss: 0.388219\n",
      "[1500]\ttraining's binary_logloss: 0.2017\tvalid_1's binary_logloss: 0.389345\n",
      "[1600]\ttraining's binary_logloss: 0.192692\tvalid_1's binary_logloss: 0.389093\n",
      "[1700]\ttraining's binary_logloss: 0.184594\tvalid_1's binary_logloss: 0.391342\n",
      "[1800]\ttraining's binary_logloss: 0.176508\tvalid_1's binary_logloss: 0.392765\n",
      "[1900]\ttraining's binary_logloss: 0.169362\tvalid_1's binary_logloss: 0.393132\n",
      "[2000]\ttraining's binary_logloss: 0.162558\tvalid_1's binary_logloss: 0.393284\n",
      "[2100]\ttraining's binary_logloss: 0.156237\tvalid_1's binary_logloss: 0.392896\n",
      "[2200]\ttraining's binary_logloss: 0.1503\tvalid_1's binary_logloss: 0.393591\n",
      "[2300]\ttraining's binary_logloss: 0.144782\tvalid_1's binary_logloss: 0.395223\n",
      "[2400]\ttraining's binary_logloss: 0.139409\tvalid_1's binary_logloss: 0.396132\n",
      "[2500]\ttraining's binary_logloss: 0.134112\tvalid_1's binary_logloss: 0.39762\n",
      "[2600]\ttraining's binary_logloss: 0.129217\tvalid_1's binary_logloss: 0.398134\n",
      "[2700]\ttraining's binary_logloss: 0.124422\tvalid_1's binary_logloss: 0.399134\n",
      "[2800]\ttraining's binary_logloss: 0.119965\tvalid_1's binary_logloss: 0.401842\n",
      "[2900]\ttraining's binary_logloss: 0.115674\tvalid_1's binary_logloss: 0.401899\n",
      "[3000]\ttraining's binary_logloss: 0.111291\tvalid_1's binary_logloss: 0.402705\n",
      "[3100]\ttraining's binary_logloss: 0.107197\tvalid_1's binary_logloss: 0.403435\n",
      "[3200]\ttraining's binary_logloss: 0.103343\tvalid_1's binary_logloss: 0.404545\n",
      "[3300]\ttraining's binary_logloss: 0.0997674\tvalid_1's binary_logloss: 0.405495\n",
      "[3400]\ttraining's binary_logloss: 0.0960366\tvalid_1's binary_logloss: 0.40555\n",
      "[3500]\ttraining's binary_logloss: 0.0923571\tvalid_1's binary_logloss: 0.407095\n",
      "[3600]\ttraining's binary_logloss: 0.0891491\tvalid_1's binary_logloss: 0.409468\n",
      "[3700]\ttraining's binary_logloss: 0.0860678\tvalid_1's binary_logloss: 0.411096\n",
      "[3800]\ttraining's binary_logloss: 0.0830656\tvalid_1's binary_logloss: 0.413375\n",
      "[3900]\ttraining's binary_logloss: 0.0800522\tvalid_1's binary_logloss: 0.413904\n",
      "[4000]\ttraining's binary_logloss: 0.0773099\tvalid_1's binary_logloss: 0.414483\n",
      "[4100]\ttraining's binary_logloss: 0.0746413\tvalid_1's binary_logloss: 0.416109\n",
      "[4200]\ttraining's binary_logloss: 0.0721297\tvalid_1's binary_logloss: 0.419\n",
      "[4300]\ttraining's binary_logloss: 0.0695128\tvalid_1's binary_logloss: 0.421965\n",
      "[4400]\ttraining's binary_logloss: 0.0670148\tvalid_1's binary_logloss: 0.423925\n",
      "[4500]\ttraining's binary_logloss: 0.0646905\tvalid_1's binary_logloss: 0.426319\n",
      "[4600]\ttraining's binary_logloss: 0.0625563\tvalid_1's binary_logloss: 0.428057\n",
      "[4700]\ttraining's binary_logloss: 0.0604598\tvalid_1's binary_logloss: 0.430445\n",
      "[4800]\ttraining's binary_logloss: 0.0583859\tvalid_1's binary_logloss: 0.43307\n",
      "[4900]\ttraining's binary_logloss: 0.0563721\tvalid_1's binary_logloss: 0.43643\n",
      "[5000]\ttraining's binary_logloss: 0.0544104\tvalid_1's binary_logloss: 0.438547\n",
      "Partial score of fold 4 is: 0.43854712723920247\n",
      "[100]\ttraining's binary_logloss: 0.532588\tvalid_1's binary_logloss: 0.534048\n",
      "[200]\ttraining's binary_logloss: 0.452374\tvalid_1's binary_logloss: 0.456811\n",
      "[300]\ttraining's binary_logloss: 0.402236\tvalid_1's binary_logloss: 0.42301\n",
      "[400]\ttraining's binary_logloss: 0.368285\tvalid_1's binary_logloss: 0.405891\n",
      "[500]\ttraining's binary_logloss: 0.341504\tvalid_1's binary_logloss: 0.397957\n",
      "[600]\ttraining's binary_logloss: 0.320316\tvalid_1's binary_logloss: 0.390374\n",
      "[700]\ttraining's binary_logloss: 0.301975\tvalid_1's binary_logloss: 0.379555\n",
      "[800]\ttraining's binary_logloss: 0.286693\tvalid_1's binary_logloss: 0.373965\n",
      "[900]\ttraining's binary_logloss: 0.272933\tvalid_1's binary_logloss: 0.369429\n",
      "[1000]\ttraining's binary_logloss: 0.260079\tvalid_1's binary_logloss: 0.365133\n",
      "[1100]\ttraining's binary_logloss: 0.248245\tvalid_1's binary_logloss: 0.363348\n",
      "[1200]\ttraining's binary_logloss: 0.236459\tvalid_1's binary_logloss: 0.360535\n",
      "[1300]\ttraining's binary_logloss: 0.225384\tvalid_1's binary_logloss: 0.358476\n",
      "[1400]\ttraining's binary_logloss: 0.214742\tvalid_1's binary_logloss: 0.35546\n",
      "[1500]\ttraining's binary_logloss: 0.205471\tvalid_1's binary_logloss: 0.351514\n",
      "[1600]\ttraining's binary_logloss: 0.196235\tvalid_1's binary_logloss: 0.350344\n",
      "[1700]\ttraining's binary_logloss: 0.187647\tvalid_1's binary_logloss: 0.351338\n",
      "[1800]\ttraining's binary_logloss: 0.18005\tvalid_1's binary_logloss: 0.351857\n",
      "[1900]\ttraining's binary_logloss: 0.172957\tvalid_1's binary_logloss: 0.352961\n",
      "[2000]\ttraining's binary_logloss: 0.165928\tvalid_1's binary_logloss: 0.354624\n",
      "[2100]\ttraining's binary_logloss: 0.159485\tvalid_1's binary_logloss: 0.356136\n",
      "[2200]\ttraining's binary_logloss: 0.153445\tvalid_1's binary_logloss: 0.357731\n",
      "[2300]\ttraining's binary_logloss: 0.147706\tvalid_1's binary_logloss: 0.357887\n",
      "[2400]\ttraining's binary_logloss: 0.142493\tvalid_1's binary_logloss: 0.359893\n",
      "[2500]\ttraining's binary_logloss: 0.137298\tvalid_1's binary_logloss: 0.360033\n",
      "[2600]\ttraining's binary_logloss: 0.132122\tvalid_1's binary_logloss: 0.36035\n",
      "[2700]\ttraining's binary_logloss: 0.127156\tvalid_1's binary_logloss: 0.360518\n",
      "[2800]\ttraining's binary_logloss: 0.122329\tvalid_1's binary_logloss: 0.360384\n",
      "[2900]\ttraining's binary_logloss: 0.117627\tvalid_1's binary_logloss: 0.361058\n",
      "[3000]\ttraining's binary_logloss: 0.113201\tvalid_1's binary_logloss: 0.363087\n",
      "[3100]\ttraining's binary_logloss: 0.109092\tvalid_1's binary_logloss: 0.363664\n",
      "[3200]\ttraining's binary_logloss: 0.104992\tvalid_1's binary_logloss: 0.364417\n",
      "[3300]\ttraining's binary_logloss: 0.101152\tvalid_1's binary_logloss: 0.364964\n",
      "[3400]\ttraining's binary_logloss: 0.0973598\tvalid_1's binary_logloss: 0.36518\n",
      "[3500]\ttraining's binary_logloss: 0.0937864\tvalid_1's binary_logloss: 0.366352\n",
      "[3600]\ttraining's binary_logloss: 0.0905643\tvalid_1's binary_logloss: 0.368333\n",
      "[3700]\ttraining's binary_logloss: 0.0874501\tvalid_1's binary_logloss: 0.370055\n",
      "[3800]\ttraining's binary_logloss: 0.0843283\tvalid_1's binary_logloss: 0.370905\n",
      "[3900]\ttraining's binary_logloss: 0.0813434\tvalid_1's binary_logloss: 0.371729\n",
      "[4000]\ttraining's binary_logloss: 0.0784878\tvalid_1's binary_logloss: 0.372149\n",
      "[4100]\ttraining's binary_logloss: 0.0758203\tvalid_1's binary_logloss: 0.372932\n",
      "[4200]\ttraining's binary_logloss: 0.0732579\tvalid_1's binary_logloss: 0.373177\n",
      "[4300]\ttraining's binary_logloss: 0.0707561\tvalid_1's binary_logloss: 0.375312\n",
      "[4400]\ttraining's binary_logloss: 0.0682709\tvalid_1's binary_logloss: 0.376718\n",
      "[4500]\ttraining's binary_logloss: 0.065953\tvalid_1's binary_logloss: 0.378116\n",
      "[4600]\ttraining's binary_logloss: 0.0637173\tvalid_1's binary_logloss: 0.379864\n",
      "[4700]\ttraining's binary_logloss: 0.0614563\tvalid_1's binary_logloss: 0.38076\n",
      "[4800]\ttraining's binary_logloss: 0.0593741\tvalid_1's binary_logloss: 0.382262\n",
      "[4900]\ttraining's binary_logloss: 0.0573591\tvalid_1's binary_logloss: 0.384497\n",
      "[5000]\ttraining's binary_logloss: 0.0553968\tvalid_1's binary_logloss: 0.38549\n",
      "Partial score of fold 5 is: 0.3854899568410011\n",
      "[100]\ttraining's binary_logloss: 0.5347\tvalid_1's binary_logloss: 0.536485\n",
      "[200]\ttraining's binary_logloss: 0.453619\tvalid_1's binary_logloss: 0.461381\n",
      "[300]\ttraining's binary_logloss: 0.404354\tvalid_1's binary_logloss: 0.421988\n",
      "[400]\ttraining's binary_logloss: 0.370286\tvalid_1's binary_logloss: 0.396161\n",
      "[500]\ttraining's binary_logloss: 0.34348\tvalid_1's binary_logloss: 0.381804\n",
      "[600]\ttraining's binary_logloss: 0.320743\tvalid_1's binary_logloss: 0.371939\n",
      "[700]\ttraining's binary_logloss: 0.302657\tvalid_1's binary_logloss: 0.364962\n",
      "[800]\ttraining's binary_logloss: 0.286045\tvalid_1's binary_logloss: 0.360106\n",
      "[900]\ttraining's binary_logloss: 0.270984\tvalid_1's binary_logloss: 0.35881\n",
      "[1000]\ttraining's binary_logloss: 0.257451\tvalid_1's binary_logloss: 0.356615\n",
      "[1100]\ttraining's binary_logloss: 0.245376\tvalid_1's binary_logloss: 0.357489\n",
      "[1200]\ttraining's binary_logloss: 0.23371\tvalid_1's binary_logloss: 0.356755\n",
      "[1300]\ttraining's binary_logloss: 0.223497\tvalid_1's binary_logloss: 0.357551\n",
      "[1400]\ttraining's binary_logloss: 0.214069\tvalid_1's binary_logloss: 0.358862\n",
      "[1500]\ttraining's binary_logloss: 0.204971\tvalid_1's binary_logloss: 0.360638\n",
      "[1600]\ttraining's binary_logloss: 0.196076\tvalid_1's binary_logloss: 0.363331\n",
      "[1700]\ttraining's binary_logloss: 0.188116\tvalid_1's binary_logloss: 0.367269\n",
      "[1800]\ttraining's binary_logloss: 0.180562\tvalid_1's binary_logloss: 0.369566\n",
      "[1900]\ttraining's binary_logloss: 0.173301\tvalid_1's binary_logloss: 0.370771\n",
      "[2000]\ttraining's binary_logloss: 0.166088\tvalid_1's binary_logloss: 0.370802\n",
      "[2100]\ttraining's binary_logloss: 0.159243\tvalid_1's binary_logloss: 0.371432\n",
      "[2200]\ttraining's binary_logloss: 0.153021\tvalid_1's binary_logloss: 0.371523\n",
      "[2300]\ttraining's binary_logloss: 0.146711\tvalid_1's binary_logloss: 0.370053\n",
      "[2400]\ttraining's binary_logloss: 0.141006\tvalid_1's binary_logloss: 0.371437\n",
      "[2500]\ttraining's binary_logloss: 0.135639\tvalid_1's binary_logloss: 0.373204\n",
      "[2600]\ttraining's binary_logloss: 0.130412\tvalid_1's binary_logloss: 0.374141\n",
      "[2700]\ttraining's binary_logloss: 0.125349\tvalid_1's binary_logloss: 0.375698\n",
      "[2800]\ttraining's binary_logloss: 0.120517\tvalid_1's binary_logloss: 0.377281\n",
      "[2900]\ttraining's binary_logloss: 0.116107\tvalid_1's binary_logloss: 0.379835\n",
      "[3000]\ttraining's binary_logloss: 0.111725\tvalid_1's binary_logloss: 0.381851\n",
      "[3100]\ttraining's binary_logloss: 0.107706\tvalid_1's binary_logloss: 0.384981\n",
      "[3200]\ttraining's binary_logloss: 0.103985\tvalid_1's binary_logloss: 0.388206\n",
      "[3300]\ttraining's binary_logloss: 0.100488\tvalid_1's binary_logloss: 0.391073\n",
      "[3400]\ttraining's binary_logloss: 0.0969662\tvalid_1's binary_logloss: 0.392853\n",
      "[3500]\ttraining's binary_logloss: 0.0934728\tvalid_1's binary_logloss: 0.393716\n",
      "[3600]\ttraining's binary_logloss: 0.089933\tvalid_1's binary_logloss: 0.393996\n",
      "[3700]\ttraining's binary_logloss: 0.0865769\tvalid_1's binary_logloss: 0.395726\n",
      "[3800]\ttraining's binary_logloss: 0.0834073\tvalid_1's binary_logloss: 0.39625\n",
      "[3900]\ttraining's binary_logloss: 0.0804486\tvalid_1's binary_logloss: 0.397371\n",
      "[4000]\ttraining's binary_logloss: 0.0777172\tvalid_1's binary_logloss: 0.399326\n",
      "[4100]\ttraining's binary_logloss: 0.0749558\tvalid_1's binary_logloss: 0.400044\n",
      "[4200]\ttraining's binary_logloss: 0.0723781\tvalid_1's binary_logloss: 0.40201\n",
      "[4300]\ttraining's binary_logloss: 0.0699742\tvalid_1's binary_logloss: 0.404\n",
      "[4400]\ttraining's binary_logloss: 0.0675571\tvalid_1's binary_logloss: 0.404759\n",
      "[4500]\ttraining's binary_logloss: 0.0652911\tvalid_1's binary_logloss: 0.407322\n",
      "[4600]\ttraining's binary_logloss: 0.0629647\tvalid_1's binary_logloss: 0.409291\n",
      "[4700]\ttraining's binary_logloss: 0.0607286\tvalid_1's binary_logloss: 0.412673\n",
      "[4800]\ttraining's binary_logloss: 0.0586216\tvalid_1's binary_logloss: 0.415621\n",
      "[4900]\ttraining's binary_logloss: 0.0565263\tvalid_1's binary_logloss: 0.418111\n",
      "[5000]\ttraining's binary_logloss: 0.0544316\tvalid_1's binary_logloss: 0.420363\n",
      "Partial score of fold 6 is: 0.42036347918929345\n",
      "[100]\ttraining's binary_logloss: 0.533767\tvalid_1's binary_logloss: 0.543378\n",
      "[200]\ttraining's binary_logloss: 0.450954\tvalid_1's binary_logloss: 0.476249\n",
      "[300]\ttraining's binary_logloss: 0.401369\tvalid_1's binary_logloss: 0.440251\n",
      "[400]\ttraining's binary_logloss: 0.367544\tvalid_1's binary_logloss: 0.418552\n",
      "[500]\ttraining's binary_logloss: 0.342053\tvalid_1's binary_logloss: 0.403347\n",
      "[600]\ttraining's binary_logloss: 0.319499\tvalid_1's binary_logloss: 0.389982\n",
      "[700]\ttraining's binary_logloss: 0.300029\tvalid_1's binary_logloss: 0.380374\n",
      "[800]\ttraining's binary_logloss: 0.28348\tvalid_1's binary_logloss: 0.373766\n",
      "[900]\ttraining's binary_logloss: 0.268912\tvalid_1's binary_logloss: 0.36921\n",
      "[1000]\ttraining's binary_logloss: 0.256409\tvalid_1's binary_logloss: 0.368068\n",
      "[1100]\ttraining's binary_logloss: 0.244349\tvalid_1's binary_logloss: 0.36839\n",
      "[1200]\ttraining's binary_logloss: 0.23321\tvalid_1's binary_logloss: 0.367427\n",
      "[1300]\ttraining's binary_logloss: 0.222717\tvalid_1's binary_logloss: 0.367325\n",
      "[1400]\ttraining's binary_logloss: 0.212892\tvalid_1's binary_logloss: 0.367525\n",
      "[1500]\ttraining's binary_logloss: 0.203843\tvalid_1's binary_logloss: 0.367332\n",
      "[1600]\ttraining's binary_logloss: 0.195648\tvalid_1's binary_logloss: 0.366817\n",
      "[1700]\ttraining's binary_logloss: 0.187803\tvalid_1's binary_logloss: 0.366874\n",
      "[1800]\ttraining's binary_logloss: 0.180313\tvalid_1's binary_logloss: 0.368573\n",
      "[1900]\ttraining's binary_logloss: 0.172862\tvalid_1's binary_logloss: 0.368962\n",
      "[2000]\ttraining's binary_logloss: 0.166074\tvalid_1's binary_logloss: 0.370281\n",
      "[2100]\ttraining's binary_logloss: 0.159751\tvalid_1's binary_logloss: 0.370647\n",
      "[2200]\ttraining's binary_logloss: 0.153758\tvalid_1's binary_logloss: 0.373338\n",
      "[2300]\ttraining's binary_logloss: 0.147974\tvalid_1's binary_logloss: 0.373213\n",
      "[2400]\ttraining's binary_logloss: 0.142345\tvalid_1's binary_logloss: 0.374311\n",
      "[2500]\ttraining's binary_logloss: 0.136855\tvalid_1's binary_logloss: 0.3762\n",
      "[2600]\ttraining's binary_logloss: 0.131984\tvalid_1's binary_logloss: 0.376679\n",
      "[2700]\ttraining's binary_logloss: 0.127225\tvalid_1's binary_logloss: 0.377578\n",
      "[2800]\ttraining's binary_logloss: 0.122559\tvalid_1's binary_logloss: 0.379271\n",
      "[2900]\ttraining's binary_logloss: 0.118265\tvalid_1's binary_logloss: 0.379827\n",
      "[3000]\ttraining's binary_logloss: 0.114127\tvalid_1's binary_logloss: 0.38073\n",
      "[3100]\ttraining's binary_logloss: 0.110005\tvalid_1's binary_logloss: 0.381921\n",
      "[3200]\ttraining's binary_logloss: 0.105983\tvalid_1's binary_logloss: 0.384052\n",
      "[3300]\ttraining's binary_logloss: 0.102164\tvalid_1's binary_logloss: 0.385588\n",
      "[3400]\ttraining's binary_logloss: 0.0986562\tvalid_1's binary_logloss: 0.389416\n",
      "[3500]\ttraining's binary_logloss: 0.0950526\tvalid_1's binary_logloss: 0.392028\n",
      "[3600]\ttraining's binary_logloss: 0.0917956\tvalid_1's binary_logloss: 0.395502\n",
      "[3700]\ttraining's binary_logloss: 0.0884645\tvalid_1's binary_logloss: 0.397456\n",
      "[3800]\ttraining's binary_logloss: 0.08548\tvalid_1's binary_logloss: 0.399819\n",
      "[3900]\ttraining's binary_logloss: 0.0825553\tvalid_1's binary_logloss: 0.401422\n",
      "[4000]\ttraining's binary_logloss: 0.0796702\tvalid_1's binary_logloss: 0.403309\n",
      "[4100]\ttraining's binary_logloss: 0.0769473\tvalid_1's binary_logloss: 0.405176\n",
      "[4200]\ttraining's binary_logloss: 0.0742506\tvalid_1's binary_logloss: 0.408859\n",
      "[4300]\ttraining's binary_logloss: 0.0716519\tvalid_1's binary_logloss: 0.412968\n",
      "[4400]\ttraining's binary_logloss: 0.0691966\tvalid_1's binary_logloss: 0.416594\n",
      "[4500]\ttraining's binary_logloss: 0.0668321\tvalid_1's binary_logloss: 0.420347\n",
      "[4600]\ttraining's binary_logloss: 0.0645598\tvalid_1's binary_logloss: 0.422711\n",
      "[4700]\ttraining's binary_logloss: 0.0624367\tvalid_1's binary_logloss: 0.424542\n",
      "[4800]\ttraining's binary_logloss: 0.0603166\tvalid_1's binary_logloss: 0.427833\n",
      "[4900]\ttraining's binary_logloss: 0.0582128\tvalid_1's binary_logloss: 0.430149\n",
      "[5000]\ttraining's binary_logloss: 0.0563161\tvalid_1's binary_logloss: 0.432922\n",
      "Partial score of fold 7 is: 0.43292207274541106\n",
      "[100]\ttraining's binary_logloss: 0.531263\tvalid_1's binary_logloss: 0.544641\n",
      "[200]\ttraining's binary_logloss: 0.451043\tvalid_1's binary_logloss: 0.471718\n",
      "[300]\ttraining's binary_logloss: 0.403379\tvalid_1's binary_logloss: 0.434293\n",
      "[400]\ttraining's binary_logloss: 0.369514\tvalid_1's binary_logloss: 0.409237\n",
      "[500]\ttraining's binary_logloss: 0.343338\tvalid_1's binary_logloss: 0.393951\n",
      "[600]\ttraining's binary_logloss: 0.322007\tvalid_1's binary_logloss: 0.382626\n",
      "[700]\ttraining's binary_logloss: 0.302415\tvalid_1's binary_logloss: 0.371617\n",
      "[800]\ttraining's binary_logloss: 0.2864\tvalid_1's binary_logloss: 0.36683\n",
      "[900]\ttraining's binary_logloss: 0.272439\tvalid_1's binary_logloss: 0.361472\n",
      "[1000]\ttraining's binary_logloss: 0.258944\tvalid_1's binary_logloss: 0.354875\n",
      "[1100]\ttraining's binary_logloss: 0.246781\tvalid_1's binary_logloss: 0.349828\n",
      "[1200]\ttraining's binary_logloss: 0.235805\tvalid_1's binary_logloss: 0.348423\n",
      "[1300]\ttraining's binary_logloss: 0.225421\tvalid_1's binary_logloss: 0.345466\n",
      "[1400]\ttraining's binary_logloss: 0.215474\tvalid_1's binary_logloss: 0.344175\n",
      "[1500]\ttraining's binary_logloss: 0.206052\tvalid_1's binary_logloss: 0.341828\n",
      "[1600]\ttraining's binary_logloss: 0.197466\tvalid_1's binary_logloss: 0.339447\n",
      "[1700]\ttraining's binary_logloss: 0.189098\tvalid_1's binary_logloss: 0.336896\n",
      "[1800]\ttraining's binary_logloss: 0.181354\tvalid_1's binary_logloss: 0.335606\n",
      "[1900]\ttraining's binary_logloss: 0.174287\tvalid_1's binary_logloss: 0.335265\n",
      "[2000]\ttraining's binary_logloss: 0.167113\tvalid_1's binary_logloss: 0.334653\n",
      "[2100]\ttraining's binary_logloss: 0.159887\tvalid_1's binary_logloss: 0.333142\n",
      "[2200]\ttraining's binary_logloss: 0.153513\tvalid_1's binary_logloss: 0.331999\n",
      "[2300]\ttraining's binary_logloss: 0.147655\tvalid_1's binary_logloss: 0.332509\n",
      "[2400]\ttraining's binary_logloss: 0.141789\tvalid_1's binary_logloss: 0.332648\n",
      "[2500]\ttraining's binary_logloss: 0.136289\tvalid_1's binary_logloss: 0.330801\n",
      "[2600]\ttraining's binary_logloss: 0.131071\tvalid_1's binary_logloss: 0.330838\n",
      "[2700]\ttraining's binary_logloss: 0.126219\tvalid_1's binary_logloss: 0.331441\n",
      "[2800]\ttraining's binary_logloss: 0.12172\tvalid_1's binary_logloss: 0.332448\n",
      "[2900]\ttraining's binary_logloss: 0.117415\tvalid_1's binary_logloss: 0.333611\n",
      "[3000]\ttraining's binary_logloss: 0.113026\tvalid_1's binary_logloss: 0.334439\n",
      "[3100]\ttraining's binary_logloss: 0.108637\tvalid_1's binary_logloss: 0.335859\n",
      "[3200]\ttraining's binary_logloss: 0.104698\tvalid_1's binary_logloss: 0.337625\n",
      "[3300]\ttraining's binary_logloss: 0.101005\tvalid_1's binary_logloss: 0.339516\n",
      "[3400]\ttraining's binary_logloss: 0.0974831\tvalid_1's binary_logloss: 0.340699\n",
      "[3500]\ttraining's binary_logloss: 0.0942375\tvalid_1's binary_logloss: 0.340907\n",
      "[3600]\ttraining's binary_logloss: 0.0909516\tvalid_1's binary_logloss: 0.340244\n",
      "[3700]\ttraining's binary_logloss: 0.0877185\tvalid_1's binary_logloss: 0.340085\n",
      "[3800]\ttraining's binary_logloss: 0.0845922\tvalid_1's binary_logloss: 0.341587\n",
      "[3900]\ttraining's binary_logloss: 0.0816907\tvalid_1's binary_logloss: 0.34212\n",
      "[4000]\ttraining's binary_logloss: 0.0788382\tvalid_1's binary_logloss: 0.341852\n",
      "[4100]\ttraining's binary_logloss: 0.0761296\tvalid_1's binary_logloss: 0.342631\n",
      "[4200]\ttraining's binary_logloss: 0.0735165\tvalid_1's binary_logloss: 0.342361\n",
      "[4300]\ttraining's binary_logloss: 0.0708069\tvalid_1's binary_logloss: 0.343346\n",
      "[4400]\ttraining's binary_logloss: 0.0682346\tvalid_1's binary_logloss: 0.345412\n",
      "[4500]\ttraining's binary_logloss: 0.0659679\tvalid_1's binary_logloss: 0.34604\n",
      "[4600]\ttraining's binary_logloss: 0.0637233\tvalid_1's binary_logloss: 0.346925\n",
      "[4700]\ttraining's binary_logloss: 0.061589\tvalid_1's binary_logloss: 0.34922\n",
      "[4800]\ttraining's binary_logloss: 0.0595435\tvalid_1's binary_logloss: 0.349759\n",
      "[4900]\ttraining's binary_logloss: 0.0575568\tvalid_1's binary_logloss: 0.35058\n",
      "[5000]\ttraining's binary_logloss: 0.0555846\tvalid_1's binary_logloss: 0.351507\n",
      "Partial score of fold 8 is: 0.35150683095565816\n",
      "[100]\ttraining's binary_logloss: 0.531685\tvalid_1's binary_logloss: 0.556849\n",
      "[200]\ttraining's binary_logloss: 0.449269\tvalid_1's binary_logloss: 0.497865\n",
      "[300]\ttraining's binary_logloss: 0.399382\tvalid_1's binary_logloss: 0.46617\n",
      "[400]\ttraining's binary_logloss: 0.36557\tvalid_1's binary_logloss: 0.446582\n",
      "[500]\ttraining's binary_logloss: 0.338168\tvalid_1's binary_logloss: 0.42919\n",
      "[600]\ttraining's binary_logloss: 0.315938\tvalid_1's binary_logloss: 0.422289\n",
      "[700]\ttraining's binary_logloss: 0.296177\tvalid_1's binary_logloss: 0.416125\n",
      "[800]\ttraining's binary_logloss: 0.279601\tvalid_1's binary_logloss: 0.415336\n",
      "[900]\ttraining's binary_logloss: 0.265313\tvalid_1's binary_logloss: 0.41573\n",
      "[1000]\ttraining's binary_logloss: 0.252459\tvalid_1's binary_logloss: 0.416002\n",
      "[1100]\ttraining's binary_logloss: 0.240908\tvalid_1's binary_logloss: 0.416838\n",
      "[1200]\ttraining's binary_logloss: 0.229629\tvalid_1's binary_logloss: 0.418057\n",
      "[1300]\ttraining's binary_logloss: 0.21887\tvalid_1's binary_logloss: 0.419749\n",
      "[1400]\ttraining's binary_logloss: 0.207969\tvalid_1's binary_logloss: 0.419602\n",
      "[1500]\ttraining's binary_logloss: 0.198728\tvalid_1's binary_logloss: 0.421805\n",
      "[1600]\ttraining's binary_logloss: 0.190235\tvalid_1's binary_logloss: 0.42226\n",
      "[1700]\ttraining's binary_logloss: 0.181784\tvalid_1's binary_logloss: 0.423557\n",
      "[1800]\ttraining's binary_logloss: 0.173566\tvalid_1's binary_logloss: 0.427456\n",
      "[1900]\ttraining's binary_logloss: 0.166079\tvalid_1's binary_logloss: 0.429157\n",
      "[2000]\ttraining's binary_logloss: 0.158993\tvalid_1's binary_logloss: 0.430447\n",
      "[2100]\ttraining's binary_logloss: 0.152487\tvalid_1's binary_logloss: 0.432325\n",
      "[2200]\ttraining's binary_logloss: 0.146429\tvalid_1's binary_logloss: 0.433088\n",
      "[2300]\ttraining's binary_logloss: 0.140631\tvalid_1's binary_logloss: 0.435172\n",
      "[2400]\ttraining's binary_logloss: 0.134794\tvalid_1's binary_logloss: 0.437736\n",
      "[2500]\ttraining's binary_logloss: 0.129719\tvalid_1's binary_logloss: 0.440425\n",
      "[2600]\ttraining's binary_logloss: 0.12496\tvalid_1's binary_logloss: 0.444828\n",
      "[2700]\ttraining's binary_logloss: 0.120341\tvalid_1's binary_logloss: 0.448627\n",
      "[2800]\ttraining's binary_logloss: 0.115805\tvalid_1's binary_logloss: 0.452179\n",
      "[2900]\ttraining's binary_logloss: 0.111506\tvalid_1's binary_logloss: 0.456529\n",
      "[3000]\ttraining's binary_logloss: 0.107472\tvalid_1's binary_logloss: 0.46086\n",
      "[3100]\ttraining's binary_logloss: 0.103488\tvalid_1's binary_logloss: 0.465087\n",
      "[3200]\ttraining's binary_logloss: 0.0996713\tvalid_1's binary_logloss: 0.468563\n",
      "[3300]\ttraining's binary_logloss: 0.0960846\tvalid_1's binary_logloss: 0.471781\n",
      "[3400]\ttraining's binary_logloss: 0.0926674\tvalid_1's binary_logloss: 0.474323\n",
      "[3500]\ttraining's binary_logloss: 0.0893472\tvalid_1's binary_logloss: 0.477664\n",
      "[3600]\ttraining's binary_logloss: 0.0862264\tvalid_1's binary_logloss: 0.480175\n",
      "[3700]\ttraining's binary_logloss: 0.0831486\tvalid_1's binary_logloss: 0.482611\n",
      "[3800]\ttraining's binary_logloss: 0.0800907\tvalid_1's binary_logloss: 0.486394\n",
      "[3900]\ttraining's binary_logloss: 0.0771376\tvalid_1's binary_logloss: 0.488936\n",
      "[4000]\ttraining's binary_logloss: 0.074427\tvalid_1's binary_logloss: 0.492705\n",
      "[4100]\ttraining's binary_logloss: 0.0717557\tvalid_1's binary_logloss: 0.495593\n",
      "[4200]\ttraining's binary_logloss: 0.0691871\tvalid_1's binary_logloss: 0.498729\n",
      "[4300]\ttraining's binary_logloss: 0.0667857\tvalid_1's binary_logloss: 0.501902\n",
      "[4400]\ttraining's binary_logloss: 0.0644745\tvalid_1's binary_logloss: 0.505548\n",
      "[4500]\ttraining's binary_logloss: 0.0623121\tvalid_1's binary_logloss: 0.509565\n",
      "[4600]\ttraining's binary_logloss: 0.0602176\tvalid_1's binary_logloss: 0.512493\n",
      "[4700]\ttraining's binary_logloss: 0.0582195\tvalid_1's binary_logloss: 0.515477\n",
      "[4800]\ttraining's binary_logloss: 0.0562323\tvalid_1's binary_logloss: 0.51779\n",
      "[4900]\ttraining's binary_logloss: 0.0542931\tvalid_1's binary_logloss: 0.520555\n",
      "[5000]\ttraining's binary_logloss: 0.0524508\tvalid_1's binary_logloss: 0.524612\n",
      "Partial score of fold 9 is: 0.5246124469835572\n",
      "Our oof loss score is:  0.42437298623183445\n",
      "Predicting 2016...\n",
      "[100]\ttraining's binary_logloss: 0.533879\tvalid_1's binary_logloss: 0.534065\n",
      "[200]\ttraining's binary_logloss: 0.452487\tvalid_1's binary_logloss: 0.46114\n",
      "[300]\ttraining's binary_logloss: 0.403154\tvalid_1's binary_logloss: 0.421739\n",
      "[400]\ttraining's binary_logloss: 0.36762\tvalid_1's binary_logloss: 0.397692\n",
      "[500]\ttraining's binary_logloss: 0.341535\tvalid_1's binary_logloss: 0.385279\n",
      "[600]\ttraining's binary_logloss: 0.318978\tvalid_1's binary_logloss: 0.376851\n",
      "[700]\ttraining's binary_logloss: 0.30085\tvalid_1's binary_logloss: 0.369637\n",
      "[800]\ttraining's binary_logloss: 0.284574\tvalid_1's binary_logloss: 0.367872\n",
      "[900]\ttraining's binary_logloss: 0.269425\tvalid_1's binary_logloss: 0.366573\n",
      "[1000]\ttraining's binary_logloss: 0.255449\tvalid_1's binary_logloss: 0.368907\n",
      "[1100]\ttraining's binary_logloss: 0.242711\tvalid_1's binary_logloss: 0.369007\n",
      "[1200]\ttraining's binary_logloss: 0.231964\tvalid_1's binary_logloss: 0.368506\n",
      "[1300]\ttraining's binary_logloss: 0.221943\tvalid_1's binary_logloss: 0.37021\n",
      "[1400]\ttraining's binary_logloss: 0.211687\tvalid_1's binary_logloss: 0.369412\n",
      "[1500]\ttraining's binary_logloss: 0.202533\tvalid_1's binary_logloss: 0.370966\n",
      "[1600]\ttraining's binary_logloss: 0.193914\tvalid_1's binary_logloss: 0.371372\n",
      "[1700]\ttraining's binary_logloss: 0.185807\tvalid_1's binary_logloss: 0.372936\n",
      "[1800]\ttraining's binary_logloss: 0.178325\tvalid_1's binary_logloss: 0.374704\n",
      "[1900]\ttraining's binary_logloss: 0.171353\tvalid_1's binary_logloss: 0.376542\n",
      "[2000]\ttraining's binary_logloss: 0.164523\tvalid_1's binary_logloss: 0.376931\n",
      "[2100]\ttraining's binary_logloss: 0.157939\tvalid_1's binary_logloss: 0.378364\n",
      "[2200]\ttraining's binary_logloss: 0.151368\tvalid_1's binary_logloss: 0.379831\n",
      "[2300]\ttraining's binary_logloss: 0.145395\tvalid_1's binary_logloss: 0.380688\n",
      "[2400]\ttraining's binary_logloss: 0.139983\tvalid_1's binary_logloss: 0.380542\n",
      "[2500]\ttraining's binary_logloss: 0.134606\tvalid_1's binary_logloss: 0.380424\n",
      "[2600]\ttraining's binary_logloss: 0.129612\tvalid_1's binary_logloss: 0.382421\n",
      "[2700]\ttraining's binary_logloss: 0.124962\tvalid_1's binary_logloss: 0.38418\n",
      "[2800]\ttraining's binary_logloss: 0.12038\tvalid_1's binary_logloss: 0.3852\n",
      "[2900]\ttraining's binary_logloss: 0.116159\tvalid_1's binary_logloss: 0.386413\n",
      "[3000]\ttraining's binary_logloss: 0.111946\tvalid_1's binary_logloss: 0.388673\n",
      "[3100]\ttraining's binary_logloss: 0.108017\tvalid_1's binary_logloss: 0.389113\n",
      "[3200]\ttraining's binary_logloss: 0.10444\tvalid_1's binary_logloss: 0.390926\n",
      "[3300]\ttraining's binary_logloss: 0.100677\tvalid_1's binary_logloss: 0.392834\n",
      "[3400]\ttraining's binary_logloss: 0.0970393\tvalid_1's binary_logloss: 0.394797\n",
      "[3500]\ttraining's binary_logloss: 0.0935917\tvalid_1's binary_logloss: 0.397031\n",
      "[3600]\ttraining's binary_logloss: 0.0904213\tvalid_1's binary_logloss: 0.397639\n",
      "[3700]\ttraining's binary_logloss: 0.0873464\tvalid_1's binary_logloss: 0.397845\n",
      "[3800]\ttraining's binary_logloss: 0.0843028\tvalid_1's binary_logloss: 0.399672\n",
      "[3900]\ttraining's binary_logloss: 0.0812572\tvalid_1's binary_logloss: 0.400708\n",
      "[4000]\ttraining's binary_logloss: 0.0781527\tvalid_1's binary_logloss: 0.40245\n",
      "[4100]\ttraining's binary_logloss: 0.0754306\tvalid_1's binary_logloss: 0.403645\n",
      "[4200]\ttraining's binary_logloss: 0.0727553\tvalid_1's binary_logloss: 0.405596\n",
      "[4300]\ttraining's binary_logloss: 0.0699965\tvalid_1's binary_logloss: 0.407887\n",
      "[4400]\ttraining's binary_logloss: 0.0675656\tvalid_1's binary_logloss: 0.409225\n",
      "[4500]\ttraining's binary_logloss: 0.0652473\tvalid_1's binary_logloss: 0.411902\n",
      "[4600]\ttraining's binary_logloss: 0.0629514\tvalid_1's binary_logloss: 0.413904\n",
      "[4700]\ttraining's binary_logloss: 0.0606707\tvalid_1's binary_logloss: 0.417078\n",
      "[4800]\ttraining's binary_logloss: 0.0584421\tvalid_1's binary_logloss: 0.421263\n",
      "[4900]\ttraining's binary_logloss: 0.0564469\tvalid_1's binary_logloss: 0.424689\n",
      "[5000]\ttraining's binary_logloss: 0.0544951\tvalid_1's binary_logloss: 0.426622\n",
      "Partial score of fold 0 is: 0.42662156595615264\n",
      "[100]\ttraining's binary_logloss: 0.530438\tvalid_1's binary_logloss: 0.558449\n",
      "[200]\ttraining's binary_logloss: 0.447642\tvalid_1's binary_logloss: 0.494672\n",
      "[300]\ttraining's binary_logloss: 0.39838\tvalid_1's binary_logloss: 0.462501\n",
      "[400]\ttraining's binary_logloss: 0.364537\tvalid_1's binary_logloss: 0.441584\n",
      "[500]\ttraining's binary_logloss: 0.338264\tvalid_1's binary_logloss: 0.425405\n",
      "[600]\ttraining's binary_logloss: 0.316262\tvalid_1's binary_logloss: 0.413279\n",
      "[700]\ttraining's binary_logloss: 0.297503\tvalid_1's binary_logloss: 0.401126\n",
      "[800]\ttraining's binary_logloss: 0.281868\tvalid_1's binary_logloss: 0.395245\n",
      "[900]\ttraining's binary_logloss: 0.266963\tvalid_1's binary_logloss: 0.392217\n",
      "[1000]\ttraining's binary_logloss: 0.253438\tvalid_1's binary_logloss: 0.388792\n",
      "[1100]\ttraining's binary_logloss: 0.241799\tvalid_1's binary_logloss: 0.387876\n",
      "[1200]\ttraining's binary_logloss: 0.230304\tvalid_1's binary_logloss: 0.388533\n",
      "[1300]\ttraining's binary_logloss: 0.219818\tvalid_1's binary_logloss: 0.388828\n",
      "[1400]\ttraining's binary_logloss: 0.210796\tvalid_1's binary_logloss: 0.387442\n",
      "[1500]\ttraining's binary_logloss: 0.201804\tvalid_1's binary_logloss: 0.38349\n",
      "[1600]\ttraining's binary_logloss: 0.192676\tvalid_1's binary_logloss: 0.382124\n",
      "[1700]\ttraining's binary_logloss: 0.18439\tvalid_1's binary_logloss: 0.381894\n",
      "[1800]\ttraining's binary_logloss: 0.17671\tvalid_1's binary_logloss: 0.382925\n",
      "[1900]\ttraining's binary_logloss: 0.169522\tvalid_1's binary_logloss: 0.384151\n",
      "[2000]\ttraining's binary_logloss: 0.162754\tvalid_1's binary_logloss: 0.387153\n",
      "[2100]\ttraining's binary_logloss: 0.156364\tvalid_1's binary_logloss: 0.388848\n",
      "[2200]\ttraining's binary_logloss: 0.150222\tvalid_1's binary_logloss: 0.389225\n",
      "[2300]\ttraining's binary_logloss: 0.144416\tvalid_1's binary_logloss: 0.39068\n",
      "[2400]\ttraining's binary_logloss: 0.138904\tvalid_1's binary_logloss: 0.391381\n",
      "[2500]\ttraining's binary_logloss: 0.133795\tvalid_1's binary_logloss: 0.392873\n",
      "[2600]\ttraining's binary_logloss: 0.128855\tvalid_1's binary_logloss: 0.393753\n",
      "[2700]\ttraining's binary_logloss: 0.123958\tvalid_1's binary_logloss: 0.395305\n",
      "[2800]\ttraining's binary_logloss: 0.119385\tvalid_1's binary_logloss: 0.3972\n",
      "[2900]\ttraining's binary_logloss: 0.115016\tvalid_1's binary_logloss: 0.397092\n",
      "[3000]\ttraining's binary_logloss: 0.110934\tvalid_1's binary_logloss: 0.398833\n",
      "[3100]\ttraining's binary_logloss: 0.106994\tvalid_1's binary_logloss: 0.399147\n",
      "[3200]\ttraining's binary_logloss: 0.103212\tvalid_1's binary_logloss: 0.397454\n",
      "[3300]\ttraining's binary_logloss: 0.0995624\tvalid_1's binary_logloss: 0.397103\n",
      "[3400]\ttraining's binary_logloss: 0.0962272\tvalid_1's binary_logloss: 0.398199\n",
      "[3500]\ttraining's binary_logloss: 0.0929324\tvalid_1's binary_logloss: 0.399208\n",
      "[3600]\ttraining's binary_logloss: 0.0895938\tvalid_1's binary_logloss: 0.400215\n",
      "[3700]\ttraining's binary_logloss: 0.0864706\tvalid_1's binary_logloss: 0.401542\n",
      "[3800]\ttraining's binary_logloss: 0.083555\tvalid_1's binary_logloss: 0.403102\n",
      "[3900]\ttraining's binary_logloss: 0.0805301\tvalid_1's binary_logloss: 0.404623\n",
      "[4000]\ttraining's binary_logloss: 0.0776831\tvalid_1's binary_logloss: 0.405612\n",
      "[4100]\ttraining's binary_logloss: 0.075055\tvalid_1's binary_logloss: 0.407654\n",
      "[4200]\ttraining's binary_logloss: 0.0724351\tvalid_1's binary_logloss: 0.409381\n",
      "[4300]\ttraining's binary_logloss: 0.0700671\tvalid_1's binary_logloss: 0.411627\n",
      "[4400]\ttraining's binary_logloss: 0.0677596\tvalid_1's binary_logloss: 0.412996\n",
      "[4500]\ttraining's binary_logloss: 0.0655712\tvalid_1's binary_logloss: 0.414448\n",
      "[4600]\ttraining's binary_logloss: 0.0633367\tvalid_1's binary_logloss: 0.41432\n",
      "[4700]\ttraining's binary_logloss: 0.0611838\tvalid_1's binary_logloss: 0.416275\n",
      "[4800]\ttraining's binary_logloss: 0.0590429\tvalid_1's binary_logloss: 0.4188\n",
      "[4900]\ttraining's binary_logloss: 0.0569747\tvalid_1's binary_logloss: 0.420533\n",
      "[5000]\ttraining's binary_logloss: 0.0550032\tvalid_1's binary_logloss: 0.422815\n",
      "Partial score of fold 1 is: 0.42281512322351805\n",
      "[100]\ttraining's binary_logloss: 0.531659\tvalid_1's binary_logloss: 0.551978\n",
      "[200]\ttraining's binary_logloss: 0.450432\tvalid_1's binary_logloss: 0.481607\n",
      "[300]\ttraining's binary_logloss: 0.401965\tvalid_1's binary_logloss: 0.440426\n",
      "[400]\ttraining's binary_logloss: 0.368132\tvalid_1's binary_logloss: 0.41241\n",
      "[500]\ttraining's binary_logloss: 0.341827\tvalid_1's binary_logloss: 0.396649\n",
      "[600]\ttraining's binary_logloss: 0.319436\tvalid_1's binary_logloss: 0.386696\n",
      "[700]\ttraining's binary_logloss: 0.299313\tvalid_1's binary_logloss: 0.379062\n",
      "[800]\ttraining's binary_logloss: 0.281861\tvalid_1's binary_logloss: 0.375632\n",
      "[900]\ttraining's binary_logloss: 0.267045\tvalid_1's binary_logloss: 0.374904\n",
      "[1000]\ttraining's binary_logloss: 0.254546\tvalid_1's binary_logloss: 0.37277\n",
      "[1100]\ttraining's binary_logloss: 0.242942\tvalid_1's binary_logloss: 0.372153\n",
      "[1200]\ttraining's binary_logloss: 0.231424\tvalid_1's binary_logloss: 0.374227\n",
      "[1300]\ttraining's binary_logloss: 0.220939\tvalid_1's binary_logloss: 0.375613\n",
      "[1400]\ttraining's binary_logloss: 0.211329\tvalid_1's binary_logloss: 0.377424\n",
      "[1500]\ttraining's binary_logloss: 0.202066\tvalid_1's binary_logloss: 0.378829\n",
      "[1600]\ttraining's binary_logloss: 0.193317\tvalid_1's binary_logloss: 0.379931\n",
      "[1700]\ttraining's binary_logloss: 0.185\tvalid_1's binary_logloss: 0.381917\n",
      "[1800]\ttraining's binary_logloss: 0.177432\tvalid_1's binary_logloss: 0.383454\n",
      "[1900]\ttraining's binary_logloss: 0.170168\tvalid_1's binary_logloss: 0.38613\n",
      "[2000]\ttraining's binary_logloss: 0.163186\tvalid_1's binary_logloss: 0.387726\n",
      "[2100]\ttraining's binary_logloss: 0.156751\tvalid_1's binary_logloss: 0.39108\n",
      "[2200]\ttraining's binary_logloss: 0.150822\tvalid_1's binary_logloss: 0.394201\n",
      "[2300]\ttraining's binary_logloss: 0.145051\tvalid_1's binary_logloss: 0.397381\n",
      "[2400]\ttraining's binary_logloss: 0.139212\tvalid_1's binary_logloss: 0.400304\n",
      "[2500]\ttraining's binary_logloss: 0.133871\tvalid_1's binary_logloss: 0.404038\n",
      "[2600]\ttraining's binary_logloss: 0.128806\tvalid_1's binary_logloss: 0.408005\n",
      "[2700]\ttraining's binary_logloss: 0.123777\tvalid_1's binary_logloss: 0.409688\n",
      "[2800]\ttraining's binary_logloss: 0.118944\tvalid_1's binary_logloss: 0.410787\n",
      "[2900]\ttraining's binary_logloss: 0.114424\tvalid_1's binary_logloss: 0.411524\n",
      "[3000]\ttraining's binary_logloss: 0.110064\tvalid_1's binary_logloss: 0.412231\n",
      "[3100]\ttraining's binary_logloss: 0.106018\tvalid_1's binary_logloss: 0.413983\n",
      "[3200]\ttraining's binary_logloss: 0.102122\tvalid_1's binary_logloss: 0.416922\n",
      "[3300]\ttraining's binary_logloss: 0.098301\tvalid_1's binary_logloss: 0.419291\n",
      "[3400]\ttraining's binary_logloss: 0.0946849\tvalid_1's binary_logloss: 0.423835\n",
      "[3500]\ttraining's binary_logloss: 0.0911475\tvalid_1's binary_logloss: 0.427682\n",
      "[3600]\ttraining's binary_logloss: 0.0878085\tvalid_1's binary_logloss: 0.430953\n",
      "[3700]\ttraining's binary_logloss: 0.0846108\tvalid_1's binary_logloss: 0.433879\n",
      "[3800]\ttraining's binary_logloss: 0.0815005\tvalid_1's binary_logloss: 0.43633\n",
      "[3900]\ttraining's binary_logloss: 0.0785155\tvalid_1's binary_logloss: 0.439659\n",
      "[4000]\ttraining's binary_logloss: 0.0756991\tvalid_1's binary_logloss: 0.441381\n",
      "[4100]\ttraining's binary_logloss: 0.0730795\tvalid_1's binary_logloss: 0.44361\n",
      "[4200]\ttraining's binary_logloss: 0.0705581\tvalid_1's binary_logloss: 0.445482\n",
      "[4300]\ttraining's binary_logloss: 0.0680622\tvalid_1's binary_logloss: 0.446788\n",
      "[4400]\ttraining's binary_logloss: 0.0656703\tvalid_1's binary_logloss: 0.448533\n",
      "[4500]\ttraining's binary_logloss: 0.0633806\tvalid_1's binary_logloss: 0.451458\n",
      "[4600]\ttraining's binary_logloss: 0.0611404\tvalid_1's binary_logloss: 0.454736\n",
      "[4700]\ttraining's binary_logloss: 0.0589495\tvalid_1's binary_logloss: 0.457747\n",
      "[4800]\ttraining's binary_logloss: 0.0568939\tvalid_1's binary_logloss: 0.461163\n",
      "[4900]\ttraining's binary_logloss: 0.0549723\tvalid_1's binary_logloss: 0.464822\n",
      "[5000]\ttraining's binary_logloss: 0.0530444\tvalid_1's binary_logloss: 0.466911\n",
      "Partial score of fold 2 is: 0.4669114262800087\n",
      "[100]\ttraining's binary_logloss: 0.530339\tvalid_1's binary_logloss: 0.553748\n",
      "[200]\ttraining's binary_logloss: 0.448659\tvalid_1's binary_logloss: 0.49148\n",
      "[300]\ttraining's binary_logloss: 0.400933\tvalid_1's binary_logloss: 0.458645\n",
      "[400]\ttraining's binary_logloss: 0.366942\tvalid_1's binary_logloss: 0.434217\n",
      "[500]\ttraining's binary_logloss: 0.341418\tvalid_1's binary_logloss: 0.41699\n",
      "[600]\ttraining's binary_logloss: 0.319602\tvalid_1's binary_logloss: 0.405681\n",
      "[700]\ttraining's binary_logloss: 0.302145\tvalid_1's binary_logloss: 0.396424\n",
      "[800]\ttraining's binary_logloss: 0.285723\tvalid_1's binary_logloss: 0.38785\n",
      "[900]\ttraining's binary_logloss: 0.270712\tvalid_1's binary_logloss: 0.378617\n",
      "[1000]\ttraining's binary_logloss: 0.256994\tvalid_1's binary_logloss: 0.371381\n",
      "[1100]\ttraining's binary_logloss: 0.244546\tvalid_1's binary_logloss: 0.367102\n",
      "[1200]\ttraining's binary_logloss: 0.232735\tvalid_1's binary_logloss: 0.364709\n",
      "[1300]\ttraining's binary_logloss: 0.221547\tvalid_1's binary_logloss: 0.364609\n",
      "[1400]\ttraining's binary_logloss: 0.211528\tvalid_1's binary_logloss: 0.361082\n",
      "[1500]\ttraining's binary_logloss: 0.202474\tvalid_1's binary_logloss: 0.359661\n",
      "[1600]\ttraining's binary_logloss: 0.193828\tvalid_1's binary_logloss: 0.358836\n",
      "[1700]\ttraining's binary_logloss: 0.18594\tvalid_1's binary_logloss: 0.357816\n",
      "[1800]\ttraining's binary_logloss: 0.178084\tvalid_1's binary_logloss: 0.357598\n",
      "[1900]\ttraining's binary_logloss: 0.170703\tvalid_1's binary_logloss: 0.356676\n",
      "[2000]\ttraining's binary_logloss: 0.163761\tvalid_1's binary_logloss: 0.355811\n",
      "[2100]\ttraining's binary_logloss: 0.15727\tvalid_1's binary_logloss: 0.354328\n",
      "[2200]\ttraining's binary_logloss: 0.151053\tvalid_1's binary_logloss: 0.35311\n",
      "[2300]\ttraining's binary_logloss: 0.145158\tvalid_1's binary_logloss: 0.351953\n",
      "[2400]\ttraining's binary_logloss: 0.139519\tvalid_1's binary_logloss: 0.351956\n",
      "[2500]\ttraining's binary_logloss: 0.133985\tvalid_1's binary_logloss: 0.351625\n",
      "[2600]\ttraining's binary_logloss: 0.128939\tvalid_1's binary_logloss: 0.352851\n",
      "[2700]\ttraining's binary_logloss: 0.124421\tvalid_1's binary_logloss: 0.353913\n",
      "[2800]\ttraining's binary_logloss: 0.119941\tvalid_1's binary_logloss: 0.3543\n",
      "[2900]\ttraining's binary_logloss: 0.115704\tvalid_1's binary_logloss: 0.355869\n",
      "[3000]\ttraining's binary_logloss: 0.111641\tvalid_1's binary_logloss: 0.356307\n",
      "[3100]\ttraining's binary_logloss: 0.107663\tvalid_1's binary_logloss: 0.357082\n",
      "[3200]\ttraining's binary_logloss: 0.103931\tvalid_1's binary_logloss: 0.356326\n",
      "[3300]\ttraining's binary_logloss: 0.100212\tvalid_1's binary_logloss: 0.356747\n",
      "[3400]\ttraining's binary_logloss: 0.0966412\tvalid_1's binary_logloss: 0.357642\n",
      "[3500]\ttraining's binary_logloss: 0.0931266\tvalid_1's binary_logloss: 0.358141\n",
      "[3600]\ttraining's binary_logloss: 0.0898515\tvalid_1's binary_logloss: 0.360204\n",
      "[3700]\ttraining's binary_logloss: 0.0866503\tvalid_1's binary_logloss: 0.361612\n",
      "[3800]\ttraining's binary_logloss: 0.0835909\tvalid_1's binary_logloss: 0.363981\n",
      "[3900]\ttraining's binary_logloss: 0.0805405\tvalid_1's binary_logloss: 0.36614\n",
      "[4000]\ttraining's binary_logloss: 0.0777963\tvalid_1's binary_logloss: 0.367623\n",
      "[4100]\ttraining's binary_logloss: 0.0751431\tvalid_1's binary_logloss: 0.367707\n",
      "[4200]\ttraining's binary_logloss: 0.0726022\tvalid_1's binary_logloss: 0.368909\n",
      "[4300]\ttraining's binary_logloss: 0.0700562\tvalid_1's binary_logloss: 0.369212\n",
      "[4400]\ttraining's binary_logloss: 0.0676707\tvalid_1's binary_logloss: 0.369494\n",
      "[4500]\ttraining's binary_logloss: 0.065345\tvalid_1's binary_logloss: 0.370199\n",
      "[4600]\ttraining's binary_logloss: 0.0630438\tvalid_1's binary_logloss: 0.371331\n",
      "[4700]\ttraining's binary_logloss: 0.061033\tvalid_1's binary_logloss: 0.372265\n",
      "[4800]\ttraining's binary_logloss: 0.0590266\tvalid_1's binary_logloss: 0.373438\n",
      "[4900]\ttraining's binary_logloss: 0.0571166\tvalid_1's binary_logloss: 0.374169\n",
      "[5000]\ttraining's binary_logloss: 0.0552094\tvalid_1's binary_logloss: 0.374913\n",
      "Partial score of fold 3 is: 0.3749130315526168\n",
      "[100]\ttraining's binary_logloss: 0.531849\tvalid_1's binary_logloss: 0.550082\n",
      "[200]\ttraining's binary_logloss: 0.449828\tvalid_1's binary_logloss: 0.482729\n",
      "[300]\ttraining's binary_logloss: 0.399152\tvalid_1's binary_logloss: 0.4479\n",
      "[400]\ttraining's binary_logloss: 0.365826\tvalid_1's binary_logloss: 0.429751\n",
      "[500]\ttraining's binary_logloss: 0.339025\tvalid_1's binary_logloss: 0.417744\n",
      "[600]\ttraining's binary_logloss: 0.317371\tvalid_1's binary_logloss: 0.407631\n",
      "[700]\ttraining's binary_logloss: 0.299591\tvalid_1's binary_logloss: 0.401681\n",
      "[800]\ttraining's binary_logloss: 0.284032\tvalid_1's binary_logloss: 0.397361\n",
      "[900]\ttraining's binary_logloss: 0.26989\tvalid_1's binary_logloss: 0.393892\n",
      "[1000]\ttraining's binary_logloss: 0.255998\tvalid_1's binary_logloss: 0.392542\n",
      "[1100]\ttraining's binary_logloss: 0.243475\tvalid_1's binary_logloss: 0.390296\n",
      "[1200]\ttraining's binary_logloss: 0.231923\tvalid_1's binary_logloss: 0.38798\n",
      "[1300]\ttraining's binary_logloss: 0.221225\tvalid_1's binary_logloss: 0.38668\n",
      "[1400]\ttraining's binary_logloss: 0.211457\tvalid_1's binary_logloss: 0.388219\n",
      "[1500]\ttraining's binary_logloss: 0.2017\tvalid_1's binary_logloss: 0.389345\n",
      "[1600]\ttraining's binary_logloss: 0.192692\tvalid_1's binary_logloss: 0.389093\n",
      "[1700]\ttraining's binary_logloss: 0.184594\tvalid_1's binary_logloss: 0.391342\n",
      "[1800]\ttraining's binary_logloss: 0.176508\tvalid_1's binary_logloss: 0.392765\n",
      "[1900]\ttraining's binary_logloss: 0.169362\tvalid_1's binary_logloss: 0.393132\n",
      "[2000]\ttraining's binary_logloss: 0.162558\tvalid_1's binary_logloss: 0.393284\n",
      "[2100]\ttraining's binary_logloss: 0.156237\tvalid_1's binary_logloss: 0.392896\n",
      "[2200]\ttraining's binary_logloss: 0.1503\tvalid_1's binary_logloss: 0.393591\n",
      "[2300]\ttraining's binary_logloss: 0.144782\tvalid_1's binary_logloss: 0.395223\n",
      "[2400]\ttraining's binary_logloss: 0.139409\tvalid_1's binary_logloss: 0.396132\n",
      "[2500]\ttraining's binary_logloss: 0.134112\tvalid_1's binary_logloss: 0.39762\n",
      "[2600]\ttraining's binary_logloss: 0.129217\tvalid_1's binary_logloss: 0.398134\n",
      "[2700]\ttraining's binary_logloss: 0.124422\tvalid_1's binary_logloss: 0.399134\n",
      "[2800]\ttraining's binary_logloss: 0.119965\tvalid_1's binary_logloss: 0.401842\n",
      "[2900]\ttraining's binary_logloss: 0.115674\tvalid_1's binary_logloss: 0.401899\n",
      "[3000]\ttraining's binary_logloss: 0.111291\tvalid_1's binary_logloss: 0.402705\n",
      "[3100]\ttraining's binary_logloss: 0.107197\tvalid_1's binary_logloss: 0.403435\n",
      "[3200]\ttraining's binary_logloss: 0.103343\tvalid_1's binary_logloss: 0.404545\n",
      "[3300]\ttraining's binary_logloss: 0.0997674\tvalid_1's binary_logloss: 0.405495\n",
      "[3400]\ttraining's binary_logloss: 0.0960366\tvalid_1's binary_logloss: 0.40555\n",
      "[3500]\ttraining's binary_logloss: 0.0923571\tvalid_1's binary_logloss: 0.407095\n",
      "[3600]\ttraining's binary_logloss: 0.0891491\tvalid_1's binary_logloss: 0.409468\n",
      "[3700]\ttraining's binary_logloss: 0.0860678\tvalid_1's binary_logloss: 0.411096\n",
      "[3800]\ttraining's binary_logloss: 0.0830656\tvalid_1's binary_logloss: 0.413375\n",
      "[3900]\ttraining's binary_logloss: 0.0800522\tvalid_1's binary_logloss: 0.413904\n",
      "[4000]\ttraining's binary_logloss: 0.0773099\tvalid_1's binary_logloss: 0.414483\n",
      "[4100]\ttraining's binary_logloss: 0.0746413\tvalid_1's binary_logloss: 0.416109\n",
      "[4200]\ttraining's binary_logloss: 0.0721297\tvalid_1's binary_logloss: 0.419\n",
      "[4300]\ttraining's binary_logloss: 0.0695128\tvalid_1's binary_logloss: 0.421965\n",
      "[4400]\ttraining's binary_logloss: 0.0670148\tvalid_1's binary_logloss: 0.423925\n",
      "[4500]\ttraining's binary_logloss: 0.0646905\tvalid_1's binary_logloss: 0.426319\n",
      "[4600]\ttraining's binary_logloss: 0.0625563\tvalid_1's binary_logloss: 0.428057\n",
      "[4700]\ttraining's binary_logloss: 0.0604598\tvalid_1's binary_logloss: 0.430445\n",
      "[4800]\ttraining's binary_logloss: 0.0583859\tvalid_1's binary_logloss: 0.43307\n",
      "[4900]\ttraining's binary_logloss: 0.0563721\tvalid_1's binary_logloss: 0.43643\n",
      "[5000]\ttraining's binary_logloss: 0.0544104\tvalid_1's binary_logloss: 0.438547\n",
      "Partial score of fold 4 is: 0.43854712723920247\n",
      "[100]\ttraining's binary_logloss: 0.532588\tvalid_1's binary_logloss: 0.534048\n",
      "[200]\ttraining's binary_logloss: 0.452374\tvalid_1's binary_logloss: 0.456811\n",
      "[300]\ttraining's binary_logloss: 0.402236\tvalid_1's binary_logloss: 0.42301\n",
      "[400]\ttraining's binary_logloss: 0.368285\tvalid_1's binary_logloss: 0.405891\n",
      "[500]\ttraining's binary_logloss: 0.341504\tvalid_1's binary_logloss: 0.397957\n",
      "[600]\ttraining's binary_logloss: 0.320316\tvalid_1's binary_logloss: 0.390374\n",
      "[700]\ttraining's binary_logloss: 0.301975\tvalid_1's binary_logloss: 0.379555\n",
      "[800]\ttraining's binary_logloss: 0.286693\tvalid_1's binary_logloss: 0.373965\n",
      "[900]\ttraining's binary_logloss: 0.272933\tvalid_1's binary_logloss: 0.369429\n",
      "[1000]\ttraining's binary_logloss: 0.260079\tvalid_1's binary_logloss: 0.365133\n",
      "[1100]\ttraining's binary_logloss: 0.248245\tvalid_1's binary_logloss: 0.363348\n",
      "[1200]\ttraining's binary_logloss: 0.236459\tvalid_1's binary_logloss: 0.360535\n",
      "[1300]\ttraining's binary_logloss: 0.225384\tvalid_1's binary_logloss: 0.358476\n",
      "[1400]\ttraining's binary_logloss: 0.214742\tvalid_1's binary_logloss: 0.35546\n",
      "[1500]\ttraining's binary_logloss: 0.205471\tvalid_1's binary_logloss: 0.351514\n",
      "[1600]\ttraining's binary_logloss: 0.196235\tvalid_1's binary_logloss: 0.350344\n",
      "[1700]\ttraining's binary_logloss: 0.187647\tvalid_1's binary_logloss: 0.351338\n",
      "[1800]\ttraining's binary_logloss: 0.18005\tvalid_1's binary_logloss: 0.351857\n",
      "[1900]\ttraining's binary_logloss: 0.172957\tvalid_1's binary_logloss: 0.352961\n",
      "[2000]\ttraining's binary_logloss: 0.165928\tvalid_1's binary_logloss: 0.354624\n",
      "[2100]\ttraining's binary_logloss: 0.159485\tvalid_1's binary_logloss: 0.356136\n",
      "[2200]\ttraining's binary_logloss: 0.153445\tvalid_1's binary_logloss: 0.357731\n",
      "[2300]\ttraining's binary_logloss: 0.147706\tvalid_1's binary_logloss: 0.357887\n",
      "[2400]\ttraining's binary_logloss: 0.142493\tvalid_1's binary_logloss: 0.359893\n",
      "[2500]\ttraining's binary_logloss: 0.137298\tvalid_1's binary_logloss: 0.360033\n",
      "[2600]\ttraining's binary_logloss: 0.132122\tvalid_1's binary_logloss: 0.36035\n",
      "[2700]\ttraining's binary_logloss: 0.127156\tvalid_1's binary_logloss: 0.360518\n",
      "[2800]\ttraining's binary_logloss: 0.122329\tvalid_1's binary_logloss: 0.360384\n",
      "[2900]\ttraining's binary_logloss: 0.117627\tvalid_1's binary_logloss: 0.361058\n",
      "[3000]\ttraining's binary_logloss: 0.113201\tvalid_1's binary_logloss: 0.363087\n",
      "[3100]\ttraining's binary_logloss: 0.109092\tvalid_1's binary_logloss: 0.363664\n",
      "[3200]\ttraining's binary_logloss: 0.104992\tvalid_1's binary_logloss: 0.364417\n",
      "[3300]\ttraining's binary_logloss: 0.101152\tvalid_1's binary_logloss: 0.364964\n",
      "[3400]\ttraining's binary_logloss: 0.0973598\tvalid_1's binary_logloss: 0.36518\n",
      "[3500]\ttraining's binary_logloss: 0.0937864\tvalid_1's binary_logloss: 0.366352\n",
      "[3600]\ttraining's binary_logloss: 0.0905643\tvalid_1's binary_logloss: 0.368333\n",
      "[3700]\ttraining's binary_logloss: 0.0874501\tvalid_1's binary_logloss: 0.370055\n",
      "[3800]\ttraining's binary_logloss: 0.0843283\tvalid_1's binary_logloss: 0.370905\n",
      "[3900]\ttraining's binary_logloss: 0.0813434\tvalid_1's binary_logloss: 0.371729\n",
      "[4000]\ttraining's binary_logloss: 0.0784878\tvalid_1's binary_logloss: 0.372149\n",
      "[4100]\ttraining's binary_logloss: 0.0758203\tvalid_1's binary_logloss: 0.372932\n",
      "[4200]\ttraining's binary_logloss: 0.0732579\tvalid_1's binary_logloss: 0.373177\n",
      "[4300]\ttraining's binary_logloss: 0.0707561\tvalid_1's binary_logloss: 0.375312\n",
      "[4400]\ttraining's binary_logloss: 0.0682709\tvalid_1's binary_logloss: 0.376718\n",
      "[4500]\ttraining's binary_logloss: 0.065953\tvalid_1's binary_logloss: 0.378116\n",
      "[4600]\ttraining's binary_logloss: 0.0637173\tvalid_1's binary_logloss: 0.379864\n",
      "[4700]\ttraining's binary_logloss: 0.0614563\tvalid_1's binary_logloss: 0.38076\n",
      "[4800]\ttraining's binary_logloss: 0.0593741\tvalid_1's binary_logloss: 0.382262\n",
      "[4900]\ttraining's binary_logloss: 0.0573591\tvalid_1's binary_logloss: 0.384497\n",
      "[5000]\ttraining's binary_logloss: 0.0553968\tvalid_1's binary_logloss: 0.38549\n",
      "Partial score of fold 5 is: 0.3854899568410011\n",
      "[100]\ttraining's binary_logloss: 0.5347\tvalid_1's binary_logloss: 0.536485\n",
      "[200]\ttraining's binary_logloss: 0.453619\tvalid_1's binary_logloss: 0.461381\n",
      "[300]\ttraining's binary_logloss: 0.404354\tvalid_1's binary_logloss: 0.421988\n",
      "[400]\ttraining's binary_logloss: 0.370286\tvalid_1's binary_logloss: 0.396161\n",
      "[500]\ttraining's binary_logloss: 0.34348\tvalid_1's binary_logloss: 0.381804\n",
      "[600]\ttraining's binary_logloss: 0.320743\tvalid_1's binary_logloss: 0.371939\n",
      "[700]\ttraining's binary_logloss: 0.302657\tvalid_1's binary_logloss: 0.364962\n",
      "[800]\ttraining's binary_logloss: 0.286045\tvalid_1's binary_logloss: 0.360106\n",
      "[900]\ttraining's binary_logloss: 0.270984\tvalid_1's binary_logloss: 0.35881\n",
      "[1000]\ttraining's binary_logloss: 0.257451\tvalid_1's binary_logloss: 0.356615\n",
      "[1100]\ttraining's binary_logloss: 0.245376\tvalid_1's binary_logloss: 0.357489\n",
      "[1200]\ttraining's binary_logloss: 0.23371\tvalid_1's binary_logloss: 0.356755\n",
      "[1300]\ttraining's binary_logloss: 0.223497\tvalid_1's binary_logloss: 0.357551\n",
      "[1400]\ttraining's binary_logloss: 0.214069\tvalid_1's binary_logloss: 0.358862\n",
      "[1500]\ttraining's binary_logloss: 0.204971\tvalid_1's binary_logloss: 0.360638\n",
      "[1600]\ttraining's binary_logloss: 0.196076\tvalid_1's binary_logloss: 0.363331\n",
      "[1700]\ttraining's binary_logloss: 0.188116\tvalid_1's binary_logloss: 0.367269\n",
      "[1800]\ttraining's binary_logloss: 0.180562\tvalid_1's binary_logloss: 0.369566\n",
      "[1900]\ttraining's binary_logloss: 0.173301\tvalid_1's binary_logloss: 0.370771\n",
      "[2000]\ttraining's binary_logloss: 0.166088\tvalid_1's binary_logloss: 0.370802\n",
      "[2100]\ttraining's binary_logloss: 0.159243\tvalid_1's binary_logloss: 0.371432\n",
      "[2200]\ttraining's binary_logloss: 0.153021\tvalid_1's binary_logloss: 0.371523\n",
      "[2300]\ttraining's binary_logloss: 0.146711\tvalid_1's binary_logloss: 0.370053\n",
      "[2400]\ttraining's binary_logloss: 0.141006\tvalid_1's binary_logloss: 0.371437\n",
      "[2500]\ttraining's binary_logloss: 0.135639\tvalid_1's binary_logloss: 0.373204\n",
      "[2600]\ttraining's binary_logloss: 0.130412\tvalid_1's binary_logloss: 0.374141\n",
      "[2700]\ttraining's binary_logloss: 0.125349\tvalid_1's binary_logloss: 0.375698\n",
      "[2800]\ttraining's binary_logloss: 0.120517\tvalid_1's binary_logloss: 0.377281\n",
      "[2900]\ttraining's binary_logloss: 0.116107\tvalid_1's binary_logloss: 0.379835\n",
      "[3000]\ttraining's binary_logloss: 0.111725\tvalid_1's binary_logloss: 0.381851\n",
      "[3100]\ttraining's binary_logloss: 0.107706\tvalid_1's binary_logloss: 0.384981\n",
      "[3200]\ttraining's binary_logloss: 0.103985\tvalid_1's binary_logloss: 0.388206\n",
      "[3300]\ttraining's binary_logloss: 0.100488\tvalid_1's binary_logloss: 0.391073\n",
      "[3400]\ttraining's binary_logloss: 0.0969662\tvalid_1's binary_logloss: 0.392853\n",
      "[3500]\ttraining's binary_logloss: 0.0934728\tvalid_1's binary_logloss: 0.393716\n",
      "[3600]\ttraining's binary_logloss: 0.089933\tvalid_1's binary_logloss: 0.393996\n",
      "[3700]\ttraining's binary_logloss: 0.0865769\tvalid_1's binary_logloss: 0.395726\n",
      "[3800]\ttraining's binary_logloss: 0.0834073\tvalid_1's binary_logloss: 0.39625\n",
      "[3900]\ttraining's binary_logloss: 0.0804486\tvalid_1's binary_logloss: 0.397371\n",
      "[4000]\ttraining's binary_logloss: 0.0777172\tvalid_1's binary_logloss: 0.399326\n",
      "[4100]\ttraining's binary_logloss: 0.0749558\tvalid_1's binary_logloss: 0.400044\n",
      "[4200]\ttraining's binary_logloss: 0.0723781\tvalid_1's binary_logloss: 0.40201\n",
      "[4300]\ttraining's binary_logloss: 0.0699742\tvalid_1's binary_logloss: 0.404\n",
      "[4400]\ttraining's binary_logloss: 0.0675571\tvalid_1's binary_logloss: 0.404759\n",
      "[4500]\ttraining's binary_logloss: 0.0652911\tvalid_1's binary_logloss: 0.407322\n",
      "[4600]\ttraining's binary_logloss: 0.0629647\tvalid_1's binary_logloss: 0.409291\n",
      "[4700]\ttraining's binary_logloss: 0.0607286\tvalid_1's binary_logloss: 0.412673\n",
      "[4800]\ttraining's binary_logloss: 0.0586216\tvalid_1's binary_logloss: 0.415621\n",
      "[4900]\ttraining's binary_logloss: 0.0565263\tvalid_1's binary_logloss: 0.418111\n",
      "[5000]\ttraining's binary_logloss: 0.0544316\tvalid_1's binary_logloss: 0.420363\n",
      "Partial score of fold 6 is: 0.42036347918929345\n",
      "[100]\ttraining's binary_logloss: 0.533767\tvalid_1's binary_logloss: 0.543378\n",
      "[200]\ttraining's binary_logloss: 0.450954\tvalid_1's binary_logloss: 0.476249\n",
      "[300]\ttraining's binary_logloss: 0.401369\tvalid_1's binary_logloss: 0.440251\n",
      "[400]\ttraining's binary_logloss: 0.367544\tvalid_1's binary_logloss: 0.418552\n",
      "[500]\ttraining's binary_logloss: 0.342053\tvalid_1's binary_logloss: 0.403347\n",
      "[600]\ttraining's binary_logloss: 0.319499\tvalid_1's binary_logloss: 0.389982\n",
      "[700]\ttraining's binary_logloss: 0.300029\tvalid_1's binary_logloss: 0.380374\n",
      "[800]\ttraining's binary_logloss: 0.28348\tvalid_1's binary_logloss: 0.373766\n",
      "[900]\ttraining's binary_logloss: 0.268912\tvalid_1's binary_logloss: 0.36921\n",
      "[1000]\ttraining's binary_logloss: 0.256409\tvalid_1's binary_logloss: 0.368068\n",
      "[1100]\ttraining's binary_logloss: 0.244349\tvalid_1's binary_logloss: 0.36839\n",
      "[1200]\ttraining's binary_logloss: 0.23321\tvalid_1's binary_logloss: 0.367427\n",
      "[1300]\ttraining's binary_logloss: 0.222717\tvalid_1's binary_logloss: 0.367325\n",
      "[1400]\ttraining's binary_logloss: 0.212892\tvalid_1's binary_logloss: 0.367525\n",
      "[1500]\ttraining's binary_logloss: 0.203843\tvalid_1's binary_logloss: 0.367332\n",
      "[1600]\ttraining's binary_logloss: 0.195648\tvalid_1's binary_logloss: 0.366817\n",
      "[1700]\ttraining's binary_logloss: 0.187803\tvalid_1's binary_logloss: 0.366874\n",
      "[1800]\ttraining's binary_logloss: 0.180313\tvalid_1's binary_logloss: 0.368573\n",
      "[1900]\ttraining's binary_logloss: 0.172862\tvalid_1's binary_logloss: 0.368962\n",
      "[2000]\ttraining's binary_logloss: 0.166074\tvalid_1's binary_logloss: 0.370281\n",
      "[2100]\ttraining's binary_logloss: 0.159751\tvalid_1's binary_logloss: 0.370647\n",
      "[2200]\ttraining's binary_logloss: 0.153758\tvalid_1's binary_logloss: 0.373338\n",
      "[2300]\ttraining's binary_logloss: 0.147974\tvalid_1's binary_logloss: 0.373213\n",
      "[2400]\ttraining's binary_logloss: 0.142345\tvalid_1's binary_logloss: 0.374311\n",
      "[2500]\ttraining's binary_logloss: 0.136855\tvalid_1's binary_logloss: 0.3762\n",
      "[2600]\ttraining's binary_logloss: 0.131984\tvalid_1's binary_logloss: 0.376679\n",
      "[2700]\ttraining's binary_logloss: 0.127225\tvalid_1's binary_logloss: 0.377578\n",
      "[2800]\ttraining's binary_logloss: 0.122559\tvalid_1's binary_logloss: 0.379271\n",
      "[2900]\ttraining's binary_logloss: 0.118265\tvalid_1's binary_logloss: 0.379827\n",
      "[3000]\ttraining's binary_logloss: 0.114127\tvalid_1's binary_logloss: 0.38073\n",
      "[3100]\ttraining's binary_logloss: 0.110005\tvalid_1's binary_logloss: 0.381921\n",
      "[3200]\ttraining's binary_logloss: 0.105983\tvalid_1's binary_logloss: 0.384052\n",
      "[3300]\ttraining's binary_logloss: 0.102164\tvalid_1's binary_logloss: 0.385588\n",
      "[3400]\ttraining's binary_logloss: 0.0986562\tvalid_1's binary_logloss: 0.389416\n",
      "[3500]\ttraining's binary_logloss: 0.0950526\tvalid_1's binary_logloss: 0.392028\n",
      "[3600]\ttraining's binary_logloss: 0.0917956\tvalid_1's binary_logloss: 0.395502\n",
      "[3700]\ttraining's binary_logloss: 0.0884645\tvalid_1's binary_logloss: 0.397456\n",
      "[3800]\ttraining's binary_logloss: 0.08548\tvalid_1's binary_logloss: 0.399819\n",
      "[3900]\ttraining's binary_logloss: 0.0825553\tvalid_1's binary_logloss: 0.401422\n",
      "[4000]\ttraining's binary_logloss: 0.0796702\tvalid_1's binary_logloss: 0.403309\n",
      "[4100]\ttraining's binary_logloss: 0.0769473\tvalid_1's binary_logloss: 0.405176\n",
      "[4200]\ttraining's binary_logloss: 0.0742506\tvalid_1's binary_logloss: 0.408859\n",
      "[4300]\ttraining's binary_logloss: 0.0716519\tvalid_1's binary_logloss: 0.412968\n",
      "[4400]\ttraining's binary_logloss: 0.0691966\tvalid_1's binary_logloss: 0.416594\n",
      "[4500]\ttraining's binary_logloss: 0.0668321\tvalid_1's binary_logloss: 0.420347\n",
      "[4600]\ttraining's binary_logloss: 0.0645598\tvalid_1's binary_logloss: 0.422711\n",
      "[4700]\ttraining's binary_logloss: 0.0624367\tvalid_1's binary_logloss: 0.424542\n",
      "[4800]\ttraining's binary_logloss: 0.0603166\tvalid_1's binary_logloss: 0.427833\n",
      "[4900]\ttraining's binary_logloss: 0.0582128\tvalid_1's binary_logloss: 0.430149\n",
      "[5000]\ttraining's binary_logloss: 0.0563161\tvalid_1's binary_logloss: 0.432922\n",
      "Partial score of fold 7 is: 0.43292207274541106\n",
      "[100]\ttraining's binary_logloss: 0.531263\tvalid_1's binary_logloss: 0.544641\n",
      "[200]\ttraining's binary_logloss: 0.451043\tvalid_1's binary_logloss: 0.471718\n",
      "[300]\ttraining's binary_logloss: 0.403379\tvalid_1's binary_logloss: 0.434293\n",
      "[400]\ttraining's binary_logloss: 0.369514\tvalid_1's binary_logloss: 0.409237\n",
      "[500]\ttraining's binary_logloss: 0.343338\tvalid_1's binary_logloss: 0.393951\n",
      "[600]\ttraining's binary_logloss: 0.322007\tvalid_1's binary_logloss: 0.382626\n",
      "[700]\ttraining's binary_logloss: 0.302415\tvalid_1's binary_logloss: 0.371617\n",
      "[800]\ttraining's binary_logloss: 0.2864\tvalid_1's binary_logloss: 0.36683\n",
      "[900]\ttraining's binary_logloss: 0.272439\tvalid_1's binary_logloss: 0.361472\n",
      "[1000]\ttraining's binary_logloss: 0.258944\tvalid_1's binary_logloss: 0.354875\n",
      "[1100]\ttraining's binary_logloss: 0.246781\tvalid_1's binary_logloss: 0.349828\n",
      "[1200]\ttraining's binary_logloss: 0.235805\tvalid_1's binary_logloss: 0.348423\n",
      "[1300]\ttraining's binary_logloss: 0.225421\tvalid_1's binary_logloss: 0.345466\n",
      "[1400]\ttraining's binary_logloss: 0.215474\tvalid_1's binary_logloss: 0.344175\n",
      "[1500]\ttraining's binary_logloss: 0.206052\tvalid_1's binary_logloss: 0.341828\n",
      "[1600]\ttraining's binary_logloss: 0.197466\tvalid_1's binary_logloss: 0.339447\n",
      "[1700]\ttraining's binary_logloss: 0.189098\tvalid_1's binary_logloss: 0.336896\n",
      "[1800]\ttraining's binary_logloss: 0.181354\tvalid_1's binary_logloss: 0.335606\n",
      "[1900]\ttraining's binary_logloss: 0.174287\tvalid_1's binary_logloss: 0.335265\n",
      "[2000]\ttraining's binary_logloss: 0.167113\tvalid_1's binary_logloss: 0.334653\n",
      "[2100]\ttraining's binary_logloss: 0.159887\tvalid_1's binary_logloss: 0.333142\n",
      "[2200]\ttraining's binary_logloss: 0.153513\tvalid_1's binary_logloss: 0.331999\n",
      "[2300]\ttraining's binary_logloss: 0.147655\tvalid_1's binary_logloss: 0.332509\n",
      "[2400]\ttraining's binary_logloss: 0.141789\tvalid_1's binary_logloss: 0.332648\n",
      "[2500]\ttraining's binary_logloss: 0.136289\tvalid_1's binary_logloss: 0.330801\n",
      "[2600]\ttraining's binary_logloss: 0.131071\tvalid_1's binary_logloss: 0.330838\n",
      "[2700]\ttraining's binary_logloss: 0.126219\tvalid_1's binary_logloss: 0.331441\n",
      "[2800]\ttraining's binary_logloss: 0.12172\tvalid_1's binary_logloss: 0.332448\n",
      "[2900]\ttraining's binary_logloss: 0.117415\tvalid_1's binary_logloss: 0.333611\n",
      "[3000]\ttraining's binary_logloss: 0.113026\tvalid_1's binary_logloss: 0.334439\n",
      "[3100]\ttraining's binary_logloss: 0.108637\tvalid_1's binary_logloss: 0.335859\n",
      "[3200]\ttraining's binary_logloss: 0.104698\tvalid_1's binary_logloss: 0.337625\n",
      "[3300]\ttraining's binary_logloss: 0.101005\tvalid_1's binary_logloss: 0.339516\n",
      "[3400]\ttraining's binary_logloss: 0.0974831\tvalid_1's binary_logloss: 0.340699\n",
      "[3500]\ttraining's binary_logloss: 0.0942375\tvalid_1's binary_logloss: 0.340907\n",
      "[3600]\ttraining's binary_logloss: 0.0909516\tvalid_1's binary_logloss: 0.340244\n",
      "[3700]\ttraining's binary_logloss: 0.0877185\tvalid_1's binary_logloss: 0.340085\n",
      "[3800]\ttraining's binary_logloss: 0.0845922\tvalid_1's binary_logloss: 0.341587\n",
      "[3900]\ttraining's binary_logloss: 0.0816907\tvalid_1's binary_logloss: 0.34212\n",
      "[4000]\ttraining's binary_logloss: 0.0788382\tvalid_1's binary_logloss: 0.341852\n",
      "[4100]\ttraining's binary_logloss: 0.0761296\tvalid_1's binary_logloss: 0.342631\n",
      "[4200]\ttraining's binary_logloss: 0.0735165\tvalid_1's binary_logloss: 0.342361\n",
      "[4300]\ttraining's binary_logloss: 0.0708069\tvalid_1's binary_logloss: 0.343346\n",
      "[4400]\ttraining's binary_logloss: 0.0682346\tvalid_1's binary_logloss: 0.345412\n",
      "[4500]\ttraining's binary_logloss: 0.0659679\tvalid_1's binary_logloss: 0.34604\n",
      "[4600]\ttraining's binary_logloss: 0.0637233\tvalid_1's binary_logloss: 0.346925\n",
      "[4700]\ttraining's binary_logloss: 0.061589\tvalid_1's binary_logloss: 0.34922\n",
      "[4800]\ttraining's binary_logloss: 0.0595435\tvalid_1's binary_logloss: 0.349759\n",
      "[4900]\ttraining's binary_logloss: 0.0575568\tvalid_1's binary_logloss: 0.35058\n",
      "[5000]\ttraining's binary_logloss: 0.0555846\tvalid_1's binary_logloss: 0.351507\n",
      "Partial score of fold 8 is: 0.35150683095565816\n",
      "[100]\ttraining's binary_logloss: 0.531685\tvalid_1's binary_logloss: 0.556849\n",
      "[200]\ttraining's binary_logloss: 0.449269\tvalid_1's binary_logloss: 0.497865\n",
      "[300]\ttraining's binary_logloss: 0.399382\tvalid_1's binary_logloss: 0.46617\n",
      "[400]\ttraining's binary_logloss: 0.36557\tvalid_1's binary_logloss: 0.446582\n",
      "[500]\ttraining's binary_logloss: 0.338168\tvalid_1's binary_logloss: 0.42919\n",
      "[600]\ttraining's binary_logloss: 0.315938\tvalid_1's binary_logloss: 0.422289\n",
      "[700]\ttraining's binary_logloss: 0.296177\tvalid_1's binary_logloss: 0.416125\n",
      "[800]\ttraining's binary_logloss: 0.279601\tvalid_1's binary_logloss: 0.415336\n",
      "[900]\ttraining's binary_logloss: 0.265313\tvalid_1's binary_logloss: 0.41573\n",
      "[1000]\ttraining's binary_logloss: 0.252459\tvalid_1's binary_logloss: 0.416002\n",
      "[1100]\ttraining's binary_logloss: 0.240908\tvalid_1's binary_logloss: 0.416838\n",
      "[1200]\ttraining's binary_logloss: 0.229629\tvalid_1's binary_logloss: 0.418057\n",
      "[1300]\ttraining's binary_logloss: 0.21887\tvalid_1's binary_logloss: 0.419749\n",
      "[1400]\ttraining's binary_logloss: 0.207969\tvalid_1's binary_logloss: 0.419602\n",
      "[1500]\ttraining's binary_logloss: 0.198728\tvalid_1's binary_logloss: 0.421805\n",
      "[1600]\ttraining's binary_logloss: 0.190235\tvalid_1's binary_logloss: 0.42226\n",
      "[1700]\ttraining's binary_logloss: 0.181784\tvalid_1's binary_logloss: 0.423557\n",
      "[1800]\ttraining's binary_logloss: 0.173566\tvalid_1's binary_logloss: 0.427456\n",
      "[1900]\ttraining's binary_logloss: 0.166079\tvalid_1's binary_logloss: 0.429157\n",
      "[2000]\ttraining's binary_logloss: 0.158993\tvalid_1's binary_logloss: 0.430447\n",
      "[2100]\ttraining's binary_logloss: 0.152487\tvalid_1's binary_logloss: 0.432325\n",
      "[2200]\ttraining's binary_logloss: 0.146429\tvalid_1's binary_logloss: 0.433088\n",
      "[2300]\ttraining's binary_logloss: 0.140631\tvalid_1's binary_logloss: 0.435172\n",
      "[2400]\ttraining's binary_logloss: 0.134794\tvalid_1's binary_logloss: 0.437736\n",
      "[2500]\ttraining's binary_logloss: 0.129719\tvalid_1's binary_logloss: 0.440425\n",
      "[2600]\ttraining's binary_logloss: 0.12496\tvalid_1's binary_logloss: 0.444828\n",
      "[2700]\ttraining's binary_logloss: 0.120341\tvalid_1's binary_logloss: 0.448627\n",
      "[2800]\ttraining's binary_logloss: 0.115805\tvalid_1's binary_logloss: 0.452179\n",
      "[2900]\ttraining's binary_logloss: 0.111506\tvalid_1's binary_logloss: 0.456529\n",
      "[3000]\ttraining's binary_logloss: 0.107472\tvalid_1's binary_logloss: 0.46086\n",
      "[3100]\ttraining's binary_logloss: 0.103488\tvalid_1's binary_logloss: 0.465087\n",
      "[3200]\ttraining's binary_logloss: 0.0996713\tvalid_1's binary_logloss: 0.468563\n",
      "[3300]\ttraining's binary_logloss: 0.0960846\tvalid_1's binary_logloss: 0.471781\n",
      "[3400]\ttraining's binary_logloss: 0.0926674\tvalid_1's binary_logloss: 0.474323\n",
      "[3500]\ttraining's binary_logloss: 0.0893472\tvalid_1's binary_logloss: 0.477664\n",
      "[3600]\ttraining's binary_logloss: 0.0862264\tvalid_1's binary_logloss: 0.480175\n",
      "[3700]\ttraining's binary_logloss: 0.0831486\tvalid_1's binary_logloss: 0.482611\n",
      "[3800]\ttraining's binary_logloss: 0.0800907\tvalid_1's binary_logloss: 0.486394\n",
      "[3900]\ttraining's binary_logloss: 0.0771376\tvalid_1's binary_logloss: 0.488936\n",
      "[4000]\ttraining's binary_logloss: 0.074427\tvalid_1's binary_logloss: 0.492705\n",
      "[4100]\ttraining's binary_logloss: 0.0717557\tvalid_1's binary_logloss: 0.495593\n",
      "[4200]\ttraining's binary_logloss: 0.0691871\tvalid_1's binary_logloss: 0.498729\n",
      "[4300]\ttraining's binary_logloss: 0.0667857\tvalid_1's binary_logloss: 0.501902\n",
      "[4400]\ttraining's binary_logloss: 0.0644745\tvalid_1's binary_logloss: 0.505548\n",
      "[4500]\ttraining's binary_logloss: 0.0623121\tvalid_1's binary_logloss: 0.509565\n",
      "[4600]\ttraining's binary_logloss: 0.0602176\tvalid_1's binary_logloss: 0.512493\n",
      "[4700]\ttraining's binary_logloss: 0.0582195\tvalid_1's binary_logloss: 0.515477\n",
      "[4800]\ttraining's binary_logloss: 0.0562323\tvalid_1's binary_logloss: 0.51779\n",
      "[4900]\ttraining's binary_logloss: 0.0542931\tvalid_1's binary_logloss: 0.520555\n",
      "[5000]\ttraining's binary_logloss: 0.0524508\tvalid_1's binary_logloss: 0.524612\n",
      "Partial score of fold 9 is: 0.5246124469835572\n",
      "Our oof loss score is:  0.42437298623183445\n",
      "Predicting 2017...\n",
      "[100]\ttraining's binary_logloss: 0.533879\tvalid_1's binary_logloss: 0.534065\n",
      "[200]\ttraining's binary_logloss: 0.452487\tvalid_1's binary_logloss: 0.46114\n",
      "[300]\ttraining's binary_logloss: 0.403154\tvalid_1's binary_logloss: 0.421739\n",
      "[400]\ttraining's binary_logloss: 0.36762\tvalid_1's binary_logloss: 0.397692\n",
      "[500]\ttraining's binary_logloss: 0.341535\tvalid_1's binary_logloss: 0.385279\n",
      "[600]\ttraining's binary_logloss: 0.318978\tvalid_1's binary_logloss: 0.376851\n",
      "[700]\ttraining's binary_logloss: 0.30085\tvalid_1's binary_logloss: 0.369637\n",
      "[800]\ttraining's binary_logloss: 0.284574\tvalid_1's binary_logloss: 0.367872\n",
      "[900]\ttraining's binary_logloss: 0.269425\tvalid_1's binary_logloss: 0.366573\n",
      "[1000]\ttraining's binary_logloss: 0.255449\tvalid_1's binary_logloss: 0.368907\n",
      "[1100]\ttraining's binary_logloss: 0.242711\tvalid_1's binary_logloss: 0.369007\n",
      "[1200]\ttraining's binary_logloss: 0.231964\tvalid_1's binary_logloss: 0.368506\n",
      "[1300]\ttraining's binary_logloss: 0.221943\tvalid_1's binary_logloss: 0.37021\n",
      "[1400]\ttraining's binary_logloss: 0.211687\tvalid_1's binary_logloss: 0.369412\n",
      "[1500]\ttraining's binary_logloss: 0.202533\tvalid_1's binary_logloss: 0.370966\n",
      "[1600]\ttraining's binary_logloss: 0.193914\tvalid_1's binary_logloss: 0.371372\n",
      "[1700]\ttraining's binary_logloss: 0.185807\tvalid_1's binary_logloss: 0.372936\n",
      "[1800]\ttraining's binary_logloss: 0.178325\tvalid_1's binary_logloss: 0.374704\n",
      "[1900]\ttraining's binary_logloss: 0.171353\tvalid_1's binary_logloss: 0.376542\n",
      "[2000]\ttraining's binary_logloss: 0.164523\tvalid_1's binary_logloss: 0.376931\n",
      "[2100]\ttraining's binary_logloss: 0.157939\tvalid_1's binary_logloss: 0.378364\n",
      "[2200]\ttraining's binary_logloss: 0.151368\tvalid_1's binary_logloss: 0.379831\n",
      "[2300]\ttraining's binary_logloss: 0.145395\tvalid_1's binary_logloss: 0.380688\n",
      "[2400]\ttraining's binary_logloss: 0.139983\tvalid_1's binary_logloss: 0.380542\n",
      "[2500]\ttraining's binary_logloss: 0.134606\tvalid_1's binary_logloss: 0.380424\n",
      "[2600]\ttraining's binary_logloss: 0.129612\tvalid_1's binary_logloss: 0.382421\n",
      "[2700]\ttraining's binary_logloss: 0.124962\tvalid_1's binary_logloss: 0.38418\n",
      "[2800]\ttraining's binary_logloss: 0.12038\tvalid_1's binary_logloss: 0.3852\n",
      "[2900]\ttraining's binary_logloss: 0.116159\tvalid_1's binary_logloss: 0.386413\n",
      "[3000]\ttraining's binary_logloss: 0.111946\tvalid_1's binary_logloss: 0.388673\n",
      "[3100]\ttraining's binary_logloss: 0.108017\tvalid_1's binary_logloss: 0.389113\n",
      "[3200]\ttraining's binary_logloss: 0.10444\tvalid_1's binary_logloss: 0.390926\n",
      "[3300]\ttraining's binary_logloss: 0.100677\tvalid_1's binary_logloss: 0.392834\n",
      "[3400]\ttraining's binary_logloss: 0.0970393\tvalid_1's binary_logloss: 0.394797\n",
      "[3500]\ttraining's binary_logloss: 0.0935917\tvalid_1's binary_logloss: 0.397031\n",
      "[3600]\ttraining's binary_logloss: 0.0904213\tvalid_1's binary_logloss: 0.397639\n",
      "[3700]\ttraining's binary_logloss: 0.0873464\tvalid_1's binary_logloss: 0.397845\n",
      "[3800]\ttraining's binary_logloss: 0.0843028\tvalid_1's binary_logloss: 0.399672\n",
      "[3900]\ttraining's binary_logloss: 0.0812572\tvalid_1's binary_logloss: 0.400708\n",
      "[4000]\ttraining's binary_logloss: 0.0781527\tvalid_1's binary_logloss: 0.40245\n",
      "[4100]\ttraining's binary_logloss: 0.0754306\tvalid_1's binary_logloss: 0.403645\n",
      "[4200]\ttraining's binary_logloss: 0.0727553\tvalid_1's binary_logloss: 0.405596\n",
      "[4300]\ttraining's binary_logloss: 0.0699965\tvalid_1's binary_logloss: 0.407887\n",
      "[4400]\ttraining's binary_logloss: 0.0675656\tvalid_1's binary_logloss: 0.409225\n",
      "[4500]\ttraining's binary_logloss: 0.0652473\tvalid_1's binary_logloss: 0.411902\n",
      "[4600]\ttraining's binary_logloss: 0.0629514\tvalid_1's binary_logloss: 0.413904\n",
      "[4700]\ttraining's binary_logloss: 0.0606707\tvalid_1's binary_logloss: 0.417078\n",
      "[4800]\ttraining's binary_logloss: 0.0584421\tvalid_1's binary_logloss: 0.421263\n",
      "[4900]\ttraining's binary_logloss: 0.0564469\tvalid_1's binary_logloss: 0.424689\n",
      "[5000]\ttraining's binary_logloss: 0.0544951\tvalid_1's binary_logloss: 0.426622\n",
      "Partial score of fold 0 is: 0.42662156595615264\n",
      "[100]\ttraining's binary_logloss: 0.530438\tvalid_1's binary_logloss: 0.558449\n",
      "[200]\ttraining's binary_logloss: 0.447642\tvalid_1's binary_logloss: 0.494672\n",
      "[300]\ttraining's binary_logloss: 0.39838\tvalid_1's binary_logloss: 0.462501\n",
      "[400]\ttraining's binary_logloss: 0.364537\tvalid_1's binary_logloss: 0.441584\n",
      "[500]\ttraining's binary_logloss: 0.338264\tvalid_1's binary_logloss: 0.425405\n",
      "[600]\ttraining's binary_logloss: 0.316262\tvalid_1's binary_logloss: 0.413279\n",
      "[700]\ttraining's binary_logloss: 0.297503\tvalid_1's binary_logloss: 0.401126\n",
      "[800]\ttraining's binary_logloss: 0.281868\tvalid_1's binary_logloss: 0.395245\n",
      "[900]\ttraining's binary_logloss: 0.266963\tvalid_1's binary_logloss: 0.392217\n",
      "[1000]\ttraining's binary_logloss: 0.253438\tvalid_1's binary_logloss: 0.388792\n",
      "[1100]\ttraining's binary_logloss: 0.241799\tvalid_1's binary_logloss: 0.387876\n",
      "[1200]\ttraining's binary_logloss: 0.230304\tvalid_1's binary_logloss: 0.388533\n",
      "[1300]\ttraining's binary_logloss: 0.219818\tvalid_1's binary_logloss: 0.388828\n",
      "[1400]\ttraining's binary_logloss: 0.210796\tvalid_1's binary_logloss: 0.387442\n",
      "[1500]\ttraining's binary_logloss: 0.201804\tvalid_1's binary_logloss: 0.38349\n",
      "[1600]\ttraining's binary_logloss: 0.192676\tvalid_1's binary_logloss: 0.382124\n",
      "[1700]\ttraining's binary_logloss: 0.18439\tvalid_1's binary_logloss: 0.381894\n",
      "[1800]\ttraining's binary_logloss: 0.17671\tvalid_1's binary_logloss: 0.382925\n",
      "[1900]\ttraining's binary_logloss: 0.169522\tvalid_1's binary_logloss: 0.384151\n",
      "[2000]\ttraining's binary_logloss: 0.162754\tvalid_1's binary_logloss: 0.387153\n",
      "[2100]\ttraining's binary_logloss: 0.156364\tvalid_1's binary_logloss: 0.388848\n",
      "[2200]\ttraining's binary_logloss: 0.150222\tvalid_1's binary_logloss: 0.389225\n",
      "[2300]\ttraining's binary_logloss: 0.144416\tvalid_1's binary_logloss: 0.39068\n",
      "[2400]\ttraining's binary_logloss: 0.138904\tvalid_1's binary_logloss: 0.391381\n",
      "[2500]\ttraining's binary_logloss: 0.133795\tvalid_1's binary_logloss: 0.392873\n",
      "[2600]\ttraining's binary_logloss: 0.128855\tvalid_1's binary_logloss: 0.393753\n",
      "[2700]\ttraining's binary_logloss: 0.123958\tvalid_1's binary_logloss: 0.395305\n",
      "[2800]\ttraining's binary_logloss: 0.119385\tvalid_1's binary_logloss: 0.3972\n",
      "[2900]\ttraining's binary_logloss: 0.115016\tvalid_1's binary_logloss: 0.397092\n",
      "[3000]\ttraining's binary_logloss: 0.110934\tvalid_1's binary_logloss: 0.398833\n",
      "[3100]\ttraining's binary_logloss: 0.106994\tvalid_1's binary_logloss: 0.399147\n",
      "[3200]\ttraining's binary_logloss: 0.103212\tvalid_1's binary_logloss: 0.397454\n",
      "[3300]\ttraining's binary_logloss: 0.0995624\tvalid_1's binary_logloss: 0.397103\n",
      "[3400]\ttraining's binary_logloss: 0.0962272\tvalid_1's binary_logloss: 0.398199\n",
      "[3500]\ttraining's binary_logloss: 0.0929324\tvalid_1's binary_logloss: 0.399208\n",
      "[3600]\ttraining's binary_logloss: 0.0895938\tvalid_1's binary_logloss: 0.400215\n",
      "[3700]\ttraining's binary_logloss: 0.0864706\tvalid_1's binary_logloss: 0.401542\n",
      "[3800]\ttraining's binary_logloss: 0.083555\tvalid_1's binary_logloss: 0.403102\n",
      "[3900]\ttraining's binary_logloss: 0.0805301\tvalid_1's binary_logloss: 0.404623\n",
      "[4000]\ttraining's binary_logloss: 0.0776831\tvalid_1's binary_logloss: 0.405612\n",
      "[4100]\ttraining's binary_logloss: 0.075055\tvalid_1's binary_logloss: 0.407654\n",
      "[4200]\ttraining's binary_logloss: 0.0724351\tvalid_1's binary_logloss: 0.409381\n",
      "[4300]\ttraining's binary_logloss: 0.0700671\tvalid_1's binary_logloss: 0.411627\n",
      "[4400]\ttraining's binary_logloss: 0.0677596\tvalid_1's binary_logloss: 0.412996\n",
      "[4500]\ttraining's binary_logloss: 0.0655712\tvalid_1's binary_logloss: 0.414448\n",
      "[4600]\ttraining's binary_logloss: 0.0633367\tvalid_1's binary_logloss: 0.41432\n",
      "[4700]\ttraining's binary_logloss: 0.0611838\tvalid_1's binary_logloss: 0.416275\n",
      "[4800]\ttraining's binary_logloss: 0.0590429\tvalid_1's binary_logloss: 0.4188\n",
      "[4900]\ttraining's binary_logloss: 0.0569747\tvalid_1's binary_logloss: 0.420533\n",
      "[5000]\ttraining's binary_logloss: 0.0550032\tvalid_1's binary_logloss: 0.422815\n",
      "Partial score of fold 1 is: 0.42281512322351805\n",
      "[100]\ttraining's binary_logloss: 0.531659\tvalid_1's binary_logloss: 0.551978\n",
      "[200]\ttraining's binary_logloss: 0.450432\tvalid_1's binary_logloss: 0.481607\n",
      "[300]\ttraining's binary_logloss: 0.401965\tvalid_1's binary_logloss: 0.440426\n",
      "[400]\ttraining's binary_logloss: 0.368132\tvalid_1's binary_logloss: 0.41241\n",
      "[500]\ttraining's binary_logloss: 0.341827\tvalid_1's binary_logloss: 0.396649\n",
      "[600]\ttraining's binary_logloss: 0.319436\tvalid_1's binary_logloss: 0.386696\n",
      "[700]\ttraining's binary_logloss: 0.299313\tvalid_1's binary_logloss: 0.379062\n",
      "[800]\ttraining's binary_logloss: 0.281861\tvalid_1's binary_logloss: 0.375632\n",
      "[900]\ttraining's binary_logloss: 0.267045\tvalid_1's binary_logloss: 0.374904\n",
      "[1000]\ttraining's binary_logloss: 0.254546\tvalid_1's binary_logloss: 0.37277\n",
      "[1100]\ttraining's binary_logloss: 0.242942\tvalid_1's binary_logloss: 0.372153\n",
      "[1200]\ttraining's binary_logloss: 0.231424\tvalid_1's binary_logloss: 0.374227\n",
      "[1300]\ttraining's binary_logloss: 0.220939\tvalid_1's binary_logloss: 0.375613\n",
      "[1400]\ttraining's binary_logloss: 0.211329\tvalid_1's binary_logloss: 0.377424\n",
      "[1500]\ttraining's binary_logloss: 0.202066\tvalid_1's binary_logloss: 0.378829\n",
      "[1600]\ttraining's binary_logloss: 0.193317\tvalid_1's binary_logloss: 0.379931\n",
      "[1700]\ttraining's binary_logloss: 0.185\tvalid_1's binary_logloss: 0.381917\n",
      "[1800]\ttraining's binary_logloss: 0.177432\tvalid_1's binary_logloss: 0.383454\n",
      "[1900]\ttraining's binary_logloss: 0.170168\tvalid_1's binary_logloss: 0.38613\n",
      "[2000]\ttraining's binary_logloss: 0.163186\tvalid_1's binary_logloss: 0.387726\n",
      "[2100]\ttraining's binary_logloss: 0.156751\tvalid_1's binary_logloss: 0.39108\n",
      "[2200]\ttraining's binary_logloss: 0.150822\tvalid_1's binary_logloss: 0.394201\n",
      "[2300]\ttraining's binary_logloss: 0.145051\tvalid_1's binary_logloss: 0.397381\n",
      "[2400]\ttraining's binary_logloss: 0.139212\tvalid_1's binary_logloss: 0.400304\n",
      "[2500]\ttraining's binary_logloss: 0.133871\tvalid_1's binary_logloss: 0.404038\n",
      "[2600]\ttraining's binary_logloss: 0.128806\tvalid_1's binary_logloss: 0.408005\n",
      "[2700]\ttraining's binary_logloss: 0.123777\tvalid_1's binary_logloss: 0.409688\n",
      "[2800]\ttraining's binary_logloss: 0.118944\tvalid_1's binary_logloss: 0.410787\n",
      "[2900]\ttraining's binary_logloss: 0.114424\tvalid_1's binary_logloss: 0.411524\n",
      "[3000]\ttraining's binary_logloss: 0.110064\tvalid_1's binary_logloss: 0.412231\n",
      "[3100]\ttraining's binary_logloss: 0.106018\tvalid_1's binary_logloss: 0.413983\n",
      "[3200]\ttraining's binary_logloss: 0.102122\tvalid_1's binary_logloss: 0.416922\n",
      "[3300]\ttraining's binary_logloss: 0.098301\tvalid_1's binary_logloss: 0.419291\n",
      "[3400]\ttraining's binary_logloss: 0.0946849\tvalid_1's binary_logloss: 0.423835\n",
      "[3500]\ttraining's binary_logloss: 0.0911475\tvalid_1's binary_logloss: 0.427682\n",
      "[3600]\ttraining's binary_logloss: 0.0878085\tvalid_1's binary_logloss: 0.430953\n",
      "[3700]\ttraining's binary_logloss: 0.0846108\tvalid_1's binary_logloss: 0.433879\n",
      "[3800]\ttraining's binary_logloss: 0.0815005\tvalid_1's binary_logloss: 0.43633\n",
      "[3900]\ttraining's binary_logloss: 0.0785155\tvalid_1's binary_logloss: 0.439659\n",
      "[4000]\ttraining's binary_logloss: 0.0756991\tvalid_1's binary_logloss: 0.441381\n",
      "[4100]\ttraining's binary_logloss: 0.0730795\tvalid_1's binary_logloss: 0.44361\n",
      "[4200]\ttraining's binary_logloss: 0.0705581\tvalid_1's binary_logloss: 0.445482\n",
      "[4300]\ttraining's binary_logloss: 0.0680622\tvalid_1's binary_logloss: 0.446788\n",
      "[4400]\ttraining's binary_logloss: 0.0656703\tvalid_1's binary_logloss: 0.448533\n",
      "[4500]\ttraining's binary_logloss: 0.0633806\tvalid_1's binary_logloss: 0.451458\n",
      "[4600]\ttraining's binary_logloss: 0.0611404\tvalid_1's binary_logloss: 0.454736\n",
      "[4700]\ttraining's binary_logloss: 0.0589495\tvalid_1's binary_logloss: 0.457747\n",
      "[4800]\ttraining's binary_logloss: 0.0568939\tvalid_1's binary_logloss: 0.461163\n",
      "[4900]\ttraining's binary_logloss: 0.0549723\tvalid_1's binary_logloss: 0.464822\n",
      "[5000]\ttraining's binary_logloss: 0.0530444\tvalid_1's binary_logloss: 0.466911\n",
      "Partial score of fold 2 is: 0.4669114262800087\n",
      "[100]\ttraining's binary_logloss: 0.530339\tvalid_1's binary_logloss: 0.553748\n",
      "[200]\ttraining's binary_logloss: 0.448659\tvalid_1's binary_logloss: 0.49148\n",
      "[300]\ttraining's binary_logloss: 0.400933\tvalid_1's binary_logloss: 0.458645\n",
      "[400]\ttraining's binary_logloss: 0.366942\tvalid_1's binary_logloss: 0.434217\n",
      "[500]\ttraining's binary_logloss: 0.341418\tvalid_1's binary_logloss: 0.41699\n",
      "[600]\ttraining's binary_logloss: 0.319602\tvalid_1's binary_logloss: 0.405681\n",
      "[700]\ttraining's binary_logloss: 0.302145\tvalid_1's binary_logloss: 0.396424\n",
      "[800]\ttraining's binary_logloss: 0.285723\tvalid_1's binary_logloss: 0.38785\n",
      "[900]\ttraining's binary_logloss: 0.270712\tvalid_1's binary_logloss: 0.378617\n",
      "[1000]\ttraining's binary_logloss: 0.256994\tvalid_1's binary_logloss: 0.371381\n",
      "[1100]\ttraining's binary_logloss: 0.244546\tvalid_1's binary_logloss: 0.367102\n",
      "[1200]\ttraining's binary_logloss: 0.232735\tvalid_1's binary_logloss: 0.364709\n",
      "[1300]\ttraining's binary_logloss: 0.221547\tvalid_1's binary_logloss: 0.364609\n",
      "[1400]\ttraining's binary_logloss: 0.211528\tvalid_1's binary_logloss: 0.361082\n",
      "[1500]\ttraining's binary_logloss: 0.202474\tvalid_1's binary_logloss: 0.359661\n",
      "[1600]\ttraining's binary_logloss: 0.193828\tvalid_1's binary_logloss: 0.358836\n",
      "[1700]\ttraining's binary_logloss: 0.18594\tvalid_1's binary_logloss: 0.357816\n",
      "[1800]\ttraining's binary_logloss: 0.178084\tvalid_1's binary_logloss: 0.357598\n",
      "[1900]\ttraining's binary_logloss: 0.170703\tvalid_1's binary_logloss: 0.356676\n",
      "[2000]\ttraining's binary_logloss: 0.163761\tvalid_1's binary_logloss: 0.355811\n",
      "[2100]\ttraining's binary_logloss: 0.15727\tvalid_1's binary_logloss: 0.354328\n",
      "[2200]\ttraining's binary_logloss: 0.151053\tvalid_1's binary_logloss: 0.35311\n",
      "[2300]\ttraining's binary_logloss: 0.145158\tvalid_1's binary_logloss: 0.351953\n",
      "[2400]\ttraining's binary_logloss: 0.139519\tvalid_1's binary_logloss: 0.351956\n",
      "[2500]\ttraining's binary_logloss: 0.133985\tvalid_1's binary_logloss: 0.351625\n",
      "[2600]\ttraining's binary_logloss: 0.128939\tvalid_1's binary_logloss: 0.352851\n",
      "[2700]\ttraining's binary_logloss: 0.124421\tvalid_1's binary_logloss: 0.353913\n",
      "[2800]\ttraining's binary_logloss: 0.119941\tvalid_1's binary_logloss: 0.3543\n",
      "[2900]\ttraining's binary_logloss: 0.115704\tvalid_1's binary_logloss: 0.355869\n",
      "[3000]\ttraining's binary_logloss: 0.111641\tvalid_1's binary_logloss: 0.356307\n",
      "[3100]\ttraining's binary_logloss: 0.107663\tvalid_1's binary_logloss: 0.357082\n",
      "[3200]\ttraining's binary_logloss: 0.103931\tvalid_1's binary_logloss: 0.356326\n",
      "[3300]\ttraining's binary_logloss: 0.100212\tvalid_1's binary_logloss: 0.356747\n",
      "[3400]\ttraining's binary_logloss: 0.0966412\tvalid_1's binary_logloss: 0.357642\n",
      "[3500]\ttraining's binary_logloss: 0.0931266\tvalid_1's binary_logloss: 0.358141\n",
      "[3600]\ttraining's binary_logloss: 0.0898515\tvalid_1's binary_logloss: 0.360204\n",
      "[3700]\ttraining's binary_logloss: 0.0866503\tvalid_1's binary_logloss: 0.361612\n",
      "[3800]\ttraining's binary_logloss: 0.0835909\tvalid_1's binary_logloss: 0.363981\n",
      "[3900]\ttraining's binary_logloss: 0.0805405\tvalid_1's binary_logloss: 0.36614\n",
      "[4000]\ttraining's binary_logloss: 0.0777963\tvalid_1's binary_logloss: 0.367623\n",
      "[4100]\ttraining's binary_logloss: 0.0751431\tvalid_1's binary_logloss: 0.367707\n",
      "[4200]\ttraining's binary_logloss: 0.0726022\tvalid_1's binary_logloss: 0.368909\n",
      "[4300]\ttraining's binary_logloss: 0.0700562\tvalid_1's binary_logloss: 0.369212\n",
      "[4400]\ttraining's binary_logloss: 0.0676707\tvalid_1's binary_logloss: 0.369494\n",
      "[4500]\ttraining's binary_logloss: 0.065345\tvalid_1's binary_logloss: 0.370199\n",
      "[4600]\ttraining's binary_logloss: 0.0630438\tvalid_1's binary_logloss: 0.371331\n",
      "[4700]\ttraining's binary_logloss: 0.061033\tvalid_1's binary_logloss: 0.372265\n",
      "[4800]\ttraining's binary_logloss: 0.0590266\tvalid_1's binary_logloss: 0.373438\n",
      "[4900]\ttraining's binary_logloss: 0.0571166\tvalid_1's binary_logloss: 0.374169\n",
      "[5000]\ttraining's binary_logloss: 0.0552094\tvalid_1's binary_logloss: 0.374913\n",
      "Partial score of fold 3 is: 0.3749130315526168\n",
      "[100]\ttraining's binary_logloss: 0.531849\tvalid_1's binary_logloss: 0.550082\n",
      "[200]\ttraining's binary_logloss: 0.449828\tvalid_1's binary_logloss: 0.482729\n",
      "[300]\ttraining's binary_logloss: 0.399152\tvalid_1's binary_logloss: 0.4479\n",
      "[400]\ttraining's binary_logloss: 0.365826\tvalid_1's binary_logloss: 0.429751\n",
      "[500]\ttraining's binary_logloss: 0.339025\tvalid_1's binary_logloss: 0.417744\n",
      "[600]\ttraining's binary_logloss: 0.317371\tvalid_1's binary_logloss: 0.407631\n",
      "[700]\ttraining's binary_logloss: 0.299591\tvalid_1's binary_logloss: 0.401681\n",
      "[800]\ttraining's binary_logloss: 0.284032\tvalid_1's binary_logloss: 0.397361\n",
      "[900]\ttraining's binary_logloss: 0.26989\tvalid_1's binary_logloss: 0.393892\n",
      "[1000]\ttraining's binary_logloss: 0.255998\tvalid_1's binary_logloss: 0.392542\n",
      "[1100]\ttraining's binary_logloss: 0.243475\tvalid_1's binary_logloss: 0.390296\n",
      "[1200]\ttraining's binary_logloss: 0.231923\tvalid_1's binary_logloss: 0.38798\n",
      "[1300]\ttraining's binary_logloss: 0.221225\tvalid_1's binary_logloss: 0.38668\n",
      "[1400]\ttraining's binary_logloss: 0.211457\tvalid_1's binary_logloss: 0.388219\n",
      "[1500]\ttraining's binary_logloss: 0.2017\tvalid_1's binary_logloss: 0.389345\n",
      "[1600]\ttraining's binary_logloss: 0.192692\tvalid_1's binary_logloss: 0.389093\n",
      "[1700]\ttraining's binary_logloss: 0.184594\tvalid_1's binary_logloss: 0.391342\n",
      "[1800]\ttraining's binary_logloss: 0.176508\tvalid_1's binary_logloss: 0.392765\n",
      "[1900]\ttraining's binary_logloss: 0.169362\tvalid_1's binary_logloss: 0.393132\n",
      "[2000]\ttraining's binary_logloss: 0.162558\tvalid_1's binary_logloss: 0.393284\n",
      "[2100]\ttraining's binary_logloss: 0.156237\tvalid_1's binary_logloss: 0.392896\n",
      "[2200]\ttraining's binary_logloss: 0.1503\tvalid_1's binary_logloss: 0.393591\n",
      "[2300]\ttraining's binary_logloss: 0.144782\tvalid_1's binary_logloss: 0.395223\n",
      "[2400]\ttraining's binary_logloss: 0.139409\tvalid_1's binary_logloss: 0.396132\n",
      "[2500]\ttraining's binary_logloss: 0.134112\tvalid_1's binary_logloss: 0.39762\n",
      "[2600]\ttraining's binary_logloss: 0.129217\tvalid_1's binary_logloss: 0.398134\n",
      "[2700]\ttraining's binary_logloss: 0.124422\tvalid_1's binary_logloss: 0.399134\n",
      "[2800]\ttraining's binary_logloss: 0.119965\tvalid_1's binary_logloss: 0.401842\n",
      "[2900]\ttraining's binary_logloss: 0.115674\tvalid_1's binary_logloss: 0.401899\n",
      "[3000]\ttraining's binary_logloss: 0.111291\tvalid_1's binary_logloss: 0.402705\n",
      "[3100]\ttraining's binary_logloss: 0.107197\tvalid_1's binary_logloss: 0.403435\n",
      "[3200]\ttraining's binary_logloss: 0.103343\tvalid_1's binary_logloss: 0.404545\n",
      "[3300]\ttraining's binary_logloss: 0.0997674\tvalid_1's binary_logloss: 0.405495\n",
      "[3400]\ttraining's binary_logloss: 0.0960366\tvalid_1's binary_logloss: 0.40555\n",
      "[3500]\ttraining's binary_logloss: 0.0923571\tvalid_1's binary_logloss: 0.407095\n",
      "[3600]\ttraining's binary_logloss: 0.0891491\tvalid_1's binary_logloss: 0.409468\n",
      "[3700]\ttraining's binary_logloss: 0.0860678\tvalid_1's binary_logloss: 0.411096\n",
      "[3800]\ttraining's binary_logloss: 0.0830656\tvalid_1's binary_logloss: 0.413375\n",
      "[3900]\ttraining's binary_logloss: 0.0800522\tvalid_1's binary_logloss: 0.413904\n",
      "[4000]\ttraining's binary_logloss: 0.0773099\tvalid_1's binary_logloss: 0.414483\n",
      "[4100]\ttraining's binary_logloss: 0.0746413\tvalid_1's binary_logloss: 0.416109\n",
      "[4200]\ttraining's binary_logloss: 0.0721297\tvalid_1's binary_logloss: 0.419\n",
      "[4300]\ttraining's binary_logloss: 0.0695128\tvalid_1's binary_logloss: 0.421965\n",
      "[4400]\ttraining's binary_logloss: 0.0670148\tvalid_1's binary_logloss: 0.423925\n",
      "[4500]\ttraining's binary_logloss: 0.0646905\tvalid_1's binary_logloss: 0.426319\n",
      "[4600]\ttraining's binary_logloss: 0.0625563\tvalid_1's binary_logloss: 0.428057\n",
      "[4700]\ttraining's binary_logloss: 0.0604598\tvalid_1's binary_logloss: 0.430445\n",
      "[4800]\ttraining's binary_logloss: 0.0583859\tvalid_1's binary_logloss: 0.43307\n",
      "[4900]\ttraining's binary_logloss: 0.0563721\tvalid_1's binary_logloss: 0.43643\n",
      "[5000]\ttraining's binary_logloss: 0.0544104\tvalid_1's binary_logloss: 0.438547\n",
      "Partial score of fold 4 is: 0.43854712723920247\n",
      "[100]\ttraining's binary_logloss: 0.532588\tvalid_1's binary_logloss: 0.534048\n",
      "[200]\ttraining's binary_logloss: 0.452374\tvalid_1's binary_logloss: 0.456811\n",
      "[300]\ttraining's binary_logloss: 0.402236\tvalid_1's binary_logloss: 0.42301\n",
      "[400]\ttraining's binary_logloss: 0.368285\tvalid_1's binary_logloss: 0.405891\n",
      "[500]\ttraining's binary_logloss: 0.341504\tvalid_1's binary_logloss: 0.397957\n",
      "[600]\ttraining's binary_logloss: 0.320316\tvalid_1's binary_logloss: 0.390374\n",
      "[700]\ttraining's binary_logloss: 0.301975\tvalid_1's binary_logloss: 0.379555\n",
      "[800]\ttraining's binary_logloss: 0.286693\tvalid_1's binary_logloss: 0.373965\n",
      "[900]\ttraining's binary_logloss: 0.272933\tvalid_1's binary_logloss: 0.369429\n",
      "[1000]\ttraining's binary_logloss: 0.260079\tvalid_1's binary_logloss: 0.365133\n",
      "[1100]\ttraining's binary_logloss: 0.248245\tvalid_1's binary_logloss: 0.363348\n",
      "[1200]\ttraining's binary_logloss: 0.236459\tvalid_1's binary_logloss: 0.360535\n",
      "[1300]\ttraining's binary_logloss: 0.225384\tvalid_1's binary_logloss: 0.358476\n",
      "[1400]\ttraining's binary_logloss: 0.214742\tvalid_1's binary_logloss: 0.35546\n",
      "[1500]\ttraining's binary_logloss: 0.205471\tvalid_1's binary_logloss: 0.351514\n",
      "[1600]\ttraining's binary_logloss: 0.196235\tvalid_1's binary_logloss: 0.350344\n",
      "[1700]\ttraining's binary_logloss: 0.187647\tvalid_1's binary_logloss: 0.351338\n",
      "[1800]\ttraining's binary_logloss: 0.18005\tvalid_1's binary_logloss: 0.351857\n",
      "[1900]\ttraining's binary_logloss: 0.172957\tvalid_1's binary_logloss: 0.352961\n",
      "[2000]\ttraining's binary_logloss: 0.165928\tvalid_1's binary_logloss: 0.354624\n",
      "[2100]\ttraining's binary_logloss: 0.159485\tvalid_1's binary_logloss: 0.356136\n",
      "[2200]\ttraining's binary_logloss: 0.153445\tvalid_1's binary_logloss: 0.357731\n",
      "[2300]\ttraining's binary_logloss: 0.147706\tvalid_1's binary_logloss: 0.357887\n",
      "[2400]\ttraining's binary_logloss: 0.142493\tvalid_1's binary_logloss: 0.359893\n",
      "[2500]\ttraining's binary_logloss: 0.137298\tvalid_1's binary_logloss: 0.360033\n",
      "[2600]\ttraining's binary_logloss: 0.132122\tvalid_1's binary_logloss: 0.36035\n",
      "[2700]\ttraining's binary_logloss: 0.127156\tvalid_1's binary_logloss: 0.360518\n",
      "[2800]\ttraining's binary_logloss: 0.122329\tvalid_1's binary_logloss: 0.360384\n",
      "[2900]\ttraining's binary_logloss: 0.117627\tvalid_1's binary_logloss: 0.361058\n",
      "[3000]\ttraining's binary_logloss: 0.113201\tvalid_1's binary_logloss: 0.363087\n",
      "[3100]\ttraining's binary_logloss: 0.109092\tvalid_1's binary_logloss: 0.363664\n",
      "[3200]\ttraining's binary_logloss: 0.104992\tvalid_1's binary_logloss: 0.364417\n",
      "[3300]\ttraining's binary_logloss: 0.101152\tvalid_1's binary_logloss: 0.364964\n",
      "[3400]\ttraining's binary_logloss: 0.0973598\tvalid_1's binary_logloss: 0.36518\n",
      "[3500]\ttraining's binary_logloss: 0.0937864\tvalid_1's binary_logloss: 0.366352\n",
      "[3600]\ttraining's binary_logloss: 0.0905643\tvalid_1's binary_logloss: 0.368333\n",
      "[3700]\ttraining's binary_logloss: 0.0874501\tvalid_1's binary_logloss: 0.370055\n",
      "[3800]\ttraining's binary_logloss: 0.0843283\tvalid_1's binary_logloss: 0.370905\n",
      "[3900]\ttraining's binary_logloss: 0.0813434\tvalid_1's binary_logloss: 0.371729\n",
      "[4000]\ttraining's binary_logloss: 0.0784878\tvalid_1's binary_logloss: 0.372149\n",
      "[4100]\ttraining's binary_logloss: 0.0758203\tvalid_1's binary_logloss: 0.372932\n",
      "[4200]\ttraining's binary_logloss: 0.0732579\tvalid_1's binary_logloss: 0.373177\n",
      "[4300]\ttraining's binary_logloss: 0.0707561\tvalid_1's binary_logloss: 0.375312\n",
      "[4400]\ttraining's binary_logloss: 0.0682709\tvalid_1's binary_logloss: 0.376718\n",
      "[4500]\ttraining's binary_logloss: 0.065953\tvalid_1's binary_logloss: 0.378116\n",
      "[4600]\ttraining's binary_logloss: 0.0637173\tvalid_1's binary_logloss: 0.379864\n",
      "[4700]\ttraining's binary_logloss: 0.0614563\tvalid_1's binary_logloss: 0.38076\n",
      "[4800]\ttraining's binary_logloss: 0.0593741\tvalid_1's binary_logloss: 0.382262\n",
      "[4900]\ttraining's binary_logloss: 0.0573591\tvalid_1's binary_logloss: 0.384497\n",
      "[5000]\ttraining's binary_logloss: 0.0553968\tvalid_1's binary_logloss: 0.38549\n",
      "Partial score of fold 5 is: 0.3854899568410011\n",
      "[100]\ttraining's binary_logloss: 0.5347\tvalid_1's binary_logloss: 0.536485\n",
      "[200]\ttraining's binary_logloss: 0.453619\tvalid_1's binary_logloss: 0.461381\n",
      "[300]\ttraining's binary_logloss: 0.404354\tvalid_1's binary_logloss: 0.421988\n",
      "[400]\ttraining's binary_logloss: 0.370286\tvalid_1's binary_logloss: 0.396161\n",
      "[500]\ttraining's binary_logloss: 0.34348\tvalid_1's binary_logloss: 0.381804\n",
      "[600]\ttraining's binary_logloss: 0.320743\tvalid_1's binary_logloss: 0.371939\n",
      "[700]\ttraining's binary_logloss: 0.302657\tvalid_1's binary_logloss: 0.364962\n",
      "[800]\ttraining's binary_logloss: 0.286045\tvalid_1's binary_logloss: 0.360106\n",
      "[900]\ttraining's binary_logloss: 0.270984\tvalid_1's binary_logloss: 0.35881\n",
      "[1000]\ttraining's binary_logloss: 0.257451\tvalid_1's binary_logloss: 0.356615\n",
      "[1100]\ttraining's binary_logloss: 0.245376\tvalid_1's binary_logloss: 0.357489\n",
      "[1200]\ttraining's binary_logloss: 0.23371\tvalid_1's binary_logloss: 0.356755\n",
      "[1300]\ttraining's binary_logloss: 0.223497\tvalid_1's binary_logloss: 0.357551\n",
      "[1400]\ttraining's binary_logloss: 0.214069\tvalid_1's binary_logloss: 0.358862\n",
      "[1500]\ttraining's binary_logloss: 0.204971\tvalid_1's binary_logloss: 0.360638\n",
      "[1600]\ttraining's binary_logloss: 0.196076\tvalid_1's binary_logloss: 0.363331\n",
      "[1700]\ttraining's binary_logloss: 0.188116\tvalid_1's binary_logloss: 0.367269\n",
      "[1800]\ttraining's binary_logloss: 0.180562\tvalid_1's binary_logloss: 0.369566\n",
      "[1900]\ttraining's binary_logloss: 0.173301\tvalid_1's binary_logloss: 0.370771\n",
      "[2000]\ttraining's binary_logloss: 0.166088\tvalid_1's binary_logloss: 0.370802\n",
      "[2100]\ttraining's binary_logloss: 0.159243\tvalid_1's binary_logloss: 0.371432\n",
      "[2200]\ttraining's binary_logloss: 0.153021\tvalid_1's binary_logloss: 0.371523\n",
      "[2300]\ttraining's binary_logloss: 0.146711\tvalid_1's binary_logloss: 0.370053\n",
      "[2400]\ttraining's binary_logloss: 0.141006\tvalid_1's binary_logloss: 0.371437\n",
      "[2500]\ttraining's binary_logloss: 0.135639\tvalid_1's binary_logloss: 0.373204\n",
      "[2600]\ttraining's binary_logloss: 0.130412\tvalid_1's binary_logloss: 0.374141\n",
      "[2700]\ttraining's binary_logloss: 0.125349\tvalid_1's binary_logloss: 0.375698\n",
      "[2800]\ttraining's binary_logloss: 0.120517\tvalid_1's binary_logloss: 0.377281\n",
      "[2900]\ttraining's binary_logloss: 0.116107\tvalid_1's binary_logloss: 0.379835\n",
      "[3000]\ttraining's binary_logloss: 0.111725\tvalid_1's binary_logloss: 0.381851\n",
      "[3100]\ttraining's binary_logloss: 0.107706\tvalid_1's binary_logloss: 0.384981\n",
      "[3200]\ttraining's binary_logloss: 0.103985\tvalid_1's binary_logloss: 0.388206\n",
      "[3300]\ttraining's binary_logloss: 0.100488\tvalid_1's binary_logloss: 0.391073\n",
      "[3400]\ttraining's binary_logloss: 0.0969662\tvalid_1's binary_logloss: 0.392853\n",
      "[3500]\ttraining's binary_logloss: 0.0934728\tvalid_1's binary_logloss: 0.393716\n",
      "[3600]\ttraining's binary_logloss: 0.089933\tvalid_1's binary_logloss: 0.393996\n",
      "[3700]\ttraining's binary_logloss: 0.0865769\tvalid_1's binary_logloss: 0.395726\n",
      "[3800]\ttraining's binary_logloss: 0.0834073\tvalid_1's binary_logloss: 0.39625\n",
      "[3900]\ttraining's binary_logloss: 0.0804486\tvalid_1's binary_logloss: 0.397371\n",
      "[4000]\ttraining's binary_logloss: 0.0777172\tvalid_1's binary_logloss: 0.399326\n",
      "[4100]\ttraining's binary_logloss: 0.0749558\tvalid_1's binary_logloss: 0.400044\n",
      "[4200]\ttraining's binary_logloss: 0.0723781\tvalid_1's binary_logloss: 0.40201\n",
      "[4300]\ttraining's binary_logloss: 0.0699742\tvalid_1's binary_logloss: 0.404\n",
      "[4400]\ttraining's binary_logloss: 0.0675571\tvalid_1's binary_logloss: 0.404759\n",
      "[4500]\ttraining's binary_logloss: 0.0652911\tvalid_1's binary_logloss: 0.407322\n",
      "[4600]\ttraining's binary_logloss: 0.0629647\tvalid_1's binary_logloss: 0.409291\n",
      "[4700]\ttraining's binary_logloss: 0.0607286\tvalid_1's binary_logloss: 0.412673\n",
      "[4800]\ttraining's binary_logloss: 0.0586216\tvalid_1's binary_logloss: 0.415621\n",
      "[4900]\ttraining's binary_logloss: 0.0565263\tvalid_1's binary_logloss: 0.418111\n",
      "[5000]\ttraining's binary_logloss: 0.0544316\tvalid_1's binary_logloss: 0.420363\n",
      "Partial score of fold 6 is: 0.42036347918929345\n",
      "[100]\ttraining's binary_logloss: 0.533767\tvalid_1's binary_logloss: 0.543378\n",
      "[200]\ttraining's binary_logloss: 0.450954\tvalid_1's binary_logloss: 0.476249\n",
      "[300]\ttraining's binary_logloss: 0.401369\tvalid_1's binary_logloss: 0.440251\n",
      "[400]\ttraining's binary_logloss: 0.367544\tvalid_1's binary_logloss: 0.418552\n",
      "[500]\ttraining's binary_logloss: 0.342053\tvalid_1's binary_logloss: 0.403347\n",
      "[600]\ttraining's binary_logloss: 0.319499\tvalid_1's binary_logloss: 0.389982\n",
      "[700]\ttraining's binary_logloss: 0.300029\tvalid_1's binary_logloss: 0.380374\n",
      "[800]\ttraining's binary_logloss: 0.28348\tvalid_1's binary_logloss: 0.373766\n",
      "[900]\ttraining's binary_logloss: 0.268912\tvalid_1's binary_logloss: 0.36921\n",
      "[1000]\ttraining's binary_logloss: 0.256409\tvalid_1's binary_logloss: 0.368068\n",
      "[1100]\ttraining's binary_logloss: 0.244349\tvalid_1's binary_logloss: 0.36839\n",
      "[1200]\ttraining's binary_logloss: 0.23321\tvalid_1's binary_logloss: 0.367427\n",
      "[1300]\ttraining's binary_logloss: 0.222717\tvalid_1's binary_logloss: 0.367325\n",
      "[1400]\ttraining's binary_logloss: 0.212892\tvalid_1's binary_logloss: 0.367525\n",
      "[1500]\ttraining's binary_logloss: 0.203843\tvalid_1's binary_logloss: 0.367332\n",
      "[1600]\ttraining's binary_logloss: 0.195648\tvalid_1's binary_logloss: 0.366817\n",
      "[1700]\ttraining's binary_logloss: 0.187803\tvalid_1's binary_logloss: 0.366874\n",
      "[1800]\ttraining's binary_logloss: 0.180313\tvalid_1's binary_logloss: 0.368573\n",
      "[1900]\ttraining's binary_logloss: 0.172862\tvalid_1's binary_logloss: 0.368962\n",
      "[2000]\ttraining's binary_logloss: 0.166074\tvalid_1's binary_logloss: 0.370281\n",
      "[2100]\ttraining's binary_logloss: 0.159751\tvalid_1's binary_logloss: 0.370647\n",
      "[2200]\ttraining's binary_logloss: 0.153758\tvalid_1's binary_logloss: 0.373338\n",
      "[2300]\ttraining's binary_logloss: 0.147974\tvalid_1's binary_logloss: 0.373213\n",
      "[2400]\ttraining's binary_logloss: 0.142345\tvalid_1's binary_logloss: 0.374311\n",
      "[2500]\ttraining's binary_logloss: 0.136855\tvalid_1's binary_logloss: 0.3762\n",
      "[2600]\ttraining's binary_logloss: 0.131984\tvalid_1's binary_logloss: 0.376679\n",
      "[2700]\ttraining's binary_logloss: 0.127225\tvalid_1's binary_logloss: 0.377578\n",
      "[2800]\ttraining's binary_logloss: 0.122559\tvalid_1's binary_logloss: 0.379271\n",
      "[2900]\ttraining's binary_logloss: 0.118265\tvalid_1's binary_logloss: 0.379827\n",
      "[3000]\ttraining's binary_logloss: 0.114127\tvalid_1's binary_logloss: 0.38073\n",
      "[3100]\ttraining's binary_logloss: 0.110005\tvalid_1's binary_logloss: 0.381921\n",
      "[3200]\ttraining's binary_logloss: 0.105983\tvalid_1's binary_logloss: 0.384052\n",
      "[3300]\ttraining's binary_logloss: 0.102164\tvalid_1's binary_logloss: 0.385588\n",
      "[3400]\ttraining's binary_logloss: 0.0986562\tvalid_1's binary_logloss: 0.389416\n",
      "[3500]\ttraining's binary_logloss: 0.0950526\tvalid_1's binary_logloss: 0.392028\n",
      "[3600]\ttraining's binary_logloss: 0.0917956\tvalid_1's binary_logloss: 0.395502\n",
      "[3700]\ttraining's binary_logloss: 0.0884645\tvalid_1's binary_logloss: 0.397456\n",
      "[3800]\ttraining's binary_logloss: 0.08548\tvalid_1's binary_logloss: 0.399819\n",
      "[3900]\ttraining's binary_logloss: 0.0825553\tvalid_1's binary_logloss: 0.401422\n",
      "[4000]\ttraining's binary_logloss: 0.0796702\tvalid_1's binary_logloss: 0.403309\n",
      "[4100]\ttraining's binary_logloss: 0.0769473\tvalid_1's binary_logloss: 0.405176\n",
      "[4200]\ttraining's binary_logloss: 0.0742506\tvalid_1's binary_logloss: 0.408859\n",
      "[4300]\ttraining's binary_logloss: 0.0716519\tvalid_1's binary_logloss: 0.412968\n",
      "[4400]\ttraining's binary_logloss: 0.0691966\tvalid_1's binary_logloss: 0.416594\n",
      "[4500]\ttraining's binary_logloss: 0.0668321\tvalid_1's binary_logloss: 0.420347\n",
      "[4600]\ttraining's binary_logloss: 0.0645598\tvalid_1's binary_logloss: 0.422711\n",
      "[4700]\ttraining's binary_logloss: 0.0624367\tvalid_1's binary_logloss: 0.424542\n",
      "[4800]\ttraining's binary_logloss: 0.0603166\tvalid_1's binary_logloss: 0.427833\n",
      "[4900]\ttraining's binary_logloss: 0.0582128\tvalid_1's binary_logloss: 0.430149\n",
      "[5000]\ttraining's binary_logloss: 0.0563161\tvalid_1's binary_logloss: 0.432922\n",
      "Partial score of fold 7 is: 0.43292207274541106\n",
      "[100]\ttraining's binary_logloss: 0.531263\tvalid_1's binary_logloss: 0.544641\n",
      "[200]\ttraining's binary_logloss: 0.451043\tvalid_1's binary_logloss: 0.471718\n",
      "[300]\ttraining's binary_logloss: 0.403379\tvalid_1's binary_logloss: 0.434293\n",
      "[400]\ttraining's binary_logloss: 0.369514\tvalid_1's binary_logloss: 0.409237\n",
      "[500]\ttraining's binary_logloss: 0.343338\tvalid_1's binary_logloss: 0.393951\n",
      "[600]\ttraining's binary_logloss: 0.322007\tvalid_1's binary_logloss: 0.382626\n",
      "[700]\ttraining's binary_logloss: 0.302415\tvalid_1's binary_logloss: 0.371617\n",
      "[800]\ttraining's binary_logloss: 0.2864\tvalid_1's binary_logloss: 0.36683\n",
      "[900]\ttraining's binary_logloss: 0.272439\tvalid_1's binary_logloss: 0.361472\n",
      "[1000]\ttraining's binary_logloss: 0.258944\tvalid_1's binary_logloss: 0.354875\n",
      "[1100]\ttraining's binary_logloss: 0.246781\tvalid_1's binary_logloss: 0.349828\n",
      "[1200]\ttraining's binary_logloss: 0.235805\tvalid_1's binary_logloss: 0.348423\n",
      "[1300]\ttraining's binary_logloss: 0.225421\tvalid_1's binary_logloss: 0.345466\n",
      "[1400]\ttraining's binary_logloss: 0.215474\tvalid_1's binary_logloss: 0.344175\n",
      "[1500]\ttraining's binary_logloss: 0.206052\tvalid_1's binary_logloss: 0.341828\n",
      "[1600]\ttraining's binary_logloss: 0.197466\tvalid_1's binary_logloss: 0.339447\n",
      "[1700]\ttraining's binary_logloss: 0.189098\tvalid_1's binary_logloss: 0.336896\n",
      "[1800]\ttraining's binary_logloss: 0.181354\tvalid_1's binary_logloss: 0.335606\n",
      "[1900]\ttraining's binary_logloss: 0.174287\tvalid_1's binary_logloss: 0.335265\n",
      "[2000]\ttraining's binary_logloss: 0.167113\tvalid_1's binary_logloss: 0.334653\n",
      "[2100]\ttraining's binary_logloss: 0.159887\tvalid_1's binary_logloss: 0.333142\n",
      "[2200]\ttraining's binary_logloss: 0.153513\tvalid_1's binary_logloss: 0.331999\n",
      "[2300]\ttraining's binary_logloss: 0.147655\tvalid_1's binary_logloss: 0.332509\n",
      "[2400]\ttraining's binary_logloss: 0.141789\tvalid_1's binary_logloss: 0.332648\n",
      "[2500]\ttraining's binary_logloss: 0.136289\tvalid_1's binary_logloss: 0.330801\n",
      "[2600]\ttraining's binary_logloss: 0.131071\tvalid_1's binary_logloss: 0.330838\n",
      "[2700]\ttraining's binary_logloss: 0.126219\tvalid_1's binary_logloss: 0.331441\n",
      "[2800]\ttraining's binary_logloss: 0.12172\tvalid_1's binary_logloss: 0.332448\n",
      "[2900]\ttraining's binary_logloss: 0.117415\tvalid_1's binary_logloss: 0.333611\n",
      "[3000]\ttraining's binary_logloss: 0.113026\tvalid_1's binary_logloss: 0.334439\n",
      "[3100]\ttraining's binary_logloss: 0.108637\tvalid_1's binary_logloss: 0.335859\n",
      "[3200]\ttraining's binary_logloss: 0.104698\tvalid_1's binary_logloss: 0.337625\n",
      "[3300]\ttraining's binary_logloss: 0.101005\tvalid_1's binary_logloss: 0.339516\n",
      "[3400]\ttraining's binary_logloss: 0.0974831\tvalid_1's binary_logloss: 0.340699\n",
      "[3500]\ttraining's binary_logloss: 0.0942375\tvalid_1's binary_logloss: 0.340907\n",
      "[3600]\ttraining's binary_logloss: 0.0909516\tvalid_1's binary_logloss: 0.340244\n",
      "[3700]\ttraining's binary_logloss: 0.0877185\tvalid_1's binary_logloss: 0.340085\n",
      "[3800]\ttraining's binary_logloss: 0.0845922\tvalid_1's binary_logloss: 0.341587\n",
      "[3900]\ttraining's binary_logloss: 0.0816907\tvalid_1's binary_logloss: 0.34212\n",
      "[4000]\ttraining's binary_logloss: 0.0788382\tvalid_1's binary_logloss: 0.341852\n",
      "[4100]\ttraining's binary_logloss: 0.0761296\tvalid_1's binary_logloss: 0.342631\n",
      "[4200]\ttraining's binary_logloss: 0.0735165\tvalid_1's binary_logloss: 0.342361\n",
      "[4300]\ttraining's binary_logloss: 0.0708069\tvalid_1's binary_logloss: 0.343346\n",
      "[4400]\ttraining's binary_logloss: 0.0682346\tvalid_1's binary_logloss: 0.345412\n",
      "[4500]\ttraining's binary_logloss: 0.0659679\tvalid_1's binary_logloss: 0.34604\n",
      "[4600]\ttraining's binary_logloss: 0.0637233\tvalid_1's binary_logloss: 0.346925\n",
      "[4700]\ttraining's binary_logloss: 0.061589\tvalid_1's binary_logloss: 0.34922\n",
      "[4800]\ttraining's binary_logloss: 0.0595435\tvalid_1's binary_logloss: 0.349759\n",
      "[4900]\ttraining's binary_logloss: 0.0575568\tvalid_1's binary_logloss: 0.35058\n",
      "[5000]\ttraining's binary_logloss: 0.0555846\tvalid_1's binary_logloss: 0.351507\n",
      "Partial score of fold 8 is: 0.35150683095565816\n",
      "[100]\ttraining's binary_logloss: 0.531685\tvalid_1's binary_logloss: 0.556849\n",
      "[200]\ttraining's binary_logloss: 0.449269\tvalid_1's binary_logloss: 0.497865\n",
      "[300]\ttraining's binary_logloss: 0.399382\tvalid_1's binary_logloss: 0.46617\n",
      "[400]\ttraining's binary_logloss: 0.36557\tvalid_1's binary_logloss: 0.446582\n",
      "[500]\ttraining's binary_logloss: 0.338168\tvalid_1's binary_logloss: 0.42919\n",
      "[600]\ttraining's binary_logloss: 0.315938\tvalid_1's binary_logloss: 0.422289\n",
      "[700]\ttraining's binary_logloss: 0.296177\tvalid_1's binary_logloss: 0.416125\n",
      "[800]\ttraining's binary_logloss: 0.279601\tvalid_1's binary_logloss: 0.415336\n",
      "[900]\ttraining's binary_logloss: 0.265313\tvalid_1's binary_logloss: 0.41573\n",
      "[1000]\ttraining's binary_logloss: 0.252459\tvalid_1's binary_logloss: 0.416002\n",
      "[1100]\ttraining's binary_logloss: 0.240908\tvalid_1's binary_logloss: 0.416838\n",
      "[1200]\ttraining's binary_logloss: 0.229629\tvalid_1's binary_logloss: 0.418057\n",
      "[1300]\ttraining's binary_logloss: 0.21887\tvalid_1's binary_logloss: 0.419749\n",
      "[1400]\ttraining's binary_logloss: 0.207969\tvalid_1's binary_logloss: 0.419602\n",
      "[1500]\ttraining's binary_logloss: 0.198728\tvalid_1's binary_logloss: 0.421805\n",
      "[1600]\ttraining's binary_logloss: 0.190235\tvalid_1's binary_logloss: 0.42226\n",
      "[1700]\ttraining's binary_logloss: 0.181784\tvalid_1's binary_logloss: 0.423557\n",
      "[1800]\ttraining's binary_logloss: 0.173566\tvalid_1's binary_logloss: 0.427456\n",
      "[1900]\ttraining's binary_logloss: 0.166079\tvalid_1's binary_logloss: 0.429157\n",
      "[2000]\ttraining's binary_logloss: 0.158993\tvalid_1's binary_logloss: 0.430447\n",
      "[2100]\ttraining's binary_logloss: 0.152487\tvalid_1's binary_logloss: 0.432325\n",
      "[2200]\ttraining's binary_logloss: 0.146429\tvalid_1's binary_logloss: 0.433088\n",
      "[2300]\ttraining's binary_logloss: 0.140631\tvalid_1's binary_logloss: 0.435172\n",
      "[2400]\ttraining's binary_logloss: 0.134794\tvalid_1's binary_logloss: 0.437736\n",
      "[2500]\ttraining's binary_logloss: 0.129719\tvalid_1's binary_logloss: 0.440425\n",
      "[2600]\ttraining's binary_logloss: 0.12496\tvalid_1's binary_logloss: 0.444828\n",
      "[2700]\ttraining's binary_logloss: 0.120341\tvalid_1's binary_logloss: 0.448627\n",
      "[2800]\ttraining's binary_logloss: 0.115805\tvalid_1's binary_logloss: 0.452179\n",
      "[2900]\ttraining's binary_logloss: 0.111506\tvalid_1's binary_logloss: 0.456529\n",
      "[3000]\ttraining's binary_logloss: 0.107472\tvalid_1's binary_logloss: 0.46086\n",
      "[3100]\ttraining's binary_logloss: 0.103488\tvalid_1's binary_logloss: 0.465087\n",
      "[3200]\ttraining's binary_logloss: 0.0996713\tvalid_1's binary_logloss: 0.468563\n",
      "[3300]\ttraining's binary_logloss: 0.0960846\tvalid_1's binary_logloss: 0.471781\n",
      "[3400]\ttraining's binary_logloss: 0.0926674\tvalid_1's binary_logloss: 0.474323\n",
      "[3500]\ttraining's binary_logloss: 0.0893472\tvalid_1's binary_logloss: 0.477664\n",
      "[3600]\ttraining's binary_logloss: 0.0862264\tvalid_1's binary_logloss: 0.480175\n",
      "[3700]\ttraining's binary_logloss: 0.0831486\tvalid_1's binary_logloss: 0.482611\n",
      "[3800]\ttraining's binary_logloss: 0.0800907\tvalid_1's binary_logloss: 0.486394\n",
      "[3900]\ttraining's binary_logloss: 0.0771376\tvalid_1's binary_logloss: 0.488936\n",
      "[4000]\ttraining's binary_logloss: 0.074427\tvalid_1's binary_logloss: 0.492705\n",
      "[4100]\ttraining's binary_logloss: 0.0717557\tvalid_1's binary_logloss: 0.495593\n",
      "[4200]\ttraining's binary_logloss: 0.0691871\tvalid_1's binary_logloss: 0.498729\n",
      "[4300]\ttraining's binary_logloss: 0.0667857\tvalid_1's binary_logloss: 0.501902\n",
      "[4400]\ttraining's binary_logloss: 0.0644745\tvalid_1's binary_logloss: 0.505548\n",
      "[4500]\ttraining's binary_logloss: 0.0623121\tvalid_1's binary_logloss: 0.509565\n",
      "[4600]\ttraining's binary_logloss: 0.0602176\tvalid_1's binary_logloss: 0.512493\n",
      "[4700]\ttraining's binary_logloss: 0.0582195\tvalid_1's binary_logloss: 0.515477\n",
      "[4800]\ttraining's binary_logloss: 0.0562323\tvalid_1's binary_logloss: 0.51779\n",
      "[4900]\ttraining's binary_logloss: 0.0542931\tvalid_1's binary_logloss: 0.520555\n",
      "[5000]\ttraining's binary_logloss: 0.0524508\tvalid_1's binary_logloss: 0.524612\n",
      "Partial score of fold 9 is: 0.5246124469835572\n",
      "Our oof loss score is:  0.42437298623183445\n",
      "Predicting 2018...\n",
      "[100]\ttraining's binary_logloss: 0.533879\tvalid_1's binary_logloss: 0.534065\n",
      "[200]\ttraining's binary_logloss: 0.452487\tvalid_1's binary_logloss: 0.46114\n",
      "[300]\ttraining's binary_logloss: 0.403154\tvalid_1's binary_logloss: 0.421739\n",
      "[400]\ttraining's binary_logloss: 0.36762\tvalid_1's binary_logloss: 0.397692\n",
      "[500]\ttraining's binary_logloss: 0.341535\tvalid_1's binary_logloss: 0.385279\n",
      "[600]\ttraining's binary_logloss: 0.318978\tvalid_1's binary_logloss: 0.376851\n",
      "[700]\ttraining's binary_logloss: 0.30085\tvalid_1's binary_logloss: 0.369637\n",
      "[800]\ttraining's binary_logloss: 0.284574\tvalid_1's binary_logloss: 0.367872\n",
      "[900]\ttraining's binary_logloss: 0.269425\tvalid_1's binary_logloss: 0.366573\n",
      "[1000]\ttraining's binary_logloss: 0.255449\tvalid_1's binary_logloss: 0.368907\n",
      "[1100]\ttraining's binary_logloss: 0.242711\tvalid_1's binary_logloss: 0.369007\n",
      "[1200]\ttraining's binary_logloss: 0.231964\tvalid_1's binary_logloss: 0.368506\n",
      "[1300]\ttraining's binary_logloss: 0.221943\tvalid_1's binary_logloss: 0.37021\n",
      "[1400]\ttraining's binary_logloss: 0.211687\tvalid_1's binary_logloss: 0.369412\n",
      "[1500]\ttraining's binary_logloss: 0.202533\tvalid_1's binary_logloss: 0.370966\n",
      "[1600]\ttraining's binary_logloss: 0.193914\tvalid_1's binary_logloss: 0.371372\n",
      "[1700]\ttraining's binary_logloss: 0.185807\tvalid_1's binary_logloss: 0.372936\n",
      "[1800]\ttraining's binary_logloss: 0.178325\tvalid_1's binary_logloss: 0.374704\n",
      "[1900]\ttraining's binary_logloss: 0.171353\tvalid_1's binary_logloss: 0.376542\n",
      "[2000]\ttraining's binary_logloss: 0.164523\tvalid_1's binary_logloss: 0.376931\n",
      "[2100]\ttraining's binary_logloss: 0.157939\tvalid_1's binary_logloss: 0.378364\n",
      "[2200]\ttraining's binary_logloss: 0.151368\tvalid_1's binary_logloss: 0.379831\n",
      "[2300]\ttraining's binary_logloss: 0.145395\tvalid_1's binary_logloss: 0.380688\n",
      "[2400]\ttraining's binary_logloss: 0.139983\tvalid_1's binary_logloss: 0.380542\n",
      "[2500]\ttraining's binary_logloss: 0.134606\tvalid_1's binary_logloss: 0.380424\n",
      "[2600]\ttraining's binary_logloss: 0.129612\tvalid_1's binary_logloss: 0.382421\n",
      "[2700]\ttraining's binary_logloss: 0.124962\tvalid_1's binary_logloss: 0.38418\n",
      "[2800]\ttraining's binary_logloss: 0.12038\tvalid_1's binary_logloss: 0.3852\n",
      "[2900]\ttraining's binary_logloss: 0.116159\tvalid_1's binary_logloss: 0.386413\n",
      "[3000]\ttraining's binary_logloss: 0.111946\tvalid_1's binary_logloss: 0.388673\n",
      "[3100]\ttraining's binary_logloss: 0.108017\tvalid_1's binary_logloss: 0.389113\n",
      "[3200]\ttraining's binary_logloss: 0.10444\tvalid_1's binary_logloss: 0.390926\n",
      "[3300]\ttraining's binary_logloss: 0.100677\tvalid_1's binary_logloss: 0.392834\n",
      "[3400]\ttraining's binary_logloss: 0.0970393\tvalid_1's binary_logloss: 0.394797\n",
      "[3500]\ttraining's binary_logloss: 0.0935917\tvalid_1's binary_logloss: 0.397031\n",
      "[3600]\ttraining's binary_logloss: 0.0904213\tvalid_1's binary_logloss: 0.397639\n",
      "[3700]\ttraining's binary_logloss: 0.0873464\tvalid_1's binary_logloss: 0.397845\n",
      "[3800]\ttraining's binary_logloss: 0.0843028\tvalid_1's binary_logloss: 0.399672\n",
      "[3900]\ttraining's binary_logloss: 0.0812572\tvalid_1's binary_logloss: 0.400708\n",
      "[4000]\ttraining's binary_logloss: 0.0781527\tvalid_1's binary_logloss: 0.40245\n",
      "[4100]\ttraining's binary_logloss: 0.0754306\tvalid_1's binary_logloss: 0.403645\n",
      "[4200]\ttraining's binary_logloss: 0.0727553\tvalid_1's binary_logloss: 0.405596\n",
      "[4300]\ttraining's binary_logloss: 0.0699965\tvalid_1's binary_logloss: 0.407887\n",
      "[4400]\ttraining's binary_logloss: 0.0675656\tvalid_1's binary_logloss: 0.409225\n",
      "[4500]\ttraining's binary_logloss: 0.0652473\tvalid_1's binary_logloss: 0.411902\n",
      "[4600]\ttraining's binary_logloss: 0.0629514\tvalid_1's binary_logloss: 0.413904\n",
      "[4700]\ttraining's binary_logloss: 0.0606707\tvalid_1's binary_logloss: 0.417078\n",
      "[4800]\ttraining's binary_logloss: 0.0584421\tvalid_1's binary_logloss: 0.421263\n",
      "[4900]\ttraining's binary_logloss: 0.0564469\tvalid_1's binary_logloss: 0.424689\n",
      "[5000]\ttraining's binary_logloss: 0.0544951\tvalid_1's binary_logloss: 0.426622\n",
      "Partial score of fold 0 is: 0.42662156595615264\n",
      "[100]\ttraining's binary_logloss: 0.530438\tvalid_1's binary_logloss: 0.558449\n",
      "[200]\ttraining's binary_logloss: 0.447642\tvalid_1's binary_logloss: 0.494672\n",
      "[300]\ttraining's binary_logloss: 0.39838\tvalid_1's binary_logloss: 0.462501\n",
      "[400]\ttraining's binary_logloss: 0.364537\tvalid_1's binary_logloss: 0.441584\n",
      "[500]\ttraining's binary_logloss: 0.338264\tvalid_1's binary_logloss: 0.425405\n",
      "[600]\ttraining's binary_logloss: 0.316262\tvalid_1's binary_logloss: 0.413279\n",
      "[700]\ttraining's binary_logloss: 0.297503\tvalid_1's binary_logloss: 0.401126\n",
      "[800]\ttraining's binary_logloss: 0.281868\tvalid_1's binary_logloss: 0.395245\n",
      "[900]\ttraining's binary_logloss: 0.266963\tvalid_1's binary_logloss: 0.392217\n",
      "[1000]\ttraining's binary_logloss: 0.253438\tvalid_1's binary_logloss: 0.388792\n",
      "[1100]\ttraining's binary_logloss: 0.241799\tvalid_1's binary_logloss: 0.387876\n",
      "[1200]\ttraining's binary_logloss: 0.230304\tvalid_1's binary_logloss: 0.388533\n",
      "[1300]\ttraining's binary_logloss: 0.219818\tvalid_1's binary_logloss: 0.388828\n",
      "[1400]\ttraining's binary_logloss: 0.210796\tvalid_1's binary_logloss: 0.387442\n",
      "[1500]\ttraining's binary_logloss: 0.201804\tvalid_1's binary_logloss: 0.38349\n",
      "[1600]\ttraining's binary_logloss: 0.192676\tvalid_1's binary_logloss: 0.382124\n",
      "[1700]\ttraining's binary_logloss: 0.18439\tvalid_1's binary_logloss: 0.381894\n",
      "[1800]\ttraining's binary_logloss: 0.17671\tvalid_1's binary_logloss: 0.382925\n",
      "[1900]\ttraining's binary_logloss: 0.169522\tvalid_1's binary_logloss: 0.384151\n",
      "[2000]\ttraining's binary_logloss: 0.162754\tvalid_1's binary_logloss: 0.387153\n",
      "[2100]\ttraining's binary_logloss: 0.156364\tvalid_1's binary_logloss: 0.388848\n",
      "[2200]\ttraining's binary_logloss: 0.150222\tvalid_1's binary_logloss: 0.389225\n",
      "[2300]\ttraining's binary_logloss: 0.144416\tvalid_1's binary_logloss: 0.39068\n",
      "[2400]\ttraining's binary_logloss: 0.138904\tvalid_1's binary_logloss: 0.391381\n",
      "[2500]\ttraining's binary_logloss: 0.133795\tvalid_1's binary_logloss: 0.392873\n",
      "[2600]\ttraining's binary_logloss: 0.128855\tvalid_1's binary_logloss: 0.393753\n",
      "[2700]\ttraining's binary_logloss: 0.123958\tvalid_1's binary_logloss: 0.395305\n",
      "[2800]\ttraining's binary_logloss: 0.119385\tvalid_1's binary_logloss: 0.3972\n",
      "[2900]\ttraining's binary_logloss: 0.115016\tvalid_1's binary_logloss: 0.397092\n",
      "[3000]\ttraining's binary_logloss: 0.110934\tvalid_1's binary_logloss: 0.398833\n",
      "[3100]\ttraining's binary_logloss: 0.106994\tvalid_1's binary_logloss: 0.399147\n",
      "[3200]\ttraining's binary_logloss: 0.103212\tvalid_1's binary_logloss: 0.397454\n",
      "[3300]\ttraining's binary_logloss: 0.0995624\tvalid_1's binary_logloss: 0.397103\n",
      "[3400]\ttraining's binary_logloss: 0.0962272\tvalid_1's binary_logloss: 0.398199\n",
      "[3500]\ttraining's binary_logloss: 0.0929324\tvalid_1's binary_logloss: 0.399208\n",
      "[3600]\ttraining's binary_logloss: 0.0895938\tvalid_1's binary_logloss: 0.400215\n",
      "[3700]\ttraining's binary_logloss: 0.0864706\tvalid_1's binary_logloss: 0.401542\n",
      "[3800]\ttraining's binary_logloss: 0.083555\tvalid_1's binary_logloss: 0.403102\n",
      "[3900]\ttraining's binary_logloss: 0.0805301\tvalid_1's binary_logloss: 0.404623\n",
      "[4000]\ttraining's binary_logloss: 0.0776831\tvalid_1's binary_logloss: 0.405612\n",
      "[4100]\ttraining's binary_logloss: 0.075055\tvalid_1's binary_logloss: 0.407654\n",
      "[4200]\ttraining's binary_logloss: 0.0724351\tvalid_1's binary_logloss: 0.409381\n",
      "[4300]\ttraining's binary_logloss: 0.0700671\tvalid_1's binary_logloss: 0.411627\n",
      "[4400]\ttraining's binary_logloss: 0.0677596\tvalid_1's binary_logloss: 0.412996\n",
      "[4500]\ttraining's binary_logloss: 0.0655712\tvalid_1's binary_logloss: 0.414448\n",
      "[4600]\ttraining's binary_logloss: 0.0633367\tvalid_1's binary_logloss: 0.41432\n",
      "[4700]\ttraining's binary_logloss: 0.0611838\tvalid_1's binary_logloss: 0.416275\n",
      "[4800]\ttraining's binary_logloss: 0.0590429\tvalid_1's binary_logloss: 0.4188\n",
      "[4900]\ttraining's binary_logloss: 0.0569747\tvalid_1's binary_logloss: 0.420533\n",
      "[5000]\ttraining's binary_logloss: 0.0550032\tvalid_1's binary_logloss: 0.422815\n",
      "Partial score of fold 1 is: 0.42281512322351805\n",
      "[100]\ttraining's binary_logloss: 0.531659\tvalid_1's binary_logloss: 0.551978\n",
      "[200]\ttraining's binary_logloss: 0.450432\tvalid_1's binary_logloss: 0.481607\n",
      "[300]\ttraining's binary_logloss: 0.401965\tvalid_1's binary_logloss: 0.440426\n",
      "[400]\ttraining's binary_logloss: 0.368132\tvalid_1's binary_logloss: 0.41241\n",
      "[500]\ttraining's binary_logloss: 0.341827\tvalid_1's binary_logloss: 0.396649\n",
      "[600]\ttraining's binary_logloss: 0.319436\tvalid_1's binary_logloss: 0.386696\n",
      "[700]\ttraining's binary_logloss: 0.299313\tvalid_1's binary_logloss: 0.379062\n",
      "[800]\ttraining's binary_logloss: 0.281861\tvalid_1's binary_logloss: 0.375632\n",
      "[900]\ttraining's binary_logloss: 0.267045\tvalid_1's binary_logloss: 0.374904\n",
      "[1000]\ttraining's binary_logloss: 0.254546\tvalid_1's binary_logloss: 0.37277\n",
      "[1100]\ttraining's binary_logloss: 0.242942\tvalid_1's binary_logloss: 0.372153\n",
      "[1200]\ttraining's binary_logloss: 0.231424\tvalid_1's binary_logloss: 0.374227\n",
      "[1300]\ttraining's binary_logloss: 0.220939\tvalid_1's binary_logloss: 0.375613\n",
      "[1400]\ttraining's binary_logloss: 0.211329\tvalid_1's binary_logloss: 0.377424\n",
      "[1500]\ttraining's binary_logloss: 0.202066\tvalid_1's binary_logloss: 0.378829\n",
      "[1600]\ttraining's binary_logloss: 0.193317\tvalid_1's binary_logloss: 0.379931\n",
      "[1700]\ttraining's binary_logloss: 0.185\tvalid_1's binary_logloss: 0.381917\n",
      "[1800]\ttraining's binary_logloss: 0.177432\tvalid_1's binary_logloss: 0.383454\n",
      "[1900]\ttraining's binary_logloss: 0.170168\tvalid_1's binary_logloss: 0.38613\n",
      "[2000]\ttraining's binary_logloss: 0.163186\tvalid_1's binary_logloss: 0.387726\n",
      "[2100]\ttraining's binary_logloss: 0.156751\tvalid_1's binary_logloss: 0.39108\n",
      "[2200]\ttraining's binary_logloss: 0.150822\tvalid_1's binary_logloss: 0.394201\n",
      "[2300]\ttraining's binary_logloss: 0.145051\tvalid_1's binary_logloss: 0.397381\n",
      "[2400]\ttraining's binary_logloss: 0.139212\tvalid_1's binary_logloss: 0.400304\n",
      "[2500]\ttraining's binary_logloss: 0.133871\tvalid_1's binary_logloss: 0.404038\n",
      "[2600]\ttraining's binary_logloss: 0.128806\tvalid_1's binary_logloss: 0.408005\n",
      "[2700]\ttraining's binary_logloss: 0.123777\tvalid_1's binary_logloss: 0.409688\n",
      "[2800]\ttraining's binary_logloss: 0.118944\tvalid_1's binary_logloss: 0.410787\n",
      "[2900]\ttraining's binary_logloss: 0.114424\tvalid_1's binary_logloss: 0.411524\n",
      "[3000]\ttraining's binary_logloss: 0.110064\tvalid_1's binary_logloss: 0.412231\n",
      "[3100]\ttraining's binary_logloss: 0.106018\tvalid_1's binary_logloss: 0.413983\n",
      "[3200]\ttraining's binary_logloss: 0.102122\tvalid_1's binary_logloss: 0.416922\n",
      "[3300]\ttraining's binary_logloss: 0.098301\tvalid_1's binary_logloss: 0.419291\n",
      "[3400]\ttraining's binary_logloss: 0.0946849\tvalid_1's binary_logloss: 0.423835\n",
      "[3500]\ttraining's binary_logloss: 0.0911475\tvalid_1's binary_logloss: 0.427682\n",
      "[3600]\ttraining's binary_logloss: 0.0878085\tvalid_1's binary_logloss: 0.430953\n",
      "[3700]\ttraining's binary_logloss: 0.0846108\tvalid_1's binary_logloss: 0.433879\n",
      "[3800]\ttraining's binary_logloss: 0.0815005\tvalid_1's binary_logloss: 0.43633\n",
      "[3900]\ttraining's binary_logloss: 0.0785155\tvalid_1's binary_logloss: 0.439659\n",
      "[4000]\ttraining's binary_logloss: 0.0756991\tvalid_1's binary_logloss: 0.441381\n",
      "[4100]\ttraining's binary_logloss: 0.0730795\tvalid_1's binary_logloss: 0.44361\n",
      "[4200]\ttraining's binary_logloss: 0.0705581\tvalid_1's binary_logloss: 0.445482\n",
      "[4300]\ttraining's binary_logloss: 0.0680622\tvalid_1's binary_logloss: 0.446788\n",
      "[4400]\ttraining's binary_logloss: 0.0656703\tvalid_1's binary_logloss: 0.448533\n",
      "[4500]\ttraining's binary_logloss: 0.0633806\tvalid_1's binary_logloss: 0.451458\n",
      "[4600]\ttraining's binary_logloss: 0.0611404\tvalid_1's binary_logloss: 0.454736\n",
      "[4700]\ttraining's binary_logloss: 0.0589495\tvalid_1's binary_logloss: 0.457747\n",
      "[4800]\ttraining's binary_logloss: 0.0568939\tvalid_1's binary_logloss: 0.461163\n",
      "[4900]\ttraining's binary_logloss: 0.0549723\tvalid_1's binary_logloss: 0.464822\n",
      "[5000]\ttraining's binary_logloss: 0.0530444\tvalid_1's binary_logloss: 0.466911\n",
      "Partial score of fold 2 is: 0.4669114262800087\n",
      "[100]\ttraining's binary_logloss: 0.530339\tvalid_1's binary_logloss: 0.553748\n",
      "[200]\ttraining's binary_logloss: 0.448659\tvalid_1's binary_logloss: 0.49148\n",
      "[300]\ttraining's binary_logloss: 0.400933\tvalid_1's binary_logloss: 0.458645\n",
      "[400]\ttraining's binary_logloss: 0.366942\tvalid_1's binary_logloss: 0.434217\n",
      "[500]\ttraining's binary_logloss: 0.341418\tvalid_1's binary_logloss: 0.41699\n",
      "[600]\ttraining's binary_logloss: 0.319602\tvalid_1's binary_logloss: 0.405681\n",
      "[700]\ttraining's binary_logloss: 0.302145\tvalid_1's binary_logloss: 0.396424\n",
      "[800]\ttraining's binary_logloss: 0.285723\tvalid_1's binary_logloss: 0.38785\n",
      "[900]\ttraining's binary_logloss: 0.270712\tvalid_1's binary_logloss: 0.378617\n",
      "[1000]\ttraining's binary_logloss: 0.256994\tvalid_1's binary_logloss: 0.371381\n",
      "[1100]\ttraining's binary_logloss: 0.244546\tvalid_1's binary_logloss: 0.367102\n",
      "[1200]\ttraining's binary_logloss: 0.232735\tvalid_1's binary_logloss: 0.364709\n",
      "[1300]\ttraining's binary_logloss: 0.221547\tvalid_1's binary_logloss: 0.364609\n",
      "[1400]\ttraining's binary_logloss: 0.211528\tvalid_1's binary_logloss: 0.361082\n",
      "[1500]\ttraining's binary_logloss: 0.202474\tvalid_1's binary_logloss: 0.359661\n",
      "[1600]\ttraining's binary_logloss: 0.193828\tvalid_1's binary_logloss: 0.358836\n",
      "[1700]\ttraining's binary_logloss: 0.18594\tvalid_1's binary_logloss: 0.357816\n",
      "[1800]\ttraining's binary_logloss: 0.178084\tvalid_1's binary_logloss: 0.357598\n",
      "[1900]\ttraining's binary_logloss: 0.170703\tvalid_1's binary_logloss: 0.356676\n",
      "[2000]\ttraining's binary_logloss: 0.163761\tvalid_1's binary_logloss: 0.355811\n",
      "[2100]\ttraining's binary_logloss: 0.15727\tvalid_1's binary_logloss: 0.354328\n",
      "[2200]\ttraining's binary_logloss: 0.151053\tvalid_1's binary_logloss: 0.35311\n",
      "[2300]\ttraining's binary_logloss: 0.145158\tvalid_1's binary_logloss: 0.351953\n",
      "[2400]\ttraining's binary_logloss: 0.139519\tvalid_1's binary_logloss: 0.351956\n",
      "[2500]\ttraining's binary_logloss: 0.133985\tvalid_1's binary_logloss: 0.351625\n",
      "[2600]\ttraining's binary_logloss: 0.128939\tvalid_1's binary_logloss: 0.352851\n",
      "[2700]\ttraining's binary_logloss: 0.124421\tvalid_1's binary_logloss: 0.353913\n",
      "[2800]\ttraining's binary_logloss: 0.119941\tvalid_1's binary_logloss: 0.3543\n",
      "[2900]\ttraining's binary_logloss: 0.115704\tvalid_1's binary_logloss: 0.355869\n",
      "[3000]\ttraining's binary_logloss: 0.111641\tvalid_1's binary_logloss: 0.356307\n",
      "[3100]\ttraining's binary_logloss: 0.107663\tvalid_1's binary_logloss: 0.357082\n",
      "[3200]\ttraining's binary_logloss: 0.103931\tvalid_1's binary_logloss: 0.356326\n",
      "[3300]\ttraining's binary_logloss: 0.100212\tvalid_1's binary_logloss: 0.356747\n",
      "[3400]\ttraining's binary_logloss: 0.0966412\tvalid_1's binary_logloss: 0.357642\n",
      "[3500]\ttraining's binary_logloss: 0.0931266\tvalid_1's binary_logloss: 0.358141\n",
      "[3600]\ttraining's binary_logloss: 0.0898515\tvalid_1's binary_logloss: 0.360204\n",
      "[3700]\ttraining's binary_logloss: 0.0866503\tvalid_1's binary_logloss: 0.361612\n",
      "[3800]\ttraining's binary_logloss: 0.0835909\tvalid_1's binary_logloss: 0.363981\n",
      "[3900]\ttraining's binary_logloss: 0.0805405\tvalid_1's binary_logloss: 0.36614\n",
      "[4000]\ttraining's binary_logloss: 0.0777963\tvalid_1's binary_logloss: 0.367623\n",
      "[4100]\ttraining's binary_logloss: 0.0751431\tvalid_1's binary_logloss: 0.367707\n",
      "[4200]\ttraining's binary_logloss: 0.0726022\tvalid_1's binary_logloss: 0.368909\n",
      "[4300]\ttraining's binary_logloss: 0.0700562\tvalid_1's binary_logloss: 0.369212\n",
      "[4400]\ttraining's binary_logloss: 0.0676707\tvalid_1's binary_logloss: 0.369494\n",
      "[4500]\ttraining's binary_logloss: 0.065345\tvalid_1's binary_logloss: 0.370199\n",
      "[4600]\ttraining's binary_logloss: 0.0630438\tvalid_1's binary_logloss: 0.371331\n",
      "[4700]\ttraining's binary_logloss: 0.061033\tvalid_1's binary_logloss: 0.372265\n",
      "[4800]\ttraining's binary_logloss: 0.0590266\tvalid_1's binary_logloss: 0.373438\n",
      "[4900]\ttraining's binary_logloss: 0.0571166\tvalid_1's binary_logloss: 0.374169\n",
      "[5000]\ttraining's binary_logloss: 0.0552094\tvalid_1's binary_logloss: 0.374913\n",
      "Partial score of fold 3 is: 0.3749130315526168\n",
      "[100]\ttraining's binary_logloss: 0.531849\tvalid_1's binary_logloss: 0.550082\n",
      "[200]\ttraining's binary_logloss: 0.449828\tvalid_1's binary_logloss: 0.482729\n",
      "[300]\ttraining's binary_logloss: 0.399152\tvalid_1's binary_logloss: 0.4479\n",
      "[400]\ttraining's binary_logloss: 0.365826\tvalid_1's binary_logloss: 0.429751\n",
      "[500]\ttraining's binary_logloss: 0.339025\tvalid_1's binary_logloss: 0.417744\n",
      "[600]\ttraining's binary_logloss: 0.317371\tvalid_1's binary_logloss: 0.407631\n",
      "[700]\ttraining's binary_logloss: 0.299591\tvalid_1's binary_logloss: 0.401681\n",
      "[800]\ttraining's binary_logloss: 0.284032\tvalid_1's binary_logloss: 0.397361\n",
      "[900]\ttraining's binary_logloss: 0.26989\tvalid_1's binary_logloss: 0.393892\n",
      "[1000]\ttraining's binary_logloss: 0.255998\tvalid_1's binary_logloss: 0.392542\n",
      "[1100]\ttraining's binary_logloss: 0.243475\tvalid_1's binary_logloss: 0.390296\n",
      "[1200]\ttraining's binary_logloss: 0.231923\tvalid_1's binary_logloss: 0.38798\n",
      "[1300]\ttraining's binary_logloss: 0.221225\tvalid_1's binary_logloss: 0.38668\n",
      "[1400]\ttraining's binary_logloss: 0.211457\tvalid_1's binary_logloss: 0.388219\n",
      "[1500]\ttraining's binary_logloss: 0.2017\tvalid_1's binary_logloss: 0.389345\n",
      "[1600]\ttraining's binary_logloss: 0.192692\tvalid_1's binary_logloss: 0.389093\n",
      "[1700]\ttraining's binary_logloss: 0.184594\tvalid_1's binary_logloss: 0.391342\n",
      "[1800]\ttraining's binary_logloss: 0.176508\tvalid_1's binary_logloss: 0.392765\n",
      "[1900]\ttraining's binary_logloss: 0.169362\tvalid_1's binary_logloss: 0.393132\n",
      "[2000]\ttraining's binary_logloss: 0.162558\tvalid_1's binary_logloss: 0.393284\n",
      "[2100]\ttraining's binary_logloss: 0.156237\tvalid_1's binary_logloss: 0.392896\n",
      "[2200]\ttraining's binary_logloss: 0.1503\tvalid_1's binary_logloss: 0.393591\n",
      "[2300]\ttraining's binary_logloss: 0.144782\tvalid_1's binary_logloss: 0.395223\n",
      "[2400]\ttraining's binary_logloss: 0.139409\tvalid_1's binary_logloss: 0.396132\n",
      "[2500]\ttraining's binary_logloss: 0.134112\tvalid_1's binary_logloss: 0.39762\n",
      "[2600]\ttraining's binary_logloss: 0.129217\tvalid_1's binary_logloss: 0.398134\n",
      "[2700]\ttraining's binary_logloss: 0.124422\tvalid_1's binary_logloss: 0.399134\n",
      "[2800]\ttraining's binary_logloss: 0.119965\tvalid_1's binary_logloss: 0.401842\n",
      "[2900]\ttraining's binary_logloss: 0.115674\tvalid_1's binary_logloss: 0.401899\n",
      "[3000]\ttraining's binary_logloss: 0.111291\tvalid_1's binary_logloss: 0.402705\n",
      "[3100]\ttraining's binary_logloss: 0.107197\tvalid_1's binary_logloss: 0.403435\n",
      "[3200]\ttraining's binary_logloss: 0.103343\tvalid_1's binary_logloss: 0.404545\n",
      "[3300]\ttraining's binary_logloss: 0.0997674\tvalid_1's binary_logloss: 0.405495\n",
      "[3400]\ttraining's binary_logloss: 0.0960366\tvalid_1's binary_logloss: 0.40555\n",
      "[3500]\ttraining's binary_logloss: 0.0923571\tvalid_1's binary_logloss: 0.407095\n",
      "[3600]\ttraining's binary_logloss: 0.0891491\tvalid_1's binary_logloss: 0.409468\n",
      "[3700]\ttraining's binary_logloss: 0.0860678\tvalid_1's binary_logloss: 0.411096\n",
      "[3800]\ttraining's binary_logloss: 0.0830656\tvalid_1's binary_logloss: 0.413375\n",
      "[3900]\ttraining's binary_logloss: 0.0800522\tvalid_1's binary_logloss: 0.413904\n",
      "[4000]\ttraining's binary_logloss: 0.0773099\tvalid_1's binary_logloss: 0.414483\n",
      "[4100]\ttraining's binary_logloss: 0.0746413\tvalid_1's binary_logloss: 0.416109\n",
      "[4200]\ttraining's binary_logloss: 0.0721297\tvalid_1's binary_logloss: 0.419\n",
      "[4300]\ttraining's binary_logloss: 0.0695128\tvalid_1's binary_logloss: 0.421965\n",
      "[4400]\ttraining's binary_logloss: 0.0670148\tvalid_1's binary_logloss: 0.423925\n",
      "[4500]\ttraining's binary_logloss: 0.0646905\tvalid_1's binary_logloss: 0.426319\n",
      "[4600]\ttraining's binary_logloss: 0.0625563\tvalid_1's binary_logloss: 0.428057\n",
      "[4700]\ttraining's binary_logloss: 0.0604598\tvalid_1's binary_logloss: 0.430445\n",
      "[4800]\ttraining's binary_logloss: 0.0583859\tvalid_1's binary_logloss: 0.43307\n",
      "[4900]\ttraining's binary_logloss: 0.0563721\tvalid_1's binary_logloss: 0.43643\n",
      "[5000]\ttraining's binary_logloss: 0.0544104\tvalid_1's binary_logloss: 0.438547\n",
      "Partial score of fold 4 is: 0.43854712723920247\n",
      "[100]\ttraining's binary_logloss: 0.532588\tvalid_1's binary_logloss: 0.534048\n",
      "[200]\ttraining's binary_logloss: 0.452374\tvalid_1's binary_logloss: 0.456811\n",
      "[300]\ttraining's binary_logloss: 0.402236\tvalid_1's binary_logloss: 0.42301\n",
      "[400]\ttraining's binary_logloss: 0.368285\tvalid_1's binary_logloss: 0.405891\n",
      "[500]\ttraining's binary_logloss: 0.341504\tvalid_1's binary_logloss: 0.397957\n",
      "[600]\ttraining's binary_logloss: 0.320316\tvalid_1's binary_logloss: 0.390374\n",
      "[700]\ttraining's binary_logloss: 0.301975\tvalid_1's binary_logloss: 0.379555\n",
      "[800]\ttraining's binary_logloss: 0.286693\tvalid_1's binary_logloss: 0.373965\n",
      "[900]\ttraining's binary_logloss: 0.272933\tvalid_1's binary_logloss: 0.369429\n",
      "[1000]\ttraining's binary_logloss: 0.260079\tvalid_1's binary_logloss: 0.365133\n",
      "[1100]\ttraining's binary_logloss: 0.248245\tvalid_1's binary_logloss: 0.363348\n",
      "[1200]\ttraining's binary_logloss: 0.236459\tvalid_1's binary_logloss: 0.360535\n",
      "[1300]\ttraining's binary_logloss: 0.225384\tvalid_1's binary_logloss: 0.358476\n",
      "[1400]\ttraining's binary_logloss: 0.214742\tvalid_1's binary_logloss: 0.35546\n",
      "[1500]\ttraining's binary_logloss: 0.205471\tvalid_1's binary_logloss: 0.351514\n",
      "[1600]\ttraining's binary_logloss: 0.196235\tvalid_1's binary_logloss: 0.350344\n",
      "[1700]\ttraining's binary_logloss: 0.187647\tvalid_1's binary_logloss: 0.351338\n",
      "[1800]\ttraining's binary_logloss: 0.18005\tvalid_1's binary_logloss: 0.351857\n",
      "[1900]\ttraining's binary_logloss: 0.172957\tvalid_1's binary_logloss: 0.352961\n",
      "[2000]\ttraining's binary_logloss: 0.165928\tvalid_1's binary_logloss: 0.354624\n",
      "[2100]\ttraining's binary_logloss: 0.159485\tvalid_1's binary_logloss: 0.356136\n",
      "[2200]\ttraining's binary_logloss: 0.153445\tvalid_1's binary_logloss: 0.357731\n",
      "[2300]\ttraining's binary_logloss: 0.147706\tvalid_1's binary_logloss: 0.357887\n",
      "[2400]\ttraining's binary_logloss: 0.142493\tvalid_1's binary_logloss: 0.359893\n",
      "[2500]\ttraining's binary_logloss: 0.137298\tvalid_1's binary_logloss: 0.360033\n",
      "[2600]\ttraining's binary_logloss: 0.132122\tvalid_1's binary_logloss: 0.36035\n",
      "[2700]\ttraining's binary_logloss: 0.127156\tvalid_1's binary_logloss: 0.360518\n",
      "[2800]\ttraining's binary_logloss: 0.122329\tvalid_1's binary_logloss: 0.360384\n",
      "[2900]\ttraining's binary_logloss: 0.117627\tvalid_1's binary_logloss: 0.361058\n",
      "[3000]\ttraining's binary_logloss: 0.113201\tvalid_1's binary_logloss: 0.363087\n",
      "[3100]\ttraining's binary_logloss: 0.109092\tvalid_1's binary_logloss: 0.363664\n",
      "[3200]\ttraining's binary_logloss: 0.104992\tvalid_1's binary_logloss: 0.364417\n",
      "[3300]\ttraining's binary_logloss: 0.101152\tvalid_1's binary_logloss: 0.364964\n",
      "[3400]\ttraining's binary_logloss: 0.0973598\tvalid_1's binary_logloss: 0.36518\n",
      "[3500]\ttraining's binary_logloss: 0.0937864\tvalid_1's binary_logloss: 0.366352\n",
      "[3600]\ttraining's binary_logloss: 0.0905643\tvalid_1's binary_logloss: 0.368333\n",
      "[3700]\ttraining's binary_logloss: 0.0874501\tvalid_1's binary_logloss: 0.370055\n",
      "[3800]\ttraining's binary_logloss: 0.0843283\tvalid_1's binary_logloss: 0.370905\n",
      "[3900]\ttraining's binary_logloss: 0.0813434\tvalid_1's binary_logloss: 0.371729\n",
      "[4000]\ttraining's binary_logloss: 0.0784878\tvalid_1's binary_logloss: 0.372149\n",
      "[4100]\ttraining's binary_logloss: 0.0758203\tvalid_1's binary_logloss: 0.372932\n",
      "[4200]\ttraining's binary_logloss: 0.0732579\tvalid_1's binary_logloss: 0.373177\n",
      "[4300]\ttraining's binary_logloss: 0.0707561\tvalid_1's binary_logloss: 0.375312\n",
      "[4400]\ttraining's binary_logloss: 0.0682709\tvalid_1's binary_logloss: 0.376718\n",
      "[4500]\ttraining's binary_logloss: 0.065953\tvalid_1's binary_logloss: 0.378116\n",
      "[4600]\ttraining's binary_logloss: 0.0637173\tvalid_1's binary_logloss: 0.379864\n",
      "[4700]\ttraining's binary_logloss: 0.0614563\tvalid_1's binary_logloss: 0.38076\n",
      "[4800]\ttraining's binary_logloss: 0.0593741\tvalid_1's binary_logloss: 0.382262\n",
      "[4900]\ttraining's binary_logloss: 0.0573591\tvalid_1's binary_logloss: 0.384497\n",
      "[5000]\ttraining's binary_logloss: 0.0553968\tvalid_1's binary_logloss: 0.38549\n",
      "Partial score of fold 5 is: 0.3854899568410011\n",
      "[100]\ttraining's binary_logloss: 0.5347\tvalid_1's binary_logloss: 0.536485\n",
      "[200]\ttraining's binary_logloss: 0.453619\tvalid_1's binary_logloss: 0.461381\n",
      "[300]\ttraining's binary_logloss: 0.404354\tvalid_1's binary_logloss: 0.421988\n",
      "[400]\ttraining's binary_logloss: 0.370286\tvalid_1's binary_logloss: 0.396161\n",
      "[500]\ttraining's binary_logloss: 0.34348\tvalid_1's binary_logloss: 0.381804\n",
      "[600]\ttraining's binary_logloss: 0.320743\tvalid_1's binary_logloss: 0.371939\n",
      "[700]\ttraining's binary_logloss: 0.302657\tvalid_1's binary_logloss: 0.364962\n",
      "[800]\ttraining's binary_logloss: 0.286045\tvalid_1's binary_logloss: 0.360106\n",
      "[900]\ttraining's binary_logloss: 0.270984\tvalid_1's binary_logloss: 0.35881\n",
      "[1000]\ttraining's binary_logloss: 0.257451\tvalid_1's binary_logloss: 0.356615\n",
      "[1100]\ttraining's binary_logloss: 0.245376\tvalid_1's binary_logloss: 0.357489\n",
      "[1200]\ttraining's binary_logloss: 0.23371\tvalid_1's binary_logloss: 0.356755\n",
      "[1300]\ttraining's binary_logloss: 0.223497\tvalid_1's binary_logloss: 0.357551\n",
      "[1400]\ttraining's binary_logloss: 0.214069\tvalid_1's binary_logloss: 0.358862\n",
      "[1500]\ttraining's binary_logloss: 0.204971\tvalid_1's binary_logloss: 0.360638\n",
      "[1600]\ttraining's binary_logloss: 0.196076\tvalid_1's binary_logloss: 0.363331\n",
      "[1700]\ttraining's binary_logloss: 0.188116\tvalid_1's binary_logloss: 0.367269\n",
      "[1800]\ttraining's binary_logloss: 0.180562\tvalid_1's binary_logloss: 0.369566\n",
      "[1900]\ttraining's binary_logloss: 0.173301\tvalid_1's binary_logloss: 0.370771\n",
      "[2000]\ttraining's binary_logloss: 0.166088\tvalid_1's binary_logloss: 0.370802\n",
      "[2100]\ttraining's binary_logloss: 0.159243\tvalid_1's binary_logloss: 0.371432\n",
      "[2200]\ttraining's binary_logloss: 0.153021\tvalid_1's binary_logloss: 0.371523\n",
      "[2300]\ttraining's binary_logloss: 0.146711\tvalid_1's binary_logloss: 0.370053\n",
      "[2400]\ttraining's binary_logloss: 0.141006\tvalid_1's binary_logloss: 0.371437\n",
      "[2500]\ttraining's binary_logloss: 0.135639\tvalid_1's binary_logloss: 0.373204\n",
      "[2600]\ttraining's binary_logloss: 0.130412\tvalid_1's binary_logloss: 0.374141\n",
      "[2700]\ttraining's binary_logloss: 0.125349\tvalid_1's binary_logloss: 0.375698\n",
      "[2800]\ttraining's binary_logloss: 0.120517\tvalid_1's binary_logloss: 0.377281\n",
      "[2900]\ttraining's binary_logloss: 0.116107\tvalid_1's binary_logloss: 0.379835\n",
      "[3000]\ttraining's binary_logloss: 0.111725\tvalid_1's binary_logloss: 0.381851\n",
      "[3100]\ttraining's binary_logloss: 0.107706\tvalid_1's binary_logloss: 0.384981\n",
      "[3200]\ttraining's binary_logloss: 0.103985\tvalid_1's binary_logloss: 0.388206\n",
      "[3300]\ttraining's binary_logloss: 0.100488\tvalid_1's binary_logloss: 0.391073\n",
      "[3400]\ttraining's binary_logloss: 0.0969662\tvalid_1's binary_logloss: 0.392853\n",
      "[3500]\ttraining's binary_logloss: 0.0934728\tvalid_1's binary_logloss: 0.393716\n",
      "[3600]\ttraining's binary_logloss: 0.089933\tvalid_1's binary_logloss: 0.393996\n",
      "[3700]\ttraining's binary_logloss: 0.0865769\tvalid_1's binary_logloss: 0.395726\n",
      "[3800]\ttraining's binary_logloss: 0.0834073\tvalid_1's binary_logloss: 0.39625\n",
      "[3900]\ttraining's binary_logloss: 0.0804486\tvalid_1's binary_logloss: 0.397371\n",
      "[4000]\ttraining's binary_logloss: 0.0777172\tvalid_1's binary_logloss: 0.399326\n",
      "[4100]\ttraining's binary_logloss: 0.0749558\tvalid_1's binary_logloss: 0.400044\n",
      "[4200]\ttraining's binary_logloss: 0.0723781\tvalid_1's binary_logloss: 0.40201\n",
      "[4300]\ttraining's binary_logloss: 0.0699742\tvalid_1's binary_logloss: 0.404\n",
      "[4400]\ttraining's binary_logloss: 0.0675571\tvalid_1's binary_logloss: 0.404759\n",
      "[4500]\ttraining's binary_logloss: 0.0652911\tvalid_1's binary_logloss: 0.407322\n",
      "[4600]\ttraining's binary_logloss: 0.0629647\tvalid_1's binary_logloss: 0.409291\n",
      "[4700]\ttraining's binary_logloss: 0.0607286\tvalid_1's binary_logloss: 0.412673\n",
      "[4800]\ttraining's binary_logloss: 0.0586216\tvalid_1's binary_logloss: 0.415621\n",
      "[4900]\ttraining's binary_logloss: 0.0565263\tvalid_1's binary_logloss: 0.418111\n",
      "[5000]\ttraining's binary_logloss: 0.0544316\tvalid_1's binary_logloss: 0.420363\n",
      "Partial score of fold 6 is: 0.42036347918929345\n",
      "[100]\ttraining's binary_logloss: 0.533767\tvalid_1's binary_logloss: 0.543378\n",
      "[200]\ttraining's binary_logloss: 0.450954\tvalid_1's binary_logloss: 0.476249\n",
      "[300]\ttraining's binary_logloss: 0.401369\tvalid_1's binary_logloss: 0.440251\n",
      "[400]\ttraining's binary_logloss: 0.367544\tvalid_1's binary_logloss: 0.418552\n",
      "[500]\ttraining's binary_logloss: 0.342053\tvalid_1's binary_logloss: 0.403347\n",
      "[600]\ttraining's binary_logloss: 0.319499\tvalid_1's binary_logloss: 0.389982\n",
      "[700]\ttraining's binary_logloss: 0.300029\tvalid_1's binary_logloss: 0.380374\n",
      "[800]\ttraining's binary_logloss: 0.28348\tvalid_1's binary_logloss: 0.373766\n",
      "[900]\ttraining's binary_logloss: 0.268912\tvalid_1's binary_logloss: 0.36921\n",
      "[1000]\ttraining's binary_logloss: 0.256409\tvalid_1's binary_logloss: 0.368068\n",
      "[1100]\ttraining's binary_logloss: 0.244349\tvalid_1's binary_logloss: 0.36839\n",
      "[1200]\ttraining's binary_logloss: 0.23321\tvalid_1's binary_logloss: 0.367427\n",
      "[1300]\ttraining's binary_logloss: 0.222717\tvalid_1's binary_logloss: 0.367325\n",
      "[1400]\ttraining's binary_logloss: 0.212892\tvalid_1's binary_logloss: 0.367525\n",
      "[1500]\ttraining's binary_logloss: 0.203843\tvalid_1's binary_logloss: 0.367332\n",
      "[1600]\ttraining's binary_logloss: 0.195648\tvalid_1's binary_logloss: 0.366817\n",
      "[1700]\ttraining's binary_logloss: 0.187803\tvalid_1's binary_logloss: 0.366874\n",
      "[1800]\ttraining's binary_logloss: 0.180313\tvalid_1's binary_logloss: 0.368573\n",
      "[1900]\ttraining's binary_logloss: 0.172862\tvalid_1's binary_logloss: 0.368962\n",
      "[2000]\ttraining's binary_logloss: 0.166074\tvalid_1's binary_logloss: 0.370281\n",
      "[2100]\ttraining's binary_logloss: 0.159751\tvalid_1's binary_logloss: 0.370647\n",
      "[2200]\ttraining's binary_logloss: 0.153758\tvalid_1's binary_logloss: 0.373338\n",
      "[2300]\ttraining's binary_logloss: 0.147974\tvalid_1's binary_logloss: 0.373213\n",
      "[2400]\ttraining's binary_logloss: 0.142345\tvalid_1's binary_logloss: 0.374311\n",
      "[2500]\ttraining's binary_logloss: 0.136855\tvalid_1's binary_logloss: 0.3762\n",
      "[2600]\ttraining's binary_logloss: 0.131984\tvalid_1's binary_logloss: 0.376679\n",
      "[2700]\ttraining's binary_logloss: 0.127225\tvalid_1's binary_logloss: 0.377578\n",
      "[2800]\ttraining's binary_logloss: 0.122559\tvalid_1's binary_logloss: 0.379271\n",
      "[2900]\ttraining's binary_logloss: 0.118265\tvalid_1's binary_logloss: 0.379827\n",
      "[3000]\ttraining's binary_logloss: 0.114127\tvalid_1's binary_logloss: 0.38073\n",
      "[3100]\ttraining's binary_logloss: 0.110005\tvalid_1's binary_logloss: 0.381921\n",
      "[3200]\ttraining's binary_logloss: 0.105983\tvalid_1's binary_logloss: 0.384052\n",
      "[3300]\ttraining's binary_logloss: 0.102164\tvalid_1's binary_logloss: 0.385588\n",
      "[3400]\ttraining's binary_logloss: 0.0986562\tvalid_1's binary_logloss: 0.389416\n",
      "[3500]\ttraining's binary_logloss: 0.0950526\tvalid_1's binary_logloss: 0.392028\n",
      "[3600]\ttraining's binary_logloss: 0.0917956\tvalid_1's binary_logloss: 0.395502\n",
      "[3700]\ttraining's binary_logloss: 0.0884645\tvalid_1's binary_logloss: 0.397456\n",
      "[3800]\ttraining's binary_logloss: 0.08548\tvalid_1's binary_logloss: 0.399819\n",
      "[3900]\ttraining's binary_logloss: 0.0825553\tvalid_1's binary_logloss: 0.401422\n",
      "[4000]\ttraining's binary_logloss: 0.0796702\tvalid_1's binary_logloss: 0.403309\n",
      "[4100]\ttraining's binary_logloss: 0.0769473\tvalid_1's binary_logloss: 0.405176\n",
      "[4200]\ttraining's binary_logloss: 0.0742506\tvalid_1's binary_logloss: 0.408859\n",
      "[4300]\ttraining's binary_logloss: 0.0716519\tvalid_1's binary_logloss: 0.412968\n",
      "[4400]\ttraining's binary_logloss: 0.0691966\tvalid_1's binary_logloss: 0.416594\n",
      "[4500]\ttraining's binary_logloss: 0.0668321\tvalid_1's binary_logloss: 0.420347\n",
      "[4600]\ttraining's binary_logloss: 0.0645598\tvalid_1's binary_logloss: 0.422711\n",
      "[4700]\ttraining's binary_logloss: 0.0624367\tvalid_1's binary_logloss: 0.424542\n",
      "[4800]\ttraining's binary_logloss: 0.0603166\tvalid_1's binary_logloss: 0.427833\n",
      "[4900]\ttraining's binary_logloss: 0.0582128\tvalid_1's binary_logloss: 0.430149\n",
      "[5000]\ttraining's binary_logloss: 0.0563161\tvalid_1's binary_logloss: 0.432922\n",
      "Partial score of fold 7 is: 0.43292207274541106\n",
      "[100]\ttraining's binary_logloss: 0.531263\tvalid_1's binary_logloss: 0.544641\n",
      "[200]\ttraining's binary_logloss: 0.451043\tvalid_1's binary_logloss: 0.471718\n",
      "[300]\ttraining's binary_logloss: 0.403379\tvalid_1's binary_logloss: 0.434293\n",
      "[400]\ttraining's binary_logloss: 0.369514\tvalid_1's binary_logloss: 0.409237\n",
      "[500]\ttraining's binary_logloss: 0.343338\tvalid_1's binary_logloss: 0.393951\n",
      "[600]\ttraining's binary_logloss: 0.322007\tvalid_1's binary_logloss: 0.382626\n",
      "[700]\ttraining's binary_logloss: 0.302415\tvalid_1's binary_logloss: 0.371617\n",
      "[800]\ttraining's binary_logloss: 0.2864\tvalid_1's binary_logloss: 0.36683\n",
      "[900]\ttraining's binary_logloss: 0.272439\tvalid_1's binary_logloss: 0.361472\n",
      "[1000]\ttraining's binary_logloss: 0.258944\tvalid_1's binary_logloss: 0.354875\n",
      "[1100]\ttraining's binary_logloss: 0.246781\tvalid_1's binary_logloss: 0.349828\n",
      "[1200]\ttraining's binary_logloss: 0.235805\tvalid_1's binary_logloss: 0.348423\n",
      "[1300]\ttraining's binary_logloss: 0.225421\tvalid_1's binary_logloss: 0.345466\n",
      "[1400]\ttraining's binary_logloss: 0.215474\tvalid_1's binary_logloss: 0.344175\n",
      "[1500]\ttraining's binary_logloss: 0.206052\tvalid_1's binary_logloss: 0.341828\n",
      "[1600]\ttraining's binary_logloss: 0.197466\tvalid_1's binary_logloss: 0.339447\n",
      "[1700]\ttraining's binary_logloss: 0.189098\tvalid_1's binary_logloss: 0.336896\n",
      "[1800]\ttraining's binary_logloss: 0.181354\tvalid_1's binary_logloss: 0.335606\n",
      "[1900]\ttraining's binary_logloss: 0.174287\tvalid_1's binary_logloss: 0.335265\n",
      "[2000]\ttraining's binary_logloss: 0.167113\tvalid_1's binary_logloss: 0.334653\n",
      "[2100]\ttraining's binary_logloss: 0.159887\tvalid_1's binary_logloss: 0.333142\n",
      "[2200]\ttraining's binary_logloss: 0.153513\tvalid_1's binary_logloss: 0.331999\n",
      "[2300]\ttraining's binary_logloss: 0.147655\tvalid_1's binary_logloss: 0.332509\n",
      "[2400]\ttraining's binary_logloss: 0.141789\tvalid_1's binary_logloss: 0.332648\n",
      "[2500]\ttraining's binary_logloss: 0.136289\tvalid_1's binary_logloss: 0.330801\n",
      "[2600]\ttraining's binary_logloss: 0.131071\tvalid_1's binary_logloss: 0.330838\n",
      "[2700]\ttraining's binary_logloss: 0.126219\tvalid_1's binary_logloss: 0.331441\n",
      "[2800]\ttraining's binary_logloss: 0.12172\tvalid_1's binary_logloss: 0.332448\n",
      "[2900]\ttraining's binary_logloss: 0.117415\tvalid_1's binary_logloss: 0.333611\n",
      "[3000]\ttraining's binary_logloss: 0.113026\tvalid_1's binary_logloss: 0.334439\n",
      "[3100]\ttraining's binary_logloss: 0.108637\tvalid_1's binary_logloss: 0.335859\n",
      "[3200]\ttraining's binary_logloss: 0.104698\tvalid_1's binary_logloss: 0.337625\n",
      "[3300]\ttraining's binary_logloss: 0.101005\tvalid_1's binary_logloss: 0.339516\n",
      "[3400]\ttraining's binary_logloss: 0.0974831\tvalid_1's binary_logloss: 0.340699\n",
      "[3500]\ttraining's binary_logloss: 0.0942375\tvalid_1's binary_logloss: 0.340907\n",
      "[3600]\ttraining's binary_logloss: 0.0909516\tvalid_1's binary_logloss: 0.340244\n",
      "[3700]\ttraining's binary_logloss: 0.0877185\tvalid_1's binary_logloss: 0.340085\n",
      "[3800]\ttraining's binary_logloss: 0.0845922\tvalid_1's binary_logloss: 0.341587\n",
      "[3900]\ttraining's binary_logloss: 0.0816907\tvalid_1's binary_logloss: 0.34212\n",
      "[4000]\ttraining's binary_logloss: 0.0788382\tvalid_1's binary_logloss: 0.341852\n",
      "[4100]\ttraining's binary_logloss: 0.0761296\tvalid_1's binary_logloss: 0.342631\n",
      "[4200]\ttraining's binary_logloss: 0.0735165\tvalid_1's binary_logloss: 0.342361\n",
      "[4300]\ttraining's binary_logloss: 0.0708069\tvalid_1's binary_logloss: 0.343346\n",
      "[4400]\ttraining's binary_logloss: 0.0682346\tvalid_1's binary_logloss: 0.345412\n",
      "[4500]\ttraining's binary_logloss: 0.0659679\tvalid_1's binary_logloss: 0.34604\n",
      "[4600]\ttraining's binary_logloss: 0.0637233\tvalid_1's binary_logloss: 0.346925\n",
      "[4700]\ttraining's binary_logloss: 0.061589\tvalid_1's binary_logloss: 0.34922\n",
      "[4800]\ttraining's binary_logloss: 0.0595435\tvalid_1's binary_logloss: 0.349759\n",
      "[4900]\ttraining's binary_logloss: 0.0575568\tvalid_1's binary_logloss: 0.35058\n",
      "[5000]\ttraining's binary_logloss: 0.0555846\tvalid_1's binary_logloss: 0.351507\n",
      "Partial score of fold 8 is: 0.35150683095565816\n",
      "[100]\ttraining's binary_logloss: 0.531685\tvalid_1's binary_logloss: 0.556849\n",
      "[200]\ttraining's binary_logloss: 0.449269\tvalid_1's binary_logloss: 0.497865\n",
      "[300]\ttraining's binary_logloss: 0.399382\tvalid_1's binary_logloss: 0.46617\n",
      "[400]\ttraining's binary_logloss: 0.36557\tvalid_1's binary_logloss: 0.446582\n",
      "[500]\ttraining's binary_logloss: 0.338168\tvalid_1's binary_logloss: 0.42919\n",
      "[600]\ttraining's binary_logloss: 0.315938\tvalid_1's binary_logloss: 0.422289\n",
      "[700]\ttraining's binary_logloss: 0.296177\tvalid_1's binary_logloss: 0.416125\n",
      "[800]\ttraining's binary_logloss: 0.279601\tvalid_1's binary_logloss: 0.415336\n",
      "[900]\ttraining's binary_logloss: 0.265313\tvalid_1's binary_logloss: 0.41573\n",
      "[1000]\ttraining's binary_logloss: 0.252459\tvalid_1's binary_logloss: 0.416002\n",
      "[1100]\ttraining's binary_logloss: 0.240908\tvalid_1's binary_logloss: 0.416838\n",
      "[1200]\ttraining's binary_logloss: 0.229629\tvalid_1's binary_logloss: 0.418057\n",
      "[1300]\ttraining's binary_logloss: 0.21887\tvalid_1's binary_logloss: 0.419749\n",
      "[1400]\ttraining's binary_logloss: 0.207969\tvalid_1's binary_logloss: 0.419602\n",
      "[1500]\ttraining's binary_logloss: 0.198728\tvalid_1's binary_logloss: 0.421805\n",
      "[1600]\ttraining's binary_logloss: 0.190235\tvalid_1's binary_logloss: 0.42226\n",
      "[1700]\ttraining's binary_logloss: 0.181784\tvalid_1's binary_logloss: 0.423557\n",
      "[1800]\ttraining's binary_logloss: 0.173566\tvalid_1's binary_logloss: 0.427456\n",
      "[1900]\ttraining's binary_logloss: 0.166079\tvalid_1's binary_logloss: 0.429157\n",
      "[2000]\ttraining's binary_logloss: 0.158993\tvalid_1's binary_logloss: 0.430447\n",
      "[2100]\ttraining's binary_logloss: 0.152487\tvalid_1's binary_logloss: 0.432325\n",
      "[2200]\ttraining's binary_logloss: 0.146429\tvalid_1's binary_logloss: 0.433088\n",
      "[2300]\ttraining's binary_logloss: 0.140631\tvalid_1's binary_logloss: 0.435172\n",
      "[2400]\ttraining's binary_logloss: 0.134794\tvalid_1's binary_logloss: 0.437736\n",
      "[2500]\ttraining's binary_logloss: 0.129719\tvalid_1's binary_logloss: 0.440425\n",
      "[2600]\ttraining's binary_logloss: 0.12496\tvalid_1's binary_logloss: 0.444828\n",
      "[2700]\ttraining's binary_logloss: 0.120341\tvalid_1's binary_logloss: 0.448627\n",
      "[2800]\ttraining's binary_logloss: 0.115805\tvalid_1's binary_logloss: 0.452179\n",
      "[2900]\ttraining's binary_logloss: 0.111506\tvalid_1's binary_logloss: 0.456529\n",
      "[3000]\ttraining's binary_logloss: 0.107472\tvalid_1's binary_logloss: 0.46086\n",
      "[3100]\ttraining's binary_logloss: 0.103488\tvalid_1's binary_logloss: 0.465087\n",
      "[3200]\ttraining's binary_logloss: 0.0996713\tvalid_1's binary_logloss: 0.468563\n",
      "[3300]\ttraining's binary_logloss: 0.0960846\tvalid_1's binary_logloss: 0.471781\n",
      "[3400]\ttraining's binary_logloss: 0.0926674\tvalid_1's binary_logloss: 0.474323\n",
      "[3500]\ttraining's binary_logloss: 0.0893472\tvalid_1's binary_logloss: 0.477664\n",
      "[3600]\ttraining's binary_logloss: 0.0862264\tvalid_1's binary_logloss: 0.480175\n",
      "[3700]\ttraining's binary_logloss: 0.0831486\tvalid_1's binary_logloss: 0.482611\n",
      "[3800]\ttraining's binary_logloss: 0.0800907\tvalid_1's binary_logloss: 0.486394\n",
      "[3900]\ttraining's binary_logloss: 0.0771376\tvalid_1's binary_logloss: 0.488936\n",
      "[4000]\ttraining's binary_logloss: 0.074427\tvalid_1's binary_logloss: 0.492705\n",
      "[4100]\ttraining's binary_logloss: 0.0717557\tvalid_1's binary_logloss: 0.495593\n",
      "[4200]\ttraining's binary_logloss: 0.0691871\tvalid_1's binary_logloss: 0.498729\n",
      "[4300]\ttraining's binary_logloss: 0.0667857\tvalid_1's binary_logloss: 0.501902\n",
      "[4400]\ttraining's binary_logloss: 0.0644745\tvalid_1's binary_logloss: 0.505548\n",
      "[4500]\ttraining's binary_logloss: 0.0623121\tvalid_1's binary_logloss: 0.509565\n",
      "[4600]\ttraining's binary_logloss: 0.0602176\tvalid_1's binary_logloss: 0.512493\n",
      "[4700]\ttraining's binary_logloss: 0.0582195\tvalid_1's binary_logloss: 0.515477\n",
      "[4800]\ttraining's binary_logloss: 0.0562323\tvalid_1's binary_logloss: 0.51779\n",
      "[4900]\ttraining's binary_logloss: 0.0542931\tvalid_1's binary_logloss: 0.520555\n",
      "[5000]\ttraining's binary_logloss: 0.0524508\tvalid_1's binary_logloss: 0.524612\n",
      "Partial score of fold 9 is: 0.5246124469835572\n",
      "Our oof loss score is:  0.42437298623183445\n",
      "Predicting 2019...\n",
      "[100]\ttraining's binary_logloss: 0.533879\tvalid_1's binary_logloss: 0.534065\n",
      "[200]\ttraining's binary_logloss: 0.452487\tvalid_1's binary_logloss: 0.46114\n",
      "[300]\ttraining's binary_logloss: 0.403154\tvalid_1's binary_logloss: 0.421739\n",
      "[400]\ttraining's binary_logloss: 0.36762\tvalid_1's binary_logloss: 0.397692\n",
      "[500]\ttraining's binary_logloss: 0.341535\tvalid_1's binary_logloss: 0.385279\n",
      "[600]\ttraining's binary_logloss: 0.318978\tvalid_1's binary_logloss: 0.376851\n",
      "[700]\ttraining's binary_logloss: 0.30085\tvalid_1's binary_logloss: 0.369637\n",
      "[800]\ttraining's binary_logloss: 0.284574\tvalid_1's binary_logloss: 0.367872\n",
      "[900]\ttraining's binary_logloss: 0.269425\tvalid_1's binary_logloss: 0.366573\n",
      "[1000]\ttraining's binary_logloss: 0.255449\tvalid_1's binary_logloss: 0.368907\n",
      "[1100]\ttraining's binary_logloss: 0.242711\tvalid_1's binary_logloss: 0.369007\n",
      "[1200]\ttraining's binary_logloss: 0.231964\tvalid_1's binary_logloss: 0.368506\n",
      "[1300]\ttraining's binary_logloss: 0.221943\tvalid_1's binary_logloss: 0.37021\n",
      "[1400]\ttraining's binary_logloss: 0.211687\tvalid_1's binary_logloss: 0.369412\n",
      "[1500]\ttraining's binary_logloss: 0.202533\tvalid_1's binary_logloss: 0.370966\n",
      "[1600]\ttraining's binary_logloss: 0.193914\tvalid_1's binary_logloss: 0.371372\n",
      "[1700]\ttraining's binary_logloss: 0.185807\tvalid_1's binary_logloss: 0.372936\n",
      "[1800]\ttraining's binary_logloss: 0.178325\tvalid_1's binary_logloss: 0.374704\n",
      "[1900]\ttraining's binary_logloss: 0.171353\tvalid_1's binary_logloss: 0.376542\n",
      "[2000]\ttraining's binary_logloss: 0.164523\tvalid_1's binary_logloss: 0.376931\n",
      "[2100]\ttraining's binary_logloss: 0.157939\tvalid_1's binary_logloss: 0.378364\n",
      "[2200]\ttraining's binary_logloss: 0.151368\tvalid_1's binary_logloss: 0.379831\n",
      "[2300]\ttraining's binary_logloss: 0.145395\tvalid_1's binary_logloss: 0.380688\n",
      "[2400]\ttraining's binary_logloss: 0.139983\tvalid_1's binary_logloss: 0.380542\n",
      "[2500]\ttraining's binary_logloss: 0.134606\tvalid_1's binary_logloss: 0.380424\n",
      "[2600]\ttraining's binary_logloss: 0.129612\tvalid_1's binary_logloss: 0.382421\n",
      "[2700]\ttraining's binary_logloss: 0.124962\tvalid_1's binary_logloss: 0.38418\n",
      "[2800]\ttraining's binary_logloss: 0.12038\tvalid_1's binary_logloss: 0.3852\n",
      "[2900]\ttraining's binary_logloss: 0.116159\tvalid_1's binary_logloss: 0.386413\n",
      "[3000]\ttraining's binary_logloss: 0.111946\tvalid_1's binary_logloss: 0.388673\n",
      "[3100]\ttraining's binary_logloss: 0.108017\tvalid_1's binary_logloss: 0.389113\n",
      "[3200]\ttraining's binary_logloss: 0.10444\tvalid_1's binary_logloss: 0.390926\n",
      "[3300]\ttraining's binary_logloss: 0.100677\tvalid_1's binary_logloss: 0.392834\n",
      "[3400]\ttraining's binary_logloss: 0.0970393\tvalid_1's binary_logloss: 0.394797\n",
      "[3500]\ttraining's binary_logloss: 0.0935917\tvalid_1's binary_logloss: 0.397031\n",
      "[3600]\ttraining's binary_logloss: 0.0904213\tvalid_1's binary_logloss: 0.397639\n",
      "[3700]\ttraining's binary_logloss: 0.0873464\tvalid_1's binary_logloss: 0.397845\n",
      "[3800]\ttraining's binary_logloss: 0.0843028\tvalid_1's binary_logloss: 0.399672\n",
      "[3900]\ttraining's binary_logloss: 0.0812572\tvalid_1's binary_logloss: 0.400708\n",
      "[4000]\ttraining's binary_logloss: 0.0781527\tvalid_1's binary_logloss: 0.40245\n",
      "[4100]\ttraining's binary_logloss: 0.0754306\tvalid_1's binary_logloss: 0.403645\n",
      "[4200]\ttraining's binary_logloss: 0.0727553\tvalid_1's binary_logloss: 0.405596\n",
      "[4300]\ttraining's binary_logloss: 0.0699965\tvalid_1's binary_logloss: 0.407887\n",
      "[4400]\ttraining's binary_logloss: 0.0675656\tvalid_1's binary_logloss: 0.409225\n",
      "[4500]\ttraining's binary_logloss: 0.0652473\tvalid_1's binary_logloss: 0.411902\n",
      "[4600]\ttraining's binary_logloss: 0.0629514\tvalid_1's binary_logloss: 0.413904\n",
      "[4700]\ttraining's binary_logloss: 0.0606707\tvalid_1's binary_logloss: 0.417078\n",
      "[4800]\ttraining's binary_logloss: 0.0584421\tvalid_1's binary_logloss: 0.421263\n",
      "[4900]\ttraining's binary_logloss: 0.0564469\tvalid_1's binary_logloss: 0.424689\n",
      "[5000]\ttraining's binary_logloss: 0.0544951\tvalid_1's binary_logloss: 0.426622\n",
      "Partial score of fold 0 is: 0.42662156595615264\n",
      "[100]\ttraining's binary_logloss: 0.530438\tvalid_1's binary_logloss: 0.558449\n",
      "[200]\ttraining's binary_logloss: 0.447642\tvalid_1's binary_logloss: 0.494672\n",
      "[300]\ttraining's binary_logloss: 0.39838\tvalid_1's binary_logloss: 0.462501\n",
      "[400]\ttraining's binary_logloss: 0.364537\tvalid_1's binary_logloss: 0.441584\n",
      "[500]\ttraining's binary_logloss: 0.338264\tvalid_1's binary_logloss: 0.425405\n",
      "[600]\ttraining's binary_logloss: 0.316262\tvalid_1's binary_logloss: 0.413279\n",
      "[700]\ttraining's binary_logloss: 0.297503\tvalid_1's binary_logloss: 0.401126\n",
      "[800]\ttraining's binary_logloss: 0.281868\tvalid_1's binary_logloss: 0.395245\n",
      "[900]\ttraining's binary_logloss: 0.266963\tvalid_1's binary_logloss: 0.392217\n",
      "[1000]\ttraining's binary_logloss: 0.253438\tvalid_1's binary_logloss: 0.388792\n",
      "[1100]\ttraining's binary_logloss: 0.241799\tvalid_1's binary_logloss: 0.387876\n",
      "[1200]\ttraining's binary_logloss: 0.230304\tvalid_1's binary_logloss: 0.388533\n",
      "[1300]\ttraining's binary_logloss: 0.219818\tvalid_1's binary_logloss: 0.388828\n",
      "[1400]\ttraining's binary_logloss: 0.210796\tvalid_1's binary_logloss: 0.387442\n",
      "[1500]\ttraining's binary_logloss: 0.201804\tvalid_1's binary_logloss: 0.38349\n",
      "[1600]\ttraining's binary_logloss: 0.192676\tvalid_1's binary_logloss: 0.382124\n",
      "[1700]\ttraining's binary_logloss: 0.18439\tvalid_1's binary_logloss: 0.381894\n",
      "[1800]\ttraining's binary_logloss: 0.17671\tvalid_1's binary_logloss: 0.382925\n",
      "[1900]\ttraining's binary_logloss: 0.169522\tvalid_1's binary_logloss: 0.384151\n",
      "[2000]\ttraining's binary_logloss: 0.162754\tvalid_1's binary_logloss: 0.387153\n",
      "[2100]\ttraining's binary_logloss: 0.156364\tvalid_1's binary_logloss: 0.388848\n",
      "[2200]\ttraining's binary_logloss: 0.150222\tvalid_1's binary_logloss: 0.389225\n",
      "[2300]\ttraining's binary_logloss: 0.144416\tvalid_1's binary_logloss: 0.39068\n",
      "[2400]\ttraining's binary_logloss: 0.138904\tvalid_1's binary_logloss: 0.391381\n",
      "[2500]\ttraining's binary_logloss: 0.133795\tvalid_1's binary_logloss: 0.392873\n",
      "[2600]\ttraining's binary_logloss: 0.128855\tvalid_1's binary_logloss: 0.393753\n",
      "[2700]\ttraining's binary_logloss: 0.123958\tvalid_1's binary_logloss: 0.395305\n",
      "[2800]\ttraining's binary_logloss: 0.119385\tvalid_1's binary_logloss: 0.3972\n",
      "[2900]\ttraining's binary_logloss: 0.115016\tvalid_1's binary_logloss: 0.397092\n",
      "[3000]\ttraining's binary_logloss: 0.110934\tvalid_1's binary_logloss: 0.398833\n",
      "[3100]\ttraining's binary_logloss: 0.106994\tvalid_1's binary_logloss: 0.399147\n",
      "[3200]\ttraining's binary_logloss: 0.103212\tvalid_1's binary_logloss: 0.397454\n",
      "[3300]\ttraining's binary_logloss: 0.0995624\tvalid_1's binary_logloss: 0.397103\n",
      "[3400]\ttraining's binary_logloss: 0.0962272\tvalid_1's binary_logloss: 0.398199\n",
      "[3500]\ttraining's binary_logloss: 0.0929324\tvalid_1's binary_logloss: 0.399208\n",
      "[3600]\ttraining's binary_logloss: 0.0895938\tvalid_1's binary_logloss: 0.400215\n",
      "[3700]\ttraining's binary_logloss: 0.0864706\tvalid_1's binary_logloss: 0.401542\n",
      "[3800]\ttraining's binary_logloss: 0.083555\tvalid_1's binary_logloss: 0.403102\n",
      "[3900]\ttraining's binary_logloss: 0.0805301\tvalid_1's binary_logloss: 0.404623\n",
      "[4000]\ttraining's binary_logloss: 0.0776831\tvalid_1's binary_logloss: 0.405612\n",
      "[4100]\ttraining's binary_logloss: 0.075055\tvalid_1's binary_logloss: 0.407654\n",
      "[4200]\ttraining's binary_logloss: 0.0724351\tvalid_1's binary_logloss: 0.409381\n",
      "[4300]\ttraining's binary_logloss: 0.0700671\tvalid_1's binary_logloss: 0.411627\n",
      "[4400]\ttraining's binary_logloss: 0.0677596\tvalid_1's binary_logloss: 0.412996\n",
      "[4500]\ttraining's binary_logloss: 0.0655712\tvalid_1's binary_logloss: 0.414448\n",
      "[4600]\ttraining's binary_logloss: 0.0633367\tvalid_1's binary_logloss: 0.41432\n",
      "[4700]\ttraining's binary_logloss: 0.0611838\tvalid_1's binary_logloss: 0.416275\n",
      "[4800]\ttraining's binary_logloss: 0.0590429\tvalid_1's binary_logloss: 0.4188\n",
      "[4900]\ttraining's binary_logloss: 0.0569747\tvalid_1's binary_logloss: 0.420533\n",
      "[5000]\ttraining's binary_logloss: 0.0550032\tvalid_1's binary_logloss: 0.422815\n",
      "Partial score of fold 1 is: 0.42281512322351805\n",
      "[100]\ttraining's binary_logloss: 0.531659\tvalid_1's binary_logloss: 0.551978\n",
      "[200]\ttraining's binary_logloss: 0.450432\tvalid_1's binary_logloss: 0.481607\n",
      "[300]\ttraining's binary_logloss: 0.401965\tvalid_1's binary_logloss: 0.440426\n",
      "[400]\ttraining's binary_logloss: 0.368132\tvalid_1's binary_logloss: 0.41241\n",
      "[500]\ttraining's binary_logloss: 0.341827\tvalid_1's binary_logloss: 0.396649\n",
      "[600]\ttraining's binary_logloss: 0.319436\tvalid_1's binary_logloss: 0.386696\n",
      "[700]\ttraining's binary_logloss: 0.299313\tvalid_1's binary_logloss: 0.379062\n",
      "[800]\ttraining's binary_logloss: 0.281861\tvalid_1's binary_logloss: 0.375632\n",
      "[900]\ttraining's binary_logloss: 0.267045\tvalid_1's binary_logloss: 0.374904\n",
      "[1000]\ttraining's binary_logloss: 0.254546\tvalid_1's binary_logloss: 0.37277\n",
      "[1100]\ttraining's binary_logloss: 0.242942\tvalid_1's binary_logloss: 0.372153\n",
      "[1200]\ttraining's binary_logloss: 0.231424\tvalid_1's binary_logloss: 0.374227\n",
      "[1300]\ttraining's binary_logloss: 0.220939\tvalid_1's binary_logloss: 0.375613\n",
      "[1400]\ttraining's binary_logloss: 0.211329\tvalid_1's binary_logloss: 0.377424\n",
      "[1500]\ttraining's binary_logloss: 0.202066\tvalid_1's binary_logloss: 0.378829\n",
      "[1600]\ttraining's binary_logloss: 0.193317\tvalid_1's binary_logloss: 0.379931\n",
      "[1700]\ttraining's binary_logloss: 0.185\tvalid_1's binary_logloss: 0.381917\n",
      "[1800]\ttraining's binary_logloss: 0.177432\tvalid_1's binary_logloss: 0.383454\n",
      "[1900]\ttraining's binary_logloss: 0.170168\tvalid_1's binary_logloss: 0.38613\n",
      "[2000]\ttraining's binary_logloss: 0.163186\tvalid_1's binary_logloss: 0.387726\n",
      "[2100]\ttraining's binary_logloss: 0.156751\tvalid_1's binary_logloss: 0.39108\n",
      "[2200]\ttraining's binary_logloss: 0.150822\tvalid_1's binary_logloss: 0.394201\n",
      "[2300]\ttraining's binary_logloss: 0.145051\tvalid_1's binary_logloss: 0.397381\n",
      "[2400]\ttraining's binary_logloss: 0.139212\tvalid_1's binary_logloss: 0.400304\n",
      "[2500]\ttraining's binary_logloss: 0.133871\tvalid_1's binary_logloss: 0.404038\n",
      "[2600]\ttraining's binary_logloss: 0.128806\tvalid_1's binary_logloss: 0.408005\n",
      "[2700]\ttraining's binary_logloss: 0.123777\tvalid_1's binary_logloss: 0.409688\n",
      "[2800]\ttraining's binary_logloss: 0.118944\tvalid_1's binary_logloss: 0.410787\n",
      "[2900]\ttraining's binary_logloss: 0.114424\tvalid_1's binary_logloss: 0.411524\n",
      "[3000]\ttraining's binary_logloss: 0.110064\tvalid_1's binary_logloss: 0.412231\n",
      "[3100]\ttraining's binary_logloss: 0.106018\tvalid_1's binary_logloss: 0.413983\n",
      "[3200]\ttraining's binary_logloss: 0.102122\tvalid_1's binary_logloss: 0.416922\n",
      "[3300]\ttraining's binary_logloss: 0.098301\tvalid_1's binary_logloss: 0.419291\n",
      "[3400]\ttraining's binary_logloss: 0.0946849\tvalid_1's binary_logloss: 0.423835\n",
      "[3500]\ttraining's binary_logloss: 0.0911475\tvalid_1's binary_logloss: 0.427682\n",
      "[3600]\ttraining's binary_logloss: 0.0878085\tvalid_1's binary_logloss: 0.430953\n",
      "[3700]\ttraining's binary_logloss: 0.0846108\tvalid_1's binary_logloss: 0.433879\n",
      "[3800]\ttraining's binary_logloss: 0.0815005\tvalid_1's binary_logloss: 0.43633\n",
      "[3900]\ttraining's binary_logloss: 0.0785155\tvalid_1's binary_logloss: 0.439659\n",
      "[4000]\ttraining's binary_logloss: 0.0756991\tvalid_1's binary_logloss: 0.441381\n",
      "[4100]\ttraining's binary_logloss: 0.0730795\tvalid_1's binary_logloss: 0.44361\n",
      "[4200]\ttraining's binary_logloss: 0.0705581\tvalid_1's binary_logloss: 0.445482\n",
      "[4300]\ttraining's binary_logloss: 0.0680622\tvalid_1's binary_logloss: 0.446788\n",
      "[4400]\ttraining's binary_logloss: 0.0656703\tvalid_1's binary_logloss: 0.448533\n",
      "[4500]\ttraining's binary_logloss: 0.0633806\tvalid_1's binary_logloss: 0.451458\n",
      "[4600]\ttraining's binary_logloss: 0.0611404\tvalid_1's binary_logloss: 0.454736\n",
      "[4700]\ttraining's binary_logloss: 0.0589495\tvalid_1's binary_logloss: 0.457747\n",
      "[4800]\ttraining's binary_logloss: 0.0568939\tvalid_1's binary_logloss: 0.461163\n",
      "[4900]\ttraining's binary_logloss: 0.0549723\tvalid_1's binary_logloss: 0.464822\n",
      "[5000]\ttraining's binary_logloss: 0.0530444\tvalid_1's binary_logloss: 0.466911\n",
      "Partial score of fold 2 is: 0.4669114262800087\n",
      "[100]\ttraining's binary_logloss: 0.530339\tvalid_1's binary_logloss: 0.553748\n",
      "[200]\ttraining's binary_logloss: 0.448659\tvalid_1's binary_logloss: 0.49148\n",
      "[300]\ttraining's binary_logloss: 0.400933\tvalid_1's binary_logloss: 0.458645\n",
      "[400]\ttraining's binary_logloss: 0.366942\tvalid_1's binary_logloss: 0.434217\n",
      "[500]\ttraining's binary_logloss: 0.341418\tvalid_1's binary_logloss: 0.41699\n",
      "[600]\ttraining's binary_logloss: 0.319602\tvalid_1's binary_logloss: 0.405681\n",
      "[700]\ttraining's binary_logloss: 0.302145\tvalid_1's binary_logloss: 0.396424\n",
      "[800]\ttraining's binary_logloss: 0.285723\tvalid_1's binary_logloss: 0.38785\n",
      "[900]\ttraining's binary_logloss: 0.270712\tvalid_1's binary_logloss: 0.378617\n",
      "[1000]\ttraining's binary_logloss: 0.256994\tvalid_1's binary_logloss: 0.371381\n",
      "[1100]\ttraining's binary_logloss: 0.244546\tvalid_1's binary_logloss: 0.367102\n",
      "[1200]\ttraining's binary_logloss: 0.232735\tvalid_1's binary_logloss: 0.364709\n",
      "[1300]\ttraining's binary_logloss: 0.221547\tvalid_1's binary_logloss: 0.364609\n",
      "[1400]\ttraining's binary_logloss: 0.211528\tvalid_1's binary_logloss: 0.361082\n",
      "[1500]\ttraining's binary_logloss: 0.202474\tvalid_1's binary_logloss: 0.359661\n",
      "[1600]\ttraining's binary_logloss: 0.193828\tvalid_1's binary_logloss: 0.358836\n",
      "[1700]\ttraining's binary_logloss: 0.18594\tvalid_1's binary_logloss: 0.357816\n",
      "[1800]\ttraining's binary_logloss: 0.178084\tvalid_1's binary_logloss: 0.357598\n",
      "[1900]\ttraining's binary_logloss: 0.170703\tvalid_1's binary_logloss: 0.356676\n",
      "[2000]\ttraining's binary_logloss: 0.163761\tvalid_1's binary_logloss: 0.355811\n",
      "[2100]\ttraining's binary_logloss: 0.15727\tvalid_1's binary_logloss: 0.354328\n",
      "[2200]\ttraining's binary_logloss: 0.151053\tvalid_1's binary_logloss: 0.35311\n",
      "[2300]\ttraining's binary_logloss: 0.145158\tvalid_1's binary_logloss: 0.351953\n",
      "[2400]\ttraining's binary_logloss: 0.139519\tvalid_1's binary_logloss: 0.351956\n",
      "[2500]\ttraining's binary_logloss: 0.133985\tvalid_1's binary_logloss: 0.351625\n",
      "[2600]\ttraining's binary_logloss: 0.128939\tvalid_1's binary_logloss: 0.352851\n",
      "[2700]\ttraining's binary_logloss: 0.124421\tvalid_1's binary_logloss: 0.353913\n",
      "[2800]\ttraining's binary_logloss: 0.119941\tvalid_1's binary_logloss: 0.3543\n",
      "[2900]\ttraining's binary_logloss: 0.115704\tvalid_1's binary_logloss: 0.355869\n",
      "[3000]\ttraining's binary_logloss: 0.111641\tvalid_1's binary_logloss: 0.356307\n",
      "[3100]\ttraining's binary_logloss: 0.107663\tvalid_1's binary_logloss: 0.357082\n",
      "[3200]\ttraining's binary_logloss: 0.103931\tvalid_1's binary_logloss: 0.356326\n",
      "[3300]\ttraining's binary_logloss: 0.100212\tvalid_1's binary_logloss: 0.356747\n",
      "[3400]\ttraining's binary_logloss: 0.0966412\tvalid_1's binary_logloss: 0.357642\n",
      "[3500]\ttraining's binary_logloss: 0.0931266\tvalid_1's binary_logloss: 0.358141\n",
      "[3600]\ttraining's binary_logloss: 0.0898515\tvalid_1's binary_logloss: 0.360204\n",
      "[3700]\ttraining's binary_logloss: 0.0866503\tvalid_1's binary_logloss: 0.361612\n",
      "[3800]\ttraining's binary_logloss: 0.0835909\tvalid_1's binary_logloss: 0.363981\n",
      "[3900]\ttraining's binary_logloss: 0.0805405\tvalid_1's binary_logloss: 0.36614\n",
      "[4000]\ttraining's binary_logloss: 0.0777963\tvalid_1's binary_logloss: 0.367623\n",
      "[4100]\ttraining's binary_logloss: 0.0751431\tvalid_1's binary_logloss: 0.367707\n",
      "[4200]\ttraining's binary_logloss: 0.0726022\tvalid_1's binary_logloss: 0.368909\n",
      "[4300]\ttraining's binary_logloss: 0.0700562\tvalid_1's binary_logloss: 0.369212\n",
      "[4400]\ttraining's binary_logloss: 0.0676707\tvalid_1's binary_logloss: 0.369494\n",
      "[4500]\ttraining's binary_logloss: 0.065345\tvalid_1's binary_logloss: 0.370199\n",
      "[4600]\ttraining's binary_logloss: 0.0630438\tvalid_1's binary_logloss: 0.371331\n",
      "[4700]\ttraining's binary_logloss: 0.061033\tvalid_1's binary_logloss: 0.372265\n",
      "[4800]\ttraining's binary_logloss: 0.0590266\tvalid_1's binary_logloss: 0.373438\n",
      "[4900]\ttraining's binary_logloss: 0.0571166\tvalid_1's binary_logloss: 0.374169\n",
      "[5000]\ttraining's binary_logloss: 0.0552094\tvalid_1's binary_logloss: 0.374913\n",
      "Partial score of fold 3 is: 0.3749130315526168\n",
      "[100]\ttraining's binary_logloss: 0.531849\tvalid_1's binary_logloss: 0.550082\n",
      "[200]\ttraining's binary_logloss: 0.449828\tvalid_1's binary_logloss: 0.482729\n",
      "[300]\ttraining's binary_logloss: 0.399152\tvalid_1's binary_logloss: 0.4479\n",
      "[400]\ttraining's binary_logloss: 0.365826\tvalid_1's binary_logloss: 0.429751\n",
      "[500]\ttraining's binary_logloss: 0.339025\tvalid_1's binary_logloss: 0.417744\n",
      "[600]\ttraining's binary_logloss: 0.317371\tvalid_1's binary_logloss: 0.407631\n",
      "[700]\ttraining's binary_logloss: 0.299591\tvalid_1's binary_logloss: 0.401681\n",
      "[800]\ttraining's binary_logloss: 0.284032\tvalid_1's binary_logloss: 0.397361\n",
      "[900]\ttraining's binary_logloss: 0.26989\tvalid_1's binary_logloss: 0.393892\n",
      "[1000]\ttraining's binary_logloss: 0.255998\tvalid_1's binary_logloss: 0.392542\n",
      "[1100]\ttraining's binary_logloss: 0.243475\tvalid_1's binary_logloss: 0.390296\n",
      "[1200]\ttraining's binary_logloss: 0.231923\tvalid_1's binary_logloss: 0.38798\n",
      "[1300]\ttraining's binary_logloss: 0.221225\tvalid_1's binary_logloss: 0.38668\n",
      "[1400]\ttraining's binary_logloss: 0.211457\tvalid_1's binary_logloss: 0.388219\n",
      "[1500]\ttraining's binary_logloss: 0.2017\tvalid_1's binary_logloss: 0.389345\n",
      "[1600]\ttraining's binary_logloss: 0.192692\tvalid_1's binary_logloss: 0.389093\n",
      "[1700]\ttraining's binary_logloss: 0.184594\tvalid_1's binary_logloss: 0.391342\n",
      "[1800]\ttraining's binary_logloss: 0.176508\tvalid_1's binary_logloss: 0.392765\n",
      "[1900]\ttraining's binary_logloss: 0.169362\tvalid_1's binary_logloss: 0.393132\n",
      "[2000]\ttraining's binary_logloss: 0.162558\tvalid_1's binary_logloss: 0.393284\n",
      "[2100]\ttraining's binary_logloss: 0.156237\tvalid_1's binary_logloss: 0.392896\n",
      "[2200]\ttraining's binary_logloss: 0.1503\tvalid_1's binary_logloss: 0.393591\n",
      "[2300]\ttraining's binary_logloss: 0.144782\tvalid_1's binary_logloss: 0.395223\n",
      "[2400]\ttraining's binary_logloss: 0.139409\tvalid_1's binary_logloss: 0.396132\n",
      "[2500]\ttraining's binary_logloss: 0.134112\tvalid_1's binary_logloss: 0.39762\n",
      "[2600]\ttraining's binary_logloss: 0.129217\tvalid_1's binary_logloss: 0.398134\n",
      "[2700]\ttraining's binary_logloss: 0.124422\tvalid_1's binary_logloss: 0.399134\n",
      "[2800]\ttraining's binary_logloss: 0.119965\tvalid_1's binary_logloss: 0.401842\n",
      "[2900]\ttraining's binary_logloss: 0.115674\tvalid_1's binary_logloss: 0.401899\n",
      "[3000]\ttraining's binary_logloss: 0.111291\tvalid_1's binary_logloss: 0.402705\n",
      "[3100]\ttraining's binary_logloss: 0.107197\tvalid_1's binary_logloss: 0.403435\n",
      "[3200]\ttraining's binary_logloss: 0.103343\tvalid_1's binary_logloss: 0.404545\n",
      "[3300]\ttraining's binary_logloss: 0.0997674\tvalid_1's binary_logloss: 0.405495\n",
      "[3400]\ttraining's binary_logloss: 0.0960366\tvalid_1's binary_logloss: 0.40555\n",
      "[3500]\ttraining's binary_logloss: 0.0923571\tvalid_1's binary_logloss: 0.407095\n",
      "[3600]\ttraining's binary_logloss: 0.0891491\tvalid_1's binary_logloss: 0.409468\n",
      "[3700]\ttraining's binary_logloss: 0.0860678\tvalid_1's binary_logloss: 0.411096\n",
      "[3800]\ttraining's binary_logloss: 0.0830656\tvalid_1's binary_logloss: 0.413375\n",
      "[3900]\ttraining's binary_logloss: 0.0800522\tvalid_1's binary_logloss: 0.413904\n",
      "[4000]\ttraining's binary_logloss: 0.0773099\tvalid_1's binary_logloss: 0.414483\n",
      "[4100]\ttraining's binary_logloss: 0.0746413\tvalid_1's binary_logloss: 0.416109\n",
      "[4200]\ttraining's binary_logloss: 0.0721297\tvalid_1's binary_logloss: 0.419\n",
      "[4300]\ttraining's binary_logloss: 0.0695128\tvalid_1's binary_logloss: 0.421965\n",
      "[4400]\ttraining's binary_logloss: 0.0670148\tvalid_1's binary_logloss: 0.423925\n",
      "[4500]\ttraining's binary_logloss: 0.0646905\tvalid_1's binary_logloss: 0.426319\n",
      "[4600]\ttraining's binary_logloss: 0.0625563\tvalid_1's binary_logloss: 0.428057\n",
      "[4700]\ttraining's binary_logloss: 0.0604598\tvalid_1's binary_logloss: 0.430445\n",
      "[4800]\ttraining's binary_logloss: 0.0583859\tvalid_1's binary_logloss: 0.43307\n",
      "[4900]\ttraining's binary_logloss: 0.0563721\tvalid_1's binary_logloss: 0.43643\n",
      "[5000]\ttraining's binary_logloss: 0.0544104\tvalid_1's binary_logloss: 0.438547\n",
      "Partial score of fold 4 is: 0.43854712723920247\n",
      "[100]\ttraining's binary_logloss: 0.532588\tvalid_1's binary_logloss: 0.534048\n",
      "[200]\ttraining's binary_logloss: 0.452374\tvalid_1's binary_logloss: 0.456811\n",
      "[300]\ttraining's binary_logloss: 0.402236\tvalid_1's binary_logloss: 0.42301\n",
      "[400]\ttraining's binary_logloss: 0.368285\tvalid_1's binary_logloss: 0.405891\n",
      "[500]\ttraining's binary_logloss: 0.341504\tvalid_1's binary_logloss: 0.397957\n",
      "[600]\ttraining's binary_logloss: 0.320316\tvalid_1's binary_logloss: 0.390374\n",
      "[700]\ttraining's binary_logloss: 0.301975\tvalid_1's binary_logloss: 0.379555\n",
      "[800]\ttraining's binary_logloss: 0.286693\tvalid_1's binary_logloss: 0.373965\n",
      "[900]\ttraining's binary_logloss: 0.272933\tvalid_1's binary_logloss: 0.369429\n",
      "[1000]\ttraining's binary_logloss: 0.260079\tvalid_1's binary_logloss: 0.365133\n",
      "[1100]\ttraining's binary_logloss: 0.248245\tvalid_1's binary_logloss: 0.363348\n",
      "[1200]\ttraining's binary_logloss: 0.236459\tvalid_1's binary_logloss: 0.360535\n",
      "[1300]\ttraining's binary_logloss: 0.225384\tvalid_1's binary_logloss: 0.358476\n",
      "[1400]\ttraining's binary_logloss: 0.214742\tvalid_1's binary_logloss: 0.35546\n",
      "[1500]\ttraining's binary_logloss: 0.205471\tvalid_1's binary_logloss: 0.351514\n",
      "[1600]\ttraining's binary_logloss: 0.196235\tvalid_1's binary_logloss: 0.350344\n",
      "[1700]\ttraining's binary_logloss: 0.187647\tvalid_1's binary_logloss: 0.351338\n",
      "[1800]\ttraining's binary_logloss: 0.18005\tvalid_1's binary_logloss: 0.351857\n",
      "[1900]\ttraining's binary_logloss: 0.172957\tvalid_1's binary_logloss: 0.352961\n",
      "[2000]\ttraining's binary_logloss: 0.165928\tvalid_1's binary_logloss: 0.354624\n",
      "[2100]\ttraining's binary_logloss: 0.159485\tvalid_1's binary_logloss: 0.356136\n",
      "[2200]\ttraining's binary_logloss: 0.153445\tvalid_1's binary_logloss: 0.357731\n",
      "[2300]\ttraining's binary_logloss: 0.147706\tvalid_1's binary_logloss: 0.357887\n",
      "[2400]\ttraining's binary_logloss: 0.142493\tvalid_1's binary_logloss: 0.359893\n",
      "[2500]\ttraining's binary_logloss: 0.137298\tvalid_1's binary_logloss: 0.360033\n",
      "[2600]\ttraining's binary_logloss: 0.132122\tvalid_1's binary_logloss: 0.36035\n",
      "[2700]\ttraining's binary_logloss: 0.127156\tvalid_1's binary_logloss: 0.360518\n",
      "[2800]\ttraining's binary_logloss: 0.122329\tvalid_1's binary_logloss: 0.360384\n",
      "[2900]\ttraining's binary_logloss: 0.117627\tvalid_1's binary_logloss: 0.361058\n",
      "[3000]\ttraining's binary_logloss: 0.113201\tvalid_1's binary_logloss: 0.363087\n",
      "[3100]\ttraining's binary_logloss: 0.109092\tvalid_1's binary_logloss: 0.363664\n",
      "[3200]\ttraining's binary_logloss: 0.104992\tvalid_1's binary_logloss: 0.364417\n",
      "[3300]\ttraining's binary_logloss: 0.101152\tvalid_1's binary_logloss: 0.364964\n",
      "[3400]\ttraining's binary_logloss: 0.0973598\tvalid_1's binary_logloss: 0.36518\n",
      "[3500]\ttraining's binary_logloss: 0.0937864\tvalid_1's binary_logloss: 0.366352\n",
      "[3600]\ttraining's binary_logloss: 0.0905643\tvalid_1's binary_logloss: 0.368333\n",
      "[3700]\ttraining's binary_logloss: 0.0874501\tvalid_1's binary_logloss: 0.370055\n",
      "[3800]\ttraining's binary_logloss: 0.0843283\tvalid_1's binary_logloss: 0.370905\n",
      "[3900]\ttraining's binary_logloss: 0.0813434\tvalid_1's binary_logloss: 0.371729\n",
      "[4000]\ttraining's binary_logloss: 0.0784878\tvalid_1's binary_logloss: 0.372149\n",
      "[4100]\ttraining's binary_logloss: 0.0758203\tvalid_1's binary_logloss: 0.372932\n",
      "[4200]\ttraining's binary_logloss: 0.0732579\tvalid_1's binary_logloss: 0.373177\n",
      "[4300]\ttraining's binary_logloss: 0.0707561\tvalid_1's binary_logloss: 0.375312\n",
      "[4400]\ttraining's binary_logloss: 0.0682709\tvalid_1's binary_logloss: 0.376718\n",
      "[4500]\ttraining's binary_logloss: 0.065953\tvalid_1's binary_logloss: 0.378116\n",
      "[4600]\ttraining's binary_logloss: 0.0637173\tvalid_1's binary_logloss: 0.379864\n",
      "[4700]\ttraining's binary_logloss: 0.0614563\tvalid_1's binary_logloss: 0.38076\n",
      "[4800]\ttraining's binary_logloss: 0.0593741\tvalid_1's binary_logloss: 0.382262\n",
      "[4900]\ttraining's binary_logloss: 0.0573591\tvalid_1's binary_logloss: 0.384497\n",
      "[5000]\ttraining's binary_logloss: 0.0553968\tvalid_1's binary_logloss: 0.38549\n",
      "Partial score of fold 5 is: 0.3854899568410011\n",
      "[100]\ttraining's binary_logloss: 0.5347\tvalid_1's binary_logloss: 0.536485\n",
      "[200]\ttraining's binary_logloss: 0.453619\tvalid_1's binary_logloss: 0.461381\n",
      "[300]\ttraining's binary_logloss: 0.404354\tvalid_1's binary_logloss: 0.421988\n",
      "[400]\ttraining's binary_logloss: 0.370286\tvalid_1's binary_logloss: 0.396161\n",
      "[500]\ttraining's binary_logloss: 0.34348\tvalid_1's binary_logloss: 0.381804\n",
      "[600]\ttraining's binary_logloss: 0.320743\tvalid_1's binary_logloss: 0.371939\n",
      "[700]\ttraining's binary_logloss: 0.302657\tvalid_1's binary_logloss: 0.364962\n",
      "[800]\ttraining's binary_logloss: 0.286045\tvalid_1's binary_logloss: 0.360106\n",
      "[900]\ttraining's binary_logloss: 0.270984\tvalid_1's binary_logloss: 0.35881\n",
      "[1000]\ttraining's binary_logloss: 0.257451\tvalid_1's binary_logloss: 0.356615\n",
      "[1100]\ttraining's binary_logloss: 0.245376\tvalid_1's binary_logloss: 0.357489\n",
      "[1200]\ttraining's binary_logloss: 0.23371\tvalid_1's binary_logloss: 0.356755\n",
      "[1300]\ttraining's binary_logloss: 0.223497\tvalid_1's binary_logloss: 0.357551\n",
      "[1400]\ttraining's binary_logloss: 0.214069\tvalid_1's binary_logloss: 0.358862\n",
      "[1500]\ttraining's binary_logloss: 0.204971\tvalid_1's binary_logloss: 0.360638\n",
      "[1600]\ttraining's binary_logloss: 0.196076\tvalid_1's binary_logloss: 0.363331\n",
      "[1700]\ttraining's binary_logloss: 0.188116\tvalid_1's binary_logloss: 0.367269\n",
      "[1800]\ttraining's binary_logloss: 0.180562\tvalid_1's binary_logloss: 0.369566\n",
      "[1900]\ttraining's binary_logloss: 0.173301\tvalid_1's binary_logloss: 0.370771\n",
      "[2000]\ttraining's binary_logloss: 0.166088\tvalid_1's binary_logloss: 0.370802\n",
      "[2100]\ttraining's binary_logloss: 0.159243\tvalid_1's binary_logloss: 0.371432\n",
      "[2200]\ttraining's binary_logloss: 0.153021\tvalid_1's binary_logloss: 0.371523\n",
      "[2300]\ttraining's binary_logloss: 0.146711\tvalid_1's binary_logloss: 0.370053\n",
      "[2400]\ttraining's binary_logloss: 0.141006\tvalid_1's binary_logloss: 0.371437\n",
      "[2500]\ttraining's binary_logloss: 0.135639\tvalid_1's binary_logloss: 0.373204\n",
      "[2600]\ttraining's binary_logloss: 0.130412\tvalid_1's binary_logloss: 0.374141\n",
      "[2700]\ttraining's binary_logloss: 0.125349\tvalid_1's binary_logloss: 0.375698\n",
      "[2800]\ttraining's binary_logloss: 0.120517\tvalid_1's binary_logloss: 0.377281\n",
      "[2900]\ttraining's binary_logloss: 0.116107\tvalid_1's binary_logloss: 0.379835\n",
      "[3000]\ttraining's binary_logloss: 0.111725\tvalid_1's binary_logloss: 0.381851\n",
      "[3100]\ttraining's binary_logloss: 0.107706\tvalid_1's binary_logloss: 0.384981\n",
      "[3200]\ttraining's binary_logloss: 0.103985\tvalid_1's binary_logloss: 0.388206\n",
      "[3300]\ttraining's binary_logloss: 0.100488\tvalid_1's binary_logloss: 0.391073\n",
      "[3400]\ttraining's binary_logloss: 0.0969662\tvalid_1's binary_logloss: 0.392853\n",
      "[3500]\ttraining's binary_logloss: 0.0934728\tvalid_1's binary_logloss: 0.393716\n",
      "[3600]\ttraining's binary_logloss: 0.089933\tvalid_1's binary_logloss: 0.393996\n",
      "[3700]\ttraining's binary_logloss: 0.0865769\tvalid_1's binary_logloss: 0.395726\n",
      "[3800]\ttraining's binary_logloss: 0.0834073\tvalid_1's binary_logloss: 0.39625\n",
      "[3900]\ttraining's binary_logloss: 0.0804486\tvalid_1's binary_logloss: 0.397371\n",
      "[4000]\ttraining's binary_logloss: 0.0777172\tvalid_1's binary_logloss: 0.399326\n",
      "[4100]\ttraining's binary_logloss: 0.0749558\tvalid_1's binary_logloss: 0.400044\n",
      "[4200]\ttraining's binary_logloss: 0.0723781\tvalid_1's binary_logloss: 0.40201\n",
      "[4300]\ttraining's binary_logloss: 0.0699742\tvalid_1's binary_logloss: 0.404\n",
      "[4400]\ttraining's binary_logloss: 0.0675571\tvalid_1's binary_logloss: 0.404759\n",
      "[4500]\ttraining's binary_logloss: 0.0652911\tvalid_1's binary_logloss: 0.407322\n",
      "[4600]\ttraining's binary_logloss: 0.0629647\tvalid_1's binary_logloss: 0.409291\n",
      "[4700]\ttraining's binary_logloss: 0.0607286\tvalid_1's binary_logloss: 0.412673\n",
      "[4800]\ttraining's binary_logloss: 0.0586216\tvalid_1's binary_logloss: 0.415621\n",
      "[4900]\ttraining's binary_logloss: 0.0565263\tvalid_1's binary_logloss: 0.418111\n",
      "[5000]\ttraining's binary_logloss: 0.0544316\tvalid_1's binary_logloss: 0.420363\n",
      "Partial score of fold 6 is: 0.42036347918929345\n",
      "[100]\ttraining's binary_logloss: 0.533767\tvalid_1's binary_logloss: 0.543378\n",
      "[200]\ttraining's binary_logloss: 0.450954\tvalid_1's binary_logloss: 0.476249\n",
      "[300]\ttraining's binary_logloss: 0.401369\tvalid_1's binary_logloss: 0.440251\n",
      "[400]\ttraining's binary_logloss: 0.367544\tvalid_1's binary_logloss: 0.418552\n",
      "[500]\ttraining's binary_logloss: 0.342053\tvalid_1's binary_logloss: 0.403347\n",
      "[600]\ttraining's binary_logloss: 0.319499\tvalid_1's binary_logloss: 0.389982\n",
      "[700]\ttraining's binary_logloss: 0.300029\tvalid_1's binary_logloss: 0.380374\n",
      "[800]\ttraining's binary_logloss: 0.28348\tvalid_1's binary_logloss: 0.373766\n",
      "[900]\ttraining's binary_logloss: 0.268912\tvalid_1's binary_logloss: 0.36921\n",
      "[1000]\ttraining's binary_logloss: 0.256409\tvalid_1's binary_logloss: 0.368068\n",
      "[1100]\ttraining's binary_logloss: 0.244349\tvalid_1's binary_logloss: 0.36839\n",
      "[1200]\ttraining's binary_logloss: 0.23321\tvalid_1's binary_logloss: 0.367427\n",
      "[1300]\ttraining's binary_logloss: 0.222717\tvalid_1's binary_logloss: 0.367325\n",
      "[1400]\ttraining's binary_logloss: 0.212892\tvalid_1's binary_logloss: 0.367525\n",
      "[1500]\ttraining's binary_logloss: 0.203843\tvalid_1's binary_logloss: 0.367332\n",
      "[1600]\ttraining's binary_logloss: 0.195648\tvalid_1's binary_logloss: 0.366817\n",
      "[1700]\ttraining's binary_logloss: 0.187803\tvalid_1's binary_logloss: 0.366874\n",
      "[1800]\ttraining's binary_logloss: 0.180313\tvalid_1's binary_logloss: 0.368573\n",
      "[1900]\ttraining's binary_logloss: 0.172862\tvalid_1's binary_logloss: 0.368962\n",
      "[2000]\ttraining's binary_logloss: 0.166074\tvalid_1's binary_logloss: 0.370281\n",
      "[2100]\ttraining's binary_logloss: 0.159751\tvalid_1's binary_logloss: 0.370647\n",
      "[2200]\ttraining's binary_logloss: 0.153758\tvalid_1's binary_logloss: 0.373338\n",
      "[2300]\ttraining's binary_logloss: 0.147974\tvalid_1's binary_logloss: 0.373213\n",
      "[2400]\ttraining's binary_logloss: 0.142345\tvalid_1's binary_logloss: 0.374311\n",
      "[2500]\ttraining's binary_logloss: 0.136855\tvalid_1's binary_logloss: 0.3762\n",
      "[2600]\ttraining's binary_logloss: 0.131984\tvalid_1's binary_logloss: 0.376679\n",
      "[2700]\ttraining's binary_logloss: 0.127225\tvalid_1's binary_logloss: 0.377578\n",
      "[2800]\ttraining's binary_logloss: 0.122559\tvalid_1's binary_logloss: 0.379271\n",
      "[2900]\ttraining's binary_logloss: 0.118265\tvalid_1's binary_logloss: 0.379827\n",
      "[3000]\ttraining's binary_logloss: 0.114127\tvalid_1's binary_logloss: 0.38073\n",
      "[3100]\ttraining's binary_logloss: 0.110005\tvalid_1's binary_logloss: 0.381921\n",
      "[3200]\ttraining's binary_logloss: 0.105983\tvalid_1's binary_logloss: 0.384052\n",
      "[3300]\ttraining's binary_logloss: 0.102164\tvalid_1's binary_logloss: 0.385588\n",
      "[3400]\ttraining's binary_logloss: 0.0986562\tvalid_1's binary_logloss: 0.389416\n",
      "[3500]\ttraining's binary_logloss: 0.0950526\tvalid_1's binary_logloss: 0.392028\n",
      "[3600]\ttraining's binary_logloss: 0.0917956\tvalid_1's binary_logloss: 0.395502\n",
      "[3700]\ttraining's binary_logloss: 0.0884645\tvalid_1's binary_logloss: 0.397456\n",
      "[3800]\ttraining's binary_logloss: 0.08548\tvalid_1's binary_logloss: 0.399819\n",
      "[3900]\ttraining's binary_logloss: 0.0825553\tvalid_1's binary_logloss: 0.401422\n",
      "[4000]\ttraining's binary_logloss: 0.0796702\tvalid_1's binary_logloss: 0.403309\n",
      "[4100]\ttraining's binary_logloss: 0.0769473\tvalid_1's binary_logloss: 0.405176\n",
      "[4200]\ttraining's binary_logloss: 0.0742506\tvalid_1's binary_logloss: 0.408859\n",
      "[4300]\ttraining's binary_logloss: 0.0716519\tvalid_1's binary_logloss: 0.412968\n",
      "[4400]\ttraining's binary_logloss: 0.0691966\tvalid_1's binary_logloss: 0.416594\n",
      "[4500]\ttraining's binary_logloss: 0.0668321\tvalid_1's binary_logloss: 0.420347\n",
      "[4600]\ttraining's binary_logloss: 0.0645598\tvalid_1's binary_logloss: 0.422711\n",
      "[4700]\ttraining's binary_logloss: 0.0624367\tvalid_1's binary_logloss: 0.424542\n",
      "[4800]\ttraining's binary_logloss: 0.0603166\tvalid_1's binary_logloss: 0.427833\n",
      "[4900]\ttraining's binary_logloss: 0.0582128\tvalid_1's binary_logloss: 0.430149\n",
      "[5000]\ttraining's binary_logloss: 0.0563161\tvalid_1's binary_logloss: 0.432922\n",
      "Partial score of fold 7 is: 0.43292207274541106\n",
      "[100]\ttraining's binary_logloss: 0.531263\tvalid_1's binary_logloss: 0.544641\n",
      "[200]\ttraining's binary_logloss: 0.451043\tvalid_1's binary_logloss: 0.471718\n",
      "[300]\ttraining's binary_logloss: 0.403379\tvalid_1's binary_logloss: 0.434293\n",
      "[400]\ttraining's binary_logloss: 0.369514\tvalid_1's binary_logloss: 0.409237\n",
      "[500]\ttraining's binary_logloss: 0.343338\tvalid_1's binary_logloss: 0.393951\n",
      "[600]\ttraining's binary_logloss: 0.322007\tvalid_1's binary_logloss: 0.382626\n",
      "[700]\ttraining's binary_logloss: 0.302415\tvalid_1's binary_logloss: 0.371617\n",
      "[800]\ttraining's binary_logloss: 0.2864\tvalid_1's binary_logloss: 0.36683\n",
      "[900]\ttraining's binary_logloss: 0.272439\tvalid_1's binary_logloss: 0.361472\n",
      "[1000]\ttraining's binary_logloss: 0.258944\tvalid_1's binary_logloss: 0.354875\n",
      "[1100]\ttraining's binary_logloss: 0.246781\tvalid_1's binary_logloss: 0.349828\n",
      "[1200]\ttraining's binary_logloss: 0.235805\tvalid_1's binary_logloss: 0.348423\n",
      "[1300]\ttraining's binary_logloss: 0.225421\tvalid_1's binary_logloss: 0.345466\n",
      "[1400]\ttraining's binary_logloss: 0.215474\tvalid_1's binary_logloss: 0.344175\n",
      "[1500]\ttraining's binary_logloss: 0.206052\tvalid_1's binary_logloss: 0.341828\n",
      "[1600]\ttraining's binary_logloss: 0.197466\tvalid_1's binary_logloss: 0.339447\n",
      "[1700]\ttraining's binary_logloss: 0.189098\tvalid_1's binary_logloss: 0.336896\n",
      "[1800]\ttraining's binary_logloss: 0.181354\tvalid_1's binary_logloss: 0.335606\n",
      "[1900]\ttraining's binary_logloss: 0.174287\tvalid_1's binary_logloss: 0.335265\n",
      "[2000]\ttraining's binary_logloss: 0.167113\tvalid_1's binary_logloss: 0.334653\n",
      "[2100]\ttraining's binary_logloss: 0.159887\tvalid_1's binary_logloss: 0.333142\n",
      "[2200]\ttraining's binary_logloss: 0.153513\tvalid_1's binary_logloss: 0.331999\n",
      "[2300]\ttraining's binary_logloss: 0.147655\tvalid_1's binary_logloss: 0.332509\n",
      "[2400]\ttraining's binary_logloss: 0.141789\tvalid_1's binary_logloss: 0.332648\n",
      "[2500]\ttraining's binary_logloss: 0.136289\tvalid_1's binary_logloss: 0.330801\n",
      "[2600]\ttraining's binary_logloss: 0.131071\tvalid_1's binary_logloss: 0.330838\n",
      "[2700]\ttraining's binary_logloss: 0.126219\tvalid_1's binary_logloss: 0.331441\n",
      "[2800]\ttraining's binary_logloss: 0.12172\tvalid_1's binary_logloss: 0.332448\n",
      "[2900]\ttraining's binary_logloss: 0.117415\tvalid_1's binary_logloss: 0.333611\n",
      "[3000]\ttraining's binary_logloss: 0.113026\tvalid_1's binary_logloss: 0.334439\n",
      "[3100]\ttraining's binary_logloss: 0.108637\tvalid_1's binary_logloss: 0.335859\n",
      "[3200]\ttraining's binary_logloss: 0.104698\tvalid_1's binary_logloss: 0.337625\n",
      "[3300]\ttraining's binary_logloss: 0.101005\tvalid_1's binary_logloss: 0.339516\n",
      "[3400]\ttraining's binary_logloss: 0.0974831\tvalid_1's binary_logloss: 0.340699\n",
      "[3500]\ttraining's binary_logloss: 0.0942375\tvalid_1's binary_logloss: 0.340907\n",
      "[3600]\ttraining's binary_logloss: 0.0909516\tvalid_1's binary_logloss: 0.340244\n",
      "[3700]\ttraining's binary_logloss: 0.0877185\tvalid_1's binary_logloss: 0.340085\n",
      "[3800]\ttraining's binary_logloss: 0.0845922\tvalid_1's binary_logloss: 0.341587\n",
      "[3900]\ttraining's binary_logloss: 0.0816907\tvalid_1's binary_logloss: 0.34212\n",
      "[4000]\ttraining's binary_logloss: 0.0788382\tvalid_1's binary_logloss: 0.341852\n",
      "[4100]\ttraining's binary_logloss: 0.0761296\tvalid_1's binary_logloss: 0.342631\n",
      "[4200]\ttraining's binary_logloss: 0.0735165\tvalid_1's binary_logloss: 0.342361\n",
      "[4300]\ttraining's binary_logloss: 0.0708069\tvalid_1's binary_logloss: 0.343346\n",
      "[4400]\ttraining's binary_logloss: 0.0682346\tvalid_1's binary_logloss: 0.345412\n",
      "[4500]\ttraining's binary_logloss: 0.0659679\tvalid_1's binary_logloss: 0.34604\n",
      "[4600]\ttraining's binary_logloss: 0.0637233\tvalid_1's binary_logloss: 0.346925\n",
      "[4700]\ttraining's binary_logloss: 0.061589\tvalid_1's binary_logloss: 0.34922\n",
      "[4800]\ttraining's binary_logloss: 0.0595435\tvalid_1's binary_logloss: 0.349759\n",
      "[4900]\ttraining's binary_logloss: 0.0575568\tvalid_1's binary_logloss: 0.35058\n",
      "[5000]\ttraining's binary_logloss: 0.0555846\tvalid_1's binary_logloss: 0.351507\n",
      "Partial score of fold 8 is: 0.35150683095565816\n",
      "[100]\ttraining's binary_logloss: 0.531685\tvalid_1's binary_logloss: 0.556849\n",
      "[200]\ttraining's binary_logloss: 0.449269\tvalid_1's binary_logloss: 0.497865\n",
      "[300]\ttraining's binary_logloss: 0.399382\tvalid_1's binary_logloss: 0.46617\n",
      "[400]\ttraining's binary_logloss: 0.36557\tvalid_1's binary_logloss: 0.446582\n",
      "[500]\ttraining's binary_logloss: 0.338168\tvalid_1's binary_logloss: 0.42919\n",
      "[600]\ttraining's binary_logloss: 0.315938\tvalid_1's binary_logloss: 0.422289\n",
      "[700]\ttraining's binary_logloss: 0.296177\tvalid_1's binary_logloss: 0.416125\n",
      "[800]\ttraining's binary_logloss: 0.279601\tvalid_1's binary_logloss: 0.415336\n",
      "[900]\ttraining's binary_logloss: 0.265313\tvalid_1's binary_logloss: 0.41573\n",
      "[1000]\ttraining's binary_logloss: 0.252459\tvalid_1's binary_logloss: 0.416002\n",
      "[1100]\ttraining's binary_logloss: 0.240908\tvalid_1's binary_logloss: 0.416838\n",
      "[1200]\ttraining's binary_logloss: 0.229629\tvalid_1's binary_logloss: 0.418057\n",
      "[1300]\ttraining's binary_logloss: 0.21887\tvalid_1's binary_logloss: 0.419749\n",
      "[1400]\ttraining's binary_logloss: 0.207969\tvalid_1's binary_logloss: 0.419602\n",
      "[1500]\ttraining's binary_logloss: 0.198728\tvalid_1's binary_logloss: 0.421805\n",
      "[1600]\ttraining's binary_logloss: 0.190235\tvalid_1's binary_logloss: 0.42226\n",
      "[1700]\ttraining's binary_logloss: 0.181784\tvalid_1's binary_logloss: 0.423557\n",
      "[1800]\ttraining's binary_logloss: 0.173566\tvalid_1's binary_logloss: 0.427456\n",
      "[1900]\ttraining's binary_logloss: 0.166079\tvalid_1's binary_logloss: 0.429157\n",
      "[2000]\ttraining's binary_logloss: 0.158993\tvalid_1's binary_logloss: 0.430447\n",
      "[2100]\ttraining's binary_logloss: 0.152487\tvalid_1's binary_logloss: 0.432325\n",
      "[2200]\ttraining's binary_logloss: 0.146429\tvalid_1's binary_logloss: 0.433088\n",
      "[2300]\ttraining's binary_logloss: 0.140631\tvalid_1's binary_logloss: 0.435172\n",
      "[2400]\ttraining's binary_logloss: 0.134794\tvalid_1's binary_logloss: 0.437736\n",
      "[2500]\ttraining's binary_logloss: 0.129719\tvalid_1's binary_logloss: 0.440425\n",
      "[2600]\ttraining's binary_logloss: 0.12496\tvalid_1's binary_logloss: 0.444828\n",
      "[2700]\ttraining's binary_logloss: 0.120341\tvalid_1's binary_logloss: 0.448627\n",
      "[2800]\ttraining's binary_logloss: 0.115805\tvalid_1's binary_logloss: 0.452179\n",
      "[2900]\ttraining's binary_logloss: 0.111506\tvalid_1's binary_logloss: 0.456529\n",
      "[3000]\ttraining's binary_logloss: 0.107472\tvalid_1's binary_logloss: 0.46086\n",
      "[3100]\ttraining's binary_logloss: 0.103488\tvalid_1's binary_logloss: 0.465087\n",
      "[3200]\ttraining's binary_logloss: 0.0996713\tvalid_1's binary_logloss: 0.468563\n",
      "[3300]\ttraining's binary_logloss: 0.0960846\tvalid_1's binary_logloss: 0.471781\n",
      "[3400]\ttraining's binary_logloss: 0.0926674\tvalid_1's binary_logloss: 0.474323\n",
      "[3500]\ttraining's binary_logloss: 0.0893472\tvalid_1's binary_logloss: 0.477664\n",
      "[3600]\ttraining's binary_logloss: 0.0862264\tvalid_1's binary_logloss: 0.480175\n",
      "[3700]\ttraining's binary_logloss: 0.0831486\tvalid_1's binary_logloss: 0.482611\n",
      "[3800]\ttraining's binary_logloss: 0.0800907\tvalid_1's binary_logloss: 0.486394\n",
      "[3900]\ttraining's binary_logloss: 0.0771376\tvalid_1's binary_logloss: 0.488936\n",
      "[4000]\ttraining's binary_logloss: 0.074427\tvalid_1's binary_logloss: 0.492705\n",
      "[4100]\ttraining's binary_logloss: 0.0717557\tvalid_1's binary_logloss: 0.495593\n",
      "[4200]\ttraining's binary_logloss: 0.0691871\tvalid_1's binary_logloss: 0.498729\n",
      "[4300]\ttraining's binary_logloss: 0.0667857\tvalid_1's binary_logloss: 0.501902\n",
      "[4400]\ttraining's binary_logloss: 0.0644745\tvalid_1's binary_logloss: 0.505548\n",
      "[4500]\ttraining's binary_logloss: 0.0623121\tvalid_1's binary_logloss: 0.509565\n",
      "[4600]\ttraining's binary_logloss: 0.0602176\tvalid_1's binary_logloss: 0.512493\n",
      "[4700]\ttraining's binary_logloss: 0.0582195\tvalid_1's binary_logloss: 0.515477\n",
      "[4800]\ttraining's binary_logloss: 0.0562323\tvalid_1's binary_logloss: 0.51779\n",
      "[4900]\ttraining's binary_logloss: 0.0542931\tvalid_1's binary_logloss: 0.520555\n",
      "[5000]\ttraining's binary_logloss: 0.0524508\tvalid_1's binary_logloss: 0.524612\n",
      "Partial score of fold 9 is: 0.5246124469835572\n",
      "Our oof loss score is:  0.42437298623183445\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "test[\"Pred\"] = 0.5\n",
    "pred = np.zeros(test.shape[0])\n",
    "for season in test[\"Season\"].unique():\n",
    "    print(f\"Predicting {season}...\")\n",
    "    lgbm = LgbModel(train.loc[train[\"Season\"] < season, :], test.loc[test[\"Season\"] == season, :], target, features, categoricals=[], n_splits=10, \n",
    "                    cv_method=\"StratifiedKFold\", group=None, task=\"binary\", scaler=None, verbose=True)\n",
    "    # StratifiedKFold,TimeSeriesSplit\n",
    "    models[season] = lgbm\n",
    "    test.loc[test[\"Season\"] == season, \"Pred\"] = lgbm.y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 2015...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.522125\tvalid_1's binary_logloss: 0.537485\n",
      "[200]\ttraining's binary_logloss: 0.430374\tvalid_1's binary_logloss: 0.461534\n",
      "[300]\ttraining's binary_logloss: 0.371556\tvalid_1's binary_logloss: 0.417546\n",
      "[400]\ttraining's binary_logloss: 0.325797\tvalid_1's binary_logloss: 0.39032\n",
      "[500]\ttraining's binary_logloss: 0.287091\tvalid_1's binary_logloss: 0.368998\n",
      "[600]\ttraining's binary_logloss: 0.25769\tvalid_1's binary_logloss: 0.354284\n",
      "[700]\ttraining's binary_logloss: 0.228618\tvalid_1's binary_logloss: 0.336529\n",
      "[800]\ttraining's binary_logloss: 0.204033\tvalid_1's binary_logloss: 0.324936\n",
      "[900]\ttraining's binary_logloss: 0.183104\tvalid_1's binary_logloss: 0.315081\n",
      "[1000]\ttraining's binary_logloss: 0.165541\tvalid_1's binary_logloss: 0.30705\n",
      "[1100]\ttraining's binary_logloss: 0.150778\tvalid_1's binary_logloss: 0.302575\n",
      "[1200]\ttraining's binary_logloss: 0.137685\tvalid_1's binary_logloss: 0.301567\n",
      "[1300]\ttraining's binary_logloss: 0.125754\tvalid_1's binary_logloss: 0.301572\n",
      "[1400]\ttraining's binary_logloss: 0.115717\tvalid_1's binary_logloss: 0.30047\n",
      "[1500]\ttraining's binary_logloss: 0.106426\tvalid_1's binary_logloss: 0.301021\n",
      "[1600]\ttraining's binary_logloss: 0.097945\tvalid_1's binary_logloss: 0.299537\n",
      "[1700]\ttraining's binary_logloss: 0.0901633\tvalid_1's binary_logloss: 0.299873\n",
      "[1800]\ttraining's binary_logloss: 0.0830392\tvalid_1's binary_logloss: 0.300873\n",
      "[1900]\ttraining's binary_logloss: 0.0766071\tvalid_1's binary_logloss: 0.301601\n",
      "[2000]\ttraining's binary_logloss: 0.0708942\tvalid_1's binary_logloss: 0.299862\n",
      "[2100]\ttraining's binary_logloss: 0.0657796\tvalid_1's binary_logloss: 0.299514\n",
      "[2200]\ttraining's binary_logloss: 0.0609\tvalid_1's binary_logloss: 0.29849\n",
      "[2300]\ttraining's binary_logloss: 0.0564808\tvalid_1's binary_logloss: 0.29911\n",
      "[2400]\ttraining's binary_logloss: 0.0524222\tvalid_1's binary_logloss: 0.299783\n",
      "[2500]\ttraining's binary_logloss: 0.0487602\tvalid_1's binary_logloss: 0.29943\n",
      "[2600]\ttraining's binary_logloss: 0.0452915\tvalid_1's binary_logloss: 0.300098\n",
      "[2700]\ttraining's binary_logloss: 0.042015\tvalid_1's binary_logloss: 0.301483\n",
      "[2800]\ttraining's binary_logloss: 0.0389041\tvalid_1's binary_logloss: 0.300035\n",
      "[2900]\ttraining's binary_logloss: 0.0359828\tvalid_1's binary_logloss: 0.301126\n",
      "[3000]\ttraining's binary_logloss: 0.0331553\tvalid_1's binary_logloss: 0.303334\n",
      "[3100]\ttraining's binary_logloss: 0.0307935\tvalid_1's binary_logloss: 0.304839\n",
      "[3200]\ttraining's binary_logloss: 0.0285775\tvalid_1's binary_logloss: 0.305968\n",
      "[3300]\ttraining's binary_logloss: 0.0265262\tvalid_1's binary_logloss: 0.308712\n",
      "[3400]\ttraining's binary_logloss: 0.0247105\tvalid_1's binary_logloss: 0.311776\n",
      "[3500]\ttraining's binary_logloss: 0.0230091\tvalid_1's binary_logloss: 0.313569\n",
      "[3600]\ttraining's binary_logloss: 0.02144\tvalid_1's binary_logloss: 0.31437\n",
      "[3700]\ttraining's binary_logloss: 0.0199488\tvalid_1's binary_logloss: 0.316236\n",
      "[3800]\ttraining's binary_logloss: 0.0184672\tvalid_1's binary_logloss: 0.318954\n",
      "[3900]\ttraining's binary_logloss: 0.0171585\tvalid_1's binary_logloss: 0.322303\n",
      "[4000]\ttraining's binary_logloss: 0.0159626\tvalid_1's binary_logloss: 0.324042\n",
      "[4100]\ttraining's binary_logloss: 0.0148875\tvalid_1's binary_logloss: 0.327687\n",
      "[4200]\ttraining's binary_logloss: 0.0138401\tvalid_1's binary_logloss: 0.330016\n",
      "[4300]\ttraining's binary_logloss: 0.0129251\tvalid_1's binary_logloss: 0.332623\n",
      "[4400]\ttraining's binary_logloss: 0.0120438\tvalid_1's binary_logloss: 0.335713\n",
      "[4500]\ttraining's binary_logloss: 0.0112251\tvalid_1's binary_logloss: 0.338524\n",
      "[4600]\ttraining's binary_logloss: 0.010481\tvalid_1's binary_logloss: 0.341521\n",
      "[4700]\ttraining's binary_logloss: 0.00980009\tvalid_1's binary_logloss: 0.346514\n",
      "[4800]\ttraining's binary_logloss: 0.00917796\tvalid_1's binary_logloss: 0.350808\n",
      "[4900]\ttraining's binary_logloss: 0.00857459\tvalid_1's binary_logloss: 0.354832\n",
      "[5000]\ttraining's binary_logloss: 0.00801893\tvalid_1's binary_logloss: 0.35907\n",
      "Partial score of fold 0 is: 0.35907043727510507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.519681\tvalid_1's binary_logloss: 0.546828\n",
      "[200]\ttraining's binary_logloss: 0.425988\tvalid_1's binary_logloss: 0.481869\n",
      "[300]\ttraining's binary_logloss: 0.363114\tvalid_1's binary_logloss: 0.443005\n",
      "[400]\ttraining's binary_logloss: 0.314901\tvalid_1's binary_logloss: 0.420556\n",
      "[500]\ttraining's binary_logloss: 0.279546\tvalid_1's binary_logloss: 0.403941\n",
      "[600]\ttraining's binary_logloss: 0.248562\tvalid_1's binary_logloss: 0.383146\n",
      "[700]\ttraining's binary_logloss: 0.222969\tvalid_1's binary_logloss: 0.369535\n",
      "[800]\ttraining's binary_logloss: 0.20062\tvalid_1's binary_logloss: 0.359997\n",
      "[900]\ttraining's binary_logloss: 0.18192\tvalid_1's binary_logloss: 0.354768\n",
      "[1000]\ttraining's binary_logloss: 0.164333\tvalid_1's binary_logloss: 0.348462\n",
      "[1100]\ttraining's binary_logloss: 0.15005\tvalid_1's binary_logloss: 0.344954\n",
      "[1200]\ttraining's binary_logloss: 0.136085\tvalid_1's binary_logloss: 0.343957\n",
      "[1300]\ttraining's binary_logloss: 0.123814\tvalid_1's binary_logloss: 0.34513\n",
      "[1400]\ttraining's binary_logloss: 0.112588\tvalid_1's binary_logloss: 0.346557\n",
      "[1500]\ttraining's binary_logloss: 0.102573\tvalid_1's binary_logloss: 0.347725\n",
      "[1600]\ttraining's binary_logloss: 0.0937103\tvalid_1's binary_logloss: 0.352015\n",
      "[1700]\ttraining's binary_logloss: 0.0859567\tvalid_1's binary_logloss: 0.354539\n",
      "[1800]\ttraining's binary_logloss: 0.0791066\tvalid_1's binary_logloss: 0.359125\n",
      "[1900]\ttraining's binary_logloss: 0.0726545\tvalid_1's binary_logloss: 0.36035\n",
      "[2000]\ttraining's binary_logloss: 0.0670377\tvalid_1's binary_logloss: 0.363474\n",
      "[2100]\ttraining's binary_logloss: 0.0616703\tvalid_1's binary_logloss: 0.365385\n",
      "[2200]\ttraining's binary_logloss: 0.0566503\tvalid_1's binary_logloss: 0.364192\n",
      "[2300]\ttraining's binary_logloss: 0.0523341\tvalid_1's binary_logloss: 0.367608\n",
      "[2400]\ttraining's binary_logloss: 0.0482494\tvalid_1's binary_logloss: 0.370976\n",
      "[2500]\ttraining's binary_logloss: 0.0446393\tvalid_1's binary_logloss: 0.37389\n",
      "[2600]\ttraining's binary_logloss: 0.0413333\tvalid_1's binary_logloss: 0.378162\n",
      "[2700]\ttraining's binary_logloss: 0.0380636\tvalid_1's binary_logloss: 0.382372\n",
      "[2800]\ttraining's binary_logloss: 0.0351495\tvalid_1's binary_logloss: 0.385523\n",
      "[2900]\ttraining's binary_logloss: 0.0323831\tvalid_1's binary_logloss: 0.387423\n",
      "[3000]\ttraining's binary_logloss: 0.0299591\tvalid_1's binary_logloss: 0.391896\n",
      "[3100]\ttraining's binary_logloss: 0.0277825\tvalid_1's binary_logloss: 0.39755\n",
      "[3200]\ttraining's binary_logloss: 0.0258342\tvalid_1's binary_logloss: 0.401257\n",
      "[3300]\ttraining's binary_logloss: 0.0240196\tvalid_1's binary_logloss: 0.405804\n",
      "[3400]\ttraining's binary_logloss: 0.0222453\tvalid_1's binary_logloss: 0.409329\n",
      "[3500]\ttraining's binary_logloss: 0.0206148\tvalid_1's binary_logloss: 0.413712\n",
      "[3600]\ttraining's binary_logloss: 0.0191533\tvalid_1's binary_logloss: 0.41982\n",
      "[3700]\ttraining's binary_logloss: 0.0177654\tvalid_1's binary_logloss: 0.424017\n",
      "[3800]\ttraining's binary_logloss: 0.0165057\tvalid_1's binary_logloss: 0.42783\n",
      "[3900]\ttraining's binary_logloss: 0.0153316\tvalid_1's binary_logloss: 0.432082\n",
      "[4000]\ttraining's binary_logloss: 0.0142798\tvalid_1's binary_logloss: 0.435955\n",
      "[4100]\ttraining's binary_logloss: 0.0133\tvalid_1's binary_logloss: 0.442873\n",
      "[4200]\ttraining's binary_logloss: 0.0123909\tvalid_1's binary_logloss: 0.448537\n",
      "[4300]\ttraining's binary_logloss: 0.0115701\tvalid_1's binary_logloss: 0.453939\n",
      "[4400]\ttraining's binary_logloss: 0.0107759\tvalid_1's binary_logloss: 0.459989\n",
      "[4500]\ttraining's binary_logloss: 0.0100663\tvalid_1's binary_logloss: 0.467049\n",
      "[4600]\ttraining's binary_logloss: 0.0094235\tvalid_1's binary_logloss: 0.473089\n",
      "[4700]\ttraining's binary_logloss: 0.0088096\tvalid_1's binary_logloss: 0.47898\n",
      "[4800]\ttraining's binary_logloss: 0.00821011\tvalid_1's binary_logloss: 0.484141\n",
      "[4900]\ttraining's binary_logloss: 0.00770522\tvalid_1's binary_logloss: 0.488477\n",
      "[5000]\ttraining's binary_logloss: 0.00723226\tvalid_1's binary_logloss: 0.493704\n",
      "Partial score of fold 1 is: 0.4937042546265223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.52029\tvalid_1's binary_logloss: 0.548221\n",
      "[200]\ttraining's binary_logloss: 0.428886\tvalid_1's binary_logloss: 0.47333\n",
      "[300]\ttraining's binary_logloss: 0.37207\tvalid_1's binary_logloss: 0.432177\n",
      "[400]\ttraining's binary_logloss: 0.327514\tvalid_1's binary_logloss: 0.405142\n",
      "[500]\ttraining's binary_logloss: 0.288988\tvalid_1's binary_logloss: 0.380649\n",
      "[600]\ttraining's binary_logloss: 0.256989\tvalid_1's binary_logloss: 0.362457\n",
      "[700]\ttraining's binary_logloss: 0.228243\tvalid_1's binary_logloss: 0.345813\n",
      "[800]\ttraining's binary_logloss: 0.206234\tvalid_1's binary_logloss: 0.336025\n",
      "[900]\ttraining's binary_logloss: 0.187252\tvalid_1's binary_logloss: 0.329465\n",
      "[1000]\ttraining's binary_logloss: 0.170101\tvalid_1's binary_logloss: 0.323075\n",
      "[1100]\ttraining's binary_logloss: 0.154507\tvalid_1's binary_logloss: 0.315978\n",
      "[1200]\ttraining's binary_logloss: 0.14002\tvalid_1's binary_logloss: 0.310449\n",
      "[1300]\ttraining's binary_logloss: 0.126928\tvalid_1's binary_logloss: 0.306089\n",
      "[1400]\ttraining's binary_logloss: 0.11547\tvalid_1's binary_logloss: 0.304148\n",
      "[1500]\ttraining's binary_logloss: 0.105443\tvalid_1's binary_logloss: 0.302788\n",
      "[1600]\ttraining's binary_logloss: 0.0962548\tvalid_1's binary_logloss: 0.301153\n",
      "[1700]\ttraining's binary_logloss: 0.088093\tvalid_1's binary_logloss: 0.299264\n",
      "[1800]\ttraining's binary_logloss: 0.0808305\tvalid_1's binary_logloss: 0.298153\n",
      "[1900]\ttraining's binary_logloss: 0.0744546\tvalid_1's binary_logloss: 0.29893\n",
      "[2000]\ttraining's binary_logloss: 0.0686254\tvalid_1's binary_logloss: 0.300013\n",
      "[2100]\ttraining's binary_logloss: 0.0633526\tvalid_1's binary_logloss: 0.30239\n",
      "[2200]\ttraining's binary_logloss: 0.058215\tvalid_1's binary_logloss: 0.303767\n",
      "[2300]\ttraining's binary_logloss: 0.0535675\tvalid_1's binary_logloss: 0.305418\n",
      "[2400]\ttraining's binary_logloss: 0.049518\tvalid_1's binary_logloss: 0.306996\n",
      "[2500]\ttraining's binary_logloss: 0.0459342\tvalid_1's binary_logloss: 0.30704\n",
      "[2600]\ttraining's binary_logloss: 0.0425029\tvalid_1's binary_logloss: 0.308492\n",
      "[2700]\ttraining's binary_logloss: 0.0393446\tvalid_1's binary_logloss: 0.309648\n",
      "[2800]\ttraining's binary_logloss: 0.0364456\tvalid_1's binary_logloss: 0.31144\n",
      "[2900]\ttraining's binary_logloss: 0.0338239\tvalid_1's binary_logloss: 0.313493\n",
      "[3000]\ttraining's binary_logloss: 0.0313899\tvalid_1's binary_logloss: 0.314793\n",
      "[3100]\ttraining's binary_logloss: 0.0290508\tvalid_1's binary_logloss: 0.317498\n",
      "[3200]\ttraining's binary_logloss: 0.0269631\tvalid_1's binary_logloss: 0.319582\n",
      "[3300]\ttraining's binary_logloss: 0.0249789\tvalid_1's binary_logloss: 0.322202\n",
      "[3400]\ttraining's binary_logloss: 0.0231835\tvalid_1's binary_logloss: 0.322999\n",
      "[3500]\ttraining's binary_logloss: 0.0215425\tvalid_1's binary_logloss: 0.323917\n",
      "[3600]\ttraining's binary_logloss: 0.0200242\tvalid_1's binary_logloss: 0.326318\n",
      "[3700]\ttraining's binary_logloss: 0.018666\tvalid_1's binary_logloss: 0.326886\n",
      "[3800]\ttraining's binary_logloss: 0.0174216\tvalid_1's binary_logloss: 0.329537\n",
      "[3900]\ttraining's binary_logloss: 0.0161593\tvalid_1's binary_logloss: 0.333405\n",
      "[4000]\ttraining's binary_logloss: 0.0150329\tvalid_1's binary_logloss: 0.336237\n",
      "[4100]\ttraining's binary_logloss: 0.0140435\tvalid_1's binary_logloss: 0.338971\n",
      "[4200]\ttraining's binary_logloss: 0.0131999\tvalid_1's binary_logloss: 0.341312\n",
      "[4300]\ttraining's binary_logloss: 0.0123788\tvalid_1's binary_logloss: 0.343392\n",
      "[4400]\ttraining's binary_logloss: 0.0116148\tvalid_1's binary_logloss: 0.346171\n",
      "[4500]\ttraining's binary_logloss: 0.0108675\tvalid_1's binary_logloss: 0.349556\n",
      "[4600]\ttraining's binary_logloss: 0.0101944\tvalid_1's binary_logloss: 0.352174\n",
      "[4700]\ttraining's binary_logloss: 0.00953798\tvalid_1's binary_logloss: 0.355297\n",
      "[4800]\ttraining's binary_logloss: 0.00895876\tvalid_1's binary_logloss: 0.358598\n",
      "[4900]\ttraining's binary_logloss: 0.00840805\tvalid_1's binary_logloss: 0.361249\n",
      "[5000]\ttraining's binary_logloss: 0.00786521\tvalid_1's binary_logloss: 0.364747\n",
      "Partial score of fold 2 is: 0.3647470687433185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.519373\tvalid_1's binary_logloss: 0.542364\n",
      "[200]\ttraining's binary_logloss: 0.425837\tvalid_1's binary_logloss: 0.467244\n",
      "[300]\ttraining's binary_logloss: 0.369398\tvalid_1's binary_logloss: 0.427185\n",
      "[400]\ttraining's binary_logloss: 0.323614\tvalid_1's binary_logloss: 0.403821\n",
      "[500]\ttraining's binary_logloss: 0.285227\tvalid_1's binary_logloss: 0.380486\n",
      "[600]\ttraining's binary_logloss: 0.254103\tvalid_1's binary_logloss: 0.364513\n",
      "[700]\ttraining's binary_logloss: 0.227605\tvalid_1's binary_logloss: 0.3569\n",
      "[800]\ttraining's binary_logloss: 0.205183\tvalid_1's binary_logloss: 0.348714\n",
      "[900]\ttraining's binary_logloss: 0.18564\tvalid_1's binary_logloss: 0.340143\n",
      "[1000]\ttraining's binary_logloss: 0.169428\tvalid_1's binary_logloss: 0.336052\n",
      "[1100]\ttraining's binary_logloss: 0.154405\tvalid_1's binary_logloss: 0.331193\n",
      "[1200]\ttraining's binary_logloss: 0.140758\tvalid_1's binary_logloss: 0.32597\n",
      "[1300]\ttraining's binary_logloss: 0.128559\tvalid_1's binary_logloss: 0.322616\n",
      "[1400]\ttraining's binary_logloss: 0.117776\tvalid_1's binary_logloss: 0.318117\n",
      "[1500]\ttraining's binary_logloss: 0.108515\tvalid_1's binary_logloss: 0.317922\n",
      "[1600]\ttraining's binary_logloss: 0.0999534\tvalid_1's binary_logloss: 0.315463\n",
      "[1700]\ttraining's binary_logloss: 0.092114\tvalid_1's binary_logloss: 0.314118\n",
      "[1800]\ttraining's binary_logloss: 0.0850504\tvalid_1's binary_logloss: 0.314335\n",
      "[1900]\ttraining's binary_logloss: 0.0788368\tvalid_1's binary_logloss: 0.315348\n",
      "[2000]\ttraining's binary_logloss: 0.0728837\tvalid_1's binary_logloss: 0.316287\n",
      "[2100]\ttraining's binary_logloss: 0.0673091\tvalid_1's binary_logloss: 0.317384\n",
      "[2200]\ttraining's binary_logloss: 0.0619969\tvalid_1's binary_logloss: 0.318226\n",
      "[2300]\ttraining's binary_logloss: 0.0572271\tvalid_1's binary_logloss: 0.31855\n",
      "[2400]\ttraining's binary_logloss: 0.0529371\tvalid_1's binary_logloss: 0.317603\n",
      "[2500]\ttraining's binary_logloss: 0.048954\tvalid_1's binary_logloss: 0.316893\n",
      "[2600]\ttraining's binary_logloss: 0.0454225\tvalid_1's binary_logloss: 0.316717\n",
      "[2700]\ttraining's binary_logloss: 0.0421601\tvalid_1's binary_logloss: 0.316322\n",
      "[2800]\ttraining's binary_logloss: 0.0390666\tvalid_1's binary_logloss: 0.314867\n",
      "[2900]\ttraining's binary_logloss: 0.0362514\tvalid_1's binary_logloss: 0.313101\n",
      "[3000]\ttraining's binary_logloss: 0.0336001\tvalid_1's binary_logloss: 0.312759\n",
      "[3100]\ttraining's binary_logloss: 0.0312693\tvalid_1's binary_logloss: 0.312459\n",
      "[3200]\ttraining's binary_logloss: 0.0290735\tvalid_1's binary_logloss: 0.313819\n",
      "[3300]\ttraining's binary_logloss: 0.0269289\tvalid_1's binary_logloss: 0.315443\n",
      "[3400]\ttraining's binary_logloss: 0.0250118\tvalid_1's binary_logloss: 0.315395\n",
      "[3500]\ttraining's binary_logloss: 0.0232396\tvalid_1's binary_logloss: 0.315605\n",
      "[3600]\ttraining's binary_logloss: 0.0216436\tvalid_1's binary_logloss: 0.317825\n",
      "[3700]\ttraining's binary_logloss: 0.0201053\tvalid_1's binary_logloss: 0.320795\n",
      "[3800]\ttraining's binary_logloss: 0.0186628\tvalid_1's binary_logloss: 0.32285\n",
      "[3900]\ttraining's binary_logloss: 0.0172921\tvalid_1's binary_logloss: 0.324239\n",
      "[4000]\ttraining's binary_logloss: 0.0161146\tvalid_1's binary_logloss: 0.323958\n",
      "[4100]\ttraining's binary_logloss: 0.015067\tvalid_1's binary_logloss: 0.326398\n",
      "[4200]\ttraining's binary_logloss: 0.0141152\tvalid_1's binary_logloss: 0.327506\n",
      "[4300]\ttraining's binary_logloss: 0.0132505\tvalid_1's binary_logloss: 0.329461\n",
      "[4400]\ttraining's binary_logloss: 0.0124464\tvalid_1's binary_logloss: 0.33191\n",
      "[4500]\ttraining's binary_logloss: 0.0116736\tvalid_1's binary_logloss: 0.334282\n",
      "[4600]\ttraining's binary_logloss: 0.0109397\tvalid_1's binary_logloss: 0.336781\n",
      "[4700]\ttraining's binary_logloss: 0.0102587\tvalid_1's binary_logloss: 0.338173\n",
      "[4800]\ttraining's binary_logloss: 0.0095979\tvalid_1's binary_logloss: 0.340141\n",
      "[4900]\ttraining's binary_logloss: 0.00897567\tvalid_1's binary_logloss: 0.340414\n",
      "[5000]\ttraining's binary_logloss: 0.00838111\tvalid_1's binary_logloss: 0.342054\n",
      "Partial score of fold 3 is: 0.3420541914548099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.520995\tvalid_1's binary_logloss: 0.550529\n",
      "[200]\ttraining's binary_logloss: 0.428301\tvalid_1's binary_logloss: 0.482539\n",
      "[300]\ttraining's binary_logloss: 0.370495\tvalid_1's binary_logloss: 0.44349\n",
      "[400]\ttraining's binary_logloss: 0.32689\tvalid_1's binary_logloss: 0.419965\n",
      "[500]\ttraining's binary_logloss: 0.291105\tvalid_1's binary_logloss: 0.40552\n",
      "[600]\ttraining's binary_logloss: 0.259566\tvalid_1's binary_logloss: 0.392561\n",
      "[700]\ttraining's binary_logloss: 0.232466\tvalid_1's binary_logloss: 0.383419\n",
      "[800]\ttraining's binary_logloss: 0.208329\tvalid_1's binary_logloss: 0.379485\n",
      "[900]\ttraining's binary_logloss: 0.188449\tvalid_1's binary_logloss: 0.377105\n",
      "[1000]\ttraining's binary_logloss: 0.170009\tvalid_1's binary_logloss: 0.375973\n",
      "[1100]\ttraining's binary_logloss: 0.153917\tvalid_1's binary_logloss: 0.377917\n",
      "[1200]\ttraining's binary_logloss: 0.140276\tvalid_1's binary_logloss: 0.379374\n",
      "[1300]\ttraining's binary_logloss: 0.128355\tvalid_1's binary_logloss: 0.382319\n",
      "[1400]\ttraining's binary_logloss: 0.118143\tvalid_1's binary_logloss: 0.383809\n",
      "[1500]\ttraining's binary_logloss: 0.108965\tvalid_1's binary_logloss: 0.386201\n",
      "[1600]\ttraining's binary_logloss: 0.100202\tvalid_1's binary_logloss: 0.38903\n",
      "[1700]\ttraining's binary_logloss: 0.0922534\tvalid_1's binary_logloss: 0.392424\n",
      "[1800]\ttraining's binary_logloss: 0.0845726\tvalid_1's binary_logloss: 0.397004\n",
      "[1900]\ttraining's binary_logloss: 0.0775138\tvalid_1's binary_logloss: 0.399884\n",
      "[2000]\ttraining's binary_logloss: 0.0713154\tvalid_1's binary_logloss: 0.403151\n",
      "[2100]\ttraining's binary_logloss: 0.0651536\tvalid_1's binary_logloss: 0.408654\n",
      "[2200]\ttraining's binary_logloss: 0.0598825\tvalid_1's binary_logloss: 0.413165\n",
      "[2300]\ttraining's binary_logloss: 0.0553103\tvalid_1's binary_logloss: 0.417226\n",
      "[2400]\ttraining's binary_logloss: 0.0511461\tvalid_1's binary_logloss: 0.425606\n",
      "[2500]\ttraining's binary_logloss: 0.0471827\tvalid_1's binary_logloss: 0.432473\n",
      "[2600]\ttraining's binary_logloss: 0.0435114\tvalid_1's binary_logloss: 0.439477\n",
      "[2700]\ttraining's binary_logloss: 0.0403194\tvalid_1's binary_logloss: 0.443704\n",
      "[2800]\ttraining's binary_logloss: 0.0373896\tvalid_1's binary_logloss: 0.44894\n",
      "[2900]\ttraining's binary_logloss: 0.0347743\tvalid_1's binary_logloss: 0.453977\n",
      "[3000]\ttraining's binary_logloss: 0.0322636\tvalid_1's binary_logloss: 0.458354\n",
      "[3100]\ttraining's binary_logloss: 0.0300604\tvalid_1's binary_logloss: 0.464133\n",
      "[3200]\ttraining's binary_logloss: 0.0279031\tvalid_1's binary_logloss: 0.469358\n",
      "[3300]\ttraining's binary_logloss: 0.0259129\tvalid_1's binary_logloss: 0.475094\n",
      "[3400]\ttraining's binary_logloss: 0.0241391\tvalid_1's binary_logloss: 0.480627\n",
      "[3500]\ttraining's binary_logloss: 0.0224463\tvalid_1's binary_logloss: 0.4852\n",
      "[3600]\ttraining's binary_logloss: 0.0208798\tvalid_1's binary_logloss: 0.490999\n",
      "[3700]\ttraining's binary_logloss: 0.0193961\tvalid_1's binary_logloss: 0.496829\n",
      "[3800]\ttraining's binary_logloss: 0.0179339\tvalid_1's binary_logloss: 0.498478\n",
      "[3900]\ttraining's binary_logloss: 0.016608\tvalid_1's binary_logloss: 0.502547\n",
      "[4000]\ttraining's binary_logloss: 0.0154531\tvalid_1's binary_logloss: 0.506562\n",
      "[4100]\ttraining's binary_logloss: 0.0144352\tvalid_1's binary_logloss: 0.510705\n",
      "[4200]\ttraining's binary_logloss: 0.0134564\tvalid_1's binary_logloss: 0.514678\n",
      "[4300]\ttraining's binary_logloss: 0.0126105\tvalid_1's binary_logloss: 0.519878\n",
      "[4400]\ttraining's binary_logloss: 0.0118238\tvalid_1's binary_logloss: 0.527707\n",
      "[4500]\ttraining's binary_logloss: 0.0110622\tvalid_1's binary_logloss: 0.534707\n",
      "[4600]\ttraining's binary_logloss: 0.0103431\tvalid_1's binary_logloss: 0.539437\n",
      "[4700]\ttraining's binary_logloss: 0.00969154\tvalid_1's binary_logloss: 0.545096\n",
      "[4800]\ttraining's binary_logloss: 0.00909398\tvalid_1's binary_logloss: 0.551258\n",
      "[4900]\ttraining's binary_logloss: 0.00852626\tvalid_1's binary_logloss: 0.555764\n",
      "[5000]\ttraining's binary_logloss: 0.00801194\tvalid_1's binary_logloss: 0.55817\n",
      "Partial score of fold 4 is: 0.5581703418702959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.521819\tvalid_1's binary_logloss: 0.536742\n",
      "[200]\ttraining's binary_logloss: 0.427774\tvalid_1's binary_logloss: 0.458685\n",
      "[300]\ttraining's binary_logloss: 0.36932\tvalid_1's binary_logloss: 0.409735\n",
      "[400]\ttraining's binary_logloss: 0.324173\tvalid_1's binary_logloss: 0.383873\n",
      "[500]\ttraining's binary_logloss: 0.286741\tvalid_1's binary_logloss: 0.370743\n",
      "[600]\ttraining's binary_logloss: 0.257263\tvalid_1's binary_logloss: 0.364307\n",
      "[700]\ttraining's binary_logloss: 0.229812\tvalid_1's binary_logloss: 0.352819\n",
      "[800]\ttraining's binary_logloss: 0.204941\tvalid_1's binary_logloss: 0.342704\n",
      "[900]\ttraining's binary_logloss: 0.185552\tvalid_1's binary_logloss: 0.336509\n",
      "[1000]\ttraining's binary_logloss: 0.169126\tvalid_1's binary_logloss: 0.332739\n",
      "[1100]\ttraining's binary_logloss: 0.153915\tvalid_1's binary_logloss: 0.329805\n",
      "[1200]\ttraining's binary_logloss: 0.140022\tvalid_1's binary_logloss: 0.327643\n",
      "[1300]\ttraining's binary_logloss: 0.127479\tvalid_1's binary_logloss: 0.328232\n",
      "[1400]\ttraining's binary_logloss: 0.11669\tvalid_1's binary_logloss: 0.330686\n",
      "[1500]\ttraining's binary_logloss: 0.106437\tvalid_1's binary_logloss: 0.331669\n",
      "[1600]\ttraining's binary_logloss: 0.0971869\tvalid_1's binary_logloss: 0.333086\n",
      "[1700]\ttraining's binary_logloss: 0.0888413\tvalid_1's binary_logloss: 0.336091\n",
      "[1800]\ttraining's binary_logloss: 0.0813738\tvalid_1's binary_logloss: 0.340206\n",
      "[1900]\ttraining's binary_logloss: 0.0743593\tvalid_1's binary_logloss: 0.34096\n",
      "[2000]\ttraining's binary_logloss: 0.0683133\tvalid_1's binary_logloss: 0.343704\n",
      "[2100]\ttraining's binary_logloss: 0.0625496\tvalid_1's binary_logloss: 0.345631\n",
      "[2200]\ttraining's binary_logloss: 0.0573376\tvalid_1's binary_logloss: 0.348647\n",
      "[2300]\ttraining's binary_logloss: 0.0529226\tvalid_1's binary_logloss: 0.350798\n",
      "[2400]\ttraining's binary_logloss: 0.048814\tvalid_1's binary_logloss: 0.353011\n",
      "[2500]\ttraining's binary_logloss: 0.0452004\tvalid_1's binary_logloss: 0.355912\n",
      "[2600]\ttraining's binary_logloss: 0.0416767\tvalid_1's binary_logloss: 0.358529\n",
      "[2700]\ttraining's binary_logloss: 0.0385249\tvalid_1's binary_logloss: 0.36206\n",
      "[2800]\ttraining's binary_logloss: 0.0355144\tvalid_1's binary_logloss: 0.364637\n",
      "[2900]\ttraining's binary_logloss: 0.0326717\tvalid_1's binary_logloss: 0.366995\n",
      "[3000]\ttraining's binary_logloss: 0.0300412\tvalid_1's binary_logloss: 0.36875\n",
      "[3100]\ttraining's binary_logloss: 0.0278762\tvalid_1's binary_logloss: 0.37243\n",
      "[3200]\ttraining's binary_logloss: 0.0258876\tvalid_1's binary_logloss: 0.375817\n",
      "[3300]\ttraining's binary_logloss: 0.0240095\tvalid_1's binary_logloss: 0.379586\n",
      "[3400]\ttraining's binary_logloss: 0.0222723\tvalid_1's binary_logloss: 0.381892\n",
      "[3500]\ttraining's binary_logloss: 0.020699\tvalid_1's binary_logloss: 0.383086\n",
      "[3600]\ttraining's binary_logloss: 0.0192327\tvalid_1's binary_logloss: 0.384968\n",
      "[3700]\ttraining's binary_logloss: 0.0179147\tvalid_1's binary_logloss: 0.387343\n",
      "[3800]\ttraining's binary_logloss: 0.0166879\tvalid_1's binary_logloss: 0.389571\n",
      "[3900]\ttraining's binary_logloss: 0.0155435\tvalid_1's binary_logloss: 0.392477\n",
      "[4000]\ttraining's binary_logloss: 0.0145054\tvalid_1's binary_logloss: 0.395977\n",
      "[4100]\ttraining's binary_logloss: 0.0135182\tvalid_1's binary_logloss: 0.399808\n",
      "[4200]\ttraining's binary_logloss: 0.0126343\tvalid_1's binary_logloss: 0.403686\n",
      "[4300]\ttraining's binary_logloss: 0.0117783\tvalid_1's binary_logloss: 0.407642\n",
      "[4400]\ttraining's binary_logloss: 0.0110309\tvalid_1's binary_logloss: 0.412094\n",
      "[4500]\ttraining's binary_logloss: 0.0103393\tvalid_1's binary_logloss: 0.414337\n",
      "[4600]\ttraining's binary_logloss: 0.00967504\tvalid_1's binary_logloss: 0.417033\n",
      "[4700]\ttraining's binary_logloss: 0.00906181\tvalid_1's binary_logloss: 0.419559\n",
      "[4800]\ttraining's binary_logloss: 0.00848033\tvalid_1's binary_logloss: 0.423969\n",
      "[4900]\ttraining's binary_logloss: 0.00792034\tvalid_1's binary_logloss: 0.429587\n",
      "[5000]\ttraining's binary_logloss: 0.00742526\tvalid_1's binary_logloss: 0.434953\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-76a35c432443>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Predicting {season}...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     lgbm = LgbModel(train.loc[train[\"Season\"] < season, :], test.loc[test[\"Season\"] == season, :], target, features, categoricals=categoricals, n_splits=10, \n\u001b[1;32m----> 5\u001b[1;33m                     cv_method=\"StratifiedKFold\", group=None, task=\"classification\", scaler=None, verbose=True)\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseason\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Season\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mseason\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Pred\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-6bfb03ce0130>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, train_df, test_df, target, features, categoricals, n_splits, cv_method, group, task, parameter_tuning, scaler, verbose)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moof\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfi_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-6bfb03ce0130>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0moof_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_x_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moof_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Partial score of fold {} is: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moof_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[0;32m   2413\u001b[0m         return predictor.predict(data, num_iteration,\n\u001b[0;32m   2414\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2415\u001b[1;33m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[0;32m   2416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2417\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[1;34m(self, mat, num_iteration, predict_type)\u001b[0m\n\u001b[0;32m    621\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__pred_for_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[1;34m(mat, num_iteration, predict_type, preds)\u001b[0m\n\u001b[0;32m    603\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_parameter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_num_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m                 preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[0;32m    606\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_preds\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mout_num_preds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Wrong length for predict results\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# other\n",
    "for season in test[\"Season\"].unique():\n",
    "    print(f\"Predicting {season}...\")\n",
    "    lgbm = LgbModel(train.loc[train[\"Season\"] < season, :], test.loc[test[\"Season\"] == season, :], target, features, categoricals=[], n_splits=10, \n",
    "                    cv_method=\"StratifiedKFold\", group=None, task=\"binary\", scaler=None, verbose=True)\n",
    "    models[season] = lgbm\n",
    "    test.loc[test[\"Season\"] == season, \"Pred\"] = lgbm.y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.051043\n",
       "1        0.091716\n",
       "2        0.000101\n",
       "3        0.048542\n",
       "4        0.049260\n",
       "           ...   \n",
       "10075    0.761587\n",
       "10076    0.983058\n",
       "10077    0.212244\n",
       "10078    0.243313\n",
       "10079    0.974453\n",
       "Name: Pred, Length: 10080, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lgbm.y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h2o = pd.read_csv(os.path.join(path, 'NCAAW_h2o.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>0.051043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>0.091716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>0.048542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>0.049260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10075</th>\n",
       "      <td>2019_3413_3417</td>\n",
       "      <td>0.761587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10076</th>\n",
       "      <td>2019_3413_3460</td>\n",
       "      <td>0.983058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10077</th>\n",
       "      <td>2019_3416_3417</td>\n",
       "      <td>0.212244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>2019_3416_3460</td>\n",
       "      <td>0.243313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10079</th>\n",
       "      <td>2019_3417_3460</td>\n",
       "      <td>0.974453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10080 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID      Pred\n",
       "0      2015_3106_3107  0.051043\n",
       "1      2015_3106_3110  0.091716\n",
       "2      2015_3106_3113  0.000101\n",
       "3      2015_3106_3114  0.048542\n",
       "4      2015_3106_3116  0.049260\n",
       "...               ...       ...\n",
       "10075  2019_3413_3417  0.761587\n",
       "10076  2019_3413_3460  0.983058\n",
       "10077  2019_3416_3417  0.212244\n",
       "10078  2019_3416_3460  0.243313\n",
       "10079  2019_3417_3460  0.974453\n",
       "\n",
       "[10080 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(os.path.join(path, 'WSampleSubmissionStage1_2020.csv'))\n",
    "submission['Pred'] = test['Pred']\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('NCAAW_Ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Season = pd.merge(SeasonCompactResults, SeasonDetailedResults, how = 'left',\n",
    "              on=['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc', 'NumOT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>WFGA3</th>\n",
       "      <th>WFTM</th>\n",
       "      <th>WFTA</th>\n",
       "      <th>WOR</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WAst</th>\n",
       "      <th>WTO</th>\n",
       "      <th>WStl</th>\n",
       "      <th>WBlk</th>\n",
       "      <th>WPF</th>\n",
       "      <th>LFGM</th>\n",
       "      <th>LFGA</th>\n",
       "      <th>LFGM3</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>18</td>\n",
       "      <td>3104</td>\n",
       "      <td>91</td>\n",
       "      <td>3202</td>\n",
       "      <td>41</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>18</td>\n",
       "      <td>3163</td>\n",
       "      <td>87</td>\n",
       "      <td>3221</td>\n",
       "      <td>76</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>18</td>\n",
       "      <td>3222</td>\n",
       "      <td>66</td>\n",
       "      <td>3261</td>\n",
       "      <td>59</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>18</td>\n",
       "      <td>3307</td>\n",
       "      <td>69</td>\n",
       "      <td>3365</td>\n",
       "      <td>62</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>18</td>\n",
       "      <td>3349</td>\n",
       "      <td>115</td>\n",
       "      <td>3411</td>\n",
       "      <td>35</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
       "0    1998      18     3104      91     3202      41    H      0   NaN   NaN   \n",
       "1    1998      18     3163      87     3221      76    H      0   NaN   NaN   \n",
       "2    1998      18     3222      66     3261      59    H      0   NaN   NaN   \n",
       "3    1998      18     3307      69     3365      62    H      0   NaN   NaN   \n",
       "4    1998      18     3349     115     3411      35    H      0   NaN   NaN   \n",
       "\n",
       "   WFGM3  WFGA3  WFTM  WFTA  WOR  WDR  WAst  WTO  WStl  WBlk  WPF  LFGM  LFGA  \\\n",
       "0    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "1    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "2    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "3    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "4    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   \n",
       "\n",
       "   LFGM3  LFGA3  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF  \n",
       "0    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN  \n",
       "1    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN  \n",
       "2    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN  \n",
       "3    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN  \n",
       "4    NaN    NaN   NaN   NaN  NaN  NaN   NaN  NaN   NaN   NaN  NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Season.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split winners and losers\n",
    "team_win_score = Season.groupby(['Season', 'WTeamID']).agg({'WScore':['sum', 'count', 'var']}).reset_index()\n",
    "team_win_score.columns = [' '.join(col).strip() for col in team_win_score.columns.values]\n",
    "team_loss_score = Season.groupby(['Season', 'LTeamID']).agg({'LScore':['sum', 'count', 'var']}).reset_index()\n",
    "team_loss_score.columns = [' '.join(col).strip() for col in team_loss_score.columns.values]\n",
    "\n",
    "train = pd.merge(train, team_win_score, how='left', left_on=['Season', 'WTeamID'], right_on=['Season', 'WTeamID'])\n",
    "train = pd.merge(train, team_loss_score, how='left', left_on=['Season', 'LTeamID'], right_on=['Season', 'LTeamID'])\n",
    "train = pd.merge(train, team_loss_score, how='left', left_on=['Season', 'WTeamID'], right_on=['Season', 'LTeamID'])\n",
    "train = pd.merge(train, team_win_score, how='left', left_on=['Season', 'LTeamID_x'], right_on=['Season', 'WTeamID'])\n",
    "train.drop(['LTeamID_y', 'WTeamID_y'], axis=1, inplace=True)\n",
    "\n",
    "test = pd.merge(test, team_win_score, how='left', left_on=['Season', 'WTeamID'], right_on=['Season', 'WTeamID'])\n",
    "test = pd.merge(test, team_loss_score, how='left', left_on=['Season', 'LTeamID'], right_on=['Season', 'LTeamID'])\n",
    "test = pd.merge(test, team_loss_score, how='left', left_on=['Season', 'WTeamID'], right_on=['Season', 'LTeamID'])\n",
    "test = pd.merge(test, team_win_score, how='left', left_on=['Season', 'LTeamID_x'], right_on=['Season', 'WTeamID'])\n",
    "test.drop(['LTeamID_y', 'WTeamID_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th colspan=\"3\" halign=\"left\">WScore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>3102</td>\n",
       "      <td>263</td>\n",
       "      <td>4</td>\n",
       "      <td>108.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>3103</td>\n",
       "      <td>842</td>\n",
       "      <td>11</td>\n",
       "      <td>96.872727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>3104</td>\n",
       "      <td>1657</td>\n",
       "      <td>21</td>\n",
       "      <td>146.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>3106</td>\n",
       "      <td>421</td>\n",
       "      <td>6</td>\n",
       "      <td>78.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>3108</td>\n",
       "      <td>898</td>\n",
       "      <td>12</td>\n",
       "      <td>42.878788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Season WTeamID WScore                  \n",
       "                    sum count         var\n",
       "0   1998    3102    263     4  108.916667\n",
       "1   1998    3103    842    11   96.872727\n",
       "2   1998    3104   1657    21  146.190476\n",
       "3   1998    3106    421     6   78.566667\n",
       "4   1998    3108    898    12   42.878788"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split winners and losers\n",
    "team_win_score = Season.groupby(['Season', 'WTeamID']).agg({'WScore':['sum', 'count', 'var']}).reset_index()\n",
    "team_win_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_win_score.columns = [' '.join(col).strip() for col in team_win_score.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore sum</th>\n",
       "      <th>WScore count</th>\n",
       "      <th>WScore var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>3102</td>\n",
       "      <td>263</td>\n",
       "      <td>4</td>\n",
       "      <td>108.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>3103</td>\n",
       "      <td>842</td>\n",
       "      <td>11</td>\n",
       "      <td>96.872727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>3104</td>\n",
       "      <td>1657</td>\n",
       "      <td>21</td>\n",
       "      <td>146.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>3106</td>\n",
       "      <td>421</td>\n",
       "      <td>6</td>\n",
       "      <td>78.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>3108</td>\n",
       "      <td>898</td>\n",
       "      <td>12</td>\n",
       "      <td>42.878788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  WTeamID  WScore sum  WScore count  WScore var\n",
       "0    1998     3102         263             4  108.916667\n",
       "1    1998     3103         842            11   96.872727\n",
       "2    1998     3104        1657            21  146.190476\n",
       "3    1998     3106         421             6   78.566667\n",
       "4    1998     3108         898            12   42.878788"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_win_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_loss_score = Season.groupby(['Season', 'LTeamID']).agg({'LScore':['sum', 'count', 'var']}).reset_index()\n",
    "team_loss_score.columns = [' '.join(col).strip() for col in team_loss_score.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del Season\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7337, 5)\n"
     ]
    }
   ],
   "source": [
    "print(team_win_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7342, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore sum</th>\n",
       "      <th>LScore count</th>\n",
       "      <th>LScore var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>3102</td>\n",
       "      <td>1112</td>\n",
       "      <td>20</td>\n",
       "      <td>89.515789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>3103</td>\n",
       "      <td>1166</td>\n",
       "      <td>18</td>\n",
       "      <td>138.771242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>3104</td>\n",
       "      <td>640</td>\n",
       "      <td>9</td>\n",
       "      <td>131.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>3106</td>\n",
       "      <td>865</td>\n",
       "      <td>15</td>\n",
       "      <td>95.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>3108</td>\n",
       "      <td>662</td>\n",
       "      <td>11</td>\n",
       "      <td>59.363636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  LTeamID  LScore sum  LScore count  LScore var\n",
       "0    1998     3102        1112            20   89.515789\n",
       "1    1998     3103        1166            18  138.771242\n",
       "2    1998     3104         640             9  131.111111\n",
       "3    1998     3106         865            15   95.809524\n",
       "4    1998     3108         662            11   59.363636"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(team_loss_score.shape)\n",
    "team_loss_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID_x</th>\n",
       "      <th>LTeamID_x</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>State</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>RegionW</th>\n",
       "      <th>RegionX</th>\n",
       "      <th>RegionY</th>\n",
       "      <th>RegionZ</th>\n",
       "      <th>TeamName_W</th>\n",
       "      <th>TeamName_L</th>\n",
       "      <th>Seed_W</th>\n",
       "      <th>Seed_L</th>\n",
       "      <th>WScore sum_x</th>\n",
       "      <th>WScore count_x</th>\n",
       "      <th>WScore var_x</th>\n",
       "      <th>LScore sum_x</th>\n",
       "      <th>LScore count_x</th>\n",
       "      <th>LScore var_x</th>\n",
       "      <th>LScore sum_y</th>\n",
       "      <th>LScore count_y</th>\n",
       "      <th>LScore var_y</th>\n",
       "      <th>WScore sum_y</th>\n",
       "      <th>WScore count_y</th>\n",
       "      <th>WScore var_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3104</td>\n",
       "      <td>3422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>UNC Greensboro</td>\n",
       "      <td>X02</td>\n",
       "      <td>X15</td>\n",
       "      <td>1657</td>\n",
       "      <td>21</td>\n",
       "      <td>146.190476</td>\n",
       "      <td>496.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>85.142857</td>\n",
       "      <td>640.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>131.111111</td>\n",
       "      <td>1514</td>\n",
       "      <td>19</td>\n",
       "      <td>59.561404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3112</td>\n",
       "      <td>3365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>W03</td>\n",
       "      <td>W14</td>\n",
       "      <td>1708</td>\n",
       "      <td>21</td>\n",
       "      <td>122.433333</td>\n",
       "      <td>387.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>408.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>154.800000</td>\n",
       "      <td>1757</td>\n",
       "      <td>22</td>\n",
       "      <td>160.504329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3163</td>\n",
       "      <td>3193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>W02</td>\n",
       "      <td>W15</td>\n",
       "      <td>2557</td>\n",
       "      <td>30</td>\n",
       "      <td>197.081609</td>\n",
       "      <td>462.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>108.214286</td>\n",
       "      <td>139.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1488</td>\n",
       "      <td>20</td>\n",
       "      <td>106.147368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3198</td>\n",
       "      <td>3266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Florida Intl</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>Y07</td>\n",
       "      <td>Y10</td>\n",
       "      <td>2270</td>\n",
       "      <td>28</td>\n",
       "      <td>113.920635</td>\n",
       "      <td>415.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>148.966667</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1492</td>\n",
       "      <td>20</td>\n",
       "      <td>46.252632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3203</td>\n",
       "      <td>3208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>G Washington</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>W10</td>\n",
       "      <td>W07</td>\n",
       "      <td>1283</td>\n",
       "      <td>17</td>\n",
       "      <td>110.014706</td>\n",
       "      <td>598.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>104.527778</td>\n",
       "      <td>535.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>51.777778</td>\n",
       "      <td>1398</td>\n",
       "      <td>17</td>\n",
       "      <td>100.441176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID_x  LTeamID_x CRType City  CityID State     DayZero  \\\n",
       "0    1998     137       3104       3422    NaN  NaN     NaN   NaN  10/27/1997   \n",
       "1    1998     137       3112       3365    NaN  NaN     NaN   NaN  10/27/1997   \n",
       "2    1998     137       3163       3193    NaN  NaN     NaN   NaN  10/27/1997   \n",
       "3    1998     137       3198       3266    NaN  NaN     NaN   NaN  10/27/1997   \n",
       "4    1998     137       3203       3208    NaN  NaN     NaN   NaN  10/27/1997   \n",
       "\n",
       "  RegionW  RegionX  RegionY RegionZ    TeamName_W      TeamName_L Seed_W  \\\n",
       "0    East  Midwest  Mideast    West       Alabama  UNC Greensboro    X02   \n",
       "1    East  Midwest  Mideast    West       Arizona     Santa Clara    W03   \n",
       "2    East  Midwest  Mideast    West   Connecticut       Fairfield    W02   \n",
       "3    East  Midwest  Mideast    West  Florida Intl       Marquette    Y07   \n",
       "4    East  Midwest  Mideast    West  G Washington         Georgia    W10   \n",
       "\n",
       "  Seed_L  WScore sum_x  WScore count_x  WScore var_x  LScore sum_x  \\\n",
       "0    X15          1657              21    146.190476         496.0   \n",
       "1    W14          1708              21    122.433333         387.0   \n",
       "2    W15          2557              30    197.081609         462.0   \n",
       "3    Y10          2270              28    113.920635         415.0   \n",
       "4    W07          1283              17    110.014706         598.0   \n",
       "\n",
       "   LScore count_x  LScore var_x  LScore sum_y  LScore count_y  LScore var_y  \\\n",
       "0             8.0     85.142857         640.0             9.0    131.111111   \n",
       "1             6.0     87.500000         408.0             6.0    154.800000   \n",
       "2             8.0    108.214286         139.0             2.0      0.500000   \n",
       "3             6.0    148.966667          67.0             1.0           NaN   \n",
       "4             9.0    104.527778         535.0             9.0     51.777778   \n",
       "\n",
       "   WScore sum_y  WScore count_y  WScore var_y  \n",
       "0          1514              19     59.561404  \n",
       "1          1757              22    160.504329  \n",
       "2          1488              20    106.147368  \n",
       "3          1492              20     46.252632  \n",
       "4          1398              17    100.441176  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge with train \n",
    "train = pd.merge(train, team_win_score, how='left', left_on=['Season', 'WTeamID'], right_on=['Season', 'WTeamID'])\n",
    "train = pd.merge(train, team_loss_score, how='left', left_on=['Season', 'LTeamID'], right_on=['Season', 'LTeamID'])\n",
    "train = pd.merge(train, team_loss_score, how='left', left_on=['Season', 'WTeamID'], right_on=['Season', 'LTeamID'])\n",
    "train = pd.merge(train, team_win_score, how='left', left_on=['Season', 'LTeamID_x'], right_on=['Season', 'WTeamID'])\n",
    "train.drop(['LTeamID_y', 'WTeamID_y'], axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>WTeamID_x</th>\n",
       "      <th>LTeamID_x</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>State</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>RegionW</th>\n",
       "      <th>RegionX</th>\n",
       "      <th>RegionY</th>\n",
       "      <th>RegionZ</th>\n",
       "      <th>TeamName_W</th>\n",
       "      <th>TeamName_L</th>\n",
       "      <th>Seed_W</th>\n",
       "      <th>Seed_L</th>\n",
       "      <th>WScore sum_x</th>\n",
       "      <th>WScore count_x</th>\n",
       "      <th>WScore var_x</th>\n",
       "      <th>LScore sum_x</th>\n",
       "      <th>LScore count_x</th>\n",
       "      <th>LScore var_x</th>\n",
       "      <th>LScore sum_y</th>\n",
       "      <th>LScore count_y</th>\n",
       "      <th>LScore var_y</th>\n",
       "      <th>WScore sum_y</th>\n",
       "      <th>WScore count_y</th>\n",
       "      <th>WScore var_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>SUNY Albany</td>\n",
       "      <td>Y15</td>\n",
       "      <td>X13</td>\n",
       "      <td>885</td>\n",
       "      <td>14</td>\n",
       "      <td>32.950549</td>\n",
       "      <td>460.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>50.857143</td>\n",
       "      <td>807.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>122.247253</td>\n",
       "      <td>1761</td>\n",
       "      <td>24</td>\n",
       "      <td>122.244565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>American Univ</td>\n",
       "      <td>Y15</td>\n",
       "      <td>Z14</td>\n",
       "      <td>885</td>\n",
       "      <td>14</td>\n",
       "      <td>32.950549</td>\n",
       "      <td>469.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.696429</td>\n",
       "      <td>807.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>122.247253</td>\n",
       "      <td>1558</td>\n",
       "      <td>24</td>\n",
       "      <td>96.514493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>Arizona St</td>\n",
       "      <td>Y15</td>\n",
       "      <td>Y03</td>\n",
       "      <td>885</td>\n",
       "      <td>14</td>\n",
       "      <td>32.950549</td>\n",
       "      <td>283.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.300000</td>\n",
       "      <td>807.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>122.247253</td>\n",
       "      <td>1891</td>\n",
       "      <td>27</td>\n",
       "      <td>126.498575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>Ark Little Rock</td>\n",
       "      <td>Y15</td>\n",
       "      <td>Y11</td>\n",
       "      <td>885</td>\n",
       "      <td>14</td>\n",
       "      <td>32.950549</td>\n",
       "      <td>231.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.916667</td>\n",
       "      <td>807.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>122.247253</td>\n",
       "      <td>1858</td>\n",
       "      <td>28</td>\n",
       "      <td>78.534392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>2015</td>\n",
       "      <td>3106</td>\n",
       "      <td>3116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/2014</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>OklahomaCity</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Y15</td>\n",
       "      <td>Z10</td>\n",
       "      <td>885</td>\n",
       "      <td>14</td>\n",
       "      <td>32.950549</td>\n",
       "      <td>692.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>83.692308</td>\n",
       "      <td>807.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>122.247253</td>\n",
       "      <td>1117</td>\n",
       "      <td>17</td>\n",
       "      <td>89.220588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Season  WTeamID_x  LTeamID_x CRType City  CityID  DayNum  \\\n",
       "0  2015_3106_3107    2015       3106       3107    NaN  NaN     NaN     NaN   \n",
       "1  2015_3106_3110    2015       3106       3110    NaN  NaN     NaN     NaN   \n",
       "2  2015_3106_3113    2015       3106       3113    NaN  NaN     NaN     NaN   \n",
       "3  2015_3106_3114    2015       3106       3114    NaN  NaN     NaN     NaN   \n",
       "4  2015_3106_3116    2015       3106       3116    NaN  NaN     NaN     NaN   \n",
       "\n",
       "  State    DayZero RegionW  RegionX     RegionY       RegionZ  TeamName_W  \\\n",
       "0   NaN  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "1   NaN  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "2   NaN  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "3   NaN  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "4   NaN  11/3/2014  Albany  Spokane  Greensboro  OklahomaCity  Alabama St   \n",
       "\n",
       "        TeamName_L Seed_W Seed_L  WScore sum_x  WScore count_x  WScore var_x  \\\n",
       "0      SUNY Albany    Y15    X13           885              14     32.950549   \n",
       "1    American Univ    Y15    Z14           885              14     32.950549   \n",
       "2       Arizona St    Y15    Y03           885              14     32.950549   \n",
       "3  Ark Little Rock    Y15    Y11           885              14     32.950549   \n",
       "4         Arkansas    Y15    Z10           885              14     32.950549   \n",
       "\n",
       "   LScore sum_x  LScore count_x  LScore var_x  LScore sum_y  LScore count_y  \\\n",
       "0         460.0             8.0     50.857143         807.0            14.0   \n",
       "1         469.0             8.0     29.696429         807.0            14.0   \n",
       "2         283.0             5.0     28.300000         807.0            14.0   \n",
       "3         231.0             4.0    130.916667         807.0            14.0   \n",
       "4         692.0            13.0     83.692308         807.0            14.0   \n",
       "\n",
       "   LScore var_y  WScore sum_y  WScore count_y  WScore var_y  \n",
       "0    122.247253          1761              24    122.244565  \n",
       "1    122.247253          1558              24     96.514493  \n",
       "2    122.247253          1891              27    126.498575  \n",
       "3    122.247253          1858              28     78.534392  \n",
       "4    122.247253          1117              17     89.220588  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge with test \n",
    "test = pd.merge(test, team_win_score, how='left', left_on=['Season', 'WTeamID'], right_on=['Season', 'WTeamID'])\n",
    "test = pd.merge(test, team_loss_score, how='left', left_on=['Season', 'LTeamID'], right_on=['Season', 'LTeamID'])\n",
    "test = pd.merge(test, team_loss_score, how='left', left_on=['Season', 'WTeamID'], right_on=['Season', 'LTeamID'])\n",
    "test = pd.merge(test, team_win_score, how='left', left_on=['Season', 'LTeamID_x'], right_on=['Season', 'WTeamID'])\n",
    "test.drop(['LTeamID_y', 'WTeamID_y'], axis=1, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition(table):\n",
    "    table['x_score'] = table['WScore sum_x'] + table['LScore sum_y']\n",
    "    table['y_score'] = table['WScore sum_y'] + table['LScore sum_x']\n",
    "    table['x_count'] = table['WScore count_x'] + table['LScore count_y']\n",
    "    table['y_count'] = table['WScore count_y'] + table['WScore count_x']\n",
    "    table['x_var'] = table['WScore var_x'] + table['LScore var_y']\n",
    "    table['y_var'] = table['WScore var_y'] + table['WScore var_x']\n",
    "    return table\n",
    "train = addition(train)\n",
    "test = addition(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID_x</th>\n",
       "      <th>LTeamID_x</th>\n",
       "      <th>CRType</th>\n",
       "      <th>City</th>\n",
       "      <th>CityID</th>\n",
       "      <th>State</th>\n",
       "      <th>DayZero</th>\n",
       "      <th>RegionW</th>\n",
       "      <th>RegionX</th>\n",
       "      <th>RegionY</th>\n",
       "      <th>RegionZ</th>\n",
       "      <th>TeamName_W</th>\n",
       "      <th>TeamName_L</th>\n",
       "      <th>Seed_W</th>\n",
       "      <th>Seed_L</th>\n",
       "      <th>WScore sum_x</th>\n",
       "      <th>WScore count_x</th>\n",
       "      <th>WScore var_x</th>\n",
       "      <th>LScore sum_x</th>\n",
       "      <th>LScore count_x</th>\n",
       "      <th>LScore var_x</th>\n",
       "      <th>LScore sum_y</th>\n",
       "      <th>LScore count_y</th>\n",
       "      <th>LScore var_y</th>\n",
       "      <th>WScore sum_y</th>\n",
       "      <th>WScore count_y</th>\n",
       "      <th>WScore var_y</th>\n",
       "      <th>x_score</th>\n",
       "      <th>y_score</th>\n",
       "      <th>x_count</th>\n",
       "      <th>y_count</th>\n",
       "      <th>x_var</th>\n",
       "      <th>y_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3104</td>\n",
       "      <td>3422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>UNC Greensboro</td>\n",
       "      <td>X02</td>\n",
       "      <td>X15</td>\n",
       "      <td>1657</td>\n",
       "      <td>21</td>\n",
       "      <td>146.190476</td>\n",
       "      <td>496.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>85.142857</td>\n",
       "      <td>640.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>131.111111</td>\n",
       "      <td>1514</td>\n",
       "      <td>19</td>\n",
       "      <td>59.561404</td>\n",
       "      <td>2297.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40</td>\n",
       "      <td>277.301587</td>\n",
       "      <td>205.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3112</td>\n",
       "      <td>3365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>W03</td>\n",
       "      <td>W14</td>\n",
       "      <td>1708</td>\n",
       "      <td>21</td>\n",
       "      <td>122.433333</td>\n",
       "      <td>387.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>408.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>154.800000</td>\n",
       "      <td>1757</td>\n",
       "      <td>22</td>\n",
       "      <td>160.504329</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>2144.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>43</td>\n",
       "      <td>277.233333</td>\n",
       "      <td>282.937662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3163</td>\n",
       "      <td>3193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>W02</td>\n",
       "      <td>W15</td>\n",
       "      <td>2557</td>\n",
       "      <td>30</td>\n",
       "      <td>197.081609</td>\n",
       "      <td>462.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>108.214286</td>\n",
       "      <td>139.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1488</td>\n",
       "      <td>20</td>\n",
       "      <td>106.147368</td>\n",
       "      <td>2696.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>50</td>\n",
       "      <td>197.581609</td>\n",
       "      <td>303.228978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3198</td>\n",
       "      <td>3266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>Florida Intl</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>Y07</td>\n",
       "      <td>Y10</td>\n",
       "      <td>2270</td>\n",
       "      <td>28</td>\n",
       "      <td>113.920635</td>\n",
       "      <td>415.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>148.966667</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1492</td>\n",
       "      <td>20</td>\n",
       "      <td>46.252632</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.173266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>137</td>\n",
       "      <td>3203</td>\n",
       "      <td>3208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/1997</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Mideast</td>\n",
       "      <td>West</td>\n",
       "      <td>G Washington</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>W10</td>\n",
       "      <td>W07</td>\n",
       "      <td>1283</td>\n",
       "      <td>17</td>\n",
       "      <td>110.014706</td>\n",
       "      <td>598.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>104.527778</td>\n",
       "      <td>535.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>51.777778</td>\n",
       "      <td>1398</td>\n",
       "      <td>17</td>\n",
       "      <td>100.441176</td>\n",
       "      <td>1818.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>34</td>\n",
       "      <td>161.792484</td>\n",
       "      <td>210.455882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID_x  LTeamID_x CRType City  CityID State     DayZero  \\\n",
       "0    1998     137       3104       3422    NaN  NaN     NaN   NaN  10/27/1997   \n",
       "1    1998     137       3112       3365    NaN  NaN     NaN   NaN  10/27/1997   \n",
       "2    1998     137       3163       3193    NaN  NaN     NaN   NaN  10/27/1997   \n",
       "3    1998     137       3198       3266    NaN  NaN     NaN   NaN  10/27/1997   \n",
       "4    1998     137       3203       3208    NaN  NaN     NaN   NaN  10/27/1997   \n",
       "\n",
       "  RegionW  RegionX  RegionY RegionZ    TeamName_W      TeamName_L Seed_W  \\\n",
       "0    East  Midwest  Mideast    West       Alabama  UNC Greensboro    X02   \n",
       "1    East  Midwest  Mideast    West       Arizona     Santa Clara    W03   \n",
       "2    East  Midwest  Mideast    West   Connecticut       Fairfield    W02   \n",
       "3    East  Midwest  Mideast    West  Florida Intl       Marquette    Y07   \n",
       "4    East  Midwest  Mideast    West  G Washington         Georgia    W10   \n",
       "\n",
       "  Seed_L  WScore sum_x  WScore count_x  WScore var_x  LScore sum_x  \\\n",
       "0    X15          1657              21    146.190476         496.0   \n",
       "1    W14          1708              21    122.433333         387.0   \n",
       "2    W15          2557              30    197.081609         462.0   \n",
       "3    Y10          2270              28    113.920635         415.0   \n",
       "4    W07          1283              17    110.014706         598.0   \n",
       "\n",
       "   LScore count_x  LScore var_x  LScore sum_y  LScore count_y  LScore var_y  \\\n",
       "0             8.0     85.142857         640.0             9.0    131.111111   \n",
       "1             6.0     87.500000         408.0             6.0    154.800000   \n",
       "2             8.0    108.214286         139.0             2.0      0.500000   \n",
       "3             6.0    148.966667          67.0             1.0           NaN   \n",
       "4             9.0    104.527778         535.0             9.0     51.777778   \n",
       "\n",
       "   WScore sum_y  WScore count_y  WScore var_y  x_score  y_score  x_count  \\\n",
       "0          1514              19     59.561404   2297.0   2010.0     30.0   \n",
       "1          1757              22    160.504329   2116.0   2144.0     27.0   \n",
       "2          1488              20    106.147368   2696.0   1950.0     32.0   \n",
       "3          1492              20     46.252632   2337.0   1907.0     29.0   \n",
       "4          1398              17    100.441176   1818.0   1996.0     26.0   \n",
       "\n",
       "   y_count       x_var       y_var  \n",
       "0       40  277.301587  205.751880  \n",
       "1       43  277.233333  282.937662  \n",
       "2       50  197.581609  303.228978  \n",
       "3       48         NaN  160.173266  \n",
       "4       34  161.792484  210.455882  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make winner and loser train\n",
    "train_win = train.copy()\n",
    "train_los = train.copy()\n",
    "train_win = train_win[['Seed_W', 'Seed_L', 'TeamName_W', 'TeamName_L', \n",
    "                 'x_score', 'y_score', 'x_count', 'y_count', 'x_var', 'y_var']]\n",
    "train_los = train_los[['Seed_L', 'Seed_W', 'TeamName_L', 'TeamName_W', \n",
    "                 'y_score', 'x_score', 'x_count', 'y_count', 'x_var', 'y_var']]\n",
    "train_win.columns = ['Seed_1', 'Seed_2', 'TeamName_1', 'TeamName_2',\n",
    "                  'Score_1', 'Score_2', 'Count_1', 'Count_2', 'Var_1', 'Var_2']\n",
    "train_los.columns = ['Seed_1', 'Seed_2', 'TeamName_1', 'TeamName_2',\n",
    "                  'Score_1', 'Score_2', 'Count_1', 'Count_2', 'Var_1', 'Var_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same processing for test\n",
    "test = test[['ID', 'Seed_W', 'Seed_L', 'TeamName_W', 'TeamName_L', \n",
    "                 'x_score', 'y_score', 'x_count', 'y_count', 'x_var', 'y_var']]\n",
    "test.columns = ['ID', 'Seed_1', 'Seed_2', 'TeamName_1', 'TeamName_2',\n",
    "                  'Score_1', 'Score_2', 'Count_1', 'Count_2', 'Var_1', 'Var_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seed(x):\n",
    "    return int(x[1:3])\n",
    "train_win['Seed_1'] = train_win['Seed_1'].map(lambda x: get_seed(x))\n",
    "train_win['Seed_2'] = train_win['Seed_2'].map(lambda x: get_seed(x))\n",
    "\n",
    "train_los['Seed_1'] = train_los['Seed_1'].map(lambda x: get_seed(x))\n",
    "train_los['Seed_2']= train_los['Seed_2'].map(lambda x: get_seed(x))\n",
    "\n",
    "test['Seed_1'] = test['Seed_1'].map(lambda x: get_seed(x))\n",
    "test['Seed_2']= test['Seed_2'].map(lambda x: get_seed(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_win[\"result\"] = 1\n",
    "train_los[\"result\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed_1</th>\n",
       "      <th>Seed_2</th>\n",
       "      <th>TeamName_1</th>\n",
       "      <th>TeamName_2</th>\n",
       "      <th>Score_1</th>\n",
       "      <th>Score_2</th>\n",
       "      <th>Count_1</th>\n",
       "      <th>Count_2</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Var_2</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>UNC Greensboro</td>\n",
       "      <td>2297.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40</td>\n",
       "      <td>277.301587</td>\n",
       "      <td>205.751880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>2144.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>43</td>\n",
       "      <td>277.233333</td>\n",
       "      <td>282.937662</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>2696.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>50</td>\n",
       "      <td>197.581609</td>\n",
       "      <td>303.228978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>Florida Intl</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.173266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>G Washington</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>1818.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>34</td>\n",
       "      <td>161.792484</td>\n",
       "      <td>210.455882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Seed_1  Seed_2    TeamName_1      TeamName_2  Score_1  Score_2  Count_1  \\\n",
       "0       2      15       Alabama  UNC Greensboro   2297.0   2010.0     30.0   \n",
       "1       3      14       Arizona     Santa Clara   2116.0   2144.0     27.0   \n",
       "2       2      15   Connecticut       Fairfield   2696.0   1950.0     32.0   \n",
       "3       7      10  Florida Intl       Marquette   2337.0   1907.0     29.0   \n",
       "4      10       7  G Washington         Georgia   1818.0   1996.0     26.0   \n",
       "\n",
       "   Count_2       Var_1       Var_2  result  \n",
       "0       40  277.301587  205.751880       1  \n",
       "1       43  277.233333  282.937662       1  \n",
       "2       50  197.581609  303.228978       1  \n",
       "3       48         NaN  160.173266       1  \n",
       "4       34  161.792484  210.455882       1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat((train_win, train_los)).reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMportant step ## Add more ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition2(table):\n",
    "    table['Seed_diff'] = table['Seed_1'] - table['Seed_2']\n",
    "    table['Score_diff'] = table['Score_1'] - table['Score_2']\n",
    "    table['Count_diff'] = table['Count_1'] - table['Count_2']\n",
    "    table['Var_diff'] = table['Var_1'] - table['Var_2']\n",
    "    table['Mean_score1'] = table['Score_1'] / table['Count_1']\n",
    "    table['Mean_score2'] = table['Score_2'] / table['Count_2']\n",
    "    table['Mean_score_diff'] = table['Mean_score1'] - table['Mean_score2']\n",
    "    table['FanoFactor_1'] = table['Var_1'] / table['Mean_score1']\n",
    "    table['FanoFactor_2'] = table['Var_2'] / table['Mean_score2']    \n",
    "    return table\n",
    "train = addition2(train)\n",
    "test = addition2(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed_1</th>\n",
       "      <th>Seed_2</th>\n",
       "      <th>TeamName_1</th>\n",
       "      <th>TeamName_2</th>\n",
       "      <th>Score_1</th>\n",
       "      <th>Score_2</th>\n",
       "      <th>Count_1</th>\n",
       "      <th>Count_2</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Var_2</th>\n",
       "      <th>result</th>\n",
       "      <th>Seed_diff</th>\n",
       "      <th>Score_diff</th>\n",
       "      <th>Count_diff</th>\n",
       "      <th>Var_diff</th>\n",
       "      <th>Mean_score1</th>\n",
       "      <th>Mean_score2</th>\n",
       "      <th>Mean_score_diff</th>\n",
       "      <th>FanoFactor_1</th>\n",
       "      <th>FanoFactor_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>UNC Greensboro</td>\n",
       "      <td>2297.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40</td>\n",
       "      <td>277.301587</td>\n",
       "      <td>205.751880</td>\n",
       "      <td>1</td>\n",
       "      <td>-13</td>\n",
       "      <td>287.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>71.549708</td>\n",
       "      <td>76.566667</td>\n",
       "      <td>50.250000</td>\n",
       "      <td>26.316667</td>\n",
       "      <td>3.621701</td>\n",
       "      <td>4.094565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>2144.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>43</td>\n",
       "      <td>277.233333</td>\n",
       "      <td>282.937662</td>\n",
       "      <td>1</td>\n",
       "      <td>-11</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-5.704329</td>\n",
       "      <td>78.370370</td>\n",
       "      <td>49.860465</td>\n",
       "      <td>28.509905</td>\n",
       "      <td>3.537476</td>\n",
       "      <td>5.674589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>2696.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>50</td>\n",
       "      <td>197.581609</td>\n",
       "      <td>303.228978</td>\n",
       "      <td>1</td>\n",
       "      <td>-13</td>\n",
       "      <td>746.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-105.647368</td>\n",
       "      <td>84.250000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>2.345182</td>\n",
       "      <td>7.775102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>Florida Intl</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.173266</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>430.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.586207</td>\n",
       "      <td>39.729167</td>\n",
       "      <td>40.857040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.031629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>G Washington</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>1818.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>34</td>\n",
       "      <td>161.792484</td>\n",
       "      <td>210.455882</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-48.663399</td>\n",
       "      <td>69.923077</td>\n",
       "      <td>58.705882</td>\n",
       "      <td>11.217195</td>\n",
       "      <td>2.313864</td>\n",
       "      <td>3.584920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Seed_1  Seed_2    TeamName_1      TeamName_2  Score_1  Score_2  Count_1  \\\n",
       "0       2      15       Alabama  UNC Greensboro   2297.0   2010.0     30.0   \n",
       "1       3      14       Arizona     Santa Clara   2116.0   2144.0     27.0   \n",
       "2       2      15   Connecticut       Fairfield   2696.0   1950.0     32.0   \n",
       "3       7      10  Florida Intl       Marquette   2337.0   1907.0     29.0   \n",
       "4      10       7  G Washington         Georgia   1818.0   1996.0     26.0   \n",
       "\n",
       "   Count_2       Var_1       Var_2  result  Seed_diff  Score_diff  Count_diff  \\\n",
       "0       40  277.301587  205.751880       1        -13       287.0       -10.0   \n",
       "1       43  277.233333  282.937662       1        -11       -28.0       -16.0   \n",
       "2       50  197.581609  303.228978       1        -13       746.0       -18.0   \n",
       "3       48         NaN  160.173266       1         -3       430.0       -19.0   \n",
       "4       34  161.792484  210.455882       1          3      -178.0        -8.0   \n",
       "\n",
       "     Var_diff  Mean_score1  Mean_score2  Mean_score_diff  FanoFactor_1  \\\n",
       "0   71.549708    76.566667    50.250000        26.316667      3.621701   \n",
       "1   -5.704329    78.370370    49.860465        28.509905      3.537476   \n",
       "2 -105.647368    84.250000    39.000000        45.250000      2.345182   \n",
       "3         NaN    80.586207    39.729167        40.857040           NaN   \n",
       "4  -48.663399    69.923077    58.705882        11.217195      2.313864   \n",
       "\n",
       "   FanoFactor_2  \n",
       "0      4.094565  \n",
       "1      5.674589  \n",
       "2      7.775102  \n",
       "3      4.031629  \n",
       "4      3.584920  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed_1</th>\n",
       "      <th>Seed_2</th>\n",
       "      <th>TeamName_1</th>\n",
       "      <th>TeamName_2</th>\n",
       "      <th>Score_1</th>\n",
       "      <th>Score_2</th>\n",
       "      <th>Count_1</th>\n",
       "      <th>Count_2</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Var_2</th>\n",
       "      <th>result</th>\n",
       "      <th>Seed_diff</th>\n",
       "      <th>Score_diff</th>\n",
       "      <th>Count_diff</th>\n",
       "      <th>Var_diff</th>\n",
       "      <th>Mean_score1</th>\n",
       "      <th>Mean_score2</th>\n",
       "      <th>Mean_score_diff</th>\n",
       "      <th>FanoFactor_1</th>\n",
       "      <th>FanoFactor_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>226</td>\n",
       "      <td>2297.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40</td>\n",
       "      <td>277.301587</td>\n",
       "      <td>205.751880</td>\n",
       "      <td>1</td>\n",
       "      <td>-13</td>\n",
       "      <td>287.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>71.549708</td>\n",
       "      <td>76.566667</td>\n",
       "      <td>50.250000</td>\n",
       "      <td>26.316667</td>\n",
       "      <td>3.621701</td>\n",
       "      <td>4.094565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>183</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>2144.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>43</td>\n",
       "      <td>277.233333</td>\n",
       "      <td>282.937662</td>\n",
       "      <td>1</td>\n",
       "      <td>-11</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-5.704329</td>\n",
       "      <td>78.370370</td>\n",
       "      <td>49.860465</td>\n",
       "      <td>28.509905</td>\n",
       "      <td>3.537476</td>\n",
       "      <td>5.674589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>62</td>\n",
       "      <td>2696.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>50</td>\n",
       "      <td>197.581609</td>\n",
       "      <td>303.228978</td>\n",
       "      <td>1</td>\n",
       "      <td>-13</td>\n",
       "      <td>746.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-105.647368</td>\n",
       "      <td>84.250000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>2.345182</td>\n",
       "      <td>7.775102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>115</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.173266</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>430.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.586207</td>\n",
       "      <td>39.729167</td>\n",
       "      <td>40.857040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.031629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>1818.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>34</td>\n",
       "      <td>161.792484</td>\n",
       "      <td>210.455882</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-48.663399</td>\n",
       "      <td>69.923077</td>\n",
       "      <td>58.705882</td>\n",
       "      <td>11.217195</td>\n",
       "      <td>2.313864</td>\n",
       "      <td>3.584920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Seed_1  Seed_2  TeamName_1  TeamName_2  Score_1  Score_2  Count_1  Count_2  \\\n",
       "0       2      15           2         226   2297.0   2010.0     30.0       40   \n",
       "1       3      14           7         183   2116.0   2144.0     27.0       43   \n",
       "2       2      15          40          62   2696.0   1950.0     32.0       50   \n",
       "3       7      10          65         115   2337.0   1907.0     29.0       48   \n",
       "4      10       7          70          73   1818.0   1996.0     26.0       34   \n",
       "\n",
       "        Var_1       Var_2  result  Seed_diff  Score_diff  Count_diff  \\\n",
       "0  277.301587  205.751880       1        -13       287.0       -10.0   \n",
       "1  277.233333  282.937662       1        -11       -28.0       -16.0   \n",
       "2  197.581609  303.228978       1        -13       746.0       -18.0   \n",
       "3         NaN  160.173266       1         -3       430.0       -19.0   \n",
       "4  161.792484  210.455882       1          3      -178.0        -8.0   \n",
       "\n",
       "     Var_diff  Mean_score1  Mean_score2  Mean_score_diff  FanoFactor_1  \\\n",
       "0   71.549708    76.566667    50.250000        26.316667      3.621701   \n",
       "1   -5.704329    78.370370    49.860465        28.509905      3.537476   \n",
       "2 -105.647368    84.250000    39.000000        45.250000      2.345182   \n",
       "3         NaN    80.586207    39.729167        40.857040           NaN   \n",
       "4  -48.663399    69.923077    58.705882        11.217195      2.313864   \n",
       "\n",
       "   FanoFactor_2  \n",
       "0      4.094565  \n",
       "1      5.674589  \n",
       "2      7.775102  \n",
       "3      4.031629  \n",
       "4      3.584920  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label encoding\n",
    "categoricals = [\"TeamName_1\", \"TeamName_2\"]\n",
    "for c in categoricals:\n",
    "    le = LabelEncoder()\n",
    "    train[c] = train[c].fillna(\"NaN\")\n",
    "    train[c] = le.fit_transform(train[c])\n",
    "    test[c] = le.transform(test[c])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Seed_1</th>\n",
       "      <th>Seed_2</th>\n",
       "      <th>TeamName_1</th>\n",
       "      <th>TeamName_2</th>\n",
       "      <th>Score_1</th>\n",
       "      <th>Score_2</th>\n",
       "      <th>Count_1</th>\n",
       "      <th>Count_2</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Var_2</th>\n",
       "      <th>Seed_diff</th>\n",
       "      <th>Score_diff</th>\n",
       "      <th>Count_diff</th>\n",
       "      <th>Var_diff</th>\n",
       "      <th>Mean_score1</th>\n",
       "      <th>Mean_score2</th>\n",
       "      <th>Mean_score_diff</th>\n",
       "      <th>FanoFactor_1</th>\n",
       "      <th>FanoFactor_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>2221.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38</td>\n",
       "      <td>155.197802</td>\n",
       "      <td>155.195115</td>\n",
       "      <td>2</td>\n",
       "      <td>-529.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>60.428571</td>\n",
       "      <td>58.447368</td>\n",
       "      <td>1.981203</td>\n",
       "      <td>2.568285</td>\n",
       "      <td>2.655297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38</td>\n",
       "      <td>155.197802</td>\n",
       "      <td>129.465042</td>\n",
       "      <td>1</td>\n",
       "      <td>-335.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>25.732760</td>\n",
       "      <td>60.428571</td>\n",
       "      <td>53.342105</td>\n",
       "      <td>7.086466</td>\n",
       "      <td>2.568285</td>\n",
       "      <td>2.427070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>41</td>\n",
       "      <td>155.197802</td>\n",
       "      <td>159.449125</td>\n",
       "      <td>12</td>\n",
       "      <td>-482.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-4.251323</td>\n",
       "      <td>60.428571</td>\n",
       "      <td>53.024390</td>\n",
       "      <td>7.404181</td>\n",
       "      <td>2.568285</td>\n",
       "      <td>3.007090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>42</td>\n",
       "      <td>155.197802</td>\n",
       "      <td>111.484941</td>\n",
       "      <td>4</td>\n",
       "      <td>-397.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>43.712861</td>\n",
       "      <td>60.428571</td>\n",
       "      <td>49.738095</td>\n",
       "      <td>10.690476</td>\n",
       "      <td>2.568285</td>\n",
       "      <td>2.241440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31</td>\n",
       "      <td>155.197802</td>\n",
       "      <td>122.171138</td>\n",
       "      <td>5</td>\n",
       "      <td>-117.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>33.026665</td>\n",
       "      <td>60.428571</td>\n",
       "      <td>58.354839</td>\n",
       "      <td>2.073733</td>\n",
       "      <td>2.568285</td>\n",
       "      <td>2.093591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Seed_1  Seed_2  TeamName_1  TeamName_2  Score_1  Score_2  \\\n",
       "0  2015_3106_3107      15      13           3         177   1692.0   2221.0   \n",
       "1  2015_3106_3110      15      14           3           5   1692.0   2027.0   \n",
       "2  2015_3106_3113      15       3           3           8   1692.0   2174.0   \n",
       "3  2015_3106_3114      15      11           3           9   1692.0   2089.0   \n",
       "4  2015_3106_3116      15      10           3          10   1692.0   1809.0   \n",
       "\n",
       "   Count_1  Count_2       Var_1       Var_2  Seed_diff  Score_diff  \\\n",
       "0     28.0       38  155.197802  155.195115          2      -529.0   \n",
       "1     28.0       38  155.197802  129.465042          1      -335.0   \n",
       "2     28.0       41  155.197802  159.449125         12      -482.0   \n",
       "3     28.0       42  155.197802  111.484941          4      -397.0   \n",
       "4     28.0       31  155.197802  122.171138          5      -117.0   \n",
       "\n",
       "   Count_diff   Var_diff  Mean_score1  Mean_score2  Mean_score_diff  \\\n",
       "0       -10.0   0.002688    60.428571    58.447368         1.981203   \n",
       "1       -10.0  25.732760    60.428571    53.342105         7.086466   \n",
       "2       -13.0  -4.251323    60.428571    53.024390         7.404181   \n",
       "3       -14.0  43.712861    60.428571    49.738095        10.690476   \n",
       "4        -3.0  33.026665    60.428571    58.354839         2.073733   \n",
       "\n",
       "   FanoFactor_1  FanoFactor_2  \n",
       "0      2.568285      2.655297  \n",
       "1      2.568285      2.427070  \n",
       "2      2.568285      3.007090  \n",
       "3      2.568285      2.241440  \n",
       "4      2.568285      2.093591  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\bokhy\\\\Desktop\\\\'\n",
    "train = pd.read_csv(os.path.join(path, 'NCAAW_train.csv'))\n",
    "test = pd.read_csv(os.path.join(path, 'NCAAW_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "    \"\"\"\n",
    "    Base Model Class\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_df, test_df, target, features, categoricals=[], \n",
    "                n_splits=3, cv_method=\"KFold\", group=None, task=\"regression\", \n",
    "                parameter_tuning=False, scaler=None, verbose=True):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.target = target\n",
    "        self.features = features\n",
    "        self.n_splits = n_splits\n",
    "        self.categoricals = categoricals\n",
    "        self.cv_method = cv_method\n",
    "        self.group = group\n",
    "        self.task = task\n",
    "        self.parameter_tuning = parameter_tuning\n",
    "        self.scaler = scaler\n",
    "        self.cv = self.get_cv()\n",
    "        self.verbose = verbose\n",
    "        self.params = self.get_params()\n",
    "        self.y_pred, self.score, self.model, self.oof, self.y_val, self.fi_df = self.fit()\n",
    "\n",
    "    def train_model(self, train_set, val_set):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_params(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def convert_x(self, x):\n",
    "        return x\n",
    "\n",
    "    def calc_metric(self, y_true, y_pred): # this may need to be changed based on the metric of interest\n",
    "        if self.task == \"classification\":\n",
    "            return log_loss(y_true, y_pred)\n",
    "        elif self.task == \"binary\":\n",
    "            return log_loss(y_true, y_pred)\n",
    "#             return roc_auc_score(y_true, y_pred)\n",
    "        elif self.task == \"regression\":\n",
    "            return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    def get_cv(self):\n",
    "        if self.cv_method == \"KFold\":\n",
    "            cv = KFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "            return cv.split(self.train_df)\n",
    "        elif self.cv_method == \"StratifiedKFold\":\n",
    "            cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "            return cv.split(self.train_df, self.train_df[self.target])\n",
    "        elif self.cv_method == \"TimeSeriesSplit\":\n",
    "            cv = TimeSeriesSplit(max_train_size=None, n_splits=self.n_splits)\n",
    "            return cv.split(self.train_df)\n",
    "        elif self.cv_method == \"GroupKFold\":\n",
    "            cv = GroupKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "            return cv.split(self.train_df, self.train_df[self.target], self.group)\n",
    "        elif self.cv_method == \"StratifiedGroupKFold\":\n",
    "            cv = StratifiedGroupKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "            return cv.split(self.train_df, self.train_df[self.target], self.group)\n",
    "\n",
    "    def fit(self):\n",
    "        # initialize\n",
    "        oof_pred = np.zeros((self.train_df.shape[0], ))\n",
    "        y_vals = np.zeros((self.train_df.shape[0], ))\n",
    "        y_pred = np.zeros((self.test_df.shape[0], ))\n",
    "        if self.group is not None:\n",
    "            if self.group in self.features:\n",
    "                self.features.remove(self.group)\n",
    "            if self.group in self.categoricals:\n",
    "                self.categoricals.remove(self.group)\n",
    "        fi = np.zeros((self.n_splits, len(self.features)))\n",
    "\n",
    "        # scaling, if necessary\n",
    "        if self.scaler is not None:\n",
    "            # fill NaN\n",
    "            numerical_features = [f for f in self.features if f not in self.categoricals]\n",
    "            self.train_df[numerical_features] = self.train_df[numerical_features].fillna(self.train_df[numerical_features].median())\n",
    "            self.test_df[numerical_features] = self.test_df[numerical_features].fillna(self.test_df[numerical_features].median())\n",
    "            self.train_df[self.categoricals] = self.train_df[self.categoricals].fillna(self.train_df[self.categoricals].mode().iloc[0])\n",
    "            self.test_df[self.categoricals] = self.test_df[self.categoricals].fillna(self.test_df[self.categoricals].mode().iloc[0])\n",
    "\n",
    "            # scaling\n",
    "            if self.scaler == \"MinMax\":\n",
    "                scaler = MinMaxScaler()\n",
    "            elif self.scaler == \"Standard\":\n",
    "                scaler = StandardScaler()\n",
    "            df = pd.concat([self.train_df[numerical_features], self.test_df[numerical_features]], ignore_index=True)\n",
    "            scaler.fit(df[numerical_features])\n",
    "            x_test = self.test_df.copy()\n",
    "            x_test[numerical_features] = scaler.transform(x_test[numerical_features])\n",
    "            x_test = [np.absolute(x_test[i]) for i in self.categoricals] + [x_test[numerical_features]]\n",
    "        else:\n",
    "            x_test = self.test_df[self.features]\n",
    "            \n",
    "        # fitting with out of fold\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv):\n",
    "            # train test split\n",
    "            x_train, x_val = self.train_df.loc[train_idx, self.features], self.train_df.loc[val_idx, self.features]\n",
    "            y_train, y_val = self.train_df.loc[train_idx, self.target], self.train_df.loc[val_idx, self.target]\n",
    "\n",
    "            # fitting & get feature importance\n",
    "            if self.scaler is not None:\n",
    "                x_train[numerical_features] = scaler.transform(x_train[numerical_features])\n",
    "                x_val[numerical_features] = scaler.transform(x_val[numerical_features])\n",
    "                x_train = [np.absolute(x_train[i]) for i in self.categoricals] + [x_train[numerical_features]]\n",
    "                x_val = [np.absolute(x_val[i]) for i in self.categoricals] + [x_val[numerical_features]]\n",
    "            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n",
    "            model, importance = self.train_model(train_set, val_set)\n",
    "            fi[fold, :] = importance\n",
    "            conv_x_val = self.convert_x(x_val)\n",
    "            y_vals[val_idx] = y_val\n",
    "            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n",
    "            x_test = self.convert_x(x_test)\n",
    "            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n",
    "            print('Partial score of fold {} is: {}'.format(fold, self.calc_metric(y_val, oof_pred[val_idx])))\n",
    "\n",
    "        # feature importance data frame\n",
    "        fi_df = pd.DataFrame()\n",
    "        for n in np.arange(self.n_splits):\n",
    "            tmp = pd.DataFrame()\n",
    "            tmp[\"features\"] = self.features\n",
    "            tmp[\"importance\"] = fi[n, :]\n",
    "            tmp[\"fold\"] = n\n",
    "            fi_df = pd.concat([fi_df, tmp], ignore_index=True)\n",
    "        gfi = fi_df[[\"features\", \"importance\"]].groupby([\"features\"]).mean().reset_index()\n",
    "        fi_df = fi_df.merge(gfi, on=\"features\", how=\"left\", suffixes=('', '_mean'))\n",
    "\n",
    "        # outputs\n",
    "        loss_score = self.calc_metric(self.train_df[self.target], oof_pred)\n",
    "        if self.verbose:\n",
    "            print('Our oof loss score is: ', loss_score)\n",
    "        return y_pred, loss_score, model, oof_pred, y_vals, fi_df\n",
    "\n",
    "    def plot_feature_importance(self, rank_range=[1, 50]):\n",
    "        # plot\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 20))\n",
    "        sorted_df = self.fi_df.sort_values(by = \"importance_mean\", ascending=False).reset_index().iloc[self.n_splits * (rank_range[0]-1) : self.n_splits * rank_range[1]]\n",
    "        sns.barplot(data=sorted_df, x =\"importance\", y =\"features\", orient='h')\n",
    "        ax.set_xlabel(\"feature importance\")\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LgbModel(BaseModel):\n",
    "\n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        model = lgb.train(self.params, train_set, num_boost_round = 10000, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n",
    "        fi = model.feature_importance(importance_type=\"gain\")\n",
    "        return model, fi\n",
    "\n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val, categorical_feature=self.categoricals)\n",
    "        return train_set, val_set\n",
    "\n",
    "    def get_params(self):\n",
    "        # params from https://www.kaggle.com/vbmokin/mm-2020-ncaam-simple-lightgbm-on-kfold-tuning\n",
    "        params = {\n",
    "          'objective': self.task,\n",
    "          'num_leaves': 127,\n",
    "          'min_data_in_leaf': 50,\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.005,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"verbosity\": -1,\n",
    "          'random_state': 42,\n",
    "         }\n",
    "        \n",
    "        if self.task == \"regression\":\n",
    "            params[\"objective\"] = \"regression\"\n",
    "            params[\"metric\"] = \"rmse\"\n",
    "        elif self.task == \"classification\":\n",
    "            params[\"objective\"] = \"binary\"\n",
    "            params[\"metric\"] = \"binary_logloss\"\n",
    "        \n",
    "        # Bayesian Optimization by Optuna\n",
    "        if self.parameter_tuning == True:\n",
    "            # define objective function\n",
    "            def objective(trial):\n",
    "                # train, test split\n",
    "                train_x, test_x, train_y, test_y = train_test_split(self.train_df[self.features], \n",
    "                                                                    self.train_df[self.target],\n",
    "                                                                    test_size=0.3, random_state=42)\n",
    "                dtrain = lgb.Dataset(train_x, train_y, categorical_feature=self.categoricals)\n",
    "                dtest = lgb.Dataset(test_x, test_y, categorical_feature=self.categoricals)\n",
    "\n",
    "                # parameters to be explored\n",
    "                hyperparams = {'num_leaves': trial.suggest_int('num_leaves', 24, 1024),\n",
    "                        'boosting_type': 'gbdt',\n",
    "                        'objective': params[\"objective\"],\n",
    "                        'metric': params[\"metric\"],\n",
    "                        'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
    "                        'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "                        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "                        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "                        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "                        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "                        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "                        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "                        'early_stopping_rounds': 100\n",
    "                        }\n",
    "\n",
    "                # LGB\n",
    "                model = lgb.train(hyperparams, dtrain, valid_sets=dtest, verbose_eval=500)\n",
    "                pred = model.predict(test_x)\n",
    "                if self.task == \"classification\":\n",
    "                    return log_loss(test_y, pred)\n",
    "                elif self.task == \"regression\":\n",
    "                    return np.sqrt(mean_squared_error(test_y, pred))\n",
    "\n",
    "            # run optimization\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            study.optimize(objective, n_trials=100)\n",
    "\n",
    "            print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "            print('Best trial:')\n",
    "            trial = study.best_trial\n",
    "            print('  Value: {}'.format(trial.value))\n",
    "            print('  Params: ')\n",
    "            for key, value in trial.params.items():\n",
    "                print('    {}: {}'.format(key, value))\n",
    "\n",
    "            params = trial.params\n",
    "\n",
    "            # lower learning rate for better accuracy\n",
    "            params[\"learning_rate\"] = 0.001\n",
    "\n",
    "            # plot history\n",
    "            plot_optimization_history(study)\n",
    "\n",
    "        return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('result', axis=1)\n",
    "y = train.result\n",
    "testdf = test.drop('ID', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X[features], y, test_size=0.2)\n",
    "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "    dtest = xgb.DMatrix(test_x, label=test_y)\n",
    "\n",
    "    param = {\n",
    "        'silent': 1,\n",
    "        'objective': 'binary:logistic',\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0)\n",
    "    }\n",
    "\n",
    "    if param['booster'] == 'gbtree' or param['booster'] == 'dart':\n",
    "        param['max_depth'] = trial.suggest_int('max_depth', 1, 100)\n",
    "        param['n_estimators'] = trial.suggest_int('n_estimators', 0, 10000)\n",
    "        param['min_child_weight'] = trial.suggest_int('min_child_weight', 1, 20)\n",
    "        param['scale_pos_weight'] = trial.suggest_int('scale_pos_weight', 1, 100)\n",
    "#        param['subsample'] = trial.suggest_discrete_uniform('subsample', 0.5, 0.9, 0.1)\n",
    "#        param['colsample_bytree'] = trial.suggest_discrete_uniform('colsample_bytree', 0.5, 0.9, 0.1)\n",
    "        param['eta'] = trial.suggest_loguniform('eta', 1e-8, 1.0)\n",
    "        param['gamma'] = trial.suggest_loguniform('gamma', 1e-8, 1.0)\n",
    "        param['grow_policy'] = trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide'])\n",
    "    if param['booster'] == 'dart':\n",
    "        param['sample_type'] = trial.suggest_categorical('sample_type', ['uniform', 'weighted'])\n",
    "        param['normalize_type'] = trial.suggest_categorical('normalize_type', ['tree', 'forest'])\n",
    "        param['rate_drop'] = trial.suggest_loguniform('rate_drop', 1e-8, 1.0)\n",
    "        param['skip_drop'] = trial.suggest_loguniform('skip_drop', 1e-8, 1.0)\n",
    "\n",
    "    bst = xgb.train(param, dtrain)\n",
    "    preds = bst.predict(dtest)\n",
    "    pred_labels = np.rint(preds)\n",
    "    mse = sklearn.metrics.mean_squared_error(test_y, pred_labels)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:06,602] Finished trial#0 resulted in value: 0.1958041958041958. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:06,692] Finished trial#1 resulted in value: 0.23251748251748253. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:06,840] Finished trial#2 resulted in value: 0.2867132867132867. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:06,931] Finished trial#3 resulted in value: 0.23426573426573427. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:07,020] Finished trial#4 resulted in value: 0.22727272727272727. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:07,115] Finished trial#5 resulted in value: 0.229020979020979. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:07,281] Finished trial#6 resulted in value: 0.2972027972027972. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:07,468] Finished trial#7 resulted in value: 0.25. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:07,557] Finished trial#8 resulted in value: 0.2395104895104895. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:07,699] Finished trial#9 resulted in value: 0.25. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:07,907] Finished trial#10 resulted in value: 0.3076923076923077. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:08,002] Finished trial#11 resulted in value: 0.229020979020979. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:08,090] Finished trial#12 resulted in value: 0.2097902097902098. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:08,184] Finished trial#13 resulted in value: 0.21328671328671328. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:08,270] Finished trial#14 resulted in value: 0.26223776223776224. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:08,450] Finished trial#15 resulted in value: 0.3741258741258741. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:08,544] Finished trial#16 resulted in value: 0.2202797202797203. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:08,635] Finished trial#17 resulted in value: 0.229020979020979. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:08,730] Finished trial#18 resulted in value: 0.21853146853146854. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:08,823] Finished trial#19 resulted in value: 0.21678321678321677. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:09,008] Finished trial#20 resulted in value: 0.33916083916083917. Current best value is 0.1958041958041958 with parameters: {'booster': 'gblinear', 'lambda': 5.0917321013677575e-05, 'alpha': 3.5617545288722005e-08}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:09,100] Finished trial#21 resulted in value: 0.18181818181818182. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:09,194] Finished trial#22 resulted in value: 0.20279720279720279. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:09,290] Finished trial#23 resulted in value: 0.22552447552447552. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:09,383] Finished trial#24 resulted in value: 0.22727272727272727. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:09,473] Finished trial#25 resulted in value: 0.1958041958041958. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:09,663] Finished trial#26 resulted in value: 0.3811188811188811. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:09,755] Finished trial#27 resulted in value: 0.21853146853146854. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:09,847] Finished trial#28 resulted in value: 0.22552447552447552. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:09,943] Finished trial#29 resulted in value: 0.22202797202797203. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:10,031] Finished trial#30 resulted in value: 0.2097902097902098. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:10,124] Finished trial#31 resulted in value: 0.21678321678321677. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:10,222] Finished trial#32 resulted in value: 0.21853146853146854. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:10,320] Finished trial#33 resulted in value: 0.229020979020979. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:10,417] Finished trial#34 resulted in value: 0.22377622377622378. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:10,610] Finished trial#35 resulted in value: 0.25. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:10,706] Finished trial#36 resulted in value: 0.21153846153846154. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:10,800] Finished trial#37 resulted in value: 0.23076923076923078. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:10,929] Finished trial#38 resulted in value: 0.25874125874125875. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:11,025] Finished trial#39 resulted in value: 0.243006993006993. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:11,122] Finished trial#40 resulted in value: 0.21328671328671328. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:11,219] Finished trial#41 resulted in value: 0.2202797202797203. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:11,314] Finished trial#42 resulted in value: 0.20804195804195805. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:11,411] Finished trial#43 resulted in value: 0.20454545454545456. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:11,509] Finished trial#44 resulted in value: 0.20454545454545456. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:11,606] Finished trial#45 resulted in value: 0.2097902097902098. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:11,828] Finished trial#46 resulted in value: 0.21153846153846154. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:12,018] Finished trial#47 resulted in value: 0.229020979020979. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:12,114] Finished trial#48 resulted in value: 0.22727272727272727. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:12,213] Finished trial#49 resulted in value: 0.229020979020979. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:12,309] Finished trial#50 resulted in value: 0.21503496503496503. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:12,394] Finished trial#51 resulted in value: 0.21153846153846154. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:12,487] Finished trial#52 resulted in value: 0.25. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:12,585] Finished trial#53 resulted in value: 0.2062937062937063. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:12,683] Finished trial#54 resulted in value: 0.19755244755244755. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:12,781] Finished trial#55 resulted in value: 0.21678321678321677. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:12,875] Finished trial#56 resulted in value: 0.23076923076923078. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:12,973] Finished trial#57 resulted in value: 0.2202797202797203. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:13,191] Finished trial#58 resulted in value: 0.2762237762237762. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:13,290] Finished trial#59 resulted in value: 0.22377622377622378. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:13,498] Finished trial#60 resulted in value: 0.243006993006993. Current best value is 0.18181818181818182 with parameters: {'booster': 'gblinear', 'lambda': 3.046682041224362e-07, 'alpha': 1.8436407664745187e-06}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:13,594] Finished trial#61 resulted in value: 0.17832167832167833. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:13,693] Finished trial#62 resulted in value: 0.23426573426573427. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:13,787] Finished trial#63 resulted in value: 0.23776223776223776. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:13,881] Finished trial#64 resulted in value: 0.20104895104895104. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:13,980] Finished trial#65 resulted in value: 0.21328671328671328. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:14,078] Finished trial#66 resulted in value: 0.21503496503496503. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:14,173] Finished trial#67 resulted in value: 0.21853146853146854. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:14,269] Finished trial#68 resulted in value: 0.20804195804195805. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:14,366] Finished trial#69 resulted in value: 0.2062937062937063. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:14,461] Finished trial#70 resulted in value: 0.2202797202797203. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:14,556] Finished trial#71 resulted in value: 0.22377622377622378. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:14,655] Finished trial#72 resulted in value: 0.1993006993006993. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:14,753] Finished trial#73 resulted in value: 0.2062937062937063. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:14,849] Finished trial#74 resulted in value: 0.20104895104895104. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:14,946] Finished trial#75 resulted in value: 0.2062937062937063. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:15,042] Finished trial#76 resulted in value: 0.22727272727272727. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:15,140] Finished trial#77 resulted in value: 0.2395104895104895. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:15,236] Finished trial#78 resulted in value: 0.21678321678321677. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:15,464] Finished trial#79 resulted in value: 0.2867132867132867. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:15,559] Finished trial#80 resulted in value: 0.21678321678321677. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:15,660] Finished trial#81 resulted in value: 0.20454545454545456. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:15,758] Finished trial#82 resulted in value: 0.20104895104895104. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:15,857] Finished trial#83 resulted in value: 0.22552447552447552. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:15,954] Finished trial#84 resulted in value: 0.21328671328671328. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:16,047] Finished trial#85 resulted in value: 0.21328671328671328. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:16,249] Finished trial#86 resulted in value: 0.22727272727272727. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:16,335] Finished trial#87 resulted in value: 0.22377622377622378. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:16,426] Finished trial#88 resulted in value: 0.22202797202797203. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:16,513] Finished trial#89 resulted in value: 0.2202797202797203. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:16,612] Finished trial#90 resulted in value: 0.22552447552447552. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:16,709] Finished trial#91 resulted in value: 0.20804195804195805. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:16,806] Finished trial#92 resulted in value: 0.2062937062937063. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:16,905] Finished trial#93 resulted in value: 0.21153846153846154. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:17,004] Finished trial#94 resulted in value: 0.22377622377622378. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:17,104] Finished trial#95 resulted in value: 0.20454545454545456. Current best value is 0.17832167832167833 with parameters: {'booster': 'gblinear', 'lambda': 2.7575534083932355e-06, 'alpha': 0.0009206121305383647}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:17,200] Finished trial#96 resulted in value: 0.17307692307692307. Current best value is 0.17307692307692307 with parameters: {'booster': 'gblinear', 'lambda': 0.00020707899904106472, 'alpha': 1.7315145105803258e-05}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:17,296] Finished trial#97 resulted in value: 0.23601398601398602. Current best value is 0.17307692307692307 with parameters: {'booster': 'gblinear', 'lambda': 0.00020707899904106472, 'alpha': 1.7315145105803258e-05}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:17,393] Finished trial#98 resulted in value: 0.1958041958041958. Current best value is 0.17307692307692307 with parameters: {'booster': 'gblinear', 'lambda': 0.00020707899904106472, 'alpha': 1.7315145105803258e-05}.\n",
      "c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[I 2020-02-22 12:05:17,489] Finished trial#99 resulted in value: 0.20279720279720279. Current best value is 0.17307692307692307 with parameters: {'booster': 'gblinear', 'lambda': 0.00020707899904106472, 'alpha': 1.7315145105803258e-05}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=96, value=0.17307692307692307, datetime_start=datetime.datetime(2020, 2, 22, 12, 5, 17, 106153), datetime_complete=datetime.datetime(2020, 2, 22, 12, 5, 17, 200900), params={'booster': 'gblinear', 'lambda': 0.00020707899904106472, 'alpha': 1.7315145105803258e-05}, distributions={'booster': CategoricalDistribution(choices=('gbtree', 'gblinear', 'dart')), 'lambda': LogUniformDistribution(high=1.0, low=1e-08), 'alpha': LogUniformDistribution(high=1.0, low=1e-08)}, user_attrs={}, system_attrs={'_number': 96}, intermediate_values={}, trial_id=96, state=TrialState.COMPLETE)\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 'gblinear',\n",
       " 'lambda': 0.00020707899904106472,\n",
       " 'alpha': 1.7315145105803258e-05}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "params = trial.params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {'colsample_bytree': 0.8,                 \n",
    "              'learning_rate': 0.001,\n",
    "              'max_depth': 30,\n",
    "              'subsample': 1,\n",
    "              'objective':'binary:logistic',\n",
    "              'eval_metric':'logloss',\n",
    "              'min_child_weight':2,\n",
    "              'gamma':0.25,\n",
    "              'n_estimators':5000\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "[0]\ttrain-logloss:0.693086\tval-logloss:0.693109\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681367\tval-logloss:0.686901\n",
      "[400]\ttrain-logloss:0.669977\tval-logloss:0.680923\n",
      "[600]\ttrain-logloss:0.658893\tval-logloss:0.675317\n",
      "[800]\ttrain-logloss:0.648149\tval-logloss:0.669869\n",
      "[1000]\ttrain-logloss:0.637729\tval-logloss:0.664652\n",
      "[1200]\ttrain-logloss:0.627616\tval-logloss:0.659624\n",
      "[1400]\ttrain-logloss:0.617774\tval-logloss:0.654804\n",
      "[1600]\ttrain-logloss:0.608171\tval-logloss:0.650146\n",
      "[1800]\ttrain-logloss:0.598819\tval-logloss:0.645573\n",
      "[2000]\ttrain-logloss:0.589721\tval-logloss:0.6412\n",
      "[2200]\ttrain-logloss:0.580874\tval-logloss:0.636962\n",
      "[2400]\ttrain-logloss:0.572256\tval-logloss:0.632913\n",
      "[2600]\ttrain-logloss:0.563847\tval-logloss:0.629109\n",
      "[2800]\ttrain-logloss:0.555667\tval-logloss:0.625406\n",
      "[3000]\ttrain-logloss:0.547704\tval-logloss:0.621777\n",
      "[3200]\ttrain-logloss:0.539927\tval-logloss:0.618372\n",
      "[3400]\ttrain-logloss:0.532324\tval-logloss:0.615087\n",
      "[3600]\ttrain-logloss:0.524908\tval-logloss:0.611988\n",
      "[3800]\ttrain-logloss:0.517666\tval-logloss:0.609148\n",
      "[4000]\ttrain-logloss:0.510589\tval-logloss:0.606188\n",
      "[4200]\ttrain-logloss:0.50366\tval-logloss:0.60336\n",
      "[4400]\ttrain-logloss:0.496883\tval-logloss:0.600649\n",
      "[4600]\ttrain-logloss:0.490292\tval-logloss:0.59807\n",
      "[4800]\ttrain-logloss:0.483842\tval-logloss:0.595554\n",
      "[5000]\ttrain-logloss:0.47752\tval-logloss:0.593188\n",
      "[5200]\ttrain-logloss:0.471338\tval-logloss:0.590935\n",
      "[5400]\ttrain-logloss:0.465303\tval-logloss:0.588819\n",
      "[5600]\ttrain-logloss:0.459399\tval-logloss:0.586723\n",
      "[5800]\ttrain-logloss:0.453618\tval-logloss:0.584777\n",
      "[6000]\ttrain-logloss:0.447967\tval-logloss:0.582849\n",
      "[6200]\ttrain-logloss:0.442433\tval-logloss:0.581025\n",
      "[6400]\ttrain-logloss:0.436996\tval-logloss:0.57929\n",
      "[6600]\ttrain-logloss:0.431669\tval-logloss:0.577471\n",
      "[6800]\ttrain-logloss:0.426439\tval-logloss:0.575643\n",
      "[7000]\ttrain-logloss:0.421318\tval-logloss:0.573761\n",
      "[7200]\ttrain-logloss:0.416319\tval-logloss:0.571915\n",
      "[7400]\ttrain-logloss:0.41142\tval-logloss:0.570127\n",
      "[7600]\ttrain-logloss:0.406619\tval-logloss:0.568489\n",
      "[7800]\ttrain-logloss:0.401896\tval-logloss:0.567048\n",
      "[8000]\ttrain-logloss:0.397261\tval-logloss:0.565731\n",
      "[8200]\ttrain-logloss:0.392715\tval-logloss:0.564443\n",
      "[8400]\ttrain-logloss:0.388249\tval-logloss:0.563199\n",
      "[8600]\ttrain-logloss:0.383881\tval-logloss:0.561997\n",
      "[8800]\ttrain-logloss:0.379585\tval-logloss:0.560908\n",
      "[9000]\ttrain-logloss:0.375346\tval-logloss:0.560025\n",
      "[9200]\ttrain-logloss:0.371193\tval-logloss:0.559264\n",
      "[9400]\ttrain-logloss:0.367102\tval-logloss:0.558472\n",
      "[9600]\ttrain-logloss:0.36308\tval-logloss:0.557681\n",
      "[9800]\ttrain-logloss:0.359153\tval-logloss:0.556932\n",
      "[9999]\ttrain-logloss:0.355296\tval-logloss:0.556234\n",
      "Fold: 2\n",
      "[0]\ttrain-logloss:0.693086\tval-logloss:0.693117\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681263\tval-logloss:0.687065\n",
      "[400]\ttrain-logloss:0.669789\tval-logloss:0.681202\n",
      "[600]\ttrain-logloss:0.658666\tval-logloss:0.675571\n",
      "[800]\ttrain-logloss:0.647918\tval-logloss:0.670067\n",
      "[1000]\ttrain-logloss:0.637487\tval-logloss:0.664687\n",
      "[1200]\ttrain-logloss:0.627358\tval-logloss:0.65955\n",
      "[1400]\ttrain-logloss:0.617519\tval-logloss:0.654677\n",
      "[1600]\ttrain-logloss:0.607901\tval-logloss:0.650101\n",
      "[1800]\ttrain-logloss:0.598572\tval-logloss:0.645648\n",
      "[2000]\ttrain-logloss:0.589526\tval-logloss:0.641053\n",
      "[2200]\ttrain-logloss:0.580726\tval-logloss:0.636537\n",
      "[2400]\ttrain-logloss:0.572147\tval-logloss:0.632218\n",
      "[2600]\ttrain-logloss:0.56378\tval-logloss:0.628099\n",
      "[2800]\ttrain-logloss:0.555621\tval-logloss:0.624098\n",
      "[3000]\ttrain-logloss:0.547652\tval-logloss:0.620373\n",
      "[3200]\ttrain-logloss:0.539872\tval-logloss:0.616815\n",
      "[3400]\ttrain-logloss:0.532288\tval-logloss:0.613335\n",
      "[3600]\ttrain-logloss:0.524899\tval-logloss:0.610017\n",
      "[3800]\ttrain-logloss:0.517695\tval-logloss:0.606837\n",
      "[4000]\ttrain-logloss:0.510658\tval-logloss:0.603675\n",
      "[4200]\ttrain-logloss:0.503768\tval-logloss:0.600576\n",
      "[4400]\ttrain-logloss:0.497056\tval-logloss:0.597568\n",
      "[4600]\ttrain-logloss:0.490496\tval-logloss:0.594804\n",
      "[4800]\ttrain-logloss:0.484098\tval-logloss:0.592088\n",
      "[5000]\ttrain-logloss:0.477832\tval-logloss:0.589478\n",
      "[5200]\ttrain-logloss:0.471677\tval-logloss:0.587097\n",
      "[5400]\ttrain-logloss:0.465678\tval-logloss:0.584704\n",
      "[5600]\ttrain-logloss:0.459798\tval-logloss:0.582351\n",
      "[5800]\ttrain-logloss:0.454032\tval-logloss:0.580016\n",
      "[6000]\ttrain-logloss:0.448385\tval-logloss:0.577763\n",
      "[6200]\ttrain-logloss:0.442857\tval-logloss:0.575525\n",
      "[6400]\ttrain-logloss:0.437442\tval-logloss:0.573339\n",
      "[6600]\ttrain-logloss:0.432136\tval-logloss:0.571191\n",
      "[6800]\ttrain-logloss:0.426924\tval-logloss:0.569231\n",
      "[7000]\ttrain-logloss:0.421813\tval-logloss:0.567489\n",
      "[7200]\ttrain-logloss:0.416787\tval-logloss:0.565785\n",
      "[7400]\ttrain-logloss:0.411867\tval-logloss:0.564174\n",
      "[7600]\ttrain-logloss:0.407\tval-logloss:0.562565\n",
      "[7800]\ttrain-logloss:0.402239\tval-logloss:0.561162\n",
      "[8000]\ttrain-logloss:0.397581\tval-logloss:0.559697\n",
      "[8200]\ttrain-logloss:0.393014\tval-logloss:0.558243\n",
      "[8400]\ttrain-logloss:0.38853\tval-logloss:0.556791\n",
      "[8600]\ttrain-logloss:0.384153\tval-logloss:0.555434\n",
      "[8800]\ttrain-logloss:0.379848\tval-logloss:0.554186\n",
      "[9000]\ttrain-logloss:0.375622\tval-logloss:0.552989\n",
      "[9200]\ttrain-logloss:0.371477\tval-logloss:0.551787\n",
      "[9400]\ttrain-logloss:0.367406\tval-logloss:0.550703\n",
      "[9600]\ttrain-logloss:0.363427\tval-logloss:0.549668\n",
      "[9800]\ttrain-logloss:0.359503\tval-logloss:0.548682\n",
      "[9999]\ttrain-logloss:0.355671\tval-logloss:0.547796\n",
      "Fold: 3\n",
      "[0]\ttrain-logloss:0.693086\tval-logloss:0.69311\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681385\tval-logloss:0.686095\n",
      "[400]\ttrain-logloss:0.670022\tval-logloss:0.679334\n",
      "[600]\ttrain-logloss:0.659009\tval-logloss:0.672819\n",
      "[800]\ttrain-logloss:0.648337\tval-logloss:0.666534\n",
      "[1000]\ttrain-logloss:0.63799\tval-logloss:0.660423\n",
      "[1200]\ttrain-logloss:0.627941\tval-logloss:0.654705\n",
      "[1400]\ttrain-logloss:0.61818\tval-logloss:0.649248\n",
      "[1600]\ttrain-logloss:0.608659\tval-logloss:0.643896\n",
      "[1800]\ttrain-logloss:0.599399\tval-logloss:0.638561\n",
      "[2000]\ttrain-logloss:0.590386\tval-logloss:0.633486\n",
      "[2200]\ttrain-logloss:0.581601\tval-logloss:0.628423\n",
      "[2400]\ttrain-logloss:0.573027\tval-logloss:0.623418\n",
      "[2600]\ttrain-logloss:0.564668\tval-logloss:0.618544\n",
      "[2800]\ttrain-logloss:0.556508\tval-logloss:0.613825\n",
      "[3000]\ttrain-logloss:0.548558\tval-logloss:0.609323\n",
      "[3200]\ttrain-logloss:0.540813\tval-logloss:0.604937\n",
      "[3400]\ttrain-logloss:0.533257\tval-logloss:0.600732\n",
      "[3600]\ttrain-logloss:0.525899\tval-logloss:0.59671\n",
      "[3800]\ttrain-logloss:0.518717\tval-logloss:0.592743\n",
      "[4000]\ttrain-logloss:0.511698\tval-logloss:0.588936\n",
      "[4200]\ttrain-logloss:0.504818\tval-logloss:0.585246\n",
      "[4400]\ttrain-logloss:0.498083\tval-logloss:0.581535\n",
      "[4600]\ttrain-logloss:0.491525\tval-logloss:0.577936\n",
      "[4800]\ttrain-logloss:0.485107\tval-logloss:0.574499\n",
      "[5000]\ttrain-logloss:0.478823\tval-logloss:0.571127\n",
      "[5200]\ttrain-logloss:0.47266\tval-logloss:0.567983\n",
      "[5400]\ttrain-logloss:0.466642\tval-logloss:0.564852\n",
      "[5600]\ttrain-logloss:0.460753\tval-logloss:0.561743\n",
      "[5800]\ttrain-logloss:0.454959\tval-logloss:0.558691\n",
      "[6000]\ttrain-logloss:0.449279\tval-logloss:0.555826\n",
      "[6200]\ttrain-logloss:0.443715\tval-logloss:0.552982\n",
      "[6400]\ttrain-logloss:0.438276\tval-logloss:0.55047\n",
      "[6600]\ttrain-logloss:0.432955\tval-logloss:0.548033\n",
      "[6800]\ttrain-logloss:0.427742\tval-logloss:0.545639\n",
      "[7000]\ttrain-logloss:0.422653\tval-logloss:0.543336\n",
      "[7200]\ttrain-logloss:0.417665\tval-logloss:0.54111\n",
      "[7400]\ttrain-logloss:0.412771\tval-logloss:0.538939\n",
      "[7600]\ttrain-logloss:0.407974\tval-logloss:0.536821\n",
      "[7800]\ttrain-logloss:0.403279\tval-logloss:0.534758\n",
      "[8000]\ttrain-logloss:0.398665\tval-logloss:0.53272\n",
      "[8200]\ttrain-logloss:0.394151\tval-logloss:0.530755\n",
      "[8400]\ttrain-logloss:0.3897\tval-logloss:0.528863\n",
      "[8600]\ttrain-logloss:0.385344\tval-logloss:0.526969\n",
      "[8800]\ttrain-logloss:0.381062\tval-logloss:0.525103\n",
      "[9000]\ttrain-logloss:0.37685\tval-logloss:0.523299\n",
      "[9200]\ttrain-logloss:0.372729\tval-logloss:0.521541\n",
      "[9400]\ttrain-logloss:0.368702\tval-logloss:0.519662\n",
      "[9600]\ttrain-logloss:0.364732\tval-logloss:0.517818\n",
      "[9800]\ttrain-logloss:0.360843\tval-logloss:0.516104\n",
      "[9999]\ttrain-logloss:0.357034\tval-logloss:0.514441\n",
      "Fold: 4\n",
      "[0]\ttrain-logloss:0.693087\tval-logloss:0.693114\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681382\tval-logloss:0.687077\n",
      "[400]\ttrain-logloss:0.669982\tval-logloss:0.681179\n",
      "[600]\ttrain-logloss:0.658892\tval-logloss:0.675417\n",
      "[800]\ttrain-logloss:0.648147\tval-logloss:0.669911\n",
      "[1000]\ttrain-logloss:0.637711\tval-logloss:0.664566\n",
      "[1200]\ttrain-logloss:0.627586\tval-logloss:0.659499\n",
      "[1400]\ttrain-logloss:0.617743\tval-logloss:0.654594\n",
      "[1600]\ttrain-logloss:0.608145\tval-logloss:0.649858\n",
      "[1800]\ttrain-logloss:0.598815\tval-logloss:0.645349\n",
      "[2000]\ttrain-logloss:0.589724\tval-logloss:0.640836\n",
      "[2200]\ttrain-logloss:0.58088\tval-logloss:0.636554\n",
      "[2400]\ttrain-logloss:0.572257\tval-logloss:0.632411\n",
      "[2600]\ttrain-logloss:0.563854\tval-logloss:0.62843\n",
      "[2800]\ttrain-logloss:0.555665\tval-logloss:0.624663\n",
      "[3000]\ttrain-logloss:0.547701\tval-logloss:0.620976\n",
      "[3200]\ttrain-logloss:0.539924\tval-logloss:0.617489\n",
      "[3400]\ttrain-logloss:0.532348\tval-logloss:0.61409\n",
      "[3600]\ttrain-logloss:0.524954\tval-logloss:0.610818\n",
      "[3800]\ttrain-logloss:0.51772\tval-logloss:0.607737\n",
      "[4000]\ttrain-logloss:0.510689\tval-logloss:0.604788\n",
      "[4200]\ttrain-logloss:0.503808\tval-logloss:0.602013\n",
      "[4400]\ttrain-logloss:0.4971\tval-logloss:0.599191\n",
      "[4600]\ttrain-logloss:0.490536\tval-logloss:0.596539\n",
      "[4800]\ttrain-logloss:0.484122\tval-logloss:0.593909\n",
      "[5000]\ttrain-logloss:0.477843\tval-logloss:0.591403\n",
      "[5200]\ttrain-logloss:0.471675\tval-logloss:0.588947\n",
      "[5400]\ttrain-logloss:0.465639\tval-logloss:0.586599\n",
      "[5600]\ttrain-logloss:0.459731\tval-logloss:0.584287\n",
      "[5800]\ttrain-logloss:0.453947\tval-logloss:0.581983\n",
      "[6000]\ttrain-logloss:0.448274\tval-logloss:0.579677\n",
      "[6200]\ttrain-logloss:0.442726\tval-logloss:0.577508\n",
      "[6400]\ttrain-logloss:0.437264\tval-logloss:0.575286\n",
      "[6600]\ttrain-logloss:0.431924\tval-logloss:0.573164\n",
      "[6800]\ttrain-logloss:0.426681\tval-logloss:0.571119\n",
      "[7000]\ttrain-logloss:0.421555\tval-logloss:0.569114\n",
      "[7200]\ttrain-logloss:0.41651\tval-logloss:0.567138\n",
      "[7400]\ttrain-logloss:0.411571\tval-logloss:0.565251\n",
      "[7600]\ttrain-logloss:0.40673\tval-logloss:0.563396\n",
      "[7800]\ttrain-logloss:0.401986\tval-logloss:0.56154\n",
      "[8000]\ttrain-logloss:0.397338\tval-logloss:0.559811\n",
      "[8200]\ttrain-logloss:0.392767\tval-logloss:0.558306\n",
      "[8400]\ttrain-logloss:0.388278\tval-logloss:0.556822\n",
      "[8600]\ttrain-logloss:0.383885\tval-logloss:0.555411\n",
      "[8800]\ttrain-logloss:0.379569\tval-logloss:0.553955\n",
      "[9000]\ttrain-logloss:0.375336\tval-logloss:0.552619\n",
      "[9200]\ttrain-logloss:0.371185\tval-logloss:0.551372\n",
      "[9400]\ttrain-logloss:0.367095\tval-logloss:0.550145\n",
      "[9600]\ttrain-logloss:0.363082\tval-logloss:0.548983\n",
      "[9800]\ttrain-logloss:0.359157\tval-logloss:0.547851\n",
      "[9999]\ttrain-logloss:0.355321\tval-logloss:0.546759\n",
      "Fold: 5\n",
      "[0]\ttrain-logloss:0.693087\tval-logloss:0.693111\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681416\tval-logloss:0.686024\n",
      "[400]\ttrain-logloss:0.670091\tval-logloss:0.679152\n",
      "[600]\ttrain-logloss:0.659092\tval-logloss:0.672564\n",
      "[800]\ttrain-logloss:0.648442\tval-logloss:0.66624\n",
      "[1000]\ttrain-logloss:0.638106\tval-logloss:0.660195\n",
      "[1200]\ttrain-logloss:0.628064\tval-logloss:0.654333\n",
      "[1400]\ttrain-logloss:0.618309\tval-logloss:0.648595\n",
      "[1600]\ttrain-logloss:0.608777\tval-logloss:0.643137\n",
      "[1800]\ttrain-logloss:0.599515\tval-logloss:0.637843\n",
      "[2000]\ttrain-logloss:0.590488\tval-logloss:0.632739\n",
      "[2200]\ttrain-logloss:0.58171\tval-logloss:0.627799\n",
      "[2400]\ttrain-logloss:0.573144\tval-logloss:0.623082\n",
      "[2600]\ttrain-logloss:0.56478\tval-logloss:0.618517\n",
      "[2800]\ttrain-logloss:0.556636\tval-logloss:0.614086\n",
      "[3000]\ttrain-logloss:0.548707\tval-logloss:0.609792\n",
      "[3200]\ttrain-logloss:0.540982\tval-logloss:0.605627\n",
      "[3400]\ttrain-logloss:0.533446\tval-logloss:0.601604\n",
      "[3600]\ttrain-logloss:0.526101\tval-logloss:0.597742\n",
      "[3800]\ttrain-logloss:0.518929\tval-logloss:0.594127\n",
      "[4000]\ttrain-logloss:0.511926\tval-logloss:0.590533\n",
      "[4200]\ttrain-logloss:0.505066\tval-logloss:0.586942\n",
      "[4400]\ttrain-logloss:0.498362\tval-logloss:0.583502\n",
      "[4600]\ttrain-logloss:0.491813\tval-logloss:0.580261\n",
      "[4800]\ttrain-logloss:0.48542\tval-logloss:0.577075\n",
      "[5000]\ttrain-logloss:0.479163\tval-logloss:0.574071\n",
      "[5200]\ttrain-logloss:0.473009\tval-logloss:0.571101\n",
      "[5400]\ttrain-logloss:0.466988\tval-logloss:0.568291\n",
      "[5600]\ttrain-logloss:0.461105\tval-logloss:0.565478\n",
      "[5800]\ttrain-logloss:0.455333\tval-logloss:0.56274\n",
      "[6000]\ttrain-logloss:0.449681\tval-logloss:0.560071\n",
      "[6200]\ttrain-logloss:0.444133\tval-logloss:0.557379\n",
      "[6400]\ttrain-logloss:0.438703\tval-logloss:0.554788\n",
      "[6600]\ttrain-logloss:0.433375\tval-logloss:0.552299\n",
      "[6800]\ttrain-logloss:0.428159\tval-logloss:0.549915\n",
      "[7000]\ttrain-logloss:0.423052\tval-logloss:0.547562\n",
      "[7200]\ttrain-logloss:0.418023\tval-logloss:0.545424\n",
      "[7400]\ttrain-logloss:0.413086\tval-logloss:0.543323\n",
      "[7600]\ttrain-logloss:0.408247\tval-logloss:0.541328\n",
      "[7800]\ttrain-logloss:0.403521\tval-logloss:0.539349\n",
      "[8000]\ttrain-logloss:0.398882\tval-logloss:0.537471\n",
      "[8200]\ttrain-logloss:0.394341\tval-logloss:0.535723\n",
      "[8400]\ttrain-logloss:0.38989\tval-logloss:0.534035\n",
      "[8600]\ttrain-logloss:0.385484\tval-logloss:0.532453\n",
      "[8800]\ttrain-logloss:0.381136\tval-logloss:0.531254\n",
      "[9000]\ttrain-logloss:0.376862\tval-logloss:0.530202\n",
      "[9200]\ttrain-logloss:0.372673\tval-logloss:0.529159\n",
      "[9400]\ttrain-logloss:0.368543\tval-logloss:0.528124\n",
      "[9600]\ttrain-logloss:0.364514\tval-logloss:0.527149\n",
      "[9800]\ttrain-logloss:0.360564\tval-logloss:0.526184\n",
      "[9999]\ttrain-logloss:0.356701\tval-logloss:0.525333\n",
      "Fold: 6\n",
      "[0]\ttrain-logloss:0.693087\tval-logloss:0.693109\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681468\tval-logloss:0.685062\n",
      "[400]\ttrain-logloss:0.670178\tval-logloss:0.677292\n",
      "[600]\ttrain-logloss:0.65921\tval-logloss:0.669802\n",
      "[800]\ttrain-logloss:0.648577\tval-logloss:0.662722\n",
      "[1000]\ttrain-logloss:0.638251\tval-logloss:0.655959\n",
      "[1200]\ttrain-logloss:0.628237\tval-logloss:0.649524\n",
      "[1400]\ttrain-logloss:0.618496\tval-logloss:0.643218\n",
      "[1600]\ttrain-logloss:0.609008\tval-logloss:0.637347\n",
      "[1800]\ttrain-logloss:0.599769\tval-logloss:0.631697\n",
      "[2000]\ttrain-logloss:0.590772\tval-logloss:0.626261\n",
      "[2200]\ttrain-logloss:0.582008\tval-logloss:0.620894\n",
      "[2400]\ttrain-logloss:0.573451\tval-logloss:0.615636\n",
      "[2600]\ttrain-logloss:0.565104\tval-logloss:0.610514\n",
      "[2800]\ttrain-logloss:0.556968\tval-logloss:0.605745\n",
      "[3000]\ttrain-logloss:0.549029\tval-logloss:0.601151\n",
      "[3200]\ttrain-logloss:0.541287\tval-logloss:0.596682\n",
      "[3400]\ttrain-logloss:0.533741\tval-logloss:0.592324\n",
      "[3600]\ttrain-logloss:0.52638\tval-logloss:0.588029\n",
      "[3800]\ttrain-logloss:0.519183\tval-logloss:0.583982\n",
      "[4000]\ttrain-logloss:0.512159\tval-logloss:0.580017\n",
      "[4200]\ttrain-logloss:0.505277\tval-logloss:0.576145\n",
      "[4400]\ttrain-logloss:0.498552\tval-logloss:0.572467\n",
      "[4600]\ttrain-logloss:0.491979\tval-logloss:0.568885\n",
      "[4800]\ttrain-logloss:0.485565\tval-logloss:0.565443\n",
      "[5000]\ttrain-logloss:0.479279\tval-logloss:0.562143\n",
      "[5200]\ttrain-logloss:0.473131\tval-logloss:0.558908\n",
      "[5400]\ttrain-logloss:0.467123\tval-logloss:0.555877\n",
      "[5600]\ttrain-logloss:0.461268\tval-logloss:0.553134\n",
      "[5800]\ttrain-logloss:0.455531\tval-logloss:0.550532\n",
      "[6000]\ttrain-logloss:0.449892\tval-logloss:0.547953\n",
      "[6200]\ttrain-logloss:0.444379\tval-logloss:0.545486\n",
      "[6400]\ttrain-logloss:0.438969\tval-logloss:0.543072\n",
      "[6600]\ttrain-logloss:0.433667\tval-logloss:0.540725\n",
      "[6800]\ttrain-logloss:0.42848\tval-logloss:0.538351\n",
      "[7000]\ttrain-logloss:0.423396\tval-logloss:0.53616\n",
      "[7200]\ttrain-logloss:0.41841\tval-logloss:0.533973\n",
      "[7400]\ttrain-logloss:0.413521\tval-logloss:0.531762\n",
      "[7600]\ttrain-logloss:0.408717\tval-logloss:0.529665\n",
      "[7800]\ttrain-logloss:0.404003\tval-logloss:0.527643\n",
      "[8000]\ttrain-logloss:0.399372\tval-logloss:0.525747\n",
      "[8200]\ttrain-logloss:0.394824\tval-logloss:0.523922\n",
      "[8400]\ttrain-logloss:0.390369\tval-logloss:0.522238\n",
      "[8600]\ttrain-logloss:0.386011\tval-logloss:0.520634\n",
      "[8800]\ttrain-logloss:0.381699\tval-logloss:0.519191\n",
      "[9000]\ttrain-logloss:0.377456\tval-logloss:0.517674\n",
      "[9200]\ttrain-logloss:0.373297\tval-logloss:0.516241\n",
      "[9400]\ttrain-logloss:0.369228\tval-logloss:0.515024\n",
      "[9600]\ttrain-logloss:0.365233\tval-logloss:0.513765\n",
      "[9800]\ttrain-logloss:0.361315\tval-logloss:0.512477\n",
      "[9999]\ttrain-logloss:0.357478\tval-logloss:0.511198\n",
      "Fold: 7\n",
      "[0]\ttrain-logloss:0.693087\tval-logloss:0.693108\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681449\tval-logloss:0.685707\n",
      "[400]\ttrain-logloss:0.670169\tval-logloss:0.67855\n",
      "[600]\ttrain-logloss:0.65921\tval-logloss:0.671577\n",
      "[800]\ttrain-logloss:0.64859\tval-logloss:0.664866\n",
      "[1000]\ttrain-logloss:0.638281\tval-logloss:0.658471\n",
      "[1200]\ttrain-logloss:0.628277\tval-logloss:0.652327\n",
      "[1400]\ttrain-logloss:0.618565\tval-logloss:0.64631\n",
      "[1600]\ttrain-logloss:0.609097\tval-logloss:0.640386\n",
      "[1800]\ttrain-logloss:0.5999\tval-logloss:0.634714\n",
      "[2000]\ttrain-logloss:0.590942\tval-logloss:0.629294\n",
      "[2200]\ttrain-logloss:0.582208\tval-logloss:0.624038\n",
      "[2400]\ttrain-logloss:0.573705\tval-logloss:0.618941\n",
      "[2600]\ttrain-logloss:0.56541\tval-logloss:0.614065\n",
      "[2800]\ttrain-logloss:0.557337\tval-logloss:0.609368\n",
      "[3000]\ttrain-logloss:0.549446\tval-logloss:0.604809\n",
      "[3200]\ttrain-logloss:0.541734\tval-logloss:0.600284\n",
      "[3400]\ttrain-logloss:0.534212\tval-logloss:0.595942\n",
      "[3600]\ttrain-logloss:0.526882\tval-logloss:0.591801\n",
      "[3800]\ttrain-logloss:0.519716\tval-logloss:0.58783\n",
      "[4000]\ttrain-logloss:0.512717\tval-logloss:0.583975\n",
      "[4200]\ttrain-logloss:0.505871\tval-logloss:0.580274\n",
      "[4400]\ttrain-logloss:0.499163\tval-logloss:0.576734\n",
      "[4600]\ttrain-logloss:0.492613\tval-logloss:0.573403\n",
      "[4800]\ttrain-logloss:0.486212\tval-logloss:0.570137\n",
      "[5000]\ttrain-logloss:0.479945\tval-logloss:0.566916\n",
      "[5200]\ttrain-logloss:0.47381\tval-logloss:0.563839\n",
      "[5400]\ttrain-logloss:0.467815\tval-logloss:0.560889\n",
      "[5600]\ttrain-logloss:0.461954\tval-logloss:0.558043\n",
      "[5800]\ttrain-logloss:0.456213\tval-logloss:0.555302\n",
      "[6000]\ttrain-logloss:0.450602\tval-logloss:0.552686\n",
      "[6200]\ttrain-logloss:0.4451\tval-logloss:0.550068\n",
      "[6400]\ttrain-logloss:0.4397\tval-logloss:0.547605\n",
      "[6600]\ttrain-logloss:0.434419\tval-logloss:0.545237\n",
      "[6800]\ttrain-logloss:0.429239\tval-logloss:0.54293\n",
      "[7000]\ttrain-logloss:0.424156\tval-logloss:0.540633\n",
      "[7200]\ttrain-logloss:0.41915\tval-logloss:0.538499\n",
      "[7400]\ttrain-logloss:0.41424\tval-logloss:0.53654\n",
      "[7600]\ttrain-logloss:0.40942\tval-logloss:0.534443\n",
      "[7800]\ttrain-logloss:0.40469\tval-logloss:0.532506\n",
      "[8000]\ttrain-logloss:0.400057\tval-logloss:0.530622\n",
      "[8200]\ttrain-logloss:0.395507\tval-logloss:0.528895\n",
      "[8400]\ttrain-logloss:0.391037\tval-logloss:0.527228\n",
      "[8600]\ttrain-logloss:0.386648\tval-logloss:0.525579\n",
      "[8800]\ttrain-logloss:0.382353\tval-logloss:0.523971\n",
      "[9000]\ttrain-logloss:0.378147\tval-logloss:0.522392\n",
      "[9200]\ttrain-logloss:0.374007\tval-logloss:0.521007\n",
      "[9400]\ttrain-logloss:0.369936\tval-logloss:0.51957\n",
      "[9600]\ttrain-logloss:0.365932\tval-logloss:0.518221\n",
      "[9800]\ttrain-logloss:0.362011\tval-logloss:0.516876\n",
      "[9999]\ttrain-logloss:0.358183\tval-logloss:0.515558\n",
      "Fold: 8\n",
      "[0]\ttrain-logloss:0.693087\tval-logloss:0.693107\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681396\tval-logloss:0.685307\n",
      "[400]\ttrain-logloss:0.670061\tval-logloss:0.677765\n",
      "[600]\ttrain-logloss:0.659074\tval-logloss:0.670638\n",
      "[800]\ttrain-logloss:0.648442\tval-logloss:0.663909\n",
      "[1000]\ttrain-logloss:0.638153\tval-logloss:0.657374\n",
      "[1200]\ttrain-logloss:0.628171\tval-logloss:0.651027\n",
      "[1400]\ttrain-logloss:0.618468\tval-logloss:0.644844\n",
      "[1600]\ttrain-logloss:0.609016\tval-logloss:0.638812\n",
      "[1800]\ttrain-logloss:0.599827\tval-logloss:0.63317\n",
      "[2000]\ttrain-logloss:0.590896\tval-logloss:0.627773\n",
      "[2200]\ttrain-logloss:0.58216\tval-logloss:0.622498\n",
      "[2400]\ttrain-logloss:0.573651\tval-logloss:0.61731\n",
      "[2600]\ttrain-logloss:0.565367\tval-logloss:0.612338\n",
      "[2800]\ttrain-logloss:0.557281\tval-logloss:0.607522\n",
      "[3000]\ttrain-logloss:0.549397\tval-logloss:0.602914\n",
      "[3200]\ttrain-logloss:0.541713\tval-logloss:0.598397\n",
      "[3400]\ttrain-logloss:0.534242\tval-logloss:0.594049\n",
      "[3600]\ttrain-logloss:0.526937\tval-logloss:0.589803\n",
      "[3800]\ttrain-logloss:0.519809\tval-logloss:0.585737\n",
      "[4000]\ttrain-logloss:0.512859\tval-logloss:0.581724\n",
      "[4200]\ttrain-logloss:0.506048\tval-logloss:0.57781\n",
      "[4400]\ttrain-logloss:0.499395\tval-logloss:0.574016\n",
      "[4600]\ttrain-logloss:0.492912\tval-logloss:0.570406\n",
      "[4800]\ttrain-logloss:0.486566\tval-logloss:0.566861\n",
      "[5000]\ttrain-logloss:0.480354\tval-logloss:0.56341\n",
      "[5200]\ttrain-logloss:0.47424\tval-logloss:0.560066\n",
      "[5400]\ttrain-logloss:0.468276\tval-logloss:0.556805\n",
      "[5600]\ttrain-logloss:0.462424\tval-logloss:0.553665\n",
      "[5800]\ttrain-logloss:0.456684\tval-logloss:0.550579\n",
      "[6000]\ttrain-logloss:0.451065\tval-logloss:0.547544\n",
      "[6200]\ttrain-logloss:0.445556\tval-logloss:0.544656\n",
      "[6400]\ttrain-logloss:0.440162\tval-logloss:0.541979\n",
      "[6600]\ttrain-logloss:0.434876\tval-logloss:0.539354\n",
      "[6800]\ttrain-logloss:0.429703\tval-logloss:0.536712\n",
      "[7000]\ttrain-logloss:0.424649\tval-logloss:0.534161\n",
      "[7200]\ttrain-logloss:0.419684\tval-logloss:0.531718\n",
      "[7400]\ttrain-logloss:0.41481\tval-logloss:0.529308\n",
      "[7600]\ttrain-logloss:0.410021\tval-logloss:0.526884\n",
      "[7800]\ttrain-logloss:0.405332\tval-logloss:0.524529\n",
      "[8000]\ttrain-logloss:0.40072\tval-logloss:0.5223\n",
      "[8200]\ttrain-logloss:0.396196\tval-logloss:0.520107\n",
      "[8400]\ttrain-logloss:0.391753\tval-logloss:0.517998\n",
      "[8600]\ttrain-logloss:0.38739\tval-logloss:0.515932\n",
      "[8800]\ttrain-logloss:0.383106\tval-logloss:0.513961\n",
      "[9000]\ttrain-logloss:0.378891\tval-logloss:0.512067\n",
      "[9200]\ttrain-logloss:0.37476\tval-logloss:0.510157\n",
      "[9400]\ttrain-logloss:0.370703\tval-logloss:0.508274\n",
      "[9600]\ttrain-logloss:0.366716\tval-logloss:0.506536\n",
      "[9800]\ttrain-logloss:0.36281\tval-logloss:0.504857\n",
      "[9999]\ttrain-logloss:0.358987\tval-logloss:0.503182\n",
      "Fold: 9\n",
      "[0]\ttrain-logloss:0.693087\tval-logloss:0.693107\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681469\tval-logloss:0.685341\n",
      "[400]\ttrain-logloss:0.670181\tval-logloss:0.67792\n",
      "[600]\ttrain-logloss:0.659212\tval-logloss:0.67078\n",
      "[800]\ttrain-logloss:0.648582\tval-logloss:0.66397\n",
      "[1000]\ttrain-logloss:0.638244\tval-logloss:0.657433\n",
      "[1200]\ttrain-logloss:0.628208\tval-logloss:0.651293\n",
      "[1400]\ttrain-logloss:0.618479\tval-logloss:0.645449\n",
      "[1600]\ttrain-logloss:0.60899\tval-logloss:0.639689\n",
      "[1800]\ttrain-logloss:0.599758\tval-logloss:0.634119\n",
      "[2000]\ttrain-logloss:0.590777\tval-logloss:0.628912\n",
      "[2200]\ttrain-logloss:0.582039\tval-logloss:0.624005\n",
      "[2400]\ttrain-logloss:0.57353\tval-logloss:0.619292\n",
      "[2600]\ttrain-logloss:0.565203\tval-logloss:0.614654\n",
      "[2800]\ttrain-logloss:0.557091\tval-logloss:0.610287\n",
      "[3000]\ttrain-logloss:0.549181\tval-logloss:0.606038\n",
      "[3200]\ttrain-logloss:0.541463\tval-logloss:0.60196\n",
      "[3400]\ttrain-logloss:0.533939\tval-logloss:0.598075\n",
      "[3600]\ttrain-logloss:0.526568\tval-logloss:0.594006\n",
      "[3800]\ttrain-logloss:0.519378\tval-logloss:0.590121\n",
      "[4000]\ttrain-logloss:0.512334\tval-logloss:0.586367\n",
      "[4200]\ttrain-logloss:0.505449\tval-logloss:0.582774\n",
      "[4400]\ttrain-logloss:0.498711\tval-logloss:0.579284\n",
      "[4600]\ttrain-logloss:0.49215\tval-logloss:0.575902\n",
      "[4800]\ttrain-logloss:0.485732\tval-logloss:0.572631\n",
      "[5000]\ttrain-logloss:0.47945\tval-logloss:0.569625\n",
      "[5200]\ttrain-logloss:0.473298\tval-logloss:0.566665\n",
      "[5400]\ttrain-logloss:0.467285\tval-logloss:0.56382\n",
      "[5600]\ttrain-logloss:0.461384\tval-logloss:0.561028\n",
      "[5800]\ttrain-logloss:0.455606\tval-logloss:0.558355\n",
      "[6000]\ttrain-logloss:0.44995\tval-logloss:0.555737\n",
      "[6200]\ttrain-logloss:0.444408\tval-logloss:0.553265\n",
      "[6400]\ttrain-logloss:0.438973\tval-logloss:0.550904\n",
      "[6600]\ttrain-logloss:0.43365\tval-logloss:0.548623\n",
      "[6800]\ttrain-logloss:0.428448\tval-logloss:0.546442\n",
      "[7000]\ttrain-logloss:0.423368\tval-logloss:0.544496\n",
      "[7200]\ttrain-logloss:0.418381\tval-logloss:0.542741\n",
      "[7400]\ttrain-logloss:0.413494\tval-logloss:0.540943\n",
      "[7600]\ttrain-logloss:0.408706\tval-logloss:0.539278\n",
      "[7800]\ttrain-logloss:0.404012\tval-logloss:0.53767\n",
      "[8000]\ttrain-logloss:0.399409\tval-logloss:0.53611\n",
      "[8200]\ttrain-logloss:0.394892\tval-logloss:0.534474\n",
      "[8400]\ttrain-logloss:0.39046\tval-logloss:0.533046\n",
      "[8600]\ttrain-logloss:0.386117\tval-logloss:0.531668\n",
      "[8800]\ttrain-logloss:0.381857\tval-logloss:0.530324\n",
      "[9000]\ttrain-logloss:0.377679\tval-logloss:0.529061\n",
      "[9200]\ttrain-logloss:0.373578\tval-logloss:0.527855\n",
      "[9400]\ttrain-logloss:0.36955\tval-logloss:0.526679\n",
      "[9600]\ttrain-logloss:0.365592\tval-logloss:0.525508\n",
      "[9800]\ttrain-logloss:0.361712\tval-logloss:0.524379\n",
      "[9999]\ttrain-logloss:0.357915\tval-logloss:0.523243\n",
      "Fold: 10\n",
      "[0]\ttrain-logloss:0.693087\tval-logloss:0.693108\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681491\tval-logloss:0.685408\n",
      "[400]\ttrain-logloss:0.670236\tval-logloss:0.67799\n",
      "[600]\ttrain-logloss:0.659315\tval-logloss:0.670869\n",
      "[800]\ttrain-logloss:0.648723\tval-logloss:0.664069\n",
      "[1000]\ttrain-logloss:0.638394\tval-logloss:0.657521\n",
      "[1200]\ttrain-logloss:0.628369\tval-logloss:0.651376\n",
      "[1400]\ttrain-logloss:0.618624\tval-logloss:0.645487\n",
      "[1600]\ttrain-logloss:0.609124\tval-logloss:0.639756\n",
      "[1800]\ttrain-logloss:0.599878\tval-logloss:0.634399\n",
      "[2000]\ttrain-logloss:0.59088\tval-logloss:0.629353\n",
      "[2200]\ttrain-logloss:0.582112\tval-logloss:0.624389\n",
      "[2400]\ttrain-logloss:0.573577\tval-logloss:0.619763\n",
      "[2600]\ttrain-logloss:0.565259\tval-logloss:0.615267\n",
      "[2800]\ttrain-logloss:0.557156\tval-logloss:0.611027\n",
      "[3000]\ttrain-logloss:0.549281\tval-logloss:0.606808\n",
      "[3200]\ttrain-logloss:0.541593\tval-logloss:0.602857\n",
      "[3400]\ttrain-logloss:0.53409\tval-logloss:0.599036\n",
      "[3600]\ttrain-logloss:0.526756\tval-logloss:0.595395\n",
      "[3800]\ttrain-logloss:0.519606\tval-logloss:0.591881\n",
      "[4000]\ttrain-logloss:0.512614\tval-logloss:0.588373\n",
      "[4200]\ttrain-logloss:0.505764\tval-logloss:0.585053\n",
      "[4400]\ttrain-logloss:0.499046\tval-logloss:0.581883\n",
      "[4600]\ttrain-logloss:0.492487\tval-logloss:0.578757\n",
      "[4800]\ttrain-logloss:0.486067\tval-logloss:0.575754\n",
      "[5000]\ttrain-logloss:0.479779\tval-logloss:0.572832\n",
      "[5200]\ttrain-logloss:0.473641\tval-logloss:0.570055\n",
      "[5400]\ttrain-logloss:0.467643\tval-logloss:0.567324\n",
      "[5600]\ttrain-logloss:0.461773\tval-logloss:0.564749\n",
      "[5800]\ttrain-logloss:0.456017\tval-logloss:0.562293\n",
      "[6000]\ttrain-logloss:0.450399\tval-logloss:0.55992\n",
      "[6200]\ttrain-logloss:0.444889\tval-logloss:0.557537\n",
      "[6400]\ttrain-logloss:0.439501\tval-logloss:0.555335\n",
      "[6600]\ttrain-logloss:0.434212\tval-logloss:0.553112\n",
      "[6800]\ttrain-logloss:0.429036\tval-logloss:0.55097\n",
      "[7000]\ttrain-logloss:0.423933\tval-logloss:0.548726\n",
      "[7200]\ttrain-logloss:0.418933\tval-logloss:0.546528\n",
      "[7400]\ttrain-logloss:0.414036\tval-logloss:0.544512\n",
      "[7600]\ttrain-logloss:0.409219\tval-logloss:0.542434\n",
      "[7800]\ttrain-logloss:0.404492\tval-logloss:0.540281\n",
      "[8000]\ttrain-logloss:0.399863\tval-logloss:0.538452\n",
      "[8200]\ttrain-logloss:0.395333\tval-logloss:0.536597\n",
      "[8400]\ttrain-logloss:0.390889\tval-logloss:0.534852\n",
      "[8600]\ttrain-logloss:0.386524\tval-logloss:0.533055\n",
      "[8800]\ttrain-logloss:0.382248\tval-logloss:0.531257\n",
      "[9000]\ttrain-logloss:0.378057\tval-logloss:0.529565\n",
      "[9200]\ttrain-logloss:0.37393\tval-logloss:0.527946\n",
      "[9400]\ttrain-logloss:0.369882\tval-logloss:0.526324\n",
      "[9600]\ttrain-logloss:0.365896\tval-logloss:0.524759\n",
      "[9800]\ttrain-logloss:0.361989\tval-logloss:0.523328\n",
      "[9999]\ttrain-logloss:0.358176\tval-logloss:0.521872\n",
      "Fold: 11\n",
      "[0]\ttrain-logloss:0.693087\tval-logloss:0.693115\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681407\tval-logloss:0.686469\n",
      "[400]\ttrain-logloss:0.670054\tval-logloss:0.679997\n",
      "[600]\ttrain-logloss:0.659001\tval-logloss:0.673811\n",
      "[800]\ttrain-logloss:0.648299\tval-logloss:0.667896\n",
      "[1000]\ttrain-logloss:0.637915\tval-logloss:0.662263\n",
      "[1200]\ttrain-logloss:0.627834\tval-logloss:0.65688\n",
      "[1400]\ttrain-logloss:0.618048\tval-logloss:0.651754\n",
      "[1600]\ttrain-logloss:0.608507\tval-logloss:0.646875\n",
      "[1800]\ttrain-logloss:0.599225\tval-logloss:0.642172\n",
      "[2000]\ttrain-logloss:0.590196\tval-logloss:0.637561\n",
      "[2200]\ttrain-logloss:0.581395\tval-logloss:0.633184\n",
      "[2400]\ttrain-logloss:0.572831\tval-logloss:0.628943\n",
      "[2600]\ttrain-logloss:0.564483\tval-logloss:0.624892\n",
      "[2800]\ttrain-logloss:0.556346\tval-logloss:0.621019\n",
      "[3000]\ttrain-logloss:0.54841\tval-logloss:0.617332\n",
      "[3200]\ttrain-logloss:0.540653\tval-logloss:0.613745\n",
      "[3400]\ttrain-logloss:0.533085\tval-logloss:0.610299\n",
      "[3600]\ttrain-logloss:0.525709\tval-logloss:0.606933\n",
      "[3800]\ttrain-logloss:0.518499\tval-logloss:0.603724\n",
      "[4000]\ttrain-logloss:0.511466\tval-logloss:0.600533\n",
      "[4200]\ttrain-logloss:0.504595\tval-logloss:0.597391\n",
      "[4400]\ttrain-logloss:0.497874\tval-logloss:0.594272\n",
      "[4600]\ttrain-logloss:0.491321\tval-logloss:0.591232\n",
      "[4800]\ttrain-logloss:0.484913\tval-logloss:0.588359\n",
      "[5000]\ttrain-logloss:0.478633\tval-logloss:0.585495\n",
      "[5200]\ttrain-logloss:0.472478\tval-logloss:0.582886\n",
      "[5400]\ttrain-logloss:0.466467\tval-logloss:0.580368\n",
      "[5600]\ttrain-logloss:0.460595\tval-logloss:0.577893\n",
      "[5800]\ttrain-logloss:0.454843\tval-logloss:0.575524\n",
      "[6000]\ttrain-logloss:0.449211\tval-logloss:0.573272\n",
      "[6200]\ttrain-logloss:0.443697\tval-logloss:0.57107\n",
      "[6400]\ttrain-logloss:0.438266\tval-logloss:0.568911\n",
      "[6600]\ttrain-logloss:0.432956\tval-logloss:0.566831\n",
      "[6800]\ttrain-logloss:0.427745\tval-logloss:0.564819\n",
      "[7000]\ttrain-logloss:0.42263\tval-logloss:0.562746\n",
      "[7200]\ttrain-logloss:0.4176\tval-logloss:0.560854\n",
      "[7400]\ttrain-logloss:0.412682\tval-logloss:0.559012\n",
      "[7600]\ttrain-logloss:0.407844\tval-logloss:0.557206\n",
      "[7800]\ttrain-logloss:0.4031\tval-logloss:0.555433\n",
      "[8000]\ttrain-logloss:0.398452\tval-logloss:0.553736\n",
      "[8200]\ttrain-logloss:0.39389\tval-logloss:0.55208\n",
      "[8400]\ttrain-logloss:0.389397\tval-logloss:0.550426\n",
      "[8600]\ttrain-logloss:0.385001\tval-logloss:0.54888\n",
      "[8800]\ttrain-logloss:0.380684\tval-logloss:0.547341\n",
      "[9000]\ttrain-logloss:0.376447\tval-logloss:0.545895\n",
      "[9200]\ttrain-logloss:0.372284\tval-logloss:0.544493\n",
      "[9400]\ttrain-logloss:0.368187\tval-logloss:0.543204\n",
      "[9600]\ttrain-logloss:0.364187\tval-logloss:0.541974\n",
      "[9800]\ttrain-logloss:0.360246\tval-logloss:0.540774\n",
      "[9999]\ttrain-logloss:0.356395\tval-logloss:0.539664\n",
      "Fold: 12\n",
      "[0]\ttrain-logloss:0.693087\tval-logloss:0.69311\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681341\tval-logloss:0.686162\n",
      "[400]\ttrain-logloss:0.669946\tval-logloss:0.679447\n",
      "[600]\ttrain-logloss:0.658887\tval-logloss:0.673078\n",
      "[800]\ttrain-logloss:0.648176\tval-logloss:0.666968\n",
      "[1000]\ttrain-logloss:0.637771\tval-logloss:0.661138\n",
      "[1200]\ttrain-logloss:0.627675\tval-logloss:0.655668\n",
      "[1400]\ttrain-logloss:0.617884\tval-logloss:0.650267\n",
      "[1600]\ttrain-logloss:0.608304\tval-logloss:0.645069\n",
      "[1800]\ttrain-logloss:0.599014\tval-logloss:0.640054\n",
      "[2000]\ttrain-logloss:0.589973\tval-logloss:0.635222\n",
      "[2200]\ttrain-logloss:0.581166\tval-logloss:0.630597\n",
      "[2400]\ttrain-logloss:0.572581\tval-logloss:0.626217\n",
      "[2600]\ttrain-logloss:0.564224\tval-logloss:0.62203\n",
      "[2800]\ttrain-logloss:0.55607\tval-logloss:0.617938\n",
      "[3000]\ttrain-logloss:0.54812\tval-logloss:0.613931\n",
      "[3200]\ttrain-logloss:0.540374\tval-logloss:0.610093\n",
      "[3400]\ttrain-logloss:0.532793\tval-logloss:0.606451\n",
      "[3600]\ttrain-logloss:0.525401\tval-logloss:0.602913\n",
      "[3800]\ttrain-logloss:0.518197\tval-logloss:0.599468\n",
      "[4000]\ttrain-logloss:0.511157\tval-logloss:0.596248\n",
      "[4200]\ttrain-logloss:0.504261\tval-logloss:0.593058\n",
      "[4400]\ttrain-logloss:0.497511\tval-logloss:0.589998\n",
      "[4600]\ttrain-logloss:0.490922\tval-logloss:0.58696\n",
      "[4800]\ttrain-logloss:0.484469\tval-logloss:0.583996\n",
      "[5000]\ttrain-logloss:0.478153\tval-logloss:0.581176\n",
      "[5200]\ttrain-logloss:0.471968\tval-logloss:0.578393\n",
      "[5400]\ttrain-logloss:0.465917\tval-logloss:0.575702\n",
      "[5600]\ttrain-logloss:0.459997\tval-logloss:0.573229\n",
      "[5800]\ttrain-logloss:0.454196\tval-logloss:0.570769\n",
      "[6000]\ttrain-logloss:0.448518\tval-logloss:0.568324\n",
      "[6200]\ttrain-logloss:0.442953\tval-logloss:0.566032\n",
      "[6400]\ttrain-logloss:0.437493\tval-logloss:0.563872\n",
      "[6600]\ttrain-logloss:0.432162\tval-logloss:0.561785\n",
      "[6800]\ttrain-logloss:0.426931\tval-logloss:0.559785\n",
      "[7000]\ttrain-logloss:0.42182\tval-logloss:0.557804\n",
      "[7200]\ttrain-logloss:0.4168\tval-logloss:0.555967\n",
      "[7400]\ttrain-logloss:0.411894\tval-logloss:0.55423\n",
      "[7600]\ttrain-logloss:0.407074\tval-logloss:0.552564\n",
      "[7800]\ttrain-logloss:0.402351\tval-logloss:0.550983\n",
      "[8000]\ttrain-logloss:0.397702\tval-logloss:0.549484\n",
      "[8200]\ttrain-logloss:0.393157\tval-logloss:0.548024\n",
      "[8400]\ttrain-logloss:0.388694\tval-logloss:0.546701\n",
      "[8600]\ttrain-logloss:0.384333\tval-logloss:0.5454\n",
      "[8800]\ttrain-logloss:0.380058\tval-logloss:0.544124\n",
      "[9000]\ttrain-logloss:0.375855\tval-logloss:0.542932\n",
      "[9200]\ttrain-logloss:0.371744\tval-logloss:0.541729\n",
      "[9400]\ttrain-logloss:0.367699\tval-logloss:0.540509\n",
      "[9600]\ttrain-logloss:0.363726\tval-logloss:0.539274\n",
      "[9800]\ttrain-logloss:0.359846\tval-logloss:0.538059\n",
      "[9999]\ttrain-logloss:0.356036\tval-logloss:0.536993\n",
      "Fold: 13\n",
      "[0]\ttrain-logloss:0.693086\tval-logloss:0.693113\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681415\tval-logloss:0.685682\n",
      "[400]\ttrain-logloss:0.670089\tval-logloss:0.678403\n",
      "[600]\ttrain-logloss:0.659124\tval-logloss:0.671245\n",
      "[800]\ttrain-logloss:0.648507\tval-logloss:0.664477\n",
      "[1000]\ttrain-logloss:0.638199\tval-logloss:0.657884\n",
      "[1200]\ttrain-logloss:0.628186\tval-logloss:0.651528\n",
      "[1400]\ttrain-logloss:0.618465\tval-logloss:0.645437\n",
      "[1600]\ttrain-logloss:0.60896\tval-logloss:0.639824\n",
      "[1800]\ttrain-logloss:0.599727\tval-logloss:0.634386\n",
      "[2000]\ttrain-logloss:0.590736\tval-logloss:0.629184\n",
      "[2200]\ttrain-logloss:0.581988\tval-logloss:0.624034\n",
      "[2400]\ttrain-logloss:0.573477\tval-logloss:0.619254\n",
      "[2600]\ttrain-logloss:0.565168\tval-logloss:0.614585\n",
      "[2800]\ttrain-logloss:0.557072\tval-logloss:0.610039\n",
      "[3000]\ttrain-logloss:0.549161\tval-logloss:0.605675\n",
      "[3200]\ttrain-logloss:0.541453\tval-logloss:0.601438\n",
      "[3400]\ttrain-logloss:0.533933\tval-logloss:0.597342\n",
      "[3600]\ttrain-logloss:0.526596\tval-logloss:0.593427\n",
      "[3800]\ttrain-logloss:0.519423\tval-logloss:0.589578\n",
      "[4000]\ttrain-logloss:0.512416\tval-logloss:0.585893\n",
      "[4200]\ttrain-logloss:0.505555\tval-logloss:0.582231\n",
      "[4400]\ttrain-logloss:0.498838\tval-logloss:0.578629\n",
      "[4600]\ttrain-logloss:0.492274\tval-logloss:0.575182\n",
      "[4800]\ttrain-logloss:0.485845\tval-logloss:0.571909\n",
      "[5000]\ttrain-logloss:0.47956\tval-logloss:0.568713\n",
      "[5200]\ttrain-logloss:0.473416\tval-logloss:0.565656\n",
      "[5400]\ttrain-logloss:0.467422\tval-logloss:0.562639\n",
      "[5600]\ttrain-logloss:0.461554\tval-logloss:0.559719\n",
      "[5800]\ttrain-logloss:0.455819\tval-logloss:0.556951\n",
      "[6000]\ttrain-logloss:0.450188\tval-logloss:0.554237\n",
      "[6200]\ttrain-logloss:0.444678\tval-logloss:0.551611\n",
      "[6400]\ttrain-logloss:0.439277\tval-logloss:0.548993\n",
      "[6600]\ttrain-logloss:0.43399\tval-logloss:0.546468\n",
      "[6800]\ttrain-logloss:0.428818\tval-logloss:0.544096\n",
      "[7000]\ttrain-logloss:0.423765\tval-logloss:0.541788\n",
      "[7200]\ttrain-logloss:0.418798\tval-logloss:0.539476\n",
      "[7400]\ttrain-logloss:0.413923\tval-logloss:0.537387\n",
      "[7600]\ttrain-logloss:0.409133\tval-logloss:0.535164\n",
      "[7800]\ttrain-logloss:0.404437\tval-logloss:0.532948\n",
      "[8000]\ttrain-logloss:0.399826\tval-logloss:0.530778\n",
      "[8200]\ttrain-logloss:0.395295\tval-logloss:0.528737\n",
      "[8400]\ttrain-logloss:0.390846\tval-logloss:0.52679\n",
      "[8600]\ttrain-logloss:0.386481\tval-logloss:0.52487\n",
      "[8800]\ttrain-logloss:0.382208\tval-logloss:0.522955\n",
      "[9000]\ttrain-logloss:0.378011\tval-logloss:0.521123\n",
      "[9200]\ttrain-logloss:0.373884\tval-logloss:0.519438\n",
      "[9400]\ttrain-logloss:0.369831\tval-logloss:0.517783\n",
      "[9600]\ttrain-logloss:0.365853\tval-logloss:0.516186\n",
      "[9800]\ttrain-logloss:0.361953\tval-logloss:0.514585\n",
      "[9999]\ttrain-logloss:0.358147\tval-logloss:0.513107\n",
      "Fold: 14\n",
      "[0]\ttrain-logloss:0.693087\tval-logloss:0.693116\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681436\tval-logloss:0.687258\n",
      "[400]\ttrain-logloss:0.670083\tval-logloss:0.681296\n",
      "[600]\ttrain-logloss:0.659057\tval-logloss:0.675548\n",
      "[800]\ttrain-logloss:0.648363\tval-logloss:0.670093\n",
      "[1000]\ttrain-logloss:0.637965\tval-logloss:0.664836\n",
      "[1200]\ttrain-logloss:0.627872\tval-logloss:0.659763\n",
      "[1400]\ttrain-logloss:0.618053\tval-logloss:0.654919\n",
      "[1600]\ttrain-logloss:0.608476\tval-logloss:0.650116\n",
      "[1800]\ttrain-logloss:0.599169\tval-logloss:0.645551\n",
      "[2000]\ttrain-logloss:0.590112\tval-logloss:0.641194\n",
      "[2200]\ttrain-logloss:0.581311\tval-logloss:0.636944\n",
      "[2400]\ttrain-logloss:0.572726\tval-logloss:0.632967\n",
      "[2600]\ttrain-logloss:0.564333\tval-logloss:0.6291\n",
      "[2800]\ttrain-logloss:0.556161\tval-logloss:0.625364\n",
      "[3000]\ttrain-logloss:0.54817\tval-logloss:0.621724\n",
      "[3200]\ttrain-logloss:0.540383\tval-logloss:0.618276\n",
      "[3400]\ttrain-logloss:0.532814\tval-logloss:0.615018\n",
      "[3600]\ttrain-logloss:0.525455\tval-logloss:0.611929\n",
      "[3800]\ttrain-logloss:0.518241\tval-logloss:0.608981\n",
      "[4000]\ttrain-logloss:0.511206\tval-logloss:0.60622\n",
      "[4200]\ttrain-logloss:0.504304\tval-logloss:0.603389\n",
      "[4400]\ttrain-logloss:0.497519\tval-logloss:0.600545\n",
      "[4600]\ttrain-logloss:0.490888\tval-logloss:0.597865\n",
      "[4800]\ttrain-logloss:0.484413\tval-logloss:0.595265\n",
      "[5000]\ttrain-logloss:0.478067\tval-logloss:0.592852\n",
      "[5200]\ttrain-logloss:0.471865\tval-logloss:0.590513\n",
      "[5400]\ttrain-logloss:0.465782\tval-logloss:0.588332\n",
      "[5600]\ttrain-logloss:0.459837\tval-logloss:0.586227\n",
      "[5800]\ttrain-logloss:0.454\tval-logloss:0.584129\n",
      "[6000]\ttrain-logloss:0.4483\tval-logloss:0.581958\n",
      "[6200]\ttrain-logloss:0.442717\tval-logloss:0.579876\n",
      "[6400]\ttrain-logloss:0.437251\tval-logloss:0.577805\n",
      "[6600]\ttrain-logloss:0.431904\tval-logloss:0.575792\n",
      "[6800]\ttrain-logloss:0.426653\tval-logloss:0.573988\n",
      "[7000]\ttrain-logloss:0.421486\tval-logloss:0.572456\n",
      "[7200]\ttrain-logloss:0.416432\tval-logloss:0.570878\n",
      "[7400]\ttrain-logloss:0.411483\tval-logloss:0.569351\n",
      "[7600]\ttrain-logloss:0.40662\tval-logloss:0.567926\n",
      "[7800]\ttrain-logloss:0.40185\tval-logloss:0.566582\n",
      "[8000]\ttrain-logloss:0.397178\tval-logloss:0.565382\n",
      "[8200]\ttrain-logloss:0.392593\tval-logloss:0.564148\n",
      "[8400]\ttrain-logloss:0.388093\tval-logloss:0.563038\n",
      "[8600]\ttrain-logloss:0.383669\tval-logloss:0.562015\n",
      "[8800]\ttrain-logloss:0.37934\tval-logloss:0.560981\n",
      "[9000]\ttrain-logloss:0.375093\tval-logloss:0.559981\n",
      "[9200]\ttrain-logloss:0.370929\tval-logloss:0.558987\n",
      "[9400]\ttrain-logloss:0.366839\tval-logloss:0.558022\n",
      "[9600]\ttrain-logloss:0.362834\tval-logloss:0.557048\n",
      "[9800]\ttrain-logloss:0.358895\tval-logloss:0.556178\n",
      "[9999]\ttrain-logloss:0.355043\tval-logloss:0.555396\n",
      "Fold: 15\n",
      "[0]\ttrain-logloss:0.693087\tval-logloss:0.693103\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681408\tval-logloss:0.685587\n",
      "[400]\ttrain-logloss:0.670055\tval-logloss:0.678168\n",
      "[600]\ttrain-logloss:0.659056\tval-logloss:0.671056\n",
      "[800]\ttrain-logloss:0.648394\tval-logloss:0.664198\n",
      "[1000]\ttrain-logloss:0.638066\tval-logloss:0.657622\n",
      "[1200]\ttrain-logloss:0.628044\tval-logloss:0.651416\n",
      "[1400]\ttrain-logloss:0.618285\tval-logloss:0.645415\n",
      "[1600]\ttrain-logloss:0.608749\tval-logloss:0.639551\n",
      "[1800]\ttrain-logloss:0.599497\tval-logloss:0.633891\n",
      "[2000]\ttrain-logloss:0.59048\tval-logloss:0.628404\n",
      "[2200]\ttrain-logloss:0.581665\tval-logloss:0.623051\n",
      "[2400]\ttrain-logloss:0.573038\tval-logloss:0.617996\n",
      "[2600]\ttrain-logloss:0.564654\tval-logloss:0.613119\n",
      "[2800]\ttrain-logloss:0.556483\tval-logloss:0.608376\n",
      "[3000]\ttrain-logloss:0.54852\tval-logloss:0.603798\n",
      "[3200]\ttrain-logloss:0.54077\tval-logloss:0.599328\n",
      "[3400]\ttrain-logloss:0.53322\tval-logloss:0.594982\n",
      "[3600]\ttrain-logloss:0.525851\tval-logloss:0.590782\n",
      "[3800]\ttrain-logloss:0.518637\tval-logloss:0.586741\n",
      "[4000]\ttrain-logloss:0.511596\tval-logloss:0.582772\n",
      "[4200]\ttrain-logloss:0.5047\tval-logloss:0.578905\n",
      "[4400]\ttrain-logloss:0.497963\tval-logloss:0.575072\n",
      "[4600]\ttrain-logloss:0.49138\tval-logloss:0.571527\n",
      "[4800]\ttrain-logloss:0.484952\tval-logloss:0.568034\n",
      "[5000]\ttrain-logloss:0.478658\tval-logloss:0.564687\n",
      "[5200]\ttrain-logloss:0.472494\tval-logloss:0.561413\n",
      "[5400]\ttrain-logloss:0.466469\tval-logloss:0.558188\n",
      "[5600]\ttrain-logloss:0.460573\tval-logloss:0.555028\n",
      "[5800]\ttrain-logloss:0.454808\tval-logloss:0.552029\n",
      "[6000]\ttrain-logloss:0.449168\tval-logloss:0.549092\n",
      "[6200]\ttrain-logloss:0.443642\tval-logloss:0.546254\n",
      "[6400]\ttrain-logloss:0.438224\tval-logloss:0.543564\n",
      "[6600]\ttrain-logloss:0.432926\tval-logloss:0.541007\n",
      "[6800]\ttrain-logloss:0.427738\tval-logloss:0.538481\n",
      "[7000]\ttrain-logloss:0.422661\tval-logloss:0.535927\n",
      "[7200]\ttrain-logloss:0.417673\tval-logloss:0.533428\n",
      "[7400]\ttrain-logloss:0.412792\tval-logloss:0.531088\n",
      "[7600]\ttrain-logloss:0.408\tval-logloss:0.528741\n",
      "[7800]\ttrain-logloss:0.40331\tval-logloss:0.526491\n",
      "[8000]\ttrain-logloss:0.398717\tval-logloss:0.524449\n",
      "[8200]\ttrain-logloss:0.394206\tval-logloss:0.522565\n",
      "[8400]\ttrain-logloss:0.389777\tval-logloss:0.520746\n",
      "[8600]\ttrain-logloss:0.385439\tval-logloss:0.519021\n",
      "[8800]\ttrain-logloss:0.381191\tval-logloss:0.517357\n",
      "[9000]\ttrain-logloss:0.377024\tval-logloss:0.515688\n",
      "[9200]\ttrain-logloss:0.372933\tval-logloss:0.514146\n",
      "[9400]\ttrain-logloss:0.368916\tval-logloss:0.512612\n",
      "[9600]\ttrain-logloss:0.364963\tval-logloss:0.511105\n",
      "[9800]\ttrain-logloss:0.361072\tval-logloss:0.509768\n",
      "[9999]\ttrain-logloss:0.357259\tval-logloss:0.508539\n",
      "Fold: 16\n",
      "[0]\ttrain-logloss:0.693086\tval-logloss:0.693104\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681428\tval-logloss:0.684651\n",
      "[400]\ttrain-logloss:0.670138\tval-logloss:0.676602\n",
      "[600]\ttrain-logloss:0.659165\tval-logloss:0.668874\n",
      "[800]\ttrain-logloss:0.64853\tval-logloss:0.661438\n",
      "[1000]\ttrain-logloss:0.638222\tval-logloss:0.654305\n",
      "[1200]\ttrain-logloss:0.628205\tval-logloss:0.647453\n",
      "[1400]\ttrain-logloss:0.618467\tval-logloss:0.640919\n",
      "[1600]\ttrain-logloss:0.608972\tval-logloss:0.634607\n",
      "[1800]\ttrain-logloss:0.599736\tval-logloss:0.628431\n",
      "[2000]\ttrain-logloss:0.590748\tval-logloss:0.622429\n",
      "[2200]\ttrain-logloss:0.582009\tval-logloss:0.616644\n",
      "[2400]\ttrain-logloss:0.573476\tval-logloss:0.611031\n",
      "[2600]\ttrain-logloss:0.565174\tval-logloss:0.605601\n",
      "[2800]\ttrain-logloss:0.557064\tval-logloss:0.600469\n",
      "[3000]\ttrain-logloss:0.549129\tval-logloss:0.595598\n",
      "[3200]\ttrain-logloss:0.541393\tval-logloss:0.590898\n",
      "[3400]\ttrain-logloss:0.533819\tval-logloss:0.586411\n",
      "[3600]\ttrain-logloss:0.52644\tval-logloss:0.581964\n",
      "[3800]\ttrain-logloss:0.519231\tval-logloss:0.577738\n",
      "[4000]\ttrain-logloss:0.512226\tval-logloss:0.57364\n",
      "[4200]\ttrain-logloss:0.505362\tval-logloss:0.569654\n",
      "[4400]\ttrain-logloss:0.498652\tval-logloss:0.565896\n",
      "[4600]\ttrain-logloss:0.492106\tval-logloss:0.562178\n",
      "[4800]\ttrain-logloss:0.485698\tval-logloss:0.558579\n",
      "[5000]\ttrain-logloss:0.479413\tval-logloss:0.555094\n",
      "[5200]\ttrain-logloss:0.47326\tval-logloss:0.551724\n",
      "[5400]\ttrain-logloss:0.467272\tval-logloss:0.548544\n",
      "[5600]\ttrain-logloss:0.46142\tval-logloss:0.545467\n",
      "[5800]\ttrain-logloss:0.455685\tval-logloss:0.542569\n",
      "[6000]\ttrain-logloss:0.450069\tval-logloss:0.53967\n",
      "[6200]\ttrain-logloss:0.444578\tval-logloss:0.536892\n",
      "[6400]\ttrain-logloss:0.439176\tval-logloss:0.534263\n",
      "[6600]\ttrain-logloss:0.433887\tval-logloss:0.531671\n",
      "[6800]\ttrain-logloss:0.428697\tval-logloss:0.529094\n",
      "[7000]\ttrain-logloss:0.423642\tval-logloss:0.526686\n",
      "[7200]\ttrain-logloss:0.418672\tval-logloss:0.524228\n",
      "[7400]\ttrain-logloss:0.413794\tval-logloss:0.521877\n",
      "[7600]\ttrain-logloss:0.408991\tval-logloss:0.519606\n",
      "[7800]\ttrain-logloss:0.404294\tval-logloss:0.517386\n",
      "[8000]\ttrain-logloss:0.39968\tval-logloss:0.515319\n",
      "[8200]\ttrain-logloss:0.395159\tval-logloss:0.513252\n",
      "[8400]\ttrain-logloss:0.390727\tval-logloss:0.511195\n",
      "[8600]\ttrain-logloss:0.386356\tval-logloss:0.509263\n",
      "[8800]\ttrain-logloss:0.382077\tval-logloss:0.50734\n",
      "[9000]\ttrain-logloss:0.377867\tval-logloss:0.505555\n",
      "[9200]\ttrain-logloss:0.37373\tval-logloss:0.503706\n",
      "[9400]\ttrain-logloss:0.369658\tval-logloss:0.501906\n",
      "[9600]\ttrain-logloss:0.365666\tval-logloss:0.500149\n",
      "[9800]\ttrain-logloss:0.361753\tval-logloss:0.498494\n",
      "[9999]\ttrain-logloss:0.357923\tval-logloss:0.496856\n",
      "Fold: 17\n",
      "[0]\ttrain-logloss:0.693086\tval-logloss:0.693114\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681403\tval-logloss:0.685864\n",
      "[400]\ttrain-logloss:0.67006\tval-logloss:0.678804\n",
      "[600]\ttrain-logloss:0.659075\tval-logloss:0.67205\n",
      "[800]\ttrain-logloss:0.648425\tval-logloss:0.665604\n",
      "[1000]\ttrain-logloss:0.638083\tval-logloss:0.659282\n",
      "[1200]\ttrain-logloss:0.628061\tval-logloss:0.653248\n",
      "[1400]\ttrain-logloss:0.618327\tval-logloss:0.647379\n",
      "[1600]\ttrain-logloss:0.608815\tval-logloss:0.64155\n",
      "[1800]\ttrain-logloss:0.599576\tval-logloss:0.636041\n",
      "[2000]\ttrain-logloss:0.59059\tval-logloss:0.630764\n",
      "[2200]\ttrain-logloss:0.581827\tval-logloss:0.62558\n",
      "[2400]\ttrain-logloss:0.573307\tval-logloss:0.620607\n",
      "[2600]\ttrain-logloss:0.564997\tval-logloss:0.615779\n",
      "[2800]\ttrain-logloss:0.556884\tval-logloss:0.611237\n",
      "[3000]\ttrain-logloss:0.548987\tval-logloss:0.606729\n",
      "[3200]\ttrain-logloss:0.54128\tval-logloss:0.602399\n",
      "[3400]\ttrain-logloss:0.533734\tval-logloss:0.598118\n",
      "[3600]\ttrain-logloss:0.52639\tval-logloss:0.594029\n",
      "[3800]\ttrain-logloss:0.519221\tval-logloss:0.590068\n",
      "[4000]\ttrain-logloss:0.512217\tval-logloss:0.586256\n",
      "[4200]\ttrain-logloss:0.50533\tval-logloss:0.582509\n",
      "[4400]\ttrain-logloss:0.498606\tval-logloss:0.578912\n",
      "[4600]\ttrain-logloss:0.492057\tval-logloss:0.575559\n",
      "[4800]\ttrain-logloss:0.48564\tval-logloss:0.572193\n",
      "[5000]\ttrain-logloss:0.479357\tval-logloss:0.568966\n",
      "[5200]\ttrain-logloss:0.473202\tval-logloss:0.56601\n",
      "[5400]\ttrain-logloss:0.467181\tval-logloss:0.563256\n",
      "[5600]\ttrain-logloss:0.461294\tval-logloss:0.560342\n",
      "[5800]\ttrain-logloss:0.455517\tval-logloss:0.557514\n",
      "[6000]\ttrain-logloss:0.449863\tval-logloss:0.554793\n",
      "[6200]\ttrain-logloss:0.444326\tval-logloss:0.552124\n",
      "[6400]\ttrain-logloss:0.438899\tval-logloss:0.549514\n",
      "[6600]\ttrain-logloss:0.433594\tval-logloss:0.546965\n",
      "[6800]\ttrain-logloss:0.428398\tval-logloss:0.544525\n",
      "[7000]\ttrain-logloss:0.423301\tval-logloss:0.542166\n",
      "[7200]\ttrain-logloss:0.418314\tval-logloss:0.539848\n",
      "[7400]\ttrain-logloss:0.413432\tval-logloss:0.537643\n",
      "[7600]\ttrain-logloss:0.408635\tval-logloss:0.535604\n",
      "[7800]\ttrain-logloss:0.403936\tval-logloss:0.533576\n",
      "[8000]\ttrain-logloss:0.399236\tval-logloss:0.531337\n",
      "[8200]\ttrain-logloss:0.394604\tval-logloss:0.529132\n",
      "[8400]\ttrain-logloss:0.390062\tval-logloss:0.527112\n",
      "[8600]\ttrain-logloss:0.385607\tval-logloss:0.525188\n",
      "[8800]\ttrain-logloss:0.381234\tval-logloss:0.5233\n",
      "[9000]\ttrain-logloss:0.376942\tval-logloss:0.521437\n",
      "[9200]\ttrain-logloss:0.372734\tval-logloss:0.519696\n",
      "[9400]\ttrain-logloss:0.368591\tval-logloss:0.518036\n",
      "[9600]\ttrain-logloss:0.364536\tval-logloss:0.516363\n",
      "[9800]\ttrain-logloss:0.360559\tval-logloss:0.51469\n",
      "[9999]\ttrain-logloss:0.356681\tval-logloss:0.513114\n",
      "Fold: 18\n",
      "[0]\ttrain-logloss:0.693087\tval-logloss:0.693109\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681483\tval-logloss:0.685281\n",
      "[400]\ttrain-logloss:0.670175\tval-logloss:0.677704\n",
      "[600]\ttrain-logloss:0.65921\tval-logloss:0.670437\n",
      "[800]\ttrain-logloss:0.648587\tval-logloss:0.663419\n",
      "[1000]\ttrain-logloss:0.638277\tval-logloss:0.656626\n",
      "[1200]\ttrain-logloss:0.628292\tval-logloss:0.650252\n",
      "[1400]\ttrain-logloss:0.618607\tval-logloss:0.644243\n",
      "[1600]\ttrain-logloss:0.609167\tval-logloss:0.638335\n",
      "[1800]\ttrain-logloss:0.599986\tval-logloss:0.632681\n",
      "[2000]\ttrain-logloss:0.591052\tval-logloss:0.627173\n",
      "[2200]\ttrain-logloss:0.58233\tval-logloss:0.62191\n",
      "[2400]\ttrain-logloss:0.573849\tval-logloss:0.616867\n",
      "[2600]\ttrain-logloss:0.565579\tval-logloss:0.611938\n",
      "[2800]\ttrain-logloss:0.557526\tval-logloss:0.607168\n",
      "[3000]\ttrain-logloss:0.549672\tval-logloss:0.602566\n",
      "[3200]\ttrain-logloss:0.542021\tval-logloss:0.598076\n",
      "[3400]\ttrain-logloss:0.534557\tval-logloss:0.593746\n",
      "[3600]\ttrain-logloss:0.527264\tval-logloss:0.589407\n",
      "[3800]\ttrain-logloss:0.520154\tval-logloss:0.585165\n",
      "[4000]\ttrain-logloss:0.513208\tval-logloss:0.581006\n",
      "[4200]\ttrain-logloss:0.506405\tval-logloss:0.57705\n",
      "[4400]\ttrain-logloss:0.499736\tval-logloss:0.573222\n",
      "[4600]\ttrain-logloss:0.493228\tval-logloss:0.569587\n",
      "[4800]\ttrain-logloss:0.48686\tval-logloss:0.566044\n",
      "[5000]\ttrain-logloss:0.480627\tval-logloss:0.562545\n",
      "[5200]\ttrain-logloss:0.474529\tval-logloss:0.559101\n",
      "[5400]\ttrain-logloss:0.468568\tval-logloss:0.555685\n",
      "[5600]\ttrain-logloss:0.462729\tval-logloss:0.552461\n",
      "[5800]\ttrain-logloss:0.457003\tval-logloss:0.549372\n",
      "[6000]\ttrain-logloss:0.451409\tval-logloss:0.546329\n",
      "[6200]\ttrain-logloss:0.445923\tval-logloss:0.543345\n",
      "[6400]\ttrain-logloss:0.440541\tval-logloss:0.54044\n",
      "[6600]\ttrain-logloss:0.435287\tval-logloss:0.53761\n",
      "[6800]\ttrain-logloss:0.430133\tval-logloss:0.534901\n",
      "[7000]\ttrain-logloss:0.425068\tval-logloss:0.532338\n",
      "[7200]\ttrain-logloss:0.420103\tval-logloss:0.529818\n",
      "[7400]\ttrain-logloss:0.415227\tval-logloss:0.527466\n",
      "[7600]\ttrain-logloss:0.410454\tval-logloss:0.525107\n",
      "[7800]\ttrain-logloss:0.40578\tval-logloss:0.522823\n",
      "[8000]\ttrain-logloss:0.401188\tval-logloss:0.520621\n",
      "[8200]\ttrain-logloss:0.396684\tval-logloss:0.518454\n",
      "[8400]\ttrain-logloss:0.392251\tval-logloss:0.516391\n",
      "[8600]\ttrain-logloss:0.387886\tval-logloss:0.514301\n",
      "[8800]\ttrain-logloss:0.383611\tval-logloss:0.512327\n",
      "[9000]\ttrain-logloss:0.379428\tval-logloss:0.510402\n",
      "[9200]\ttrain-logloss:0.375305\tval-logloss:0.508578\n",
      "[9400]\ttrain-logloss:0.371232\tval-logloss:0.506698\n",
      "[9600]\ttrain-logloss:0.367239\tval-logloss:0.504895\n",
      "[9800]\ttrain-logloss:0.363308\tval-logloss:0.503074\n",
      "[9999]\ttrain-logloss:0.359482\tval-logloss:0.501341\n",
      "Fold: 19\n",
      "[0]\ttrain-logloss:0.693087\tval-logloss:0.693111\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681374\tval-logloss:0.685448\n",
      "[400]\ttrain-logloss:0.669969\tval-logloss:0.678211\n",
      "[600]\ttrain-logloss:0.658905\tval-logloss:0.671289\n",
      "[800]\ttrain-logloss:0.648195\tval-logloss:0.66468\n",
      "[1000]\ttrain-logloss:0.6378\tval-logloss:0.658276\n",
      "[1200]\ttrain-logloss:0.627722\tval-logloss:0.652217\n",
      "[1400]\ttrain-logloss:0.617934\tval-logloss:0.64631\n",
      "[1600]\ttrain-logloss:0.608394\tval-logloss:0.640655\n",
      "[1800]\ttrain-logloss:0.599108\tval-logloss:0.635223\n",
      "[2000]\ttrain-logloss:0.590063\tval-logloss:0.629865\n",
      "[2200]\ttrain-logloss:0.58125\tval-logloss:0.624756\n",
      "[2400]\ttrain-logloss:0.572675\tval-logloss:0.61989\n",
      "[2600]\ttrain-logloss:0.56433\tval-logloss:0.61518\n",
      "[2800]\ttrain-logloss:0.556188\tval-logloss:0.610648\n",
      "[3000]\ttrain-logloss:0.548246\tval-logloss:0.606282\n",
      "[3200]\ttrain-logloss:0.540492\tval-logloss:0.602142\n",
      "[3400]\ttrain-logloss:0.532948\tval-logloss:0.598004\n",
      "[3600]\ttrain-logloss:0.525579\tval-logloss:0.59409\n",
      "[3800]\ttrain-logloss:0.518381\tval-logloss:0.590346\n",
      "[4000]\ttrain-logloss:0.511349\tval-logloss:0.586848\n",
      "[4200]\ttrain-logloss:0.504476\tval-logloss:0.583424\n",
      "[4400]\ttrain-logloss:0.497757\tval-logloss:0.580082\n",
      "[4600]\ttrain-logloss:0.491206\tval-logloss:0.576875\n",
      "[4800]\ttrain-logloss:0.484802\tval-logloss:0.573891\n",
      "[5000]\ttrain-logloss:0.478544\tval-logloss:0.571052\n",
      "[5200]\ttrain-logloss:0.472412\tval-logloss:0.568355\n",
      "[5400]\ttrain-logloss:0.466401\tval-logloss:0.565759\n",
      "[5600]\ttrain-logloss:0.460534\tval-logloss:0.563287\n",
      "[5800]\ttrain-logloss:0.454772\tval-logloss:0.56091\n",
      "[6000]\ttrain-logloss:0.44914\tval-logloss:0.558559\n",
      "[6200]\ttrain-logloss:0.443616\tval-logloss:0.556229\n",
      "[6400]\ttrain-logloss:0.438195\tval-logloss:0.554049\n",
      "[6600]\ttrain-logloss:0.432903\tval-logloss:0.55197\n",
      "[6800]\ttrain-logloss:0.427721\tval-logloss:0.550016\n",
      "[7000]\ttrain-logloss:0.422645\tval-logloss:0.548126\n",
      "[7200]\ttrain-logloss:0.417677\tval-logloss:0.546318\n",
      "[7400]\ttrain-logloss:0.412804\tval-logloss:0.544581\n",
      "[7600]\ttrain-logloss:0.408024\tval-logloss:0.542917\n",
      "[7800]\ttrain-logloss:0.403327\tval-logloss:0.541242\n",
      "[8000]\ttrain-logloss:0.398721\tval-logloss:0.53972\n",
      "[8200]\ttrain-logloss:0.394205\tval-logloss:0.538292\n",
      "[8400]\ttrain-logloss:0.389771\tval-logloss:0.536886\n",
      "[8600]\ttrain-logloss:0.385427\tval-logloss:0.535595\n",
      "[8800]\ttrain-logloss:0.381158\tval-logloss:0.534132\n",
      "[9000]\ttrain-logloss:0.376952\tval-logloss:0.53282\n",
      "[9200]\ttrain-logloss:0.372816\tval-logloss:0.531549\n",
      "[9400]\ttrain-logloss:0.368762\tval-logloss:0.530271\n",
      "[9600]\ttrain-logloss:0.364772\tval-logloss:0.529046\n",
      "[9800]\ttrain-logloss:0.360852\tval-logloss:0.527841\n",
      "[9999]\ttrain-logloss:0.357015\tval-logloss:0.526634\n",
      "Fold: 20\n",
      "[0]\ttrain-logloss:0.693087\tval-logloss:0.693107\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.681373\tval-logloss:0.685441\n",
      "[400]\ttrain-logloss:0.670012\tval-logloss:0.677919\n",
      "[600]\ttrain-logloss:0.658998\tval-logloss:0.670801\n",
      "[800]\ttrain-logloss:0.648322\tval-logloss:0.664014\n",
      "[1000]\ttrain-logloss:0.637957\tval-logloss:0.65754\n",
      "[1200]\ttrain-logloss:0.627927\tval-logloss:0.651268\n",
      "[1400]\ttrain-logloss:0.618206\tval-logloss:0.645188\n",
      "[1600]\ttrain-logloss:0.608706\tval-logloss:0.639151\n",
      "[1800]\ttrain-logloss:0.599469\tval-logloss:0.633393\n",
      "[2000]\ttrain-logloss:0.590485\tval-logloss:0.627941\n",
      "[2200]\ttrain-logloss:0.581724\tval-logloss:0.622684\n",
      "[2400]\ttrain-logloss:0.573191\tval-logloss:0.617588\n",
      "[2600]\ttrain-logloss:0.564855\tval-logloss:0.612779\n",
      "[2800]\ttrain-logloss:0.556712\tval-logloss:0.608082\n",
      "[3000]\ttrain-logloss:0.548773\tval-logloss:0.603617\n",
      "[3200]\ttrain-logloss:0.541044\tval-logloss:0.599335\n",
      "[3400]\ttrain-logloss:0.533497\tval-logloss:0.595116\n",
      "[3600]\ttrain-logloss:0.526149\tval-logloss:0.591145\n",
      "[3800]\ttrain-logloss:0.518961\tval-logloss:0.587377\n",
      "[4000]\ttrain-logloss:0.511943\tval-logloss:0.58366\n",
      "[4200]\ttrain-logloss:0.505065\tval-logloss:0.579966\n",
      "[4400]\ttrain-logloss:0.498327\tval-logloss:0.576288\n",
      "[4600]\ttrain-logloss:0.491746\tval-logloss:0.572919\n",
      "[4800]\ttrain-logloss:0.485326\tval-logloss:0.56952\n",
      "[5000]\ttrain-logloss:0.479042\tval-logloss:0.566189\n",
      "[5200]\ttrain-logloss:0.472879\tval-logloss:0.562998\n",
      "[5400]\ttrain-logloss:0.466868\tval-logloss:0.559871\n",
      "[5600]\ttrain-logloss:0.460988\tval-logloss:0.556792\n",
      "[5800]\ttrain-logloss:0.455219\tval-logloss:0.55374\n",
      "[6000]\ttrain-logloss:0.449533\tval-logloss:0.55084\n",
      "[6200]\ttrain-logloss:0.443974\tval-logloss:0.54796\n",
      "[6400]\ttrain-logloss:0.438519\tval-logloss:0.545103\n",
      "[6600]\ttrain-logloss:0.433191\tval-logloss:0.542409\n",
      "[6800]\ttrain-logloss:0.427966\tval-logloss:0.539932\n",
      "[7000]\ttrain-logloss:0.42286\tval-logloss:0.537333\n",
      "[7200]\ttrain-logloss:0.41785\tval-logloss:0.53497\n",
      "[7400]\ttrain-logloss:0.412932\tval-logloss:0.532775\n",
      "[7600]\ttrain-logloss:0.408118\tval-logloss:0.530499\n",
      "[7800]\ttrain-logloss:0.403403\tval-logloss:0.528301\n",
      "[8000]\ttrain-logloss:0.398787\tval-logloss:0.526261\n",
      "[8200]\ttrain-logloss:0.394255\tval-logloss:0.52433\n",
      "[8400]\ttrain-logloss:0.389802\tval-logloss:0.522411\n",
      "[8600]\ttrain-logloss:0.385434\tval-logloss:0.520591\n",
      "[8800]\ttrain-logloss:0.381142\tval-logloss:0.518677\n",
      "[9000]\ttrain-logloss:0.376926\tval-logloss:0.516736\n",
      "[9200]\ttrain-logloss:0.372784\tval-logloss:0.5149\n",
      "[9400]\ttrain-logloss:0.368716\tval-logloss:0.513207\n",
      "[9600]\ttrain-logloss:0.364709\tval-logloss:0.511472\n",
      "[9800]\ttrain-logloss:0.360779\tval-logloss:0.509734\n",
      "[9999]\ttrain-logloss:0.356949\tval-logloss:0.508063\n"
     ]
    }
   ],
   "source": [
    "NFOLDS = 20\n",
    "folds = KFold(n_splits=NFOLDS)\n",
    "\n",
    "columns = X.columns\n",
    "splits = folds.split(X, y)\n",
    "y_xgb_preds = np.zeros(testdf.shape[0])\n",
    "y_oof = np.zeros(X.shape[0])\n",
    "\n",
    "  \n",
    "for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "    print('Fold:',fold_n+1)\n",
    "    X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    train_set = xgb.DMatrix(X_train, y_train)\n",
    "    val_set = xgb.DMatrix(X_valid, y_valid)\n",
    "    test_set = xgb.DMatrix(testdf)\n",
    "\n",
    "    clf = xgb.train(params_xgb, train_set, num_boost_round=10000, evals=[(train_set, 'train'), (val_set, 'val')], early_stopping_rounds=100, verbose_eval=200)\n",
    "    \n",
    "    y_xgb_preds += clf.predict(test_set) / NFOLDS\n",
    "    \n",
    "    del X_train, X_valid, y_train, y_valid\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10080\n"
     ]
    }
   ],
   "source": [
    "print(len(y_xgb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4662427 , 0.47839195, 0.19164555, ..., 0.26011047, 0.52683154,\n",
       "       0.68783275])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_xgb_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>0.337843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>0.392903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>0.040393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>0.302683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>0.179953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID      Pred\n",
       "0  2015_3106_3107  0.337843\n",
       "1  2015_3106_3110  0.392903\n",
       "2  2015_3106_3113  0.040393\n",
       "3  2015_3106_3114  0.302683\n",
       "4  2015_3106_3116  0.179953"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o = pd.read_csv(os.path.join(path, 'NCAAW_h2o.csv'))\n",
    "h2o.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\bokhy\\\\Desktop\\\\kaggle\\\\google-cloud-ncaa-march-madness-2020-division-1-womens-tournament\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_3106_3107</td>\n",
       "      <td>0.230428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_3106_3110</td>\n",
       "      <td>0.374999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_3106_3113</td>\n",
       "      <td>0.023223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_3106_3114</td>\n",
       "      <td>0.198371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_3106_3116</td>\n",
       "      <td>0.058016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10075</th>\n",
       "      <td>2019_3413_3417</td>\n",
       "      <td>0.030469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10076</th>\n",
       "      <td>2019_3413_3460</td>\n",
       "      <td>0.598030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10077</th>\n",
       "      <td>2019_3416_3417</td>\n",
       "      <td>0.037444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>2019_3416_3460</td>\n",
       "      <td>0.798851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10079</th>\n",
       "      <td>2019_3417_3460</td>\n",
       "      <td>0.964571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10080 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID      Pred\n",
       "0      2015_3106_3107  0.230428\n",
       "1      2015_3106_3110  0.374999\n",
       "2      2015_3106_3113  0.023223\n",
       "3      2015_3106_3114  0.198371\n",
       "4      2015_3106_3116  0.058016\n",
       "...               ...       ...\n",
       "10075  2019_3413_3417  0.030469\n",
       "10076  2019_3413_3460  0.598030\n",
       "10077  2019_3416_3417  0.037444\n",
       "10078  2019_3416_3460  0.798851\n",
       "10079  2019_3417_3460  0.964571\n",
       "\n",
       "[10080 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(os.path.join(path, 'WSampleSubmissionStage1_2020.csv'))\n",
    "submission['Pred'] = 0.85*lgbm.y_pred + 0.15*h2o['Pred'] \n",
    "#submission['Pred'] = lgbm.y_pred\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('NCAAW_Ensemble.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
